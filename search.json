[{"title":"Git 工作流","url":"http://shawnz.me/posts/6e627ce8/","content":"","categories":["程序员的自我修养"],"tags":["Git"]},{"title":"机器学习-线性代数篇","url":"http://shawnz.me/posts/178a40c8/","content":"<p>$f(x)=x_2$</p>\n<p>$$<br>\\frac{\\partial u}{\\partial t} = h^2 \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} + \\frac{\\partial^2 u}{\\partial z^2}\\right)<br>$$</p>\n","categories":["机器学习"],"tags":["机器学习"]},{"title":"学习计划","url":"http://shawnz.me/posts/5e21c553/","content":"<h2 id=\"时间安排模板\"><a href=\"#时间安排模板\" class=\"headerlink\" title=\"时间安排模板\"></a>时间安排模板</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">第N周</th>\n<th style=\"text-align:center\">周一</th>\n<th style=\"text-align:center\">周二</th>\n<th style=\"text-align:center\">周三</th>\n<th style=\"text-align:center\">周四</th>\n<th style=\"text-align:center\">周五</th>\n<th style=\"text-align:center\">周六</th>\n<th style=\"text-align:center\">周日</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">06:30~07:00</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">07:00~09:00</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">10:00~12:00</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">13:30~19:30</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">21:00~:24:00</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n</tbody>\n</table>\n<p><strong>2018-03-10总结与反思: </strong></p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 完成了哪些任务?</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 还有哪些人物没有完成?</li>\n</ul>\n<h2 id=\"任务概览\"><a href=\"#任务概览\" class=\"headerlink\" title=\"任务概览\"></a>任务概览</h2><ol>\n<li>英语</li>\n<li>Python开发</li>\n<li>程序员基本修养: 网络/数据库/算法/操作系统…</li>\n<li>系统设计/软件工程</li>\n<li>其他语言: Java/前端/Go</li>\n<li>机器学习/大数据处理</li>\n<li>开源项目</li>\n<li>业余爱好: 看书/健身</li>\n</ol>\n<h2 id=\"第二周\"><a href=\"#第二周\" class=\"headerlink\" title=\"第二周\"></a>第二周</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">第2周</th>\n<th>周一</th>\n<th>周二</th>\n<th>周三</th>\n<th>周四</th>\n<th>周五</th>\n<th>周六</th>\n<th>周日</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">06:30~07:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">07:00~09:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">10:00~12:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">13:30~19:30</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">21:00~:24:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n","categories":[],"tags":["计划"]},{"title":"理解 asyncio","url":"http://shawnz.me/posts/cc755aee/","content":"<p>在本篇文章, 我试图从三个方面: 协程, Python对协程的语法支持以及<code>asyncio</code>库, 来理解事件驱动的异步编程.</p>\n<a id=\"more\"></a>\n<h2 id=\"概念\"><a href=\"#概念\" class=\"headerlink\" title=\"概念\"></a>概念</h2><p>我们先给协程一个正式的定义: <strong>“协程是为非抢占式多任务产生子程序的计算机程序组件, 协程允许不同入口点在不同位置暂停或开始执行程序”</strong>(来自维基百科).</p>\n<h3 id=\"协程和线程\"><a href=\"#协程和线程\" class=\"headerlink\" title=\"协程和线程\"></a>协程和线程</h3><p>从协程的定义, 我们可以很好的区分协程和线程行为上的区别: 协程由应用程序提供机制提供, 属于”协作式多任务”; 而线程一般由操作系统提供, CPU负责调度, 属于”抢占式多任务”. </p>\n<p>尽管协程和线程都能用来”并发”编程, 但需要考虑到使用多线程会有以下几个问题:</p>\n<ul>\n<li>线程在计算和资源消耗的角度是较为昂贵的;</li>\n<li>在使用线程进行”并发”编程时, 需要考虑访问共享资源时, “竞态条件”和”锁机制”带来的复杂性和安全性问题;</li>\n<li>由于<code>GIL</code>的存在, Python的多线程无法发挥多核CPU的计算能力, 只有在遇到I/O阻塞的时, 才会释放<code>GIL</code>锁.</li>\n<li>既然Python的多线程更适用于”I/O”密集的场景, 那么在这种情形下, 使用协程替代线程应该能得到更好的性能.</li>\n</ul>\n<h3 id=\"事件循环\"><a href=\"#事件循环\" class=\"headerlink\" title=\"事件循环\"></a>事件循环</h3><p>在继续学习协程之前, 我们弄明白什么是事件循环?</p>\n<p>比如大部分的网络服务器框架, 诸如<code>werkzeug</code>,<code>Django</code>等实现的<code>HTTPServer</code>, 在底层都是使用I/O多路复用机制处理客户端连接的:</p>\n<pre><code class=\"python\">def loop():\n    while not QUIT:\n        events = selector.select(events_to_listen, timeout)\n        for event in events:\n            process_request(events)\n</code></pre>\n<p>这里的<code>loop</code>就相当于是一个事件循环, 它等待操作系统的事件通知, 并执行相应请求处理函数(回调函数).</p>\n<p>这里的<code>select</code>会阻塞直到请求的到来(或超时), 其实<code>select</code>底层的实现也是一个事件循环, 轮询监听的文件描述符<code>fd</code>, 在<code>fd</code>数据准备好时, 返回文件描述符, 不过我们先不关心这些. 尽管这里会发生阻塞, 但是其好处是在有大量并发连接的情况下, 使用IO多路复用不会造成: 阻塞在单个IO下, 而导致无法处理其他请求. 它会在有任何连接准备好的时候, 返回文件描述符.</p>\n<p>(PS: 不知道我这里理解的事件循环有没有问题…)</p>\n<p>事件循环: “是一种等待程序分配事件或消息的编程架构”(来自wiki). 简单来讲, 事件循环是一种循环机制, 监听哪些事件发生了, 并关心事件发生时做什么处理, 让你可以在”A发生时, 执行B”. </p>\n<p>然而, 要想设计健壮的WEB 服务框架, 单单这点还不够, 目前请求的处理都发生在单个线程中, 像<code>socket.recv()</code>、访问数据库以及读写文件等都会发生阻塞, 导致阻塞整个事件循环. 所以, 一般的WEB服务器还提供了多线程/多进程的选项, 能够以线程或进程的方式处理请求. 另外一种思路是, 将事件循环放在一个单独的子线程里, 事件的处理都放在主线程中.</p>\n<p>事件循环机制是理解异步编程的核心之一, 另一个核心就是协程.</p>\n<h3 id=\"协程和回调\"><a href=\"#协程和回调\" class=\"headerlink\" title=\"协程和回调\"></a>协程和回调</h3><p>回到事件驱动的主题上来, 当事件发生时, 事件循环机制需要找到相应的处理函数, 尽管WEB框架的处理函数一般就一个, 然后再做分派. 但是更一般的, 像<code>JS</code>中的事件就很多, 比如<code>OnClick</code>事件, 往往需要将回调函数绑定到相应的事件上, 这样才能在事件发生时执行对应的回调函数. 这就是异步机制.</p>\n<p>当回调发生时, 我们可能会碰到下面这种情况:</p>\n<pre><code class=\"python\">def stage_1(response_1):  # 回调函数1\n    request_2 = step_1(reponse_1) # 对响应处理, 并生成新的请求2\n\n    def stage_2(response_2):\n        request_3 = step_2(reponse_2)\n\n        def stage_3(response_3):\n            step_3(reponse_3)\n\n        api_call_3(request_3, stage_3) # 调用新的API函数3, 注册回调函数3\n    api_call_2(request_2, stage_2)  # 调用新的API函数2, 注册回调函数2\n\napi_call_1(request_1, stage_1)  # 调用API函数1, 注册回调函数1\n</code></pre>\n<ul>\n<li>代码结构不清晰: 同步的代码结构是从上往下, 而嵌套回调的结构会导致<code>callback hell</code>.</li>\n<li>上下文状态丢失: 执行下一个回调的时候, 无法获取上一步的<code>request_1</code>的信息. 如果需要那个值, 必须通过参数传递, 或者闭包实现.</li>\n<li>异常处理: 当<code>api_call_2</code>发生异常时, 无法在<code>stage_1</code>函数中捕获, 因为是<code>api_call_2</code>异步调用. <code>JS</code>针对这个问题的解决方案是, 注册两个回调函数, 其中有一个用作异常处理, 这样以来就变得更加复杂了.</li>\n</ul>\n<p>同样的代码逻辑, 我们可以用另外一种方式来重构:</p>\n<pre><code class=\"python\">@asyncio.coroutine\ndef three_stages(request_1):\n    response_1 = yield from api_call_1(request_1) # 第一步\n\n    request_2 = step(response_1) # 第二步\n    reponse_2 = yield from api_call_2(request_2)\n\n    reqeust_3 = step(response_2) # 第三步\n    response_3 = yield from api_call_3(request_3)\n\nloop.create_task(three_stages(request_1)) # 必须显示调用\n</code></pre>\n<p>使用协程不会存在上面那些问题, 因为整个任务执行是顺序的, 并且在一个上下文中, 如果需要捕捉异常的话, 可以使用<code>try/catch</code>将<code>yield from</code>语句包裹起来.</p>\n<h2 id=\"Python语法\"><a href=\"#Python语法\" class=\"headerlink\" title=\"Python语法\"></a>Python语法</h2><h3 id=\"yield和yield-from\"><a href=\"#yield和yield-from\" class=\"headerlink\" title=\"yield和yield from\"></a>yield和yield from</h3><p>PEP 342 中定义了协程的底层架构, 并在Python2.5中实现了. 至此<code>yield</code>成为表达式, 能够暂停执行产生值.</p>\n<p>PEP 342 中为生成器API添加了<code>send()</code>方法, 可以将数据给暂停的的生成器, 发送的值成为<code>yield</code>表达式的值. 这样以来, 生成器就可以作为协程使用了.</p>\n<p>PEP 380 为Python3.3引入了<code>yield from</code>语法, 以便生成器能够更好地作为协程使用. 在生成器<code>gen</code>中调用<code>yield from subgen()</code>时, <code>subgen</code>会获得控制权, 把产生的值返回给调用方, 即调用方可以直接控制<code>subgen</code>. 与此同时, <code>gen</code>会挂起, 等待<code>subgen</code>返回值(终止). <code>yield from</code>可以把复杂的生成器重构为小型的嵌套生成器. 例如:</p>\n<pre><code class=\"python\">def subgen():\n    while True:\n        x = yield &#39;subgen&#39;\n\ndef gen():\n    yield from &#39;AB&#39;\n    yield from range(1, 3)\n    yield from subgen()\n</code></pre>\n<p><code>yield from x</code>表达式对<code>x</code>所做的第一件事就是, 调用<code>iter(x)</code>, 从中获得迭代器. </p>\n<p>到现在为止, <code>yield</code>和<code>yield from</code>定义的生成器完全可以作为协程的实现. 仔细一点话, 我们可以发现两者的细微区别:</p>\n<ul>\n<li>生成器更注重保存状态和产生值;</li>\n<li>协程强调协同控制程序流, 是数据的消费者. (尽管使用生成器定义的协程也会<code>yield</code>产生值)</li>\n</ul>\n<h3 id=\"async和await\"><a href=\"#async和await\" class=\"headerlink\" title=\"async和await\"></a>async和await</h3><p>现在有个问题是, 在调用<code>yield from gen_or_cor()</code>时, 我们无法确定遍历的是生成器还是协程. </p>\n<p><code>asyncio.coroutine</code>和<code>types.coroutine</code>两个装饰器的作用就是: 为消除语法上的歧义. 前者是<code>asyncio</code>库的实现, 后者是Python3.5新加入的语言实现, 它会给函数的<code>__code__.co_flags</code>添加<code>CO_ITERABLE_COROUTINE</code>标识. </p>\n<p>随后Yury Selivanov提交的 “PEP 492—Coroutines with async and await syntax”, 在 Python3.5 中得以实现, 新加了两个关键字<code>async</code>和<code>await</code>. 使用<code>async def</code>定义的函数称为”原生协程”, 它会设置<code>CO_COROUTINE</code>标识. </p>\n<p>到现在为止, 协程和生成器很明确的区分开来了, 另外还有两个标识:</p>\n<ul>\n<li><code>CO_COROUTINE</code>: 标识的是原生协程, 使用<code>async def</code>定义;</li>\n<li><code>CO_ITERABLE_COROUTINE</code>: 基于迭代器的协程, 使用<code>types.coroutine</code>装饰.</li>\n</ul>\n<p>在定义了协程之后, PEP 492 引入了<code>await</code>来调用协程, 它只能在<code>async def</code>协程函数内部使用:</p>\n<pre><code class=\"python\">async def read_data(db):\n    data = await db.fetch(&#39;SELECT ...&#39;)\n    ...\n</code></pre>\n<p><code>await</code>的用法和<code>yield from</code>相似, 暂停<code>read_data</code>协程的执行, 直到<code>db.fetch</code>完成并返回结果数据.</p>\n<p>实际上, <code>await</code>内部使用<code>yield from</code>实现, 不过它对参数进行了一些额外的验证, 接受一个<code>awaitable</code>对象:</p>\n<ul>\n<li>原生协程. <code>collections.abc.Coroutine</code>继承自<code>Awaitable</code>, 自然没有问题;</li>\n<li>基于迭代器的协程, 因为<code>inspect.isawaitable</code>内部会识别<code>CO_ITERABLE_COROUTINE</code>标识.</li>\n<li>实现了<code>__await__</code>方法(必须返回一个迭代器)的对象, 即<code>collections.abc.Awaitable</code>.</li>\n</ul>\n<p>我们再来看看这个讨论<a href=\"\">《为什么只有基于生成器的协程可以真正的暂停执行并强制性返回给事件循环？》</a>.</p>\n<p>我的理解是真正暂停执行并让步, 将控制权交给事件循环的地方一定发生在<code>yield</code>处. 而<code>await/yield from</code>都没有交出控制权, 它们会进入到里层的协程, 直到碰到一个<code>yield</code>, 又或者是一个实现<code>__await__</code>方法的<code>awaitable</code>, 这个方法返回的也是一个迭代器.<br>而原生协程的语法是不允许使用<code>yield</code>的, 所以就会有上面那种说法.</p>\n<p>不过在实际使用中, 我们使用<code>await asyncio.sleep(1)</code>这些包装过的协程函数就OK了, 框架会帮我们处理底层的逻辑.</p>\n<hr>\n\n<p>除了协程函数外, PEP 492 还提出了<code>async for</code>和<code>async with</code>的用法:</p>\n<p><strong>异步上下文管理器和”async with”</strong></p>\n<p>异步上下文管理器指的是在<code>enter</code>和<code>exit</code>方法处能够暂停执行的上下文管理器.</p>\n<p>为了实现这样的功能, 需要加入两个新的<code>magic method</code>: <code>__aenter__</code>和<code>__aexit__</code>. 这两个方法都要返回一个<code>awaitable</code>对象.</p>\n<pre><code class=\"python\">class AsyncContextManager: # 定义一个上下文管理器\n    async def __aenter__(self):\n        await log(&quot;entering context...&quot;)\n\n    async def __aexit__(self, exc_type, exc, tb):\n        await log(&quot;exiting context...&quot;)\n\nasync def commit(session, data):  # 实现一个数据库事务管理器\n    async with session.transaction():\n        await session.update(data)\n</code></pre>\n<p>和常规的<code>with</code>表达式一样, 可以在一个<code>async with</code>表达式中指定多个上下文管理器.</p>\n<p>如果向<code>async with</code>表达式传入的上下文管理器中没有<code>__aenter__</code>和<code>__aexit__</code>方法, 这将引起一个错误. 如果在<code>async def</code>函数外面使用<code>async with</code>，将引起一个<code>SyntaxError</code>.</p>\n<p><strong>异步迭代器和”async for”</strong></p>\n<p>一个异步可迭代对象(<code>asynchronous iterable</code>)能够在迭代过程中调用异步代码, 而异步迭代器就是能够在<code>next</code>方法中调用异步代码. 为了支持异步迭代:</p>\n<ol>\n<li>一个对象必须实现<code>__aiter__</code>方法, 该方法返回一个异步迭代器(<code>asynchronous iterator</code>)对象; </li>\n<li>一个异步迭代器对象必须实现<code>__anext__</code>方法，该方法返回一个<code>awaitable</code>对象;</li>\n<li>为了停止迭代, <code>__anext__</code>必须抛出一个<code>StopAsyncIteration</code>异常.</li>\n</ol>\n<pre><code class=\"python\">class AsyncIterable:  ## 定义一个异步迭代器\n    def __aiter__(self):\n        return self\n\n    async def __anext__(self):\n        data = await self.fetch_data()\n        if data:\n            return data\n        else:\n            raise StopAsyncIteration\n\n    async def fetch_data(self):\n        ...\n\nasync def cor():  # 使用异步迭代器\n    async for data in AsyncInterable():\n        await process_data(data)\n</code></pre>\n<p>把一个没有<code>__aiter__</code>方法的迭代对象传递给<code>async for</code>将引起<code>TypeError</code>. </p>\n<p>和<code>async with</code>, <code>await</code>一样, 在<code>async def</code>函数外部使用<code>async for</code>将引起一个<code>SyntaxError</code>.</p>\n<p>和常规的<code>for</code>表达式一样, <code>async for</code>也有一个可选的<code>else</code>分支.</p>\n<p>和正常的生成器抛出<code>StopIteration</code>异常告知停止迭代一样, 异步迭代器抛出<code>StopAsyncIteration</code>告知外围代码迭代结束.</p>\n<p>另外在 “PEP 497–Change StopIteration handling inside generators” 中规定, 所有协程中抛出的<code>StopIteration</code>异常, 都被包装在<code>RuntimeError</code>中.</p>\n<hr>\n\n<p>在 PEP 525–Asynchronous Generators 中提出的异步生成器, 在Python3.6中实现了. 在这之前<code>async def</code>内部不允许出现<code>yield</code>表达式, 而在 Python3.6 中, 使用<code>yield</code>表达式可以定义一个异步生成器. 文档中提出: 经过测试, 异步生成器的性能是异步迭代器的2倍.</p>\n<p>文档中给出了一个”每次迭代延迟给定秒数并打印数字”的例子:</p>\n<pre><code class=\"python\">class Ticker:  # 异步迭代器版本\n    def __init__(self, delay, to):\n        self.delay = delay\n        self.i = 0\n        self.to = to\n\n    def __aiter__(self):\n        return self\n\n    async def __anext__(self):\n        i = self.i\n        if i &gt;= self.to:\n            raise StopAsyncIteration\n        self.i += 1\n        if i:\n            await asyncio.sleep(self.delay)\n        return i\n\nasync def ticker(delay, to): # 异步生成器版本\n    for i in range(to):\n        yield i\n        await asyncio.sleep(delay)\n</code></pre>\n<p>异步生成器也实现了<code>__aiter__</code>和<code>__anext__</code>方法. 在异步生成器里面使用<code>return</code>语句将引起<code>SyntaxError</code>.</p>\n<h2 id=\"出租车运营仿真\"><a href=\"#出租车运营仿真\" class=\"headerlink\" title=\"出租车运营仿真\"></a>出租车运营仿真</h2><p>到这里, 我们已经大致了解了异步编程的一些概念性问题和Python对协程的语法支持. 在真正接触<code>asyncio</code>库之前, 我们从一个出租车运营仿真程序(参考”流畅的Python”的离散仿真)开始, 想想怎么实现一个基于事件的异步编程框架.</p>\n<p>假设有几辆出租车, 每辆车会拉几个乘客, 然后回家. 出租车首先驶离车库, 四处徘徊, 寻找乘客; 拉到乘客后, 行程开始; 行程结束, 乘客下车, 继续四处徘徊…</p>\n<p>开始动手之前, 我们先想想, 都需要实现些什么?</p>\n<ol>\n<li>我们可以协程的方式模拟出租车的生命周期, 这一步应该不难, 利用<code>async/await</code>等可以实现阻塞调用时让步. </li>\n<li>有N辆出租车, 如果不用线程实现并发, 那么我们需要一个事件循环, 来驱动协程执行.</li>\n<li>实现一个<code>sleep</code>函数, 模拟出租车耗时的阻塞操作, 这个函数必须是一个<code>generator-based coroutine</code>, 因为需要<code>yield</code>让步.</li>\n</ol>\n<pre><code class=\"python\">import random\nimport asyncio\nimport time\nimport heapq\n\n\n@asyncio.coroutine\ndef sleep(seconds):\n    now = time.time()\n    wait_until = now + seconds\n    actual = yield wait_until  # 让步, 并产出下次唤醒的时间\n    return actual - now  # 返回实际等待了多长时间\n\n\nasync def taxi_coro(ident, trips, delay=0):\n    print(&quot;taxt {ident}: waiting {delay} seconds before leave garage...&quot;.\n          format(ident=ident, delay=delay))\n    detal = await sleep(delay)  # 每辆车延迟delay秒出发\n    print(&quot;taxi {ident} leave from garage after {detal}&quot;.\n          format(ident=ident, detal=int(detal)))\n    for i in range(trips):\n        print(&quot;taxi {ident} hover around... &quot;.format(ident=ident))\n        detal = await sleep(random.randint(0, 10))\n        print(&quot;taxi {ident} pick up passenger afer {detal}&quot;.format(ident=ident, detal=int(detal)))\n        detal = await sleep(random.randint(0, 10))\n        print(&quot;taxi {ident} drop off passenger afer {detal}&quot;.format(ident=ident, detal=int(detal)))\n\n    print(&quot;taxi {ident} going to home...&quot;.format(ident=ident))\n    detal = await sleep(random.randint(0, 10))\n    print(&quot;taxi {ident} has arrived at home afer {detal}!&quot;.format(ident=ident, detal=int(detal)))\n\n\nclass Task():\n\n    def __init__(self, wait_until, coro):\n        self.waiting_until = wait_until\n        self.coro = coro\n\n    def __eq__(self, other):\n        return self.waiting_until == other.waiting_until\n\n    def __lt__(self, other):\n        return self.waiting_until &lt; other.waiting_until\n\n\nclass EventLoop:\n\n    def __init__(self, *coros):\n        self._new = coros\n        self._waiting = []\n\n    def run_until_complete(self):\n\n        for coro in self._new:\n            wait_until = coro.send(None)  # 协程预激\n            heapq.heappush(self._waiting, Task(wait_until, coro))  # Task加入优先队列\n\n        while self._waiting:\n\n            now = time.time()\n\n            task = heapq.heappop(self._waiting)  # 获取最近需要执行的task\n\n            if now &lt; task.waiting_until:  # 还没到task的执行时间\n                detal = task.waiting_until - now  # 还需要等待时间\n                time.sleep(detal)  # 直接阻塞事件循环\n            try:\n                now = time.time()\n                wait_until = task.coro.send(now)\n                heapq.heappush(self._waiting, Task(wait_until, task.coro))\n            except StopIteration as e:\n                pass\n\n\ndef main():\n    loop = EventLoop(taxi_coro(&#39;A&#39;, 4), taxi_coro(&#39;B&#39;, 3, 3), taxi_coro(&#39;C&#39;, 2, 4))\n    now = time.time()\n    loop.run_until_complete()\n    print(&quot;Total elapsed time is {}&quot;.format(time.time - now))\n\n\nif __name__ == &#39;__main__&#39;:\n    main()\n</code></pre>\n<p>下面输出结果:</p>\n<pre><code class=\"bash\">taxt A: waiting 0 seconds before leave garage...\ntaxt B: waiting 3 seconds before leave garage...\ntaxt C: waiting 4 seconds before leave garage...\ntaxi A leave from garage after 0\ntaxi A hover around... \ntaxi B leave from garage after 3\ntaxi B hover around... \ntaxi C leave from garage after 4\ntaxi C hover around... \ntaxi C pick up passenger afer 2\ntaxi A pick up passenger afer 7\ntaxi A drop off passenger afer 1\ntaxi A hover around... \ntaxi B pick up passenger afer 7\ntaxi C drop off passenger afer 8\ntaxi C hover around... \ntaxi C pick up passenger afer 0\ntaxi A pick up passenger afer 7\ntaxi B drop off passenger afer 8\ntaxi B hover around... \ntaxi C drop off passenger afer 8\ntaxi C going to home...\ntaxi A drop off passenger afer 9\ntaxi A hover around... \ntaxi B pick up passenger afer 10\ntaxi A pick up passenger afer 5\ntaxi C has arrived at home, total elapsed 30!\ntaxi B drop off passenger afer 4\ntaxi B hover around... \ntaxi A drop off passenger afer 6\ntaxi A hover around... \ntaxi A pick up passenger afer 5\ntaxi A drop off passenger afer 1\ntaxi A going to home...\ntaxi B pick up passenger afer 10\ntaxi A has arrived at home, total elapsed 43!\ntaxi B drop off passenger afer 7\ntaxi B going to home...\ntaxi B has arrived at home, total elapsed 50!\nTotal elapsed time is 50  # 总耗时等于耗时最长的那辆的行程时间\n</code></pre>\n<p>从输出结果我们可以发现, 总的耗时时长和耗时最长的出租车的行驶时长相当. 在这个例子里面, 使用了<code>sleep</code>产出一个唤醒时间并作出让步, 来模拟异步的阻塞调用. 然而实际应用中这些阻塞调用, 往往涉及I/O, 网络等, 不可能产生一个唤醒时间给事件循环, 这是就需要引入一个概念”Future”(期物), 能够在任务完成时…</p>\n<h2 id=\"asyncio\"><a href=\"#asyncio\" class=\"headerlink\" title=\"asyncio\"></a>asyncio</h2><p><code>asyncio</code>是Python 3.4 引入的异步I/O框架(PEP 3156), 提供了使用协程编写单线程并发代码、通过sockets和其他方式进行多路I/O访问、运行网络客户端和服务端以及其他相关原语的基础设施. 正如文档中提出的, 提供的组件详细列表如下:</p>\n<ul>\n<li>一个包含各种特定系统实现的模块化事件循环(event loop);</li>\n<li>传输和协议抽象(类似于Twisted);</li>\n<li>对TCP、UDP、SSL、子进程管道(subprogress pipes)、延时调用以及其他的具体支持(有些可能是系统相关的);</li>\n<li>模仿concurrent.futures模块但适于事件循环(event loop)使用的Future类;</li>\n<li>基于yield from(PEP 380)的协程和任务，可以让你用顺序的方式编写并发代码;</li>\n<li>可以中止的Future和协程;</li>\n<li>模仿threading模块中的同步原语，可以用在单线程内的协程之间;</li>\n<li>当你不得不去使用一个将产生阻塞I/O的调用时，有接口可以把这个事件转移到线程池(threadpool).</li>\n</ul>\n<p>下面是官方文档中给出的一个例子:</p>\n<pre><code class=\"python\">import asyncio\n\nasync def compute(x, y):\n    print(&quot;Compute %s + %s ...&quot; % (x, y))\n    await asyncio.sleep(1.0)\n    return x + y\n\nasync def print_sum(x, y):\n    result = await compute(x, y)\n    print(&quot;%s + %s = %s&quot; % (x, y, result))\n\nloop = asyncio.get_event_loop()\nloop.run_until_complete(print_sum(1, 2))\nloop.close()\n</code></pre>\n<p>上面代码的执行流程如下:</p>\n<p><img src=\"/images/tulip_coro.png\" alt=\"\"></p>\n<p>执行过程概述如下:</p>\n<ul>\n<li>获取当前的事件循环</li>\n<li>加入</li>\n</ul>\n<p>未完待续…</p>\n<h3 id=\"Coroutine-Future-Task\"><a href=\"#Coroutine-Future-Task\" class=\"headerlink\" title=\"Coroutine, Future, Task\"></a>Coroutine, Future, Task</h3><h3 id=\"Event-Loop-Policy\"><a href=\"#Event-Loop-Policy\" class=\"headerlink\" title=\"Event Loop [Policy]\"></a>Event Loop [Policy]</h3><h3 id=\"Tansport-Protocol\"><a href=\"#Tansport-Protocol\" class=\"headerlink\" title=\"Tansport, Protocol\"></a>Tansport, Protocol</h3><h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-255/\" target=\"_blank\" rel=\"noopener\">PEP 255 – Simple Generators</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-342/\" target=\"_blank\" rel=\"noopener\">PEP 342 – Coroutines via Enhanced Generators</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-380/\" target=\"_blank\" rel=\"noopener\">PEP 380 – Syntax for Delegating to a Subgenerator</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-0492/\" target=\"_blank\" rel=\"noopener\">PEP 492 – Coroutines with async and await syntax</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-3156/\" target=\"_blank\" rel=\"noopener\">PEP 3156 – Asynchronous IO Support Rebooted: the “asyncio” Module</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.youtube.com/watch?v=1coLC-MUCJc\" target=\"_blank\" rel=\"noopener\">Tulip: Async I/O for Python 3</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://snarky.ca/how-the-heck-does-async-await-work-in-python-3-5/\" target=\"_blank\" rel=\"noopener\">How the heck does async/await work in Python 3.5?</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://www.aosabook.org/en/500L/a-web-crawler-with-asyncio-coroutines.html\" target=\"_blank\" rel=\"noopener\">A Web Crawler With asyncio Coroutines</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"https://www.kancloud.cn/kindjeff/asyncio-zh/217023\" target=\"_blank\" rel=\"noopener\">Python3 asyncio官方文档中文版</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://blog.dreamfever.me/the-magic-of-asyncio-1/\" target=\"_blank\" rel=\"noopener\">异步的魔法 — asyncio 源码剖析</a></p>\n","categories":["Python"],"tags":["Python","异步编程"]},{"title":"Vim 快捷键","url":"http://shawnz.me/posts/16764984/","content":"<!--  -->\n<a id=\"more\"></a>\n<p>记录常用的<code>Vim</code>命令…</p>\n<h2 id=\"光标移动-Cursor-Movement\"><a href=\"#光标移动-Cursor-Movement\" class=\"headerlink\" title=\"光标移动(Cursor Movement)\"></a>光标移动(Cursor Movement)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>h</code>,<code>j</code>,<code>k</code>,<code>l</code>,<code>h</code></td>\n<td>表示往左，j表示往下，k表示往右，l表示往上</td>\n</tr>\n<tr>\n<td><code>Ctrl</code>+<code>f</code></td>\n<td>上一页</td>\n</tr>\n<tr>\n<td><code>Ctrl</code>+<code>b</code></td>\n<td>下一页</td>\n</tr>\n<tr>\n<td><code>w</code>, <code>e</code>, <code>W</code>, <code>E</code></td>\n<td>跳到单词的后面，小写包括标点</td>\n</tr>\n<tr>\n<td><code>b</code>, <code>B</code></td>\n<td>以单词为单位往前跳动光标，小写包含标点</td>\n</tr>\n<tr>\n<td><code>O</code></td>\n<td>开启新的一行</td>\n</tr>\n<tr>\n<td><code>^</code></td>\n<td>一行的开始</td>\n</tr>\n<tr>\n<td><code>$</code></td>\n<td>一行的结尾</td>\n</tr>\n<tr>\n<td><code>gg</code></td>\n<td>文档的第一行</td>\n</tr>\n<tr>\n<td><code>[N]G</code></td>\n<td>文档的第N行或者最后一行</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"插入模式-Insert-Mode\"><a href=\"#插入模式-Insert-Mode\" class=\"headerlink\" title=\"插入模式(Insert Mode)\"></a>插入模式(Insert Mode)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>i</code></td>\n<td>插入到光标前面</td>\n</tr>\n<tr>\n<td><code>I</code></td>\n<td>插入到行的开始位置</td>\n</tr>\n<tr>\n<td><code>a</code></td>\n<td>插入到光标的后面</td>\n</tr>\n<tr>\n<td><code>A</code></td>\n<td>插入到行的最后位置</td>\n</tr>\n<tr>\n<td><code>o</code>, <code>O</code></td>\n<td>新开一行</td>\n</tr>\n<tr>\n<td><code>Esc</code></td>\n<td>关闭插入模式</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"编辑-Editing\"><a href=\"#编辑-Editing\" class=\"headerlink\" title=\"编辑(Editing)\"></a>编辑(Editing)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释）</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>r</code></td>\n<td>在插入模式替换光标所在的一个字符</td>\n</tr>\n<tr>\n<td><code>J</code></td>\n<td>合并下一行到上一行</td>\n</tr>\n<tr>\n<td><code>s</code></td>\n<td>删除光标所在的一个字符, 光标还在当行</td>\n</tr>\n<tr>\n<td><code>S</code></td>\n<td>删除光标所在的一行，光标还在当行，不同于dd</td>\n</tr>\n<tr>\n<td><code>u</code></td>\n<td>撤销上一步操作</td>\n</tr>\n<tr>\n<td><code>ctrl</code>+<code>r</code></td>\n<td>恢复上一步操作</td>\n</tr>\n<tr>\n<td><code>.</code></td>\n<td>重复最后一个命令</td>\n</tr>\n<tr>\n<td><code>~</code></td>\n<td>变换为大写</td>\n</tr>\n<tr>\n<td><code>[N]&gt;&gt;</code></td>\n<td>一行或N行往右移动一个tab</td>\n</tr>\n<tr>\n<td><code>[N]&lt;&lt;</code></td>\n<td>一行或N行往左移动一个tab</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"关闭-Exiting\"><a href=\"#关闭-Exiting\" class=\"headerlink\" title=\"关闭(Exiting)\"></a>关闭(Exiting)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>:w</code></td>\n<td>保存</td>\n</tr>\n<tr>\n<td><code>:wq</code>, <code>:x</code></td>\n<td>保存并关闭</td>\n</tr>\n<tr>\n<td><code>:q</code></td>\n<td>关闭（已保存）</td>\n</tr>\n<tr>\n<td><code>:q!</code></td>\n<td>强制关闭</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"搜索-Search\"><a href=\"#搜索-Search\" class=\"headerlink\" title=\"搜索(Search)\"></a>搜索(Search)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>/pattern</code></td>\n<td>搜索（非插入模式)</td>\n</tr>\n<tr>\n<td><code>?pattern</code></td>\n<td>往后搜索</td>\n</tr>\n<tr>\n<td><code>n</code></td>\n<td>光标到达搜索结果的前一个目标</td>\n</tr>\n<tr>\n<td><code>N</code></td>\n<td>光标到达搜索结果的后一个目标</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"视觉模式-Visual-Mode\"><a href=\"#视觉模式-Visual-Mode\" class=\"headerlink\" title=\"视觉模式(Visual Mode)\"></a>视觉模式(Visual Mode)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>v</code></td>\n<td>选中一个或多个字符</td>\n</tr>\n<tr>\n<td><code>V</code></td>\n<td>选中一行</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"剪切和复制-Cut-and-Paste\"><a href=\"#剪切和复制-Cut-and-Paste\" class=\"headerlink\" title=\"剪切和复制(Cut and Paste)\"></a>剪切和复制(Cut and Paste)</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>dd</code></td>\n<td>删除一行</td>\n</tr>\n<tr>\n<td><code>dw</code></td>\n<td>删除一个单词</td>\n</tr>\n<tr>\n<td><code>x</code></td>\n<td>删除后一个字符</td>\n</tr>\n<tr>\n<td><code>X</code></td>\n<td>删除前一个字符</td>\n</tr>\n<tr>\n<td><code>D</code></td>\n<td>删除一行最后一个字符</td>\n</tr>\n<tr>\n<td><code>[N]yy</code></td>\n<td>复制一行或者N行</td>\n</tr>\n<tr>\n<td><code>yw</code></td>\n<td>复制一个单词</td>\n</tr>\n<tr>\n<td><code>p</code></td>\n<td>粘贴</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"窗口操作\"><a href=\"#窗口操作\" class=\"headerlink\" title=\"窗口操作\"></a>窗口操作</h2><table>\n<thead>\n<tr>\n<th>命令</th>\n<th>作用（解释)</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>:split</code></td>\n<td>水平方向分割出一个窗口</td>\n</tr>\n<tr>\n<td><code>:vsplit</code></td>\n<td>垂直方向分割出一个窗口</td>\n</tr>\n<tr>\n<td><code>:close</code></td>\n<td>关闭窗口</td>\n</tr>\n<tr>\n<td><code>Ctrl</code>+<code>W</code></td>\n<td>切换窗口, h到左边窗口，j到下方窗口，k到上方窗口，l到右边窗口</td>\n</tr>\n</tbody>\n</table>\n","categories":["工具"],"tags":["工具","快捷键"]},{"title":"Redis数据结构与应用","url":"http://shawnz.me/posts/85682d75/","content":"<p><code>Redis</code>可以存储键与5种不同数据结构类型之间的映射, 这五种数据结构类型分别为: <code>STRING</code>,<code>LIST</code>,<code>SET</code>,<code>ZSET</code>和<code>HASH</code>.</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p><code>Redis</code>没有采用C语言传统的字符串表示(以空字符结尾的字符数组), 而是自己构建了一种名为”简单动态字符串”(simple dynamic string, SDS)的抽象结构来表示字符串.</p>\n<p>C字符串只会作为字符串字面量, 用在一些无须对字符串值作修改的地方, 如打印日志.</p>\n<pre><code class=\"c\">redisLog(REDIS_WARNING,&quot;Redis is now ready to exit, bye bye...&quot;);\n</code></pre>\n<a id=\"more\"></a>\n<p>而在键值存储的时候, <code>Redis</code>会使用<code>SDS</code>来表示字符串, 值的大小不能超过<code>512MB</code>, 其中可以存储以下三种类型值:</p>\n<ul>\n<li>字节串(byte string)</li>\n<li>整数</li>\n<li>浮点数</li>\n</ul>\n<p><code>Redis</code>的字符串有几个特性:</p>\n<ul>\n<li><code>SDS</code>结构会保存字符串长度信息, 所以<code>STRLEN</code>命令的时间复杂度为<code>O(1)</code>;</li>\n<li><code>SDS</code>采用内存预分配和惰性内存释放策略, 来优化减少内存重分配次数;</li>\n<li>二进制安全: 由于<code>Redis</code>不采用空字符作为字符串的结尾标志, 而是记录字符串长度, 所以可以用来保存一系列的二进制数据;</li>\n<li>虽然<code>SDS</code>的字符串是二进制安全的, 但它仍然遵循C字符串以空字符结尾的惯例, 所以可以重用一些C函数来操作字符串.</li>\n</ul>\n<p><strong>应用</strong></p>\n<ul>\n<li>计数器或ID生成器</li>\n<li>将数据打包成位, 需要数据具有连续性质. 优点是存储空间少, 使用位运算速度快. 例如: <code>Bitemap</code>, 定长数据存储.</li>\n<li>分布式锁</li>\n</ul>\n<p><strong>Redis分布式锁</strong></p>\n<p>实现一个<code>Redis</code>分布式锁, 需要注意几点:</p>\n<ul>\n<li><p>Q: 获取的锁需要一个过期时间, 避免在客户端持有锁的途中宕机而导致锁得不到释放.<br><br>  A: <code>Redis</code>可以很容易地给键添加<code>Expire</code>过期时间.</p>\n</li>\n<li><p>Q: 获取锁和设置锁的过期时间必须是原子的, 否则客户端依旧可能在中间过程宕机.<br><br>  A: <code>SET</code>命令, 可以设置过期时间, 并保证原子性.</p>\n</li>\n<li><p>Q: 设置锁的过期时间, 设置多久? 过短的话, 锁会在持有阶段被错误的释放掉, 不安全的访问共享资源; 过长的话, 会导致其他客户端长时间无法正常工作.<br><br>  A: 可选的做法是<code>fencing token</code>机制. 客户端在成功获取锁时, <code>Redis</code>服务器会返回锁和一个单调递增的数字. 如果锁已经失效, 且被其他客户端获取的话, 那么失效的客户端在使用<code>fencing token</code>访问共享资源时就会失败(因为有了一个更大的值). <br><br>  然而关于生成<code>fencing token</code>和资源服务器结构如何处理<code>fencing token</code>又是另外一个难点了.<br>  另外一种做法是资源服务器实现一个<code>Check-and-Set</code>的原子机制来拒绝延迟请求, 不保证请求的有序(因为没有递增的<code>fencing token</code>, 使用无序的<code>identifier</code>), 但是保证处理的互斥.</p>\n</li>\n<li><p>Q: 释放锁, 需要一个随机值<code>identifier</code>, 保证客户端释放的是自己持有的锁?<br><br>  A: 这里使用<code>uuid</code>生成一个随机字符串作为<code>identifier</code>.</p>\n</li>\n<li><p>Q: 释放锁时, 必须保证检查<code>identifier</code>和释放锁是原子的, 锁可能在检查和释放的中间过程中, 被过期释放掉, 导致客户端释放了其他客户端持有的锁.<br><br>  A: 一种做法是使用<code>Redis</code>的”事务”; 另一种做法使用<code>Lua</code>脚本.</p>\n</li>\n<li><p>Q: 还有一个就是单节点<code>Redis</code>无法保证锁的高可用, 需要采用<code>Redis</code>“复制”, 而<code>Redis</code>的主从复制是异步的, 在故障转移的过程中会丧失锁的安全性.<br><br>  A: 采用分布式锁算法<code>RedLock</code>, 基于<code>N</code>个完全独立的<code>Redis</code>节点. 然而<code>RedLock</code>是构建在不安全的系统模型之上, 它对系统的计记时假设(<code>timing assumption</code>)有着比较强的依赖.</p>\n</li>\n</ul>\n<p>这里有一个简单的<code>Redis</code>实现分布式锁实现:</p>\n<pre><code class=\"python\">import time\nimport uuid\nimport threading\nimport redis\n\n\nconn = redis.Redis()\n\n\ndef acquire_lock(conn, lockname, timeout=10):\n    identifier = str(uuid.uuid4())\n\n    end = time.time() + timeout\n\n    while time.time() &lt; end:\n        if conn.set(name=&quot;lock:&quot; + lockname, value=identifier, nx=True, px=30000):\n            print(&quot;acquire_lock...&quot;)\n            return identifier\n        time.sleep(1)\n    return False\n\n\ndef release_lock(conn, lockname, identifier):\n    if not lockname:\n        return False\n    lockname = &quot;lock:&quot; + lockname\n    while True:\n        try:\n            pipeline = conn.pipeline(True)\n            pipeline.watch(lockname)\n            if pipeline.get(lockname) == identifier.encode(&#39;utf-8&#39;):\n                pipeline.multi()\n                pipeline.delete(lockname)\n                pipeline.execute()\n                print(&quot;release_lock...&quot;)\n                return True\n            pipeline.unwatch()\n            break\n        except redis.exceptions.WatchError as e:\n            raise e\n\n\nclass Resource:\n\n    def __init__(self):\n        self.identifier = &quot;&quot;\n        self.value = 0\n        self.mutex = threading.Lock()\n\n    def check_and_set(self, identifier, value):\n        with self.mutex:\n            if self.identifier == identifier:\n                self.value = value\n\n\nif __name__ == &quot;__main__&quot;:\n    resource = Resource()\n    thread_nums = 5\n    threads = []\n\n    def incr():\n        identifier = acquire_lock(conn, &#39;test&#39;)\n        if identifier:\n            resource.identifier = identifier\n            for i in range(100):\n                value = resource.value + 1\n                resource.check_and_set(identifier, value)\n            release_lock(conn, &#39;test&#39;, identifier)\n\n    for i in range(thread_nums):\n        thread = threading.Thread(target=incr)\n        threads.append(thread)\n\n    for thread in threads:\n        thread.start()\n    for thread in threads:\n        thread.join()\n\n    print(resource.value)\n</code></pre>\n<h2 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h2><p>列表的底层是双向链表实现的, 并且通过几个属性保存了链表的头部, 尾部以及长度信息, 所以一些操作, 例如: <code>LLEN</code>, <code>LPOP</code>和<code>RPOP</code>都是<code>O(1)</code>的时间复杂度.</p>\n<p><code>Redis</code>的列表允许用户从两端推入或弹出元素, 以及各种常见的列表操作. 利用列表的特性, 我们可以实现许多实用的功能, 例如:</p>\n<ul>\n<li>消息队列(通知类, 延迟更新类)</li>\n<li>自动补全最近联系人</li>\n<li>时间轴(很容易截断)</li>\n</ul>\n<p><strong>自动补全</strong></p>\n<p>下面是一个保存最近100名联系人的”自动补全”实现的例子:</p>\n<pre><code class=\"python\">import redis\n\n\nconn = redis.Redis()\n\n\ndef add_update_contacts(conn, user, contact):\n    ac_list = &#39;recent:&#39; + user\n    pipe = conn.pipeline(True)\n    pipe.lrem(ac_list, contact)\n    pipe.lpush(ac_list, contact)\n    pipe.ltrim(ac_list, 0, 99)\n    pipe.execute()\n\n\ndef fetch_autocomplete_list(conn, user, prefix):\n    candidates = conn.lrange(&#39;recent:&#39; + user, 0, -1)\n    suggestions = []\n\n    for candidate in candidates:\n        if candidate.lower().decode(&#39;utf8&#39;).startswith(prefix):\n            suggestions.append(candidate)\n\n    return suggestions\n\n\nif __name__ == &quot;__main__&quot;:\n    add_update_contacts(conn, &#39;user&#39;, &#39;zhongshangwu&#39;)\n    print(fetch_autocomplete_list(conn, &#39;user&#39;, &#39;zh&#39;))\n</code></pre>\n<h2 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h2><p><code>Redis</code>集合以无序的方式存储各个不相同的元素, 用户可以快速的进行各种集合操作, 比如检测某个元素是否存在, 以及实现交集, 并集, 差集等.</p>\n<p>集合的特性可以应用在社交网络的关注列表上, 可以非常方便的实现如共同关注、共同喜好、二度好友等功能. 不过社交网站数据一般十分庞大, 采用这种方案往往是不切实际的.</p>\n<h2 id=\"有序集合\"><a href=\"#有序集合\" class=\"headerlink\" title=\"有序集合\"></a>有序集合</h2><p>使用<code>Redis</code>开发应用程序组件的一个强大数据结构就是有序集合. 和散列存储着键与值之间的映射类似, 有序集合提供了分值的处理命令, 以及根据分值大小有序地获取或扫描成员和分值的命令.</p>\n<p>有序集合的底层实现是散列和跳跃表. 跳跃表按分值从小到大的顺序保存了所有元素, 每个跳跃表节点代表一个集合元素, <code>object</code>属性指向了元素的成员, 而<code>double</code>类型的<code>score</code>属性则保存成员的分值. 通过一个持有跳跃表节点的结构, 有序集合能够很好的进行遍历, 取某一分值范围的元素. 另外使用一个字典保存了成员和分值的映射, 键指向元素成员, 而值则保存了元素的分值, 所以能够以<code>O(1)</code>时间复杂度的查找给定成员的分值, 例如<code>ZSCORE</code>命令. 需要注意的是使用散列和跳跃表来保存集合元素不会产生重复的成员或分值, 也不会浪费额外的内存.</p>\n<p><strong>应用</strong></p>\n<ul>\n<li>延迟任务队列</li>\n<li>排行榜</li>\n</ul>\n<p><strong>延迟任务优先队列</strong></p>\n<p>这里采用多个队列区分优先级, 有序集合存储延迟任务, 并把时间戳作为分值.</p>\n<pre><code class=\"python\">import json\nimport time\nimport uuid\nimport threading\nimport redis\nfrom redis_lock import acquire_lock, release_lock\n\n\nconn = redis.Redis()\nQUIT = False\n\n\ndef execute_delay(conn, queue, *args, priority=0, delay=0, **kwargs):\n    identifier = str(uuid.uuid4())\n    if delay &gt; 0:\n        conn.zadd(&#39;delayed:&#39;,\n                  json.dumps((identifier, queue, priority, args, kwargs)),\n                  time.time() + delay)\n    else:\n        conn.rpush(&#39;queue:&#39; + queue + &#39;:%d&#39; % priority, json.dumps((args, kwargs)))\n    return identifier\n\n\ndef worker_watch_delayed(conn):\n\n    while not QUIT:\n        item = conn.zrange(&#39;delayed:&#39;, 0, 0, withscores=True)\n        if not item or item[0][1] &gt; time.time():\n            time.sleep(1)\n            continue\n\n        item = item[0][0]\n        identifier, queue, priority, args, kwargs = json.loads(item)\n\n        lock = acquire_lock(conn, identifier)\n        if not lock:\n            continue\n        if conn.zrem(&#39;delayed:&#39;, item):\n            conn.rpush(&#39;queue:&#39; + queue + &#39;:%d&#39; % priority, json.dumps((args, kwargs)))\n\n        release_lock(conn, identifier, lock)\n\n\ndef worker_watch_queue(conn, queue, callback):\n    if not callback:\n        return\n\n    while not QUIT:\n        queues = conn.keys(&#39;queue:&#39; + queue + &#39;:*&#39;)\n        queues = sorted(queues, key=lambda x: x.decode(&#39;utf8&#39;).split(&#39;:&#39;)[-1])\n        if queues:\n            item = conn.blpop(queues, 10)\n            if not item:\n                continue\n\n            args, kwargs = json.loads(item[1])\n            callback(*args, **kwargs)\n\n\nif __name__ == &quot;__main__&quot;:\n\n    def producer_0():\n        count = 0\n        while True:\n            count += 1\n            execute_delay(conn, &#39;echo&#39;, &#39;producer_0&#39;, priority=0, msg=count)\n            time.sleep(4)\n\n    def producer_0_delay():\n        count = 0\n        while True:\n            count += 1\n            execute_delay(conn, &#39;echo&#39;, &#39;producer_0_delay&#39;, priority=1, delay=4, msg=count)\n            time.sleep(2)\n\n    def producer_1():\n        count = 0\n        while True:\n            count += 1\n            execute_delay(conn, &#39;echo&#39;, &#39;producer_1&#39;, priority=2, msg=count)\n            time.sleep(1)\n\n    def callback(producer, msg):\n        print(&#39;%s&#39; % producer + &#39; echo: &#39; + &#39;%d&#39; % msg)\n\n    thread_0 = threading.Thread(target=producer_0)\n    thread_1 = threading.Thread(target=producer_0_delay)\n    thread_2 = threading.Thread(target=producer_1)\n    thread_3 = threading.Thread(target=worker_watch_delayed, args=(conn,))\n    thread_4 = threading.Thread(target=worker_watch_queue, args=(conn, &#39;echo&#39;, callback))\n\n    thread_0.start()\n    thread_1.start()\n    thread_2.start()\n    thread_3.start()\n    thread_4.start()\n\n    thread_0.join()\n    thread_1.join()\n    thread_2.join()\n    thread_3.join()\n    thread_4.join()\n</code></pre>\n<p>输出如下:</p>\n<pre><code class=\"code\">producer_0 echo: 1\nproducer_1 echo: 1\nproducer_1 echo: 2\nproducer_1 echo: 3\nproducer_1 echo: 4\nproducer_0 echo: 2\nacquire_lock...\nrelease_lock...\nproducer_0_delay echo: 1\nproducer_1 echo: 5\nproducer_1 echo: 6\nproducer_1 echo: 7\nacquire_lock...\nproducer_0_delay echo: 2\nrelease_lock...\nproducer_1 echo: 8\nproducer_0 echo: 3\nproducer_1 echo: 9\nacquire_lock...\nproducer_0_delay echo: 3\nrelease_lock...\nproducer_1 echo: 10\nproducer_1 echo: 11\nacquire_lock...\nproducer_0_delay echo: 4\nrelease_lock...\nproducer_1 echo: 12\nproducer_0 echo: 4\nproducer_1 echo: 13\nacquire_lock...\nproducer_0_delay echo: 5\nrelease_lock...\nproducer_1 echo: 14\nproducer_1 echo: 15\nacquire_lock...\nproducer_0_delay echo: 6\nrelease_lock...\nproducer_1 echo: 16\n</code></pre>\n<h2 id=\"散列\"><a href=\"#散列\" class=\"headerlink\" title=\"散列\"></a>散列</h2><p><code>Redis</code>的散列可以存储多个键值对之间的映射. 和字符串一样, 散列存储的值即可以是字节串, 也可以是整数值, 并且用户可以使用<code>HINCR</code>和<code>HDECR</code>对整数值执行自增或自减操作.</p>\n<p>散列除了作为普通的键值映射外, 还可以将散列键看作文档数据库中的”文档”.</p>\n<h2 id=\"压缩列表\"><a href=\"#压缩列表\" class=\"headerlink\" title=\"压缩列表\"></a>压缩列表</h2><p>压缩列表是列表键,哈希键以及有序集合的底层实现之一.</p>\n<p>当一个列表键只包含少量列表项, 并且每个列表项要么就是小整数值, 要么就是长度比较短的字符串, 那么<code>Redis</code>就会使用压缩列表来做列表键的底层实现.</p>\n<p>每个压缩列表的节点都包括三个部分:</p>\n<ul>\n<li><code>previous_entry_length</code>: 上一个节点的长度;</li>\n<li><code>encoding</code>: 包括节点保存的数据类型(字节数组/整数值)以及当前节点的长度;</li>\n<li><code>content</code>: 被存储的字符串值;</li>\n</ul>\n<p>压缩列表是一种为节约内存而开发的顺序型数据结构. 添加新节点到压缩列表， 或者从压缩列表中删除节点， 由于<code>previous_entry_length</code>属性占据的字节数会发生变化, 可能会引发连锁更新操作, 但这种操作出现的几率并不高.</p>\n<p>在<code>Redis</code>配置选项中, 能够配置列表, 散列和有序集合什么时候使用压缩列表节省内存:</p>\n<pre><code class=\"ini\">list-max-ziplist-entries 512\nlist-max-ziplist-value 64\n\nhash-max-ziplist-entries 512\nhash-max-ziplist-value 64\n\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\n</code></pre>\n<p><code>entries</code>选项表示编码为压缩列表时, 最多能包含的元素数量; <code>value</code>选项说明了压缩列表每个节点的最大体积是多少字节. 当突破这些限制时, <code>Redis</code>将压缩列表会转码成正常的数据结构.</p>\n<h2 id=\"整数集合\"><a href=\"#整数集合\" class=\"headerlink\" title=\"整数集合\"></a>整数集合</h2><p>整数集合（intset）是 Redis 用于保存整数值的集合抽象数据结构, 支持<code>int16_t</code>、<code>int32_t</code>或者<code>int64_t</code>类型, 整数集合会根据添加的元素类型, 进行”升级”操作.</p>\n<p>整数集合不光能节省内存, 还可以提升所有标准集合操作的执行速度. 下面是定义整数集合最大元素数量的配置选项:</p>\n<pre><code class=\"ini\">set-max-ziplist-entries 512\n</code></pre>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://redisbook.com/\" target=\"_blank\" rel=\"noopener\">Redis设计与实现</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://redisdoc.com/\" target=\"_blank\" rel=\"noopener\">Redis命令参考</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://zhangtielei.com/posts/blog-redlock-reasoning.html\" target=\"_blank\" rel=\"noopener\">基于Redis的分布式锁到底安全吗?</a><br></p>\n","categories":["数据库"],"tags":["数据库","Redis"]},{"title":"深入Django ORM","url":"http://shawnz.me/posts/83dc4fd4/","content":"<!--  -->\n<a id=\"more\"></a>\n<p>大多数人对<code>ORM</code>褒贬不一, 一方面<code>ORM</code>能够以编码面向对象的设计方式和关系数据库关联, 从底层的数据库操作中解脱出来. 但是另一方面, <code>ORM</code>框架也导致了程序员对底层的控制力明显减弱, 而且使用<code>ORM</code>很难有针对的进行优化.</p>\n<p>Django ORM框架</p>\n<h2 id=\"源码组织\"><a href=\"#源码组织\" class=\"headerlink\" title=\"源码组织\"></a>源码组织</h2><p>Django ORM实现的源码都在<code>django.db</code>包中, 先来看一下它的代码组织结构:</p>\n<pre><code class=\"python\">├── db\n│   ├── models  # 以面向对象的方式和数据库关联\n│   │   ├── aggregates.py  # 聚合查询\n│   │   ├── base.py  # Model类定义\n│   │   ├── constants.py  # 常量\n│   │   ├── deletion.py  # 数据库表项删除的实现\n│   │   ├── expressions.py  # 表达式\n│   │   ├── fields  # 字段以及关联me\n│   │   ├── functions  # 数据库函数\n│   │   ├── indexes.py  # 索引\n│   │   ├── __init__.py  \n│   │   ├── lookups.py  # 属性查找器\n│   │   ├── manager.py  # 对象管理器\n│   │   ├── options.py  # 数据库属性\n│   │   ├── query.py  # 查询集\n│   │   ├── query_utils.py  # 查询工具\n│   │   ├── signals.py  # 信号\n│   │   ├── sql # sql语句\n│   │   └── utils.py \n</code></pre>\n<p>本篇文章主要针对<code>db.models</code>的各个模块分析<code>Django ORM</code>是怎么实现对象关系映射的以及有哪些地方是可以优化.</p>\n<h2 id=\"简单的例子\"><a href=\"#简单的例子\" class=\"headerlink\" title=\"简单的例子\"></a>简单的例子</h2><p>官方文档中的一个例子:</p>\n<pre><code class=\"python\">from django.db import models\n\nclass Person(models.Model):\n    first_name = models.CharField(max_length=30)\n    last_name = models.CharField(max_length=30)\n\n    class Meta:\n        pass\n</code></pre>\n<h2 id=\"运行时创建模型类\"><a href=\"#运行时创建模型类\" class=\"headerlink\" title=\"运行时创建模型类\"></a>运行时创建模型类</h2><p><code>Django</code>用到了<code>Python</code>许多强大的特性, 而<code>Django ORM</code>部分就使用<code>元类(metaclass)</code>编程技术, 在运行时动态创建模型类.</p>\n<p><code>ModelBase</code>正是创建模型类的元类. 它实现了<code>__new__(cls, name, bases, attrs)</code>方法, 接收四个参数:</p>\n<ul>\n<li><code>cls</code>: 元类类对象;</li>\n<li><code>name</code>: 模型类名称;</li>\n<li><code>bases</code>: 模型类的基类列表, <code>ModelBase</code>只能创建继承自<code>Model</code>的模型类;</li>\n<li><code>attrs</code>: 模型类的命名空间, 模型的<code>Field</code>字段申明以及元信息<code>Meta</code>都在这个字典里面;</li>\n</ul>\n<p><code>ModelBase</code>中创建模型类对象的过程: 是通过基本<code>type</code>先创建一个简单的Python类对象, 然后使用<code>ModelBase</code>中定义的类方法<code>add_to_class</code>动态地设置模型类对象. <code>__new__</code>创建并初始化一个类对象分为一下几个步骤:</p>\n<ol>\n<li>生成一个模型类, 保留原始模型定义所在的模块;</li>\n<li>从原始模型类的定义中获取<code>Meta</code>元信息, <code>Django</code>会尝试从中获取一些模型类的相关属性, 例如: <code>abstract</code>,<code>ordering by</code>等;</li>\n<li>查找<code>model</code>所在的应用程序的<code>app_config</code>, 如果原始模型类没有提供自定义<code>app_label</code>, 那么它将被声明为模块所在<code>app</code>的标志;</li>\n<li>原始模型的元信息类<code>Meta</code>会别包装成一个特殊<code>Options</code>对象, 并设置在新创建的模型类对象的属性<code>_meta</code>上;</li>\n<li>为新创建模型类对象添加两个模型相关的异常类<code>DoesNotExist</code>和<code>MultipleObjectsReturned</code>;</li>\n<li>如果是一个代理模型类, 必须确保它的基类没有被<code>swapped out</code>;</li>\n<li>添加原始模型类中定义的所有属性和字段到新创建的模型类对象上;</li>\n<li>设置代理模型类;</li>\n<li>从父类继承部分属性和字段;</li>\n<li>如果是一个抽象模型类则直接返回;</li>\n<li>如果模型类没有提供一个对象管理器, 那么就设置一个名为<code>objects</code>的<code>Manager</code>默认对象管理器;</li>\n<li>新的模型类会被缓存在应用程序中;</li>\n<li>返回新创建的模型类, 供以后创建类的实例使用;</li>\n</ol>\n<h2 id=\"查询\"><a href=\"#查询\" class=\"headerlink\" title=\"查询\"></a>查询</h2><h2 id=\"事务\"><a href=\"#事务\" class=\"headerlink\" title=\"事务\"></a>事务</h2>","categories":["Python"],"tags":["Python","Django","源码"]},{"title":"MySQL性能优化","url":"http://shawnz.me/posts/f75280fd/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"MySQL逻辑架构\"><a href=\"#MySQL逻辑架构\" class=\"headerlink\" title=\"MySQL逻辑架构\"></a>MySQL逻辑架构</h2><p>MySQL的逻辑架构大致分为三层:</p>\n<p><img src=\"/images/mysql-0.png\" alt=\"\"></p>\n<h2 id=\"基准测试\"><a href=\"#基准测试\" class=\"headerlink\" title=\"基准测试\"></a>基准测试</h2><p>sysbench</p>\n<h2 id=\"性能剖析\"><a href=\"#性能剖析\" class=\"headerlink\" title=\"性能剖析\"></a>性能剖析</h2><p>性能定义: 完成某件任务所需要的时间度量, 以响应时间作为性能指标, 吞吐量作为性能优化的副产品.</p>\n<p>性能剖析的手段:</p>\n<ul>\n<li><code>SHOW STATUS</code>: 返回一些计数器, 既有基于连接的会话级别计数器, 也有服务器级别全局计数器;</li>\n<li><code>SHOW PROLIE</code>: 默认关闭, 通过<code>SET PROFILING=1</code>开启后, 在服务器上执行的所有语句, 都会测量其耗费的时间和其他一些查询执行状态变更相关的数据;</li>\n<li><code>慢查询日志</code>: 默认关闭, 用来记录在MySQL中响应时间超过阀值的语句, 通过<code>long_query_time</code>参数设置阀值(默认10s). 另外日志分析工具有<code>pt-query-digst</code>和<code>mysqldumpslow</code>;</li>\n<li><code>Performance Schema</code>: 以存储引擎的方式实现, 用于收集数据库服务器性能参数;</li>\n<li><code>Information Schema</code>: 提供了访问数据库元数据的方式, 可以<code>STATISTICS</code>表查看一些索引信息;</li>\n<li><code>EXPLAIN</code>: 查看一些SQL语句的执行计划.<!-- more -->\n<h2 id=\"Schema优化\"><a href=\"#Schema优化\" class=\"headerlink\" title=\"Schema优化\"></a>Schema优化</h2></li>\n</ul>\n<h3 id=\"几个简单原则\"><a href=\"#几个简单原则\" class=\"headerlink\" title=\"几个简单原则\"></a>几个简单原则</h3><ul>\n<li>更小的通常更好: 尽量使用可以正确存储数据的最小数据类型但是要确保没有低估需要存储的值的范围;</li>\n<li>简单就好: 尽量使用简单的数据类型, 比如整型优于字符类型, 字符类型有字符集和校对规则, 因此更加复杂; 使用内建日期类型而不是字符串保存日期和时间, 用整型存储Ip地址而不是字符串.</li>\n<li>尽量避免NULL：让一个列为可以NULL的会导致耗费很多的存储空间, 尤其是那些预计会建立索引的列, 可NULL的列会导致索引的统计和值比较更加复杂. </li>\n<li>选择类型的时候, 先确定合适的大类型: 整形/字符串/日期等, 然后在确定具体类型.</li>\n</ul>\n<h3 id=\"数值类型\"><a href=\"#数值类型\" class=\"headerlink\" title=\"数值类型\"></a>数值类型</h3><ul>\n<li><code>TINYINT</code>,<code>SMALLINT</code>,<code>MEDIUMINT</code>,<code>INT</code>,<code>BIGINT</code>分别对应<code>8</code>,<code>16</code>,<code>24</code>,<code>32</code>,<code>64</code>位存储空间, 以及提供<code>UNSIGNED</code>属性, 表示不允许负值;</li>\n<li><code>FLOAT\\DOUBLE</code>类型支持单精度浮点运算和双精度浮点运算, 这种计算是近似的, 不精确的, 这是现行计算机架构的通病, 是由底层决定的, 不是MySQL导致的;</li>\n<li><code>DECIMAL</code>类型支持精确的计算, 存储精确的小数. 但是这是有代价的, 这种类型的运算比浮点运算慢, 占用空间更多;</li>\n<li>推荐使用<code>BIGINT</code>来存储精确数字, 比如要精确到<code>0.0001</code>, 那么存储数字的时候乘以一万, 而取出数字后再除以一万. 这样可以避免浮点运算的精度问题, 又不用付出<code>DECIMAL</code>高昂的代价;</li>\n<li>注意MySQL的存储类型, 运算类型和客户端显示格式的区别;</li>\n</ul>\n<h3 id=\"字符串类型\"><a href=\"#字符串类型\" class=\"headerlink\" title=\"字符串类型\"></a>字符串类型</h3><ul>\n<li><code>CHAR/VARCHAR</code><ul>\n<li><code>VARCHAR</code>变长, 需要1到2个额外的字节记录长度, 存储和检索时会保留末尾的空格;</li>\n<li><code>CHAR</code>定长, 存储时会删除末尾空格, 采用空格填充以方便比较;</li>\n<li>填充和截取空格的行为发生在服务器层, 与存储引擎无关;</li>\n<li><code>CHAR(n)</code>和<code>VARCHAR(n)</code>中的<code>n</code>代表的是字符而不是字节;</li>\n</ul>\n</li>\n<li><code>BINARY/VARBINNARY</code>: 存储的二进制字符串, 填充<code>BINARY</code>采用的是零字节<code>\\0</code>, 检索不会去掉填充值.</li>\n<li><code>BLOB/TEXT</code>:<ul>\n<li>存储很大的数据时使用这两种类型</li>\n<li>当<code>BLOB/TEXT</code>太大时, <code>InnoDB</code>会使用额外的存储区进行存储, 在行内使用1-4个字节存储指针;</li>\n<li>针对<code>BLOB/TEXT</code>, 排序和索引只会使用前面的小部分字符</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"日期类型\"><a href=\"#日期类型\" class=\"headerlink\" title=\"日期类型\"></a>日期类型</h3><ul>\n<li><code>DATETIME</code>: 保存<code>1001</code>年至<code>9999</code>年范围的日期, 精度为秒, 存储到格式为<code>YYYYMMDDHHMMSS</code>的整数中, 占8字节, 以一种直观的方式显示;</li>\n<li><code>TIMESTAMP</code>: 保存格林尼治标准时间以来的秒数, 只能表示<code>1970</code>年至<code>2038</code>年, 占4个字节, 按时区显示;</li>\n</ul>\n<h3 id=\"其他类型\"><a href=\"#其他类型\" class=\"headerlink\" title=\"其他类型\"></a>其他类型</h3><ul>\n<li><code>ENUM</code>:</li>\n</ul>\n<h3 id=\"标识列选择\"><a href=\"#标识列选择\" class=\"headerlink\" title=\"标识列选择\"></a>标识列选择</h3><ul>\n<li>确保某一种标识一旦选定了类型, 就在所有关联的表中使用同一类型, 包括<code>UNSIGNED</code>这样的属性;</li>\n<li>在满足值的要求, 并充分考虑到未来扩展性的情况下, 应使用尽可能小的数据类型, 比如存储美国各州的名字(另一张表)的<code>id</code>列, 不需要<code>INT</code>, <code>TINYINT</code>就够了;</li>\n<li><code>整数 &gt; ENUM/SET &gt; 字符串</code>, 整数的性能和扩展性最好, 字符串最糟糕, 占用很多空间, 性能也差的多;</li>\n<li>对于<code>MD5()</code>, <code>SHA1()</code>, <code>UUID()</code>这种产生随机字符串的函数要特别注意, 这些函数生成的值会导致插入和查询变得很慢, 而对于写非常多的大表, 使用”伪随机”值可以消除热点;</li>\n<li>存储<code>UUID</code>值, 要去掉’-‘号, 或者用<code>UNHEX()</code>函数转换<code>UUID</code>为<code>16</code>字节的数字, 存储在<code>BINATY(16)</code>中, 检索时再通过<code>HEX()</code>格式化成十六进制形式;</li>\n</ul>\n<h3 id=\"应该避免的情况\"><a href=\"#应该避免的情况\" class=\"headerlink\" title=\"应该避免的情况\"></a>应该避免的情况</h3><ul>\n<li>太多的列: 因为MySQL会在工作时, 从存储引擎层和服务器层之间通过行缓冲格式拷贝数据, 然后从行缓冲将编码过的列在服务器端解码成各个列, 转换的代价依赖于列的数量。<code>MyISAM</code>定长行结构与服务器层的行结构不需要转换, 而<code>InnoDB</code>和<code>MyISAM</code>的变长行结构总是需要转换;</li>\n<li>太多关联: MySQL限制每个关联操作最多只有61张表. 避免<code>实体-属性-值(EAV)</code>设计模式. 为追求查询速度和并发性, 单个查询最好是12个表以内关联. </li>\n<li>注意防止过度使用枚举: 一个好的建议是使用整数关联到字典表或查找表, 找到具体指;</li>\n<li>变相的枚举: 避免在应该使用<code>ENUM</code>的情况下使用<code>SET</code>, 比如存储是<code>Y</code>还是<code>N</code>的列。如果不会同时出现<code>YN</code>，就不需要<code>SET</code>类型;</li>\n<li>在避免使用<code>NULL</code>的原则下不要走极端, 使用特殊常数可能造成代码的<code>BUG</code>.</li>\n</ul>\n<h3 id=\"范式与反范式\"><a href=\"#范式与反范式\" class=\"headerlink\" title=\"范式与反范式\"></a>范式与反范式</h3><p>三大范式这里不做叙述了, 总结一下范式和反范式的区别:</p>\n<ul>\n<li>反范式会存储一些冗余数据, 所以通常查询会更快, 另一方面为了保持数据的一致性, 更新操作通常比范式化的数据表慢;</li>\n<li>范式化意味着没有冗余数据, 所以一般不需要<code>DISTINCT</code>和<code>GROUP BY</code>语句;</li>\n</ul>\n<p>在数据库<code>Schema</code>优化中, 大部分的工作都在衡量范式化和反范式上, 实际情况通常需要两者的结合.</p>\n<h3 id=\"技巧\"><a href=\"#技巧\" class=\"headerlink\" title=\"技巧\"></a>技巧</h3><ul>\n<li>缓存表/汇总表: 在满足检索需求时, 经常使用这种技巧. 需要权衡的问题是实时维护还是定期重建(一般来讲这是更好的选择);</li>\n<li>计数表: 在维护计数器的时候, 有时考虑到并发的影响, 可以将计数器切分到不同槽上, 再汇总起来;</li>\n<li>物化试图: 需要借助外部工具.</li>\n<li>加快<code>ALTER TABLE</code>的速度: 对于大表来讲<code>ALTER TABLE</code>的性能是一个大问题, 有两种方法可以加快<code>ALTER TABLE</code>的速度:<ul>\n<li>通过<code>ALTER COLUMN</code>操作来改变列的默认值, 这不会导致表的重建;</li>\n<li>采用替换<code>.frm</code>文件的方式: 创建一张结构相同的空表, 修改表结构, 锁定原表, 替换<code>.frm</code>文件, 解锁原表.</li>\n</ul>\n</li>\n<li>快速创建<code>MyISAM</code>索引: 先引用索引, 载入数据, 在重启索引. 这会索引的构建延迟到数据完全载入后, 这个时候可以使用排序创建索引;</li>\n</ul>\n<h2 id=\"索引优化\"><a href=\"#索引优化\" class=\"headerlink\" title=\"索引优化\"></a>索引优化</h2><h3 id=\"B-Tree索引\"><a href=\"#B-Tree索引\" class=\"headerlink\" title=\"B-Tree索引\"></a>B-Tree索引</h3><p><strong>一定要先看<code>B-Tree</code>和<code>B+Tree</code>数据结构和磁盘的存取原理.</strong></p>\n<p>简单说一下:</p>\n<ul>\n<li><code>B-Tree</code>可以利用磁盘存储的局部性原理和磁盘预读, 减少读取磁盘的次数;</li>\n<li>一个<code>B-Tree</code>节点一般对应”系统页”的整数倍, 连续的地址, 使用的时候加载到内存中(页分裂/碎片等会导致”随机I/O”); 而从磁盘读取索引节点, 一般是”随机I/O”(可以重建索引优化为”顺序I/O”). <code>MyISAM</code>索引的数据行读取是”随机I/O”. (可能理解的有问题…)</li>\n<li><code>B+Tree</code>根节点内存常驻, 内部节点只保存键值, 数据保存在叶子节点上, 相邻的叶子节点之间有指针相连, 能够提高区间查询的效率;</li>\n<li>因为<code>B-Tree</code>按顺序存储索引键值, 所以<code>ORDER BY</code>和<code>GROUP BY</code>十分高效;</li>\n</ul>\n<h4 id=\"InnoDB\"><a href=\"#InnoDB\" class=\"headerlink\" title=\"InnoDB\"></a>InnoDB</h4><p>InnoDB引擎的主键索引, 如下图(这里索引是整数值):</p>\n<p><img src=\"/images/mysql-3.png\" alt=\"\"></p>\n<p>可以看到<code>InnoDB</code>的主索引结构有一个明显的特点: 叶节点包含了完整的数据记录, 这也就是说<code>InnoDB</code>表数据文件本身就是主索引. 这种索引称为<code>簇族索引</code>, 每个叶子节点都包含了主键值, 事务ID, 用于事务和<code>MVCC</code>的回滚指针以及剩余的列, 如果主键是一个列前缀索引, <code>InnoDB</code>也会包含完整的主键列和剩余列. </p>\n<p><code>InnoDB</code>表有且仅能有一个”簇族索引”, 如果没有显示指定主键, 存储引擎会从唯一非空索引中选择一个替代, 如果无法选择, 则生成一个隐藏字段作为主键, 6个字节的长整型.</p>\n<p>由于”簇族索引”的特性, 所以一个优化建议是: 对于<code>InnoDB</code>表, 最好采用数字类型, 且具有自增规律的列作为主键. 如果是主键具有自增规律, 那么就可以通过避免插入的过程中<code>B+Tree</code>子树的重建, 来减少开销, 另外针对磁盘存储, 还可能有效地减少由于”页分裂”产生的碎片.</p>\n<p>再来看看<code>InnoDB</code>的二级索引(这里的索引是字符串):</p>\n<p><img src=\"/images/mysql-4.png\" alt=\"\"></p>\n<p>对于<code>InnoDB</code>的二级索引, 叶子节点里保存的不再是完整数据, 而是主键值, 所以<code>InnoDB</code>的二级索引需要两次索引查找. 这里不存”地址指针”的原因是: 这种策略减少了当行移动或者数据页分裂时导致的二级索引维护工作(存储”主键”不需要变动). </p>\n<p>知道了<code>InnoDB</code>的二级索引原理, 我们也就能理解为什么建议<code>InnoDB</code>主键索引采用数值类型而不是字符串了, 因为字符串会在二级索引上占据更多的存储空间.</p>\n<h4 id=\"MyISAM\"><a href=\"#MyISAM\" class=\"headerlink\" title=\"MyISAM\"></a>MyISAM</h4><p><code>MyISAM</code>的索引结构如下:</p>\n<p><img src=\"/images/mysql-1.png\" alt=\"\"></p>\n<p>和<code>InnoDB</code>的不同之处在于: <code>MyISAM</code>索引的叶子节点中存储的数据的物理地址, 这一点对于主键索引和二级索引没有区别. 两者之间的唯一区别是主键索引要求必须非空唯一.</p>\n<p>另外<code>MyISAM</code>还采用一种”压缩索引”(“前缀索引”)的技术: 先保存索引块的第一个值, 然后将后面的值和第一个值进行比较, 得到相同的前缀的字节数和剩下不同的后缀部分. 例如: 假设索引的第一个值是”perform”, 第二个值是”performmance”的话, 那么第二个值前缀压缩后存储的是类似”7,ance”这样的形式.</p>\n<p>前缀压缩技术能够大幅度的减少磁盘存储空间, 以及降低<code>I/O</code>压力, 但是在查找索引块的时候, 只能退化到顺序查找, 无法利用二分查找.</p>\n<h3 id=\"最左前缀原理\"><a href=\"#最左前缀原理\" class=\"headerlink\" title=\"最左前缀原理\"></a>最左前缀原理</h3><p>在进行索引优化前, 必须先弄明白什么样的查询会使用索引, 这和<code>B-Tree</code>索引限制有关.</p>\n<p>假设我们有如下数据表<code>People</code>:</p>\n<pre><code class=\"sql\">CREATE TABLE `People` (\n  `last_name` varchar(45) NOT NULL,\n  `first_name` varchar(45) NOT NULL,\n  `dob` date NOT NULL,\n  `gender` enum(&#39;m&#39;, &#39;f&#39;) NOT NULL,\n  KEY(`last_name`,`first_name`,`dob`)\n)ENGINE=InnoDB DEFAULT CHARSET=latin1;\n</code></pre>\n<p>索引由<code>last_name</code>,<code>first_name</code>和<code>dob</code>组成. 考虑如下几种情况:</p>\n<ul>\n<li><p>全值匹配<br><br>  指的是和索引中的所有列进行匹配. 例如查找姓名为<code>Cuba Allen</code>, 出生于<code>1960-01-10</code>的人;</p>\n</li>\n<li><p>匹配最左前缀值<br><br>  可以只使用索引的最左侧列, 例如查找所有姓氏为<code>Allen</code>的人;</p>\n</li>\n<li><p>匹配范围值<br><br>  也可以只是用列的前缀部分, 例如查找所有姓氏以<code>J</code>开头的人;</p>\n</li>\n<li><p>精确匹配某一列并范围匹配另一列<br><br>  也可以匹配姓氏为<code>Allen</code>, 名字以<code>K</code>开头的人, 即第一列全匹配, 第二列范围匹配;</p>\n</li>\n</ul>\n<p>也有些情况不会使用索引:</p>\n<ul>\n<li><p>查询条件中含有函数或表达式<br><br>  例如使用<code>left</code>函数查找姓氏前4个字符为<code>Alle</code>的人;</p>\n</li>\n<li><p><code>like</code>关键字<br><br>  如果使用以<code>like %llen</code>形式匹配姓氏, 则不会使用索引, 如果通配符<code>%</code>不出现在开头, 则可以使用索引;</p>\n</li>\n<li><p>不符合最左前缀原则<br><br>  例如跳过第一列姓氏匹配名字, 或者范围匹配不在最右侧;</p>\n</li>\n</ul>\n<h3 id=\"高性能索引策略\"><a href=\"#高性能索引策略\" class=\"headerlink\" title=\"高性能索引策略\"></a>高性能索引策略</h3><p>先前介绍了索引的原理和相关特性, 现在我们来看看怎么建立高效地选择和使用索引.</p>\n<h4 id=\"索引选择性\"><a href=\"#索引选择性\" class=\"headerlink\" title=\"索引选择性\"></a>索引选择性</h4><p>索引的选择性: 不重复的索引值(也称为”基数”)/数据表的记录总数. 选择性越高的索引查询效率越高, 因为高的选择性在查找时能过滤更多的行. 唯一索引的选择性为<code>1</code>, 性能最好.</p>\n<p>定义好了索引选择性, 就不得不提”前缀索引”: 通过只取字符串(通常是字符串)的合适前缀来建立索引, 从而缩小索引的体积. 另外MySQL强制规定在<code>BLOB/TEXT</code>或更长的<code>VARCHAR</code>类型上只能建立前缀索引.</p>\n<p>在选择多长的前缀这个问题上, 我们可以通过索引选择性来找到答案: 先计算完整列的索引选择性, 然后慢慢增加前缀, 逼近完整列的索引选择性. 这个过程可以利用<code>COUNT</code>和<code>LEFT</code>函数.</p>\n<p>另外在多列索引的选择问题上, 也可以参考索引选择性(但不是绝对).</p>\n<p>另外前缀索引也有缺点: 无法用来排序和分组, 也无法用来作为”覆盖索引”.</p>\n<h4 id=\"多列索引\"><a href=\"#多列索引\" class=\"headerlink\" title=\"多列索引\"></a>多列索引</h4><p>在选择索引上, 我们经常面临两个问题:</p>\n<ul>\n<li>是使用多个单独的一列作为索引, 还是建立一个多列的索引?</li>\n<li>如果使用多列索引, 那么这些列之间以什么样的顺序定义呢?</li>\n</ul>\n<p>我们先来解决第一个问题, 在多个单独的列上定以索引大部分情况下并不能提高MySQL性能.</p>\n<p>在MySQL5.0后, 引入了一种叫”索引合并”的策略, 在查询是能够同时使用多个单独的索引进行扫描, 并将结果合并. 这个算法有三个变种: <code>OR</code>联合, <code>AND</code>相交以及组合前两种情况的相交和联合. 不过这会耗费大量的CPU和内存资源在算法的缓存, 排序和合并操作上, 而且查询优化器不会把这部分的损耗计算在内.</p>\n<p>所以一种更健壮的索引设计是多列索引, 这就要求我们结合用到的查询, 定义好合适的索引列顺序.</p>\n<p>当你定义好一个索引列的顺序后, 索引首先会按照最左列排序, 在后续的查询语句要求遵循”最左前缀原理”, 以正确的使用索引.</p>\n<p>对于如何选择索引列顺序的一个经验法则是: 索引列选择性高的放在前面. 这在优化<code>WHERE</code>条件查询时, 无疑是最快的, 然而实际情况中还需要考虑具体值的分布, 以及排序, 分组和范围查找等情况.</p>\n<h4 id=\"按主键顺序插入行\"><a href=\"#按主键顺序插入行\" class=\"headerlink\" title=\"按主键顺序插入行\"></a>按主键顺序插入行</h4><p>最好避免随机的(不连续且值的分布范围十分广)簇族索引.</p>\n<p>如果是按主键顺序插入的话, 那么存储引擎就会顺序的添加到当前索引节点的后面, 当一页写满(“填充因子”: 减少在数据移动或追加的时候的页分裂可能), 就自动开辟一个新的页.</p>\n<p>如果插入的是随机值, 那么每次插入新的记录, 都需要寻找合适的位置—通常是已有位置的中间. 如果写入的目标页已经写入磁盘, 还需要重新读取, 由于是乱序的会造成”随机I/O”, 页分裂操作和磁盘碎片.</p>\n<h4 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h4><p>如果一个索引包含所有要查询的列的值, 就称为”覆盖索引”. 覆盖索引可以使存储引擎不需要从数据行获取数据, 而是直接使用扫面索引获取数据. </p>\n<p>这对I/O密集型的应用十分有帮助, 因为索引更小, 更容易放在内存中, 而且<code>B-Tree</code>索引是顺序存储的, 至少在单个页上是顺序I/O. 另外对于<code>InnoDB</code>的二级索引, 省去了第二次查找主键索引的消耗. </p>\n<p>另外有一个小技巧叫”延迟关联”, 它可以在需要所有列的情况下, 充分利用覆盖索引.</p>\n<h4 id=\"使用索引排序\"><a href=\"#使用索引排序\" class=\"headerlink\" title=\"使用索引排序\"></a>使用索引排序</h4><p>MySQL有两种排序方式: 排序操作, 按索引顺序扫描排序.</p>\n<p>使用索引做排序和使用索引查找一样遵循”最左前缀原理”(列的顺序相同), 而且多个<code>ORDER BY</code>的排序方向必须一致(都是正序或倒序), 如果关联多张表, 那么<code>ORDER BY</code>子句引用的字段都必须是第一张表.</p>\n<p>有一种情况可以不满足”最左前缀原理”: 那就是一个前导列被赋予了常量值, 例如索引(birth, last_name):</p>\n<pre><code class=\"sql\">select * from people where birth=&#39;1996-10-14&#39; order by last_name desc;\n</code></pre>\n<h4 id=\"重复索引\"><a href=\"#重复索引\" class=\"headerlink\" title=\"重复索引\"></a>重复索引</h4><p>MySQL允许在相同的列上创建多个索引, 大多数情况下, 这些索引都是多余的, 会浪费存储空间, 并且插入记录时维护这些索引需要耗费时间. 应该避免创建重复索引, 发现后也要立即移除.</p>\n<p>不过也有些情况下, 考虑到性能需求需要创建重复索引, 扩展原有的索引会导致其变大, 影响其他使用该索引的查询的性能.</p>\n<h3 id=\"哈希索引\"><a href=\"#哈希索引\" class=\"headerlink\" title=\"哈希索引\"></a>哈希索引</h3><p>哈希索引给予哈希表实现, 只有在精确匹配所有列的情况下才能使用, MySQL中只有<code>Memory</code>存储引擎支持哈希索引.</p>\n<p>哈希索引只存储哈希值和行地址, 不过这一点影响不大, 因为在内存中的读取速度不是问题.</p>\n<p>哈希索引在满足查找速度的时候, 牺牲了许多<code>B-Tree</code>索引的特性, 比如: 不支持部分索引列匹配, 排序, 范围匹配和比较计算等. </p>\n<p><code>InnoDB</code>有个特性”自适应哈希索引(Adaptive Hash Index, AHI)”: <code>InnoDB</code>会注意某些<code>索引列</code>用得非常频繁时, 它会为<code>缓冲池</code>中的<code>B-Tree</code>树<code>页</code>建立哈希索引. 据官方文档显示, 在启用<code>AHI</code>后, 读取和写入速度会提升两倍, 辅助索引(存储了主键值)的连接操作性能可以提升五倍. AHI是一种数据库<code>自优化</code>手段, 无需人为干涉.</p>\n<p>另外, 利用哈希函数和触发器, 我们可以创建”自定义哈希索引”, 其思想是: 使用哈希值替换那些十分长的索引列, 实质还是<code>B-Tree</code>索引. 例如有索引列(url_crc):</p>\n<pre><code class=\"sql\">select * from url where url=&quot;http://www.mysql.com&quot; and url_crc=CRC32(&quot;http://www.mysql.com&quot;)\n</code></pre>\n<p>在这里, 优化器会使用这个选择性很高而且体积小的<code>url_crc</code>索引列完成查找, 即使发生哈希冲突, 通过简单的几次键值比较就可以找到记录. 使用触发器维护哈希值:</p>\n<pre><code class=\"sql\">DELIMETER //\n\nCREATE TRIGGER pseudohash_crc_ins BEFORE INSERT ON pseudohash FOR EACH ROW BEGIN\nSET NEW.crc_url=crc32(NEW.url);\nEND;\n//\n\nCREATE TRIGGER pseudohash_crc_upd BEFORE UPDATE ON pseudohash FOR EACH ROW BEGIN\nSET NEW.crc_url=crc32(NEW.url);\nEND;\n//\n\nDELEMETER ;\n</code></pre>\n<h3 id=\"全文索引\"><a href=\"#全文索引\" class=\"headerlink\" title=\"全文索引\"></a>全文索引</h3><h2 id=\"查询优化\"><a href=\"#查询优化\" class=\"headerlink\" title=\"查询优化\"></a>查询优化</h2><p>查询优化, 索引优化和库表结构优化需要齐头并进, 一个不落. 客户端发送一条<code>SQL</code>给MySQL服务器的整个查询流程:</p>\n<p><img src=\"/images/mysql-5.jpg\" alt=\"\"></p>\n<h3 id=\"为何查询如此慢\"><a href=\"#为何查询如此慢\" class=\"headerlink\" title=\"为何查询如此慢?\"></a>为何查询如此慢?</h3><p>在进行查询优化之前, 我们先要弄明白一个查询任务是由哪些子任务构成的, 哪些子任务运行的速度很慢?</p>\n<p>在这里没有给出完整的列表, 不过可以按查询的生命周期来进行分析: 客户端, 服务器, 解析, 生成执行计划, 执行, 并返回结果给客户端. 逐步分析问题出在哪, 优化哪部分能得到大幅度的性能提升. </p>\n<p>查询任务的大部分时间会消耗在网络, CPU计算, 生成统计信息和执行计划, 锁等待等操作, 尤其是为了检索数据发起的对存储引擎的调用, 这些调用需要在内存操作, CPU操作以及内存不足引起的I/O操作消耗时间.</p>\n<p>*阿姆达尔定律: 对于一个占总响应时间不超过5%的查询进行优化, 无论如何努力, 收益也不会超过5%</p>\n<h3 id=\"优化数据访问\"><a href=\"#优化数据访问\" class=\"headerlink\" title=\"优化数据访问\"></a>优化数据访问</h3><p>查询效率低下往往是因为访问的数据太多了. 对于低效查询, 我们可以通过下面两点发现问题所在:</p>\n<ul>\n<li><p>是否向数据库请求了不需要的数据: 会给MySQL带来额外的负担, 增加网络开销, 浪费服务器CPU和内存资源. 常见的几种错误案例:</p>\n<ul>\n<li>查询不需要的行: 这种情况往往发生在应用程序编程的时候, 例如: 只取数据库结果集前面部分, 然后关闭结果集.</li>\n<li>获取不需要的列: 我们应该对<code>SELECT *</code>持审视态度, 是否真的需要全部列? 这一点在多表关联的时候尤为严重, 它会返回所有表的所有列.</li>\n<li>重复查询相同的数据: 这种情况, 我们可以在应用程序将数据缓存起来, 减少数据库查询.</li>\n</ul>\n</li>\n<li><p>MySQL是否在扫描额外的记录: 直白来讲就是MySQL需要扫描多少数据, 才能返回我们需要的数据.<br><br>  一个理想的状态是: <code>扫描的行数=返回的行数=需要的行数</code>.<br><br>  为了评估MySQL查询开销, 我们需要理解几个概念: <code>全表扫描</code>,<code>索引扫描</code>,<code>范围查询</code>,<code>唯一索引访问</code>和<code>常数引用</code>. 这里列的这些, 可以通过<code>EXPLAIN</code>中的<code>type</code>看到, 速度由慢到快.<br><br>  如果发现MySQL扫描了大量的额外数据, 通常可以采用下面几种技巧:</p>\n<ul>\n<li>索引: 索引可以让MySQL访问合适的数据;</li>\n<li>覆盖索引: 可以不用回表查询数据行;</li>\n<li>优化库表结构: 例如汇总表;</li>\n<li>重构查询: 让MySQL优化器以更优的方式执行这个查询;</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"嵌套循环关联\"><a href=\"#嵌套循环关联\" class=\"headerlink\" title=\"嵌套循环关联\"></a>嵌套循环关联</h3><p>MySQL没有哈希关联, 合并关联, 所有关联都是”嵌套循环关联”. 如果要写出高效的多表关联查询, 就必须先弄明白什么是”嵌套循环关联”, 如下图:</p>\n<p><img src=\"/images/mysql-6.jpg\" alt=\"\"></p>\n<p>嵌套循环关联: MySQL先在一个表中循环取出单条数据, 然后再嵌套循环到下一个表中寻找匹配的行, 依次下去, 直到知道到所有表中匹配的行.</p>\n<p>既然理解了MySQL的嵌套循环关联, 也就明白为什么提倡使用”小结果集来驱动大结果集, 对被驱动的表的关联列建立索引”(因为外层循环中结果集大的话, 意味着嵌套循环的次数多, 即更多的磁盘I/O).</p>\n<p>MySQL查询优化器最重要的一部分工作就是关联查询优化, 能在多种不同的关联顺序中, 找到成本比较低的关联顺序(“贪婪”搜索). 这一点上, 优化器大多数情况都能做得很好, 如果人为不能很好的分析各种关联顺序, 可以将工作交给优化器完成.</p>\n<p>关于嵌套循环关联, 还有几个相关的问题:</p>\n<ul>\n<li>对于排序, 如果所有<code>ORDER BY</code>都发生在驱动表, 那么MySQL能在驱动表查找过程中就排好序, 否则, 需要在返回的结果集(临时表)上排序.</li>\n<li>对于<code>UNION</code>操作, MySQL无法将限制条件(<code>LIMIT</code>)从”外层”下推到内层, 它会将结果集合并成临时表, 然后在返回前<code>N</code>条. 一个优化建议是, 分别对单独查询加上<code>LIMIT</code>限制. (还有一点就是从临时表中取出的数据的顺序是不一定的, 必要的话, 还需要全局的排序).</li>\n<li><code>GROUP BY</code>和<code>DISITNC</code>通常需要在临时表上进行操作.</li>\n<li>关联子查询</li>\n</ul>\n<h3 id=\"查询优化器\"><a href=\"#查询优化器\" class=\"headerlink\" title=\"查询优化器\"></a>查询优化器</h3><p>MySQL查询优化器使用了非常多的优化策略和算法, 来生成一个较优的执行计划:</p>\n<ul>\n<li>重新定义表的关联顺序: 数据表的关联顺序并不总是查询指定的顺序;</li>\n<li>将外连接转换成内连接: <code>WHERE</code>条件和库表结构可能会让外连接变为内连接;</li>\n<li>使用等价变换规则: 使用等价变换来简化并规范表达式;</li>\n<li>优化<code>COUNT()</code>,<code>MIN()</code>,<code>MAX()</code>: <code>B-Tree</code>索引可以直接找到最小最大值, 而MyISAM存储引擎有记录数据表总行数.</li>\n<li>预估并转化为常数表达式;</li>\n<li>覆盖索引扫描;</li>\n<li>子查询优化</li>\n<li>提前终止查询</li>\n<li>等值传播</li>\n<li>列表<code>IN()</code>比较: 先对列表值排序, 再二分查找.(而<code>OR</code>是简单顺序查找).</li>\n</ul>\n<p>另外, MySQL也提供了丰富的查询优化器提示(<code>hint</code>), 例如: <code>HIGH_PRIORITY</code>,<code>USE INDEX</code>,<code>FOR UPDATE</code>…</p>\n<h3 id=\"优化特定类型的查询\"><a href=\"#优化特定类型的查询\" class=\"headerlink\" title=\"优化特定类型的查询\"></a>优化特定类型的查询</h3><h4 id=\"COUNT\"><a href=\"#COUNT\" class=\"headerlink\" title=\"COUNT()\"></a>COUNT()</h4><p>关于<code>COUNT</code>这个话题, 互联网上有一大堆的信息, 但大多不够准确. 在这里总结一下:</p>\n<ul>\n<li><p>首先, <code>COUNT(*)</code>并不会扩展到所有列, 它只是统计行数(结果集/数据表).</p>\n</li>\n<li><p>然后对于<code>MyISAM</code>引擎, 因为它有记录数据表的行数, 所以<code>COUNT(*)</code>会很快. 例如:</p>\n<pre><code class=\"sql\">  select * from count(*) from tb;\n</code></pre>\n<p>   但是一旦使用了<code>WHERE</code>条件(并且没有优化掉), 就会退化到全扫描(可能是全表扫描或索引扫描). 假设我们有主键<code>i</code>, 索引<code>val</code>以及字段<code>bar</code>:</p>\n<pre><code class=\"sql\">   select count(*) from tb where i &lt; 10000;  /* 索引扫描 */\n   select count(*) from tb where val &lt; 10000; /* 全表扫描*/\n</code></pre>\n<p>  在都退化到索引扫描的时候,　例如：</p>\n<pre><code class=\"sql\">  select count(*) from tb where i &lt; 10000; /* 最快 */\n  select count(i) from tb where i &lt; 10000; /* 和count(*)等价 */\n  select count(val) from tb where i &lt; 10000; /* 较慢 */\n</code></pre>\n<p>  <code>COUNT(*)</code>会快于<code>COUNT(COL)</code>是因为前者只需要统计行数, 而后者要回表查找数据行(除非<code>COUNT(COL)</code>使用了覆盖索引, 即<code>count(i)</code>). 那么可不可以认为在<code>InnoDB</code>引擎中, 如果都走的是簇族索引的话, 是不是<code>COUNT(*)</code>和<code>COUNT(COL)</code>就没有区别了呢? (还没有去实验…)</p>\n</li>\n<li><p>另外, 有个特殊情况就是<a href=\"https://www.zhihu.com/question/50171821\" target=\"_blank\" rel=\"noopener\">MySQL下count(*)比count(id)慢的原因？</a>. <br><br>  <code>MyISAM</code>存储引擎下两个SQL语句, 这个表的主键为<code>id</code>, <code>status</code>列有个索引:</p>\n<pre><code class=\"sql\">  select count(*) from dr_keywords where status=0;  /* [1]. 0.8秒 */\n  select count(id) from dr_keywords where status=0;  /* [2]. 0.5秒 */\n</code></pre>\n<p>  以及数据分布情况如下:</p>\n<pre><code class=\"code\">  +--------+----------+\n  | status | count(*) |\n  +--------+----------+\n  |      0 |  1060349 |\n  |      1 |     2995 |\n  |      9 |      236 |\n  +--------+----------+\n</code></pre>\n<p>  这里分析的原因是: [1]SQL语句走的是<code>status</code>索引扫描, 而语句[2]被优化器优化为全表扫描.<br><br>  先不谈为什么优化器会将语句[2]优化为全表扫描, 单说索引扫描为什么会慢.<br><br>  大部分情况下, 所以扫描会块</p>\n</li>\n<li><p>在5.7版本中，<code>InnoDB</code>实现了新的<code>handler</code>的<code>records</code>接口函数，当你需要表上的精确记录个数时，会直接调用该函数进行计算,</p>\n</li>\n</ul>\n<p>所以总的来说, 大多数情况下<code>COUNT(*)</code>会不慢于<code>COUNT(COL)</code>, 但是也有例外情况. 实际还可能和索引使用情况, 数据分布情况以及数据库版本和存储引擎相关.</p>\n<h4 id=\"LIMIT\"><a href=\"#LIMIT\" class=\"headerlink\" title=\"LIMIT()\"></a>LIMIT()</h4><p>在业务中需要进行”分页”操作时, 我们经常使用数据库层的<code>OFFSET</code>和<code>LIMIT</code>实现, 并在<code>ORDER BY</code>的列上加上索引.</p>\n<p>一个令人头疼的问题是: 在偏移量非常大的时候. 例如<code>LIMIT 10000,20</code>这样的查询, 会造成MySQL查询<code>10020</code>条记录然后返回最后<code>20</code>条, 造成前面<code>10000</code>条记录被丢弃.</p>\n<p>这种问题的优化策略是: 限制分页数量, 另一个是优化查询在大偏移量时的性能.</p>\n<p>优化这类查询最简单的一个做法是, 尽量使用覆盖索引, 可以避免MySQL回表查询数据行. 如果无法做到覆盖索引, 也可以使用前面介绍的”延迟关联”的技巧. 例如:</p>\n<pre><code class=\"sql\">select film.film_id, film.description\nfrom sakila.film\ninner join (\n    select film_id from sakila.film\n    order by title limit 50,5\n) as lim using(film_id); \n</code></pre>\n<p>另外一种思路是尽可能的减少MySQL扫描的记录数, 先确定范围, 然后取N条. 例如:</p>\n<pre><code class=\"sql\">select film_id, description from sakila.film where position between 50 and 54 order by position;\n</code></pre>\n<p>如果上层应用程序能够记录上一次取数据的位置, 这种范围查找的方式, 在无论偏移量多大的情况下, 都能取得良好的性能.</p>\n<p>“分页”带来的另一个问题是, 需要知道一共能查到多少数据, 以方便应用程序计算”总页数”.</p>\n<p>一个常用的技巧是在<code>LIMIT</code>语句中加上<code>SQL_CALC_FOUND_ROWS</code>提示（<code>hint</code>), 这样做可以获得去掉<code>LIMIT</code>以后满足条件的行数, 因此可以作为分页的总数. 看起来, MySQL做了一些非常高深的优化, 像是通过某种方法预测了总行数. 但实际上MySQL只有在扫描了所有满足条件的行，然后再抛弃掉不需要的行，而不是在满足<code>LIMIT</code>的行数后就终止扫描. 所以该提示的代价非常高, 在数据量大的时候性能很差.</p>\n<p>一个更好的设计方案是将具体的页面换成“下一页”按钮, 假设每页显示<code>20</code>条记录, 那么我们每次查询都是用<code>LIMIT</code>返回<code>21</code>条记录并只显示<code>20</code>条, 如果第<code>21</code>条存在, 那么我们就显示“下一页”按钮, 否则就说明没有更多的数据, 也就无需显示“下一页”按钮了.</p>\n<p>还有一种做法, 那就是在应用程序层做”分页”, 例如, 我们一次加载<code>1000</code>条数据, 缓存下来, 以后的分页都从这个缓存中取. 如果结果集小于<code>1000</code>, 就可以显示所有的页面链接, 否则, 增加一个发现大于<code>1000</code>条数据提示.</p>\n<h4 id=\"IN\"><a href=\"#IN\" class=\"headerlink\" title=\"IN()\"></a>IN()</h4><h4 id=\"UNION\"><a href=\"#UNION\" class=\"headerlink\" title=\"UNION\"></a>UNION</h4><h2 id=\"Resources\"><a href=\"#Resources\" class=\"headerlink\" title=\"Resources\"></a>Resources</h2><p><code>&gt;&gt;&gt;</code><a href=\"http://keithlan.github.io/2015/07/17/22_performance_schema/\" target=\"_blank\" rel=\"noopener\">Mysql5.6 Performance_schema 深入浅出</a><br><br><code>&gt;&gt;&gt;</code><a href=\"http://blog.codinglabs.org/articles/theory-of-mysql-index.html\" target=\"_blank\" rel=\"noopener\">MySQL索引背后的数据结构及算法原理</a><br><br><code>&gt;&gt;&gt;</code><a href=\"http://blog.jobbole.com/100349/\" target=\"_blank\" rel=\"noopener\">如果有人问你数据库的原理, 叫他看这篇文章</a><br></p>\n","categories":["数据库"],"tags":["数据库","MySQL"]},{"title":"Python源码阅读-垃圾回收机制","url":"http://shawnz.me/posts/19171030/","content":"<h2 id=\"Python中的垃圾回收\"><a href=\"#Python中的垃圾回收\" class=\"headerlink\" title=\"Python中的垃圾回收\"></a>Python中的垃圾回收</h2><p>在Python中, 主要的内存管理手段是引用计数, 而标记-清除算法和分代收集机制是为了打破循环引用而补充的技术.</p>\n<h2 id=\"引用计数法\"><a href=\"#引用计数法\" class=\"headerlink\" title=\"引用计数法\"></a>引用计数法</h2><p>经过前面的探索, 我们知道在所有Python对象头部都有着一个计数器, 如果对象的引用增加, 则计数器加一, 反之减一. 所以在Python中, 有两个宏定义来操作这个计数器:</p>\n<a id=\"more\"></a>\n<pre><code class=\"c\">#define Py_INCREF(op) (                         \\ /* 增量计数 */\n    _Py_INC_REFTOTAL  _Py_REF_DEBUG_COMMA       \\\n    ((PyObject *)(op))-&gt;ob_refcnt++)\n\n#define Py_DECREF(op)                                   \\ /* 减量计数 */\n    do {                                                \\\n        PyObject *_py_decref_tmp = (PyObject *)(op);    \\\n        if (_Py_DEC_REFTOTAL  _Py_REF_DEBUG_COMMA       \\\n        --(_py_decref_tmp)-&gt;ob_refcnt != 0)             \\\n            _Py_CHECK_REFCNT(_py_decref_tmp)            \\\n        else                                            \\\n            _Py_Dealloc(_py_decref_tmp);                \\\n    } while (0)\n</code></pre>\n<p>此外, 还提供了针对<code>NULL</code>检查的宏:</p>\n<pre><code class=\"c\">#define Py_XINCREF(op)                                \\\n    do {                                              \\\n        PyObject *_py_xincref_tmp = (PyObject *)(op); \\\n        if (_py_xincref_tmp != NULL)                  \\\n            Py_INCREF(_py_xincref_tmp);               \\\n    } while (0)\n\n#define Py_XDECREF(op)                                \\\n    do {                                              \\\n        PyObject *_py_xdecref_tmp = (PyObject *)(op); \\\n        if (_py_xdecref_tmp != NULL)                  \\\n            Py_DECREF(_py_xdecref_tmp);               \\\n    } while (0)\n</code></pre>\n<p>另外, 在减少引用计数器的时候, 我们发现有一个宏<code>_Py_Dealloc</code>, 这个宏负责调用对象的<code>tp_dealloc</code>函数释放对象:</p>\n<pre><code class=\"c\">#define _Py_Dealloc(op) (                               \\\n    (*Py_TYPE(op)-&gt;tp_dealloc)((PyObject *)(op)))\n</code></pre>\n<p>而在<code>tp_dealloc</code>中又会调用<code>tp_free</code>, 这个函数指针一般都是<code>PyObject_GC_Del</code>函数:</p>\n<pre><code class=\"c\">void\nPyObject_GC_Del(void *op)\n{\n    PyGC_Head *g = AS_GC(op);\n    /* ... 省略部分释放前的处理 */\n    PyObject_FREE(g);\n}\n</code></pre>\n<p>最终, 回到了我们在上一节中讲到的<code>PyObject_FREE</code>, 释放分配的内存.</p>\n<p>所以引用计数的减量操作是这么一个流程:</p>\n<blockquote>\n<p><code>Py_DECREF -&gt; _PyDealloc -&gt; tp_dealloc -&gt; tp_free -&gt; PyObject_GC_Del -&gt; PyObject_FREE -&gt; PyObject_Free</code></p>\n</blockquote>\n<!-- 对于计数器, 我们还需要关注的一个问题是: 计数器溢出. -->\n<h2 id=\"容器对象\"><a href=\"#容器对象\" class=\"headerlink\" title=\"容器对象\"></a>容器对象</h2><p>并不是所有Python对象会发生循环引用, 只有那些可能保留了其它对象引用的对象, 才可能发生循环引用, 关于这类对象我们称之为”容器对象”.</p>\n<p>循环引用垃圾回收的对象只有这些容器对象. Python对于这些容器对象都分配了用于循环引用垃圾回收的结构体头, 这个头部包含一下信息:</p>\n<ul>\n<li>用于容器对象的双向链表的成员;</li>\n<li>用于复制引用计数器的成员;</li>\n</ul>\n<p>其定义如下:</p>\n<pre><code class=\"c\">[objimpl.h]\ntypedef union _gc_head {\n    struct {\n        union _gc_head *gc_next; /* 用于双向链表 */\n        union _gc_head *gc_prev; /* 用于双向链表 */\n        Py_ssize_t gc_refs; /* 用于复制 */\n    } gc;\n    double dummy;  /* force worst-case alignment */\n} PyGC_Head;\n</code></pre>\n<p>其中<code>dummy</code>的作用是: 即使结构体<code>gc</code>的大小为<code>9</code>字节这样不上不下的数值, <code>dummy</code>也可以将整个结构体<code>PyGC_Head</code>对齐为<code>long double</code>型.</p>\n<p>在Python中, 创建容器对象和创建普通对象的内存分布是不一样的:</p>\n<pre><code class=\"c\">[gcmodule.c]\nPyObject *\n_PyObject_GC_New(PyTypeObject *tp)\n{\n    PyObject *op = _PyObject_GC_Malloc(_PyObject_SIZE(tp));\n    if (op != NULL)\n        op = PyObject_INIT(op, tp);\n    return op;\n}\n</code></pre>\n<p>在生成容器对象的时候, 必须通过<code>_PyObject_GC_Malloc</code>分配用于循环引用垃圾回收的头:</p>\n<pre><code class=\"c\">#define _PyGC_REFS_UNTRACKED                    (-2)\n#define GC_UNTRACKED                    _PyGC_REFS_UNTRACKED\n\nPyObject *\n_PyObject_GC_Malloc(size_t basicsize)\n{\n    return _PyObject_GC_Alloc(0, basicsize);\n}\n\nstatic PyObject *\n_PyObject_GC_Alloc(int use_calloc, size_t basicsize)\n{\n    PyObject *op;\n    PyGC_Head *g;\n    size_t size;\n    size = sizeof(PyGC_Head) + basicsize; /* 为PyGC_Head和对象本身分配内存 */\n    g = (PyGC_Head *)PyObject_Malloc(size);\n    g-&gt;gc.gc_refs = 0;\n    _PyGCHead_SET_REFS(g, GC_UNTRACKED); \n    /* 开始进行循环引用垃圾回收 */\n    generations[0].count++; /* number of allocated GC objects */\n    if (generations[0].count &gt; generations[0].threshold &amp;&amp;\n        enabled &amp;&amp;\n        generations[0].threshold &amp;&amp;\n        !collecting &amp;&amp;\n        !PyErr_Occurred()) {\n        collecting = 1;\n        collect_generations();\n        collecting = 0;\n    }\n    op = FROM_GC(g);\n    return op;\n}\n</code></pre>\n<p>从上面的<code>_PyObject_GC_Malloc</code>可以看到, 对于容器对象, 在分配内存的时, 也为<code>PyGC_Head</code>分配了内存, 其位置位于容器对象之前.</p>\n<p>在<code>GC_Head</code>部分, 除了用于构建双向链表的两个指针, 还通过<code>_PyGCHead_SET_REFS(g, GC_UNTRACKED);</code>将<code>GC_UNTRACKED</code>设置到了<code>gc_refs</code>域上. 这个标志(<code>-2</code>)的意思是”这个容器对象还没有被追踪”, 当出现这个标志<code>GC</code>会认为这个容器对象还没有被连接到容器对象链表上. 关于这部分在后面还会讲到.</p>\n<p>所以经过这些后, 容器对象的内存分布应该如下:</p>\n<p><img src=\"/images/pygc-1.png\" alt=\"\"></p>\n<p>从图中, 我们可以发现一个问题, 那就是这些容器对象的头部有单独的一部分<code>PyGC_Head</code>, 但是在Python内部, 传递的是<code>*PyObject</code>指针. 这也就意味着需要我们在<code>PyGC_Head</code>和<code>PyObject_Head</code>之间进行地址转换, 而<code>FROM_GC</code>恰恰是将<code>PyGC_Head</code>转换成<code>PyObject_Head</code>的宏定义:</p>\n<pre><code class=\"c\">/* Get an object&#39;s GC head */\n#define AS_GC(o) ((PyGC_Head *)(o)-1)\n/* Get the object given the GC head */\n#define FROM_GC(g) ((PyObject *)(((PyGC_Head *)g)+1))\n</code></pre>\n<p>上面两个转换算法, 隐性要求<code>PyGC_Head</code>大小对齐, 如果<code>PyGC_Head</code>的大小没有对齐, 那么<code>FROM_GC</code>返回的地址也是对齐不上的.</p>\n<h2 id=\"追踪容器对象\"><a href=\"#追踪容器对象\" class=\"headerlink\" title=\"追踪容器对象\"></a>追踪容器对象</h2><p>为了释放循环引用, 需要将容器对象用双向链表连接起来. 不过在上面的内存分配过程中, 我们讲到<code>GC_UNTRACKED</code>标识着这个容器对象还没有被追踪, 那么就需要有个地方将容器对象加入双向链表中. 我们可以以列表对象的创建, 来看看容器对象是什么时候开始被追踪的:</p>\n<pre><code class=\"c\">PyObject *\nPyList_New(Py_ssize_t size)\n{\n    PyListObject *op;\n    ...\n    op = PyObject_GC_New(PyListObject, &amp;PyList_Type);\n    ...\n    _PyObject_GC_TRACK(op);\n    return (PyObject *) op;\n}\n</code></pre>\n<p>在创建<code>list</code>对象的最后, 会通过<code>_PyObject_GC_TRACK</code>宏连接容器对象链表:</p>\n<pre><code class=\"c\">#define _PyObject_GC_TRACK(o) do { \\\n    PyGC_Head *g = _Py_AS_GC(o); \\\n    if (_PyGCHead_REFS(g) != _PyGC_REFS_UNTRACKED) \\\n        Py_FatalError(&quot;GC object already tracked&quot;); \\\n    _PyGCHead_SET_REFS(g, _PyGC_REFS_REACHABLE); \\\n    g-&gt;gc.gc_next = _PyGC_generation0; \\\n    g-&gt;gc.gc_prev = _PyGC_generation0-&gt;gc.gc_prev; \\\n    g-&gt;gc.gc_prev-&gt;gc.gc_next = g; \\\n    _PyGC_generation0-&gt;gc.gc_prev = g; \\\n    } while (0);\n</code></pre>\n<p>这个宏有一点需要注意的是<code>do while</code>结构不是为了循环, 只是写宏的小技巧. 这个宏的过程可以概述为:</p>\n<ul>\n<li>首先从对象取出<code>PyGC_Head</code>的头地址;</li>\n<li>接下来将标识<code>_PyGC_REFS_REACHABLE</code>设置到<code>PyGC_Head</code>的<code>gc_refs</code>域, 表示”程序可能达到的对象”;</li>\n<li>最后拿出了连接所有容器对象的全局链表, 把这个对象加入到了链表中.</li>\n</ul>\n<p>循环引用垃圾回收正是利用这个全局链表来释放循环引用的对象.</p>\n<p>和追踪容器对象对应的, 有一个宏用于结束追踪容器对象: <code>_PyObject_GC_UNTRACK</code>.</p>\n<pre><code class=\"c\">#define _PyObject_GC_UNTRACK(o) do { \\\n    PyGC_Head *g = _Py_AS_GC(o); \\\n    _PyGCHead_SET_REFS(g, _PyGC_REFS_UNTRACKED); \\\n    g-&gt;gc.gc_prev-&gt;gc.gc_next = g-&gt;gc.gc_next; \\\n    g-&gt;gc.gc_next-&gt;gc.gc_prev = g-&gt;gc.gc_prev; \\\n    g-&gt;gc.gc_next = NULL; \\\n    } while (0);\n\n#define _PyObject_GC_IS_TRACKED(o) \\\n    (_PyGC_REFS(o) != _PyGC_REFS_UNTRACKED)\n</code></pre>\n<p>如果理解了上面的追踪容器对象, 那么这个宏也会十分容易理解: 标识容器对象未被追踪, 并将它从全局的容器对象链表中移除.</p>\n<p>另外, Python还提供了一个宏<code>_PyObject_GC_IS_TRACKED</code>, 用于检查容器对象是否被追踪.</p>\n<p>对于这个全局的容器对象链表, 我们可以画个图表示:</p>\n<p><img src=\"/images/pygc-2.png\" alt=\"\"></p>\n<h2 id=\"分代容器对象链表\"><a href=\"#分代容器对象链表\" class=\"headerlink\" title=\"分代容器对象链表\"></a>分代容器对象链表</h2><p>Python的容器对象链表被分为3代, 每一代都代表前面提到的一条容器对象链表. 为了引入分代机制, 需要增加一个额外的表头:</p>\n<pre><code class=\"c\">[gcmodule.c]\nstruct gc_generation {\n    PyGC_Head head;\n    int threshold; /* 开始GC的阀值 */\n    int count; /* 该代的对象数量 */\n};\n</code></pre>\n<p>容器对象将被连接到成员<code>head</code>, 当<code>count</code>成员数量超过<code>threshold</code>阀值时, Python就对这一代开启<code>GC</code>. Python通过一个全局变量来初始化各代的容器链表:</p>\n<pre><code class=\"c\">#define NUM_GENERATIONS 3\n#define GEN_HEAD(n) (&amp;generations[n].head)\nstatic struct gc_generation generations[NUM_GENERATIONS] = {\n    /* PyGC_Head,                               threshold,      count */\n    {{{GEN_HEAD(0), GEN_HEAD(0), 0}},           700,            0},\n    {{{GEN_HEAD(1), GEN_HEAD(1), 0}},           10,             0},\n    {{{GEN_HEAD(2), GEN_HEAD(2), 0}},           10,             0},\n};\n\nPyGC_Head *_PyGC_generation0 = GEN_HEAD(0);\n</code></pre>\n<p>各代的<code>PyGC_Head</code>, 双向链表都是以引用自身的形式初始化的, <code>_PyGC_generation0</code>指向0代容器对象链表.</p>\n<p><img src=\"/images/pygc-3.png\" alt=\"\"></p>\n<p>一开始所有刚创建的容器对象都被连接到0代链表上, 在<code>_PyObject_GC_Malloc</code>分配内存中, 会通过<code>generations[0].count++;</code>增加第0代所维护的链表的元素数量(这个<code>count</code>的增加被提前到追踪容器对象之前), 一旦这个<code>count</code>超过了<code>threshold</code>阀值, 就会触发<code>GC</code>. 从新生代到老生代, 只有经过循环引用垃圾回收存活下来的对象, 才能晋升.</p>\n<p>当第0代的对象数量超过阀值后(没有禁用<code>GC</code>/没有正在<code>GC</code>/没有发生<code>GC</code>错误), 就会触发<code>collect_generations</code>: </p>\n<pre><code class=\"c\">static Py_ssize_t\ncollect_generations(void)\n{\n    int i;\n    Py_ssize_t n = 0;\n\n    for (i = NUM_GENERATIONS-1; i &gt;= 0; i--) {\n        if (generations[i].count &gt; generations[i].threshold) {\n            if (i == NUM_GENERATIONS - 1\n                &amp;&amp; long_lived_pending &lt; long_lived_total / 4)\n                continue;\n            n = collect_with_callback(i);\n            break;\n        }\n    }\n    return n;\n}\n</code></pre>\n<p>通过这个函数我们可以看出来, Python的GC是通过第0代容器对象链表触发的. 在<code>collect_generations</code>中, 会找到超过阀值的”最老”的一代, 然后开始回收这一代的内存.</p>\n<p>需要注意关于<code>long-lived objects</code>, 这在注释中有解释:</p>\n<p>pass</p>\n<h2 id=\"标记–清除算法\"><a href=\"#标记–清除算法\" class=\"headerlink\" title=\"标记–清除算法\"></a>标记–清除算法</h2><p>这是正式进入到Python的垃圾回收, 位于<code>collect_with_callback</code>:</p>\n<pre><code class=\"c\">static Py_ssize_t\ncollect_with_callback(int generation)\n{\n    Py_ssize_t result, collected, uncollectable;\n    invoke_gc_callback(&quot;start&quot;, generation, 0, 0);\n    result = collect(generation, &amp;collected, &amp;uncollectable, 0);\n    invoke_gc_callback(&quot;stop&quot;, generation, collected, uncollectable);\n    return result;\n}\n</code></pre>\n<p>真正进行垃圾回收的是<code>collect</code>, 而<code>collect_with_callback</code>的作用是: 在之前和之后调用<code>callback</code>通知客户端垃圾回收开始或停止.</p>\n<pre><code class=\"c\">\nstatic Py_ssize_t\ncollect(int generation, Py_ssize_t *n_collected, Py_ssize_t *n_uncollectable,\n        int nofail)\n{\n    int i;\n    Py_ssize_t m = 0; /* # objects collected */\n    Py_ssize_t n = 0; /* # unreachable objects that couldn&#39;t be collected */\n    PyGC_Head *young; /* 即将查找的一代 */\n    PyGC_Head *old; /* 下一代 */\n    PyGC_Head unreachable; /* 无异样不能到达对象的链表 */\n    PyGC_Head finalizers;  /* objects with, &amp; reachable from, __del__ */\n    PyGC_Head *gc;\n    _PyTime_t t1 = 0;   /* initialize to prevent a compiler warning */\n\n    struct gc_generation_stats *stats = &amp;generation_stats[generation];\n\n    /* 更新计数器 */\n    if (generation+1 &lt; NUM_GENERATIONS)\n        generations[generation+1].count += 1;\n    for (i = 0; i &lt;= generation; i++)\n        generations[i].count = 0;\n\n    /* 合并我们正在处理的代及其以下的代的链表 */\n    for (i = 0; i &lt; generation; i++) {\n        gc_list_merge(GEN_HEAD(i), GEN_HEAD(generation));\n    }\n\n    /* 给old变量赋值 */\n    young = GEN_HEAD(generation);\n    if (generation &lt; NUM_GENERATIONS-1)\n        old = GEN_HEAD(generation+1);\n    else\n        old = young;\n\n    update_refs(young); /* 把引用计数器复制到用于循环引用垃圾回收的头里 */\n    subtract_refs(young); /* 删除实际引用 */\n\n    /* 将计数器值为0的对象移动的unreachable对象链表中 */\n    gc_list_init(&amp;unreachable); \n    move_unreachable(young, &amp;unreachable);\n\n    /* 将循环引用垃圾回收中幸存的对象移到下一代 */\n    if (young != old) {\n        if (generation == NUM_GENERATIONS - 2) {\n            long_lived_pending += gc_list_size(young);\n        }\n        gc_list_merge(young, old);\n    }\n    else {\n        untrack_dicts(young);\n        long_lived_pending = 0;\n        long_lived_total = gc_list_size(young);\n    }\n\n    /* 移出unreachable对象链表中有终结器的对象 */\n    gc_list_init(&amp;finalizers);\n    move_legacy_finalizers(&amp;unreachable, &amp;finalizers);\n    move_legacy_finalizer_reachable(&amp;finalizers);\n\n\n    /* 处理弱引用, 如果可能, 调用弱引用中注册的callback操作 */\n    m += handle_weakrefs(&amp;unreachable, old);\n\n    /* 尝试调用unreachable中的容器对象tp_finalize操作, 如果有的话 */\n    finalize_garbage(&amp;unreachable);\n\n    if (check_garbage(&amp;unreachable)) {\n        revive_garbage(&amp;unreachable);\n        gc_list_merge(&amp;unreachable, old);\n    }\n    else {\n        /* F. 调用tp_clear回收&quot;不可达&quot;容器对象\n        delete_garbage(&amp;unreachable, old);\n    }\n\n      /* E.处理finalizers链表 */\n    (void)handle_legacy_finalizers(&amp;finalizers, old);\n\n    /* 如果第3代超过了阀值, 则会清理freelists */\n    if (generation == NUM_GENERATIONS-1) {\n        clear_freelists();\n    }\n\n    if (PyErr_Occurred()) { /* 发生了GC异常 */\n        if (nofail) {\n            PyErr_Clear();\n        }\n        else {\n            if (gc_str == NULL)\n                gc_str = PyUnicode_FromString(&quot;garbage collection&quot;);\n            PyErr_WriteUnraisable(gc_str);\n            Py_FatalError(&quot;unexpected exception during garbage collection&quot;);\n        }\n    }\n\n    /* 更新统计信息 */\n    if (n_collected)\n        *n_collected = m;\n    if (n_uncollectable)\n        *n_uncollectable = n;\n    stats-&gt;collections++;\n    stats-&gt;collected += m;\n    stats-&gt;uncollectable += n;\n    return n+m;\n}\n</code></pre>\n<p>我们将这一过程分为几个小过程来一步步分析:</p>\n<ul>\n<li><p>(A). get_list_merge(): 将<code>from</code>链表连接到<code>to</code>链表的末尾:</p>\n<pre><code class=\"c\">  [gcmodule.c]\n  static void gc_list_merge(PyGC_Head *from, PyGC_Head *to)\n  {\n      PyGC_Head *tail;\n      assert(from != to);\n      if (!gc_list_is_empty(from)) {\n          tail = to-&gt;gc.gc_prev;\n          tail-&gt;gc.gc_next = from-&gt;gc.gc_next;\n          tail-&gt;gc.gc_next-&gt;gc.gc_prev = tail;\n          to-&gt;gc.gc_prev = from-&gt;gc.gc_prev;\n          to-&gt;gc.gc_prev-&gt;gc.gc_next = to;\n      }\n      gc_list_init(from);\n  }\n\n  static void gc_list_init(PyGC_Head *list)\n  {\n      list-&gt;gc.gc_prev = list;\n      list-&gt;gc.gc_next = list;\n  }\n</code></pre>\n<p>  这也是<code>collect_generations</code>找到的是超过阀值”最老”的一代, 而<code>GC</code>能够处理它以及比它”年轻”的代的原因. 之后的标记—清楚算法将在这条合并后的链表上进行.</p>\n</li>\n<li><p>(B). update_refs()和subtract_refs(): 在这个阶段我们需要找到”Root Object”(不能被删除的对象)对象的集合. 这个过程中关键点在于怎么处理循环引用, 例如<code>A</code>引用<code>B</code>, 而<code>B</code>又引用<code>A</code>的情况.</p>\n<ul>\n<li>一种可选的方法是, 对于<code>A</code>引用<code>B</code>, 则将<code>B</code>的引用计数减一; 反之, 则将<code>A</code>的引用计数减一. 如果两个对象互相引用, 那么它的引用计数将变为<code>0</code>, 表示”不可达”.<br><br>这种方法有个问题是, 如果<code>A</code>引用<code>C</code>, 而<code>C</code>不在这个链表中, 如果将<code>C</code>的引用计数减一, 而最终<code>A</code>没有被回收, 那么将会造成对<code>C</code>的悬空引用, 这就需要对<code>C</code>的引用进行恢复.</li>\n<li><p>针对循环引用, Python采用更好的做法: 复制原始引用, 只改动副本计数器, 即<code>gc_refs</code>.</p>\n<pre><code class=\"c\">static void\nupdate_refs(PyGC_Head *containers)\n{\n  PyGC_Head *gc = containers-&gt;gc.gc_next;\n  for (; gc != containers; gc = gc-&gt;gc.gc_next) {\n      _PyGCHead_SET_REFS(gc, Py_REFCNT(FROM_GC(gc)));\n  }\n}\n</code></pre>\n<p><code>update_refs</code>遍历容器对象链表, 复制容器对象的真实引用计数到<code>PyGC_Head-&gt;gc_refs</code>中. 而<code>subtract_refs</code>负责清除容链表器对象之间的循环引用.</p>\n<pre><code class=\"c\">static void\nsubtract_refs(PyGC_Head *containers)\n{\n  traverseproc traverse;\n  PyGC_Head *gc = containers-&gt;gc.gc_next;\n  for (; gc != containers; gc=gc-&gt;gc.gc_next) {\n      traverse = Py_TYPE(FROM_GC(gc))-&gt;tp_traverse;\n      (void) traverse(FROM_GC(gc),\n                     (visitproc)visit_decref,\n                     NULL);\n  }\n}\n</code></pre>\n<p><code>subtract_refs</code>中会遍历所有容器对象, 然后获得容器对象上的<code>tp_traverse</code>函数指针, 这个函数的会遍历容器对象里的元素, 并且调用函数参数<code>visit</code>传递进去的函数来访问元素. 这样一来, <code>subtract_refs</code>中就能通过传递进去函数<code>visit_decref</code>访问容器对象里的元素.<br><br>*NOTE: <code>traverse</code>实现了访问者模式, 这里访问用的函数为<code>visit_decref</code>.</p>\n<p>下面是<code>visit_decref</code>的定义:</p>\n<pre><code class=\"c\">static int\nvisit_decref(PyObject *op, void *data)\n{\n  if (PyObject_IS_GC(op)) {\n      PyGC_Head *gc = AS_GC(op);\n      if (_PyGCHead_REFS(gc) &gt; 0)\n          _PyGCHead_DECREF(gc);\n  }\n  return 0;\n}\n</code></pre>\n<p>在完成了<code>subtract_refs</code>之后, 容器对象链表中所有容器对象之间的循环引用都已被摘除. 如果还有容器对象的<code>gc_ref!=0</code>, 就意味着存在这些对象的外部引用, 也就是作为后面”标记—清楚”算法的”Root Object”集合.</p>\n</li>\n</ul>\n</li>\n<li>(C). move_unreachable(): 将原始链表划分为两个链表.<pre><code class=\"c\">  static void\n  move_unreachable(PyGC_Head *young, PyGC_Head *unreachable)\n  {\n      PyGC_Head *gc = young-&gt;gc.gc_next;\n      while (gc != young) {\n          PyGC_Head *next;\n          if (_PyGCHead_REFS(gc)) {\n              PyObject *op = FROM_GC(gc);\n              traverseproc traverse = Py_TYPE(op)-&gt;tp_traverse;\n              _PyGCHead_SET_REFS(gc, GC_REACHABLE);\n              (void) traverse(op, (visitproc)visit_reachable, (void *)young);\n              next = gc-&gt;gc.gc_next;\n          }\n          else {\n              next = gc-&gt;gc.gc_next;\n              gc_list_move(gc, unreachable);\n              _PyGCHead_SET_REFS(gc, GC_TENTATIVELY_UNREACHABLE);\n          }\n          gc = next;\n      }\n  }\n</code></pre>\n  这一过程分为两种情况:<ul>\n<li>gc_refs为0的容器对象: 对于这类容器对象, 我们将它标记为<code>GC_TENTATIVELY_UNREACHABLE</code>, 意思是”暂且认为她是不可达的”;</li>\n<li>gc_refs不为0的容器对象: 对于这些有外部引用的对象, 即<code>Root Object</code>, 我们会将它标记为<code>GC_REACHABLE</code>, 意思是”可达”的. 而且我们使用<code>visit_reachable</code>去访问容器对象里面的元素:<pre><code class=\"c\">static int\nvisit_reachable(PyObject *op, PyGC_Head *reachable)\n{\n  if (PyObject_IS_GC(op)) { \n      PyGC_Head *gc = AS_GC(op);\n      const Py_ssize_t gc_refs = _PyGCHead_REFS(gc);\n      if (gc_refs == 0) { /* 对于还没有处理的对象, 恢复其gc_refs */\n          _PyGCHead_SET_REFS(gc, 1);\n      }/* 对于已经被挪到unreachable链表的对象, 再将其移到young链表中 */\n      else if (gc_refs == GC_TENTATIVELY_UNREACHABLE) { \n          gc_list_move(gc, reachable);\n          _PyGCHead_SET_REFS(gc, 1);\n      }\n  }\n  return 0;\n}\n</code></pre>\n对于”可达”的容器对象里的容器对象, 如果, <code>gc_refs</code>为0, 则将其设定为1, 以表示准确的引用关系; 如果<code>gc_refs</code>为<code>GC_TENTATIVELY_UNREACHABLE</code>, 说明里面存了非活动对象, 需要从里面救出来, 移动到<code>reachable</code>链表(即<code>young</code>容器对象链表), 将<code>gc_refs</code>设为1.</li>\n</ul>\n</li>\n<li>(D). move_legacy_finalizers(): 移出<code>unreachable</code>容器链表中那些有终结器的容器对象, 并加入<code>finalizers</code>链表, 标识为<code>GC_REACHABLE</code>.<pre><code class=\"c\">  static void\n  move_legacy_finalizers(PyGC_Head *unreachable, PyGC_Head *finalizers)\n  {\n      PyGC_Head *gc;\n      PyGC_Head *next;\n      for (gc = unreachable-&gt;gc.gc_next; gc != unreachable; gc = next) {\n          PyObject *op = FROM_GC(gc);\n          next = gc-&gt;gc.gc_next;\n          if (has_legacy_finalizer(op)) {\n              gc_list_move(gc, finalizers);\n              _PyGCHead_SET_REFS(gc, GC_REACHABLE);\n          }\n      }\n  }\n</code></pre>\n</li>\n<li>(E). <code>move_legacy_finalizer_reachable()</code>: 从已经移出的<code>finalizers</code>链表中容器对象开始查找, 移出该对象引用的对象, 这些被引用的对象也不应该被释放.<pre><code class=\"c\">  static void\n  move_legacy_finalizer_reachable(PyGC_Head *finalizers)\n  {\n      traverseproc traverse;\n      PyGC_Head *gc = finalizers-&gt;gc.gc_next;\n      for (; gc != finalizers; gc = gc-&gt;gc.gc_next) {\n          traverse = Py_TYPE(FROM_GC(gc))-&gt;tp_traverse;\n          (void) traverse(FROM_GC(gc), visitproc)visit_move, (void *)finalizers);\n      }\n  }\n</code></pre>\n<pre><code class=\"c\">  static int\n  visit_move(PyObject *op, PyGC_Head *tolist)\n  {\n      if (PyObject_IS_GC(op)) {\n          if (IS_TENTATIVELY_UNREACHABLE(op)) {\n              PyGC_Head *gc = AS_GC(op);\n              gc_list_move(gc, tolist);\n              _PyGCHead_SET_REFS(gc, GC_REACHABLE);\n          }\n      }\n      return 0;\n  }\n</code></pre>\n</li>\n<li><p>(F). delete_garbage(): 打破容器对象的循环引用, 这就需要对对象的实际ob_ref做修改, 是它变为0, 触发对象的销毁.</p>\n<pre><code class=\"c\">  static void\n  delete_garbage(PyGC_Head *collectable, PyGC_Head *old)\n  {\n      inquiry clear;\n      while (!gc_list_is_empty(collectable)) {\n          PyGC_Head *gc = collectable-&gt;gc.gc_next;\n          PyObject *op = FROM_GC(gc);\n          if ((clear = Py_TYPE(op)-&gt;tp_clear) != NULL) {\n              Py_INCREF(op);\n              clear(op);\n              Py_DECREF(op);\n          }\n          if (collectable-&gt;gc.gc_next == gc) {\n              gc_list_move(gc, old);\n              _PyGCHead_SET_REFS(gc, GC_REACHABLE);\n          }\n      }\n  }\n</code></pre>\n<p>  在其中会调用容器对象的<code>tp_clear</code>操作, 调整容器对象中引用的每个对象的引用计数值, 从而打破循环引用安全回收.</p>\n<p>  现在我们假设两个列表<code>list_1</code>和<code>list_2</code>互相引用, 我们看看是怎么回收这两个对象的. 假设先调用<code>list_1</code>的<code>tp_clear</code>操作:</p>\n<pre><code class=\"c\">  static int\n  list_clear(PyListObject *a)\n  {\n      Py_ssize_t i;\n      PyObject **item = a-&gt;ob_item;\n      if (item != NULL) {\n          i = Py_SIZE(a);\n          Py_SIZE(a) = 0;\n          a-&gt;ob_item = NULL;\n          a-&gt;allocated = 0;\n          while (--i &gt;= 0) {\n              Py_XDECREF(item[i]);\n          }\n          PyMem_FREE(item);\n      }\n      return 0;\n  }\n</code></pre>\n<p>  它会先减少<code>list_1</code>中引用的每一个对象的引用计数, 即<code>list_2</code>的引用计数会减少到0, 引发对象销毁工作, 调用<code>list_2</code>的<code>tp_dealloc</code>操作, :</p>\n<pre><code class=\"c\">  static void\n  list_dealloc(PyListObject *op)\n  {\n      Py_ssize_t i;\n      PyObject_GC_UnTrack(op);\n      if (op-&gt;ob_item != NULL) {\n          i = Py_SIZE(op);\n          while (--i &gt;= 0) {\n              Py_XDECREF(op-&gt;ob_item[i]);\n          }\n          PyMem_FREE(op-&gt;ob_item);\n      }\n      ......\n  }\n</code></pre>\n<p>  <code>list_2</code>的<code>tp_dealloc</code>首先会将自己从<code>GC</code>容器对象链表中移出, 同样它也会调整引用的对象的计数值, 使得<code>list_1</code>的引用计数减少到0, 触发<code>list_1</code>的销毁.</p>\n</li>\n<li><p>(G). handle_legacy_finalizers(): 对全局变量<code>garbage</code>注册之前保存的<code>finalizers</code>链表.</p>\n<pre><code class=\"c\">  static int\n  handle_legacy_finalizers(PyGC_Head *finalizers, PyGC_Head *old)\n  {\n      PyGC_Head *gc = finalizers-&gt;gc.gc_next;\n      if (garbage == NULL) {\n          garbage = PyList_New(0);\n      }\n      for (; gc != finalizers; gc = gc-&gt;gc.gc_next) {\n          PyObject *op = FROM_GC(gc);\n          if ((debug &amp; DEBUG_SAVEALL) || has_legacy_finalizer(op)) {\n              if (PyList_Append(garbage, op) &lt; 0)\n                  return -1;\n          }\n      }\n      gc_list_merge(finalizers, old);\n      return 0;\n  }\n</code></pre>\n<p>  全局变量<code>garbage</code>是一个<code>PyList_Object</code>, 它保存了那些注册了<code>__del__</code>操作的实例对象, 而且这些对象会晋升到”老一代”.</p>\n<p>  为了能处理这些变量, Python提供了<code>gc</code>模块, 来处理全局变量<code>garbage</code>:</p>\n<pre><code class=\"python\">  &gt;&gt;&gt; import gc\n  &gt;&gt;&gt; gc.garbage\n</code></pre>\n</li>\n</ul>\n<p>另外, 关于Python的垃圾回收有几点需要注意的:</p>\n<ul>\n<li>在垃圾回收中有对弱引用(<code>weakref</code>)的处理, 因为它们能够注册<code>callback</code>, 能被正确的清理;</li>\n<li>而有终结器<code>__del__</code>的实例对象不同, 在Python3之前它们是不能够自动清理的, 原因是假设两个对象<code>A`</code>B<code>循环引用, 各自有自己的终结器, 如果先终结化了第一个对象</code>A<code>, 而终结第二个对象</code>B<code>的时候, 如果需要用到</code>A`, 那么就会陷入矛盾. 而在Python3中是通过一个临时可见的链表保存着这些容器对象, 使得垃圾回收能够清理这些有终结器的实例对象.</li>\n<li>虽然大部分对象创建的时候通过<code>PyGC_New</code>添加到了容器对象链表中, 但是并非垃圾收集机制才能回收, 正常的引用计数就可以完成对象的销毁.</li>\n</ul>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Sublime快捷键","url":"http://shawnz.me/posts/691b6e2d/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"精华版\"><a href=\"#精华版\" class=\"headerlink\" title=\"精华版\"></a>精华版</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Ctrl+Shift+P</strong></td>\n<td>打开命令面板</td>\n</tr>\n<tr>\n<td>Ctrl+P</td>\n<td>搜索项目中的文件</td>\n</tr>\n<tr>\n<td>Ctrl+G</td>\n<td>跳转到第几行</td>\n</tr>\n<tr>\n<td><strong>Ctrl+W</strong></td>\n<td>关闭<strong>当前</strong>打开文件</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+W</strong></td>\n<td>关闭<strong>所有</strong>打开文件</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+V</td>\n<td>粘贴并格式化</td>\n</tr>\n<tr>\n<td><strong>Ctrl+D</strong></td>\n<td>选择单词，重复可增加选择下一个相同的单词</td>\n</tr>\n<tr>\n<td><strong>Ctrl+L</strong></td>\n<td>选择行，重复可依次增加选择下一行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+L</td>\n<td>选择多行</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Enter</strong></td>\n<td>在当前行<strong>后</strong>插入新行</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+Enter</strong></td>\n<td>在当<strong>前</strong>行前插入新行</td>\n</tr>\n<tr>\n<td>Ctrl+X</td>\n<td>删除当前行</td>\n</tr>\n<tr>\n<td>Ctrl+M</td>\n<td>跳转到对应括号</td>\n</tr>\n<tr>\n<td>Ctrl+U</td>\n<td>软撤销，撤销光标位置</td>\n</tr>\n<tr>\n<td><strong>Ctrl+J</strong></td>\n<td><strong>合并行（==下一行移上来==）</strong></td>\n</tr>\n<tr>\n<td><strong>Ctrl+F</strong></td>\n<td>查找内容</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+F</td>\n<td>查找并替换</td>\n</tr>\n<tr>\n<td><strong>Ctrl+H</strong></td>\n<td><strong>替换</strong>（可以全部也可以部分替换）(也可以查找)</td>\n</tr>\n<tr>\n<td>Ctrl+R</td>\n<td>前往 method</td>\n</tr>\n<tr>\n<td>Ctrl+N</td>\n<td>新建窗口</td>\n</tr>\n<tr>\n<td><strong>Ctrl+K+B</strong></td>\n<td>（<strong>要先按Ctrl+K再按B</strong>）==开关侧栏==</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+M</td>\n<td>？选中当前括号内容，重复可选着括号本身</td>\n</tr>\n<tr>\n<td>Ctrl+F2</td>\n<td>设置/删除标记</td>\n</tr>\n<tr>\n<td>Ctrl+/</td>\n<td>注释当前行</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+/</td>\n<td>当前位置插入注释</td>\n</tr>\n<tr>\n<td>Ctrl+Alt+/</td>\n<td>？块注释，并Focus到首行，写注释说明用的</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+A</td>\n<td>选择当前标签前后，修改标签用的</td>\n</tr>\n<tr>\n<td>F11</td>\n<td>全屏</td>\n</tr>\n<tr>\n<td>Shift+F11</td>\n<td>全屏免打扰模式，只编辑当前文件</td>\n</tr>\n<tr>\n<td><strong>Alt+F3</strong></td>\n<td>选择所有相同的词</td>\n</tr>\n<tr>\n<td><strong>Alt+.</strong></td>\n<td>闭合标签</td>\n</tr>\n<tr>\n<td><strong>Alt+Shift+数字</strong></td>\n<td><strong>分屏显示</strong></td>\n</tr>\n<tr>\n<td><strong>Alt+数字</strong></td>\n<td>切换打开第N个文件</td>\n</tr>\n<tr>\n<td>Shift+右键拖动(或中键拖动）</td>\n<td>光标多不，用来更改或插入列内容</td>\n</tr>\n<tr>\n<td>鼠标的前进后退键</td>\n<td>可切换Tab文件</td>\n</tr>\n<tr>\n<td>按Ctrl,依次点击或选取</td>\n<td>可需要编辑的多个位置</td>\n</tr>\n<tr>\n<td>按Ctrl+Shift+上下键</td>\n<td>可替换行</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"选择类\"><a href=\"#选择类\" class=\"headerlink\" title=\"选择类\"></a>选择类</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+D</td>\n<td>选中光标所占的文本，继续操作则会选中下一个相同的文本。</td>\n</tr>\n<tr>\n<td><strong>Alt+F3</strong></td>\n<td>选中文本按下快捷键，即可一次性选择全部的相同文本进行同时编辑。举个例子：快速选中并更改所有相同的变量名、函数名等。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+L</strong></td>\n<td><strong>选中整行，继续操作则继续选择下一行</strong>，++继续操作的效果和 Shift+↓效果类似++。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+L</strong></td>\n<td>++先选中多行，再按下快捷键，会在==每行行尾插入光标==，即可同时编辑这些行++</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+M</td>\n<td>选择括号内的内容（继续选择父括号）。举个例子：快速选中删除函数中的代码，重写函数体代码或重写括号内里的内容。</td>\n</tr>\n<tr>\n<td>Ctrl+M</td>\n<td>？光标移动至括号内结束或开始的位置。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Enter</strong></td>\n<td>在下一行插入新行。举个例子：即使光标不在行尾，也能快速向下插入一行。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+Enter</strong></td>\n<td>在上一行插入新行。举个例子：即使光标不在行首，也能快速向上插入一行。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+[</td>\n<td>选中代码，按下快捷键，折叠代码。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+]</td>\n<td>选中代码，按下快捷键，展开代码。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+K+0</strong></td>\n<td>展开所有折叠代码。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+←</strong></td>\n<td>向左<strong>单位性地移动光标</strong>，快速移动光标。</td>\n</tr>\n<tr>\n<td>Ctrl+→</td>\n<td>向右单位性地移动光标，快速移动光标。</td>\n</tr>\n<tr>\n<td><strong>shift+↑</strong></td>\n<td>向上选中多行。</td>\n</tr>\n<tr>\n<td>shift+↓</td>\n<td>向下选中多行。</td>\n</tr>\n<tr>\n<td><strong>Shift+←</strong></td>\n<td>向左选中文本。</td>\n</tr>\n<tr>\n<td>Shift+→</td>\n<td>向右选中文本。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+←</strong></td>\n<td>向左单位性地选中文本。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+→</td>\n<td>向右单位性地选中文本。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+↑</td>\n<td>将光标所在行和上一行代码互换（将光标所在行插入到上一行之前）。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+↓</td>\n<td>将光标所在行和下一行代码互换（将光标所在行插入到下一行之后）。</td>\n</tr>\n<tr>\n<td>Ctrl+Alt+↑</td>\n<td>向上添加多行光标，可同时编辑多行。</td>\n</tr>\n<tr>\n<td>Ctrl+Alt+↓</td>\n<td>向下添加多行光标，可同时编辑多行。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"编辑类\"><a href=\"#编辑类\" class=\"headerlink\" title=\"编辑类\"></a>编辑类</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+J</td>\n<td>合并选中的多行代码为一行。举个例子：将多行格式的CSS属性合并为一行。</td>\n</tr>\n<tr>\n<td>Ctrl+Shift+D</td>\n<td>复制光标所在整行，插入到下一行。</td>\n</tr>\n<tr>\n<td>Tab / ctrl+]</td>\n<td>向右缩进。</td>\n</tr>\n<tr>\n<td><strong>Shift+Tab / ctrl+[</strong></td>\n<td>向左缩进。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+K+K</strong></td>\n<td>从光标处开始删除代码至行尾。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+K</strong></td>\n<td>删除整行（<strong>也可以用Ctrl+X</strong>来剪切整行）</td>\n</tr>\n<tr>\n<td>Ctrl+/</td>\n<td>注释单行。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+Shift+/</strong></td>\n<td>注释多行。</td>\n</tr>\n<tr>\n<td>Ctrl+K+U</td>\n<td>转换大写。</td>\n</tr>\n<tr>\n<td>Ctrl+K+L</td>\n<td>转换小写。</td>\n</tr>\n<tr>\n<td>Ctrl+Z</td>\n<td>撤销。</td>\n</tr>\n<tr>\n<td>Ctrl+Y</td>\n<td>恢复撤销。</td>\n</tr>\n<tr>\n<td>Ctrl+U</td>\n<td>软撤销，感觉和 Gtrl+Z 一样。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+F2</strong></td>\n<td><strong>设置书签</strong></td>\n</tr>\n<tr>\n<td>Ctrl+T</td>\n<td>左右字母互换。</td>\n</tr>\n<tr>\n<td><strong>F6</strong></td>\n<td><strong>单词检测拼写</strong></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"搜索类\"><a href=\"#搜索类\" class=\"headerlink\" title=\"搜索类\"></a>搜索类</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Ctrl+F</strong></td>\n<td>打开底部搜索框，查找关键字。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+shift+F</strong></td>\n<td>在<strong>文件夹内查找</strong>，与普通编辑器不同的地方是<strong>sublime允许添加多个文件夹进行查找</strong>，略高端，未研究。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+P</strong></td>\n<td><strong>打开搜索框</strong>。举个例子：1、输入当前项目中的文件名，快速搜索文件，2、输入@和关键字，查找文件中函数名，3、输入：和数字，跳转到文件中该行代码，4、输入#和关键字，查找变量名。</td>\n</tr>\n<tr>\n<td>Ctrl+G</td>\n<td>打开搜索框，自动带：，输入数字跳转到该行代码。举个例子：在页面代码比较长的文件中快速定位。</td>\n</tr>\n<tr>\n<td>Ctrl+R</td>\n<td>打开搜索框，自动带@，输入关键字，查找文件中的函数名。举个例子：在函数较多的页面快速查找某个函数。</td>\n</tr>\n<tr>\n<td>Ctrl+：</td>\n<td>打开搜索框，自动带#，输入关键字，查找文件中的变量名、属性名等。</td>\n</tr>\n<tr>\n<td><strong>==Ctrl+Shift+P==</strong></td>\n<td><strong>==打开命令框==</strong>。场景例子：打开命名框，输入关键字，调用sublimetext或插件的功能，例如使用package安装插件。</td>\n</tr>\n<tr>\n<td>Esc</td>\n<td>退出光标多行选择，退出搜索框，命令框等。</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"显示类\"><a href=\"#显示类\" class=\"headerlink\" title=\"显示类\"></a>显示类</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>操作</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><strong>Ctrl+Tab</strong></td>\n<td>++按==文件浏览过的顺序==，切换当前窗口的标签页++</td>\n</tr>\n<tr>\n<td><strong>Ctrl+PageDown</strong></td>\n<td>向左切换当前窗口的标签页。</td>\n</tr>\n<tr>\n<td><strong>Ctrl+PageUp</strong></td>\n<td>向右切换当前窗口的标签页。</td>\n</tr>\n<tr>\n<td>Alt+Shift+1</td>\n<td>窗口分屏，恢复默认1屏（非小键盘的数字）</td>\n</tr>\n<tr>\n<td>Alt+Shift+2</td>\n<td>左右分屏-2列</td>\n</tr>\n<tr>\n<td>Alt+Shift+3</td>\n<td>左右分屏-3列</td>\n</tr>\n<tr>\n<td>Alt+Shift+4</td>\n<td>左右分屏-4列</td>\n</tr>\n<tr>\n<td>Alt+Shift+5</td>\n<td>等分4屏</td>\n</tr>\n<tr>\n<td>Alt+Shift+8</td>\n<td>垂直分屏-2屏</td>\n</tr>\n<tr>\n<td>Alt+Shift+9</td>\n<td>垂直分屏-3屏</td>\n</tr>\n<tr>\n<td>Ctrl+K+B</td>\n<td>开启/关闭侧边栏。</td>\n</tr>\n<tr>\n<td><strong>F11</strong></td>\n<td><strong>全屏模式</strong></td>\n</tr>\n<tr>\n<td><strong>Shift+F11</strong></td>\n<td><strong>免打扰模式</strong></td>\n</tr>\n</tbody>\n</table>\n","categories":["工具"],"tags":["工具","快捷键"]},{"title":"Python源码阅读-运行时环境初始化","url":"http://shawnz.me/posts/73bb8543/","content":"<p>前面已经接触了许多执行引擎相关的工作，然而关于Python虚拟机还有一大块的是我们没有了解的，那就是运行时环境的初始化。</p>\n<p>Python3启动后真正有意义的初始化动作是从<code>Py_Initialize</code>(位于<code>pylifecycle.c</code>文件)开始的，其内部调用的就是<code>_Py_InitializeEx_Private</code>函数，本节的主要内容就是以这个函数为入口，深入理解Python虚拟机的启动流程。</p>\n<a id=\"more\"></a>\n<h2 id=\"线程模型\"><a href=\"#线程模型\" class=\"headerlink\" title=\"线程模型\"></a>线程模型</h2><p>在接触虚拟机启动之前先了解一下Python的线程模型，我们知道Python的进程和线程是来自于操作系统，这里所说的线程模型是指在Python内部维护的这些操作系统进程和线程状态。下面是进程和线程的结构体定义：</p>\n<pre><code class=\"c\">typedef struct _is {\n    struct _is *next;\n    struct _ts *tstate_head;\n    PyObject *modules;\n    PyObject *modules_by_index;\n    PyObject *sysdict;\n    PyObject *builtins;\n    ......\n    _PyFrameEvalFunction eval_frame;\n} PyInterpreterState;\n</code></pre>\n<p>以及</p>\n<pre><code class=\"c\">typedef struct _ts {\n    struct _ts *prev;\n    struct _ts *next;\n    PyInterpreterState *interp;\n    struct _frame *frame;\n    int recursion_depth;\n    ......\n    PyObject *dict;  /* Stores per-thread state */\n\n    int gilstate_counter;\n    long thread_id; /* Thread id where this tstate was created */\n    ......\n} PyThreadState;\n</code></pre>\n<h2 id=\"线程环境初始化\"><a href=\"#线程环境初始化\" class=\"headerlink\" title=\"线程环境初始化\"></a>线程环境初始化</h2><p>在虚拟机启动的时候，首先会初始化线程和进程环境。</p>\n<pre><code class=\"c\">interp = PyInterpreterState_New();\ntstate = PyThreadState_New(interp);\n(void) PyThreadState_Swap(tstate);\n</code></pre>\n<p>可以看到虚拟机首先会通过<code>PyInterpreterState_New</code>创建一个进程对象：</p>\n<pre><code class=\"c\">static PyInterpreterState *interp_head = NULL;\n\nPyInterpreterState *\nPyInterpreterState_New(void)\n{\n    PyInterpreterState *interp = (PyInterpreterState *)\n                                 PyMem_RawMalloc(sizeof(PyInterpreterState));\n    if (interp != NULL) {\n        HEAD_INIT();\n        interp-&gt;modules = NULL;\n        interp-&gt;modules_by_index = NULL;\n        interp-&gt;sysdict = NULL;\n        interp-&gt;builtins = NULL;\n        interp-&gt;builtins_copy = NULL;\n        interp-&gt;tstate_head = NULL;\n        ......\n        interp-&gt;eval_frame = _PyEval_EvalFrameDefault;\n        HEAD_LOCK();\n        interp-&gt;next = interp_head;\n        interp_head = interp;\n        HEAD_UNLOCK();\n    }\n    return interp;\n}\n</code></pre>\n<p>在python内部维护着一套全局管理的<code>PyInterpreterState</code>链表，表头为<code>interp_head</code>，通过指针<code>interp-&gt;next</code>指向下一个进程对象。</p>\n<p>在创建完进程对象后，接着又创建了一个全新线程状态对象：</p>\n<pre><code class=\"c\">PyThreadState *\nPyThreadState_New(PyInterpreterState *interp)\n{\n    return new_threadstate(interp, 1);\n}\n\nstatic PyThreadState *\nnew_threadstate(PyInterpreterState *interp, int init)\n{\n    PyThreadState *tstate = (PyThreadState *)PyMem_RawMalloc(sizeof(PyThreadState));\n\n    if (_PyThreadState_GetFrame == NULL) /* 设置全局的函数调用栈获取函数 */\n        _PyThreadState_GetFrame = threadstate_getframe;\n\n    if (tstate != NULL) {\n        tstate-&gt;interp = interp; /* 和线程对应的进程对象 */\n\n        tstate-&gt;frame = NULL;\n        tstate-&gt;recursion_depth = 0;\n        tstate-&gt;overflowed = 0;\n        tstate-&gt;recursion_critical = 0;\n        tstate-&gt;tracing = 0;\n        tstate-&gt;use_tracing = 0;\n        tstate-&gt;gilstate_counter = 0;\n        tstate-&gt;async_exc = NULL;\n#ifdef WITH_THREAD\n        tstate-&gt;thread_id = PyThread_get_thread_ident(); /* 线程标识 */\n#else\n        tstate-&gt;thread_id = 0;\n#endif\n        tstate-&gt;dict = NULL;\n        ......\n        if (init)\n            _PyThreadState_Init(tstate);\n        HEAD_LOCK();\n        tstate-&gt;prev = NULL; /* 线程链 */\n        tstate-&gt;next = interp-&gt;tstate_head;\n        if (tstate-&gt;next)\n            tstate-&gt;next-&gt;prev = tstate;\n        interp-&gt;tstate_head = tstate; /* 反向关联进程 */\n        HEAD_UNLOCK();\n    }\n    return tstate;\n}\n</code></pre>\n<p>在初始化线程对象的时候，Python也设置了从线程中获取函数调用栈的方法，这里说函数调用”栈“而不是“帧”是因为<code>PyFrameObject</code>之间也是一个链表结构。</p>\n<p>在创建完进程和线程对象之后，虚拟机也为它俩建立了联系，这样任何时候都可以很容易的在<code>PyInterpreterState</code>对象和<code>PyThreadState</code>对象之间穿梭。</p>\n<p>并且Python还通过一个全局的变量维护当前线程对象：</p>\n<pre><code class=\"c\">_Py_atomic_address _PyThreadState_Current = {0};\n</code></pre>\n<p>这里比较有意思的是<code>_Py_atomic_address</code>，在Python内部有一套<code>原子API</code>，使用这些<code>原子操作API</code>操作<code>原子变量</code>时，其它线程是不能访问该变量的。所以对那个全局的当前线程变量的操作是”线程安全“的。</p>\n<pre><code class=\"c\">#define GET_TSTATE() \\\n    ((PyThreadState*)_Py_atomic_load_relaxed(&amp;_PyThreadState_Current))\n#define SET_TSTATE(value) \\\n    _Py_atomic_store_relaxed(&amp;_PyThreadState_Current, (uintptr_t)(value))\n\nPyThreadState *\nPyThreadState_Swap(PyThreadState *newts)\n{\n    PyThreadState *oldts = GET_TSTATE();\n\n    SET_TSTATE(newts);\n    return oldts;\n}\n</code></pre>\n<p><code>*NOTE：Python中的GIL机制保证的是单条字节码执行的线程安全，不保证Python语句执行的线程安全。</code></p>\n<p>在初始化线程环境后，虚拟机会对Python的类型系统和缓冲池进行初始化。接着就进入了系统模块的初始化工作。</p>\n<h2 id=\"系统模块初始化\"><a href=\"#系统模块初始化\" class=\"headerlink\" title=\"系统模块初始化\"></a>系统模块初始化</h2><p>系统模块的初始，得从<code>__builtin__</code>开始：</p>\n<pre><code class=\"c\">interp-&gt;modules = PyDict_New();\nbimod = _PyBuiltin_Init();\n_PyImport_FixupBuiltin(bimod, &quot;builtins&quot;);\ninterp-&gt;builtins = PyModule_GetDict(bimod);\n</code></pre>\n<p>可以从上面看到，进程对象创建了一个字典<code>modules</code>，维护着当前进程中的所有模块。</p>\n<p>将内置类型对象添加到<code>builtins</code>模块中是在<code>_PyBuiltin_Init</code>中完成的：</p>\n<pre><code class=\"c\">PyObject *\n_PyBuiltin_Init(void)\n{\n    PyObject *mod, *dict, *debug;\n    ...... /* 检查类型系统是否初始化完毕 */\n    mod = PyModule_Create(&amp;builtinsmodule); /* 创建builtins模块 */\n    dict = PyModule_GetDict(mod);\n\n#define SETBUILTIN(NAME, OBJECT) \\ /* 宏定义 */\n    if (PyDict_SetItemString(dict, NAME, (PyObject *)OBJECT) &lt; 0)       \\\n        return NULL;                                                    \\\n    /* 将内置类型对象添加builtins模块的字典中 */\n    SETBUILTIN(&quot;None&quot;,                  Py_None);\n    SETBUILTIN(&quot;Ellipsis&quot;,              Py_Ellipsis);\n    ......\n    SETBUILTIN(&quot;zip&quot;,                   &amp;PyZip_Type);\n    return mod;\n#undef SETBUILTIN\n}\n</code></pre>\n<p><code>_PyBuiltin_Init</code>通过两个步骤完成对<code>builtin</code>的设置：</p>\n<ul>\n<li>创建<code>PyModuleObject</code>对象，这个对象正是Python内部模块的实现；</li>\n<li>填充内置类型对象到新创建的<code>__builtin__</code>模块中；</li>\n</ul>\n<p>第二步的工作十分简单，我们直接来看看<code>__builtin__</code>模块是怎么创建的。</p>\n<h3 id=\"builtin-模块\"><a href=\"#builtin-模块\" class=\"headerlink\" title=\"builtin 模块\"></a><strong>builtin</strong> 模块</h3><p>模块的创建是通过<code>PyModule_Create2</code>函数完成的：</p>\n<pre><code class=\"c\">PyObject *\nPyModule_Create2(struct PyModuleDef* module, int module_api_version)\n{\n    const char* name;\n    PyModuleObject *m;\n    PyInterpreterState *interp = PyThreadState_Get()-&gt;interp; /* 获取进程对象 */\n    if (interp-&gt;modules == NULL)\n        Py_FatalError(&quot;Python import machinery not initialized&quot;);\n    if (!PyModuleDef_Init(module))\n        return NULL;\n    name = module-&gt;m_name;\n\n    if ((m = (PyModuleObject*)PyModule_New(name)) == NULL)\n        return NULL;\n    ......\n    if (module-&gt;m_methods != NULL) { /* 添加module函数中的methods */\n        if (PyModule_AddFunctions((PyObject *) m, module-&gt;m_methods) != 0) {\n            return NULL;\n        }\n    }\n    if (module-&gt;m_doc != NULL) { /* 添加module文档注释 */\n        if (PyModule_SetDocString((PyObject *) m, module-&gt;m_doc) != 0) {\n            return NULL;\n        }\n    }\n    m-&gt;md_def = module;\n    return (PyObject*)m;\n}\n</code></pre>\n<p>我们说<code>PyModuleObject</code>才是Python中模块的实现，那么<code>PyModuleDef</code>又是什么呢？我们来比较一下：</p>\n<pre><code class=\"c\">typedef struct PyModuleDef{\n  PyModuleDef_Base m_base;\n  const char* m_name;\n  const char* m_doc;\n  Py_ssize_t m_size;\n  PyMethodDef *m_methods;\n  struct PyModuleDef_Slot* m_slots;\n  traverseproc m_traverse;\n  inquiry m_clear;\n  freefunc m_free;\n} PyModuleDef;\n\ntypedef struct {\n    PyObject_HEAD\n    PyObject *md_dict;\n    struct PyModuleDef *md_def;\n    void *md_state;\n    PyObject *md_weaklist;\n    PyObject *md_name;\n} PyModuleObject;\n</code></pre>\n<p>应该可以大致看出来<code>PyModuleDef</code>是创建模块对象的一个模块定义，在这里面定义了模块名、注释以及模块函数等等。这么一来<code>builtinsmodule</code>应该就是<code>builtin</code>模块的定义所在，我来看看这里面都有什么：</p>\n<pre><code class=\"c\">static struct PyModuleDef builtinsmodule = {\n    PyModuleDef_HEAD_INIT,\n    &quot;builtins&quot;,\n    builtin_doc,\n    -1, /* multiple &quot;initialization&quot; just copies the module dict. */\n    builtin_methods,\n    NULL,NULL,NULL,NULL\n};\n\nstatic PyMethodDef builtin_methods[] = {\n    {&quot;__build_class__&quot;, (PyCFunction)builtin___build_class__,\n    METH_VARARGS | METH_KEYWORDS, build_class_doc},\n    {&quot;__import__&quot;,      (PyCFunction)builtin___import__, METH_VARARGS | METH_KEYWORDS, import_doc},\n    BUILTIN_ABS_METHODDEF\n    BUILTIN_ALL_METHODDEF\n    ......\n    {&quot;print&quot;,           (PyCFunction)builtin_print,      METH_VARARGS | METH_KEYWORDS, print_doc},\n    {NULL,              NULL},\n};\n</code></pre>\n<p>在<code>builtinsmodule</code>结构体中定义了<code>builtins</code>模块名，另外和模块定义相似，对于函数，Python也有类似的结构<code>PyMethodDef</code>，而<code>builtin_methods</code>结构体数组就维护了一大堆的函数名称到函数指针的映射。</p>\n<p>现在弄懂了<code>PyModuleObject</code>和<code>PyModuleDef</code>后，我们再回到函数<code>PyModule_Create2</code>中，真正的创建模块对象的函数是<code>PyModule_New</code>：</p>\n<pre><code class=\"c\">PyObject *\nPyModule_NewObject(PyObject *name)\n{\n    PyModuleObject *m;\n    m = PyObject_GC_New(PyModuleObject, &amp;PyModule_Type); /* 分配内存 */\n    m-&gt;md_def = NULL;\n    m-&gt;md_state = NULL;\n    m-&gt;md_weaklist = NULL;\n    m-&gt;md_name = NULL;\n    m-&gt;md_dict = PyDict_New(); /* 初始化各个域 */\n    if (module_init_dict(m, m-&gt;md_dict, name, NULL) != 0) /* 填充dict */\n        goto fail;\n    return (PyObject *)m;\n}\n\nstatic int\nmodule_init_dict(PyModuleObject *mod, PyObject *md_dict,\n                 PyObject *name, PyObject *doc)\n{\n    _Py_IDENTIFIER(__name__);\n    _Py_IDENTIFIER(__doc__);\n    ......\n    if (md_dict == NULL)\n        return -1;\n    if (doc == NULL)\n        doc = Py_None;\n    if (_PyDict_SetItemId(md_dict, &amp;PyId___name__, name) != 0)\n        return -1;\n    if (_PyDict_SetItemId(md_dict, &amp;PyId___doc__, doc) != 0)\n        return -1;\n    ......\n\n    return 0;\n}\n</code></pre>\n<p>在上面的函数中，我们通过<code>PyObject_GC_New</code>为模块对象分配内存后，就对各个域进行了初始化，其中<code>md_dict</code>是一个字典，在创建一个模块对象后，虚拟机会通过<code>module_init_dict</code>，在其中填充模块的<code>__name__</code>和<code>__doc__</code>等属性。</p>\n<p>到现在模块对象有了，而且<code>md_dict</code>域中也有了名称和注释，但虚拟机还需要进一步的设置，模块才能正常工作。依旧是<code>PyModule_Create2</code>函数中，虚拟机会根据模块对象的<code>m_methods</code>域设置模块函数。</p>\n<pre><code class=\"c\">int\nPyModule_AddFunctions(PyObject *m, PyMethodDef *functions)\n{\n    int res;\n    PyObject *name = PyModule_GetNameObject(m);\n    res = _add_methods_to_object(m, name, functions); /* 添加模块函数 */\n    return res;\n}\n\nstatic int\n_add_methods_to_object(PyObject *module, PyObject *name, PyMethodDef *functions)\n{\n    PyObject *func;\n    PyMethodDef *fdef;\n\n    for (fdef = functions; fdef-&gt;ml_name != NULL; fdef++) {\n        if ((fdef-&gt;ml_flags &amp; METH_CLASS) ||\n            (fdef-&gt;ml_flags &amp; METH_STATIC)) { /* 类方法和静态方法不做处理 */\n            return -1;\n        }\n        func = PyCFunction_NewEx(fdef, (PyObject*)module, name); /* 创建函数对象 */\n        if (PyObject_SetAttrString(module, fdef-&gt;ml_name, func) != 0) { /* 设置属性 */\n            return -1;\n        }\n    }\n    return 0;\n}\n</code></pre>\n<p>针对每个<code>PyMethodDef</code>结构，Python都会创建一个对应的<code>PyCFunctionObject</code>对象(这里面也用到了“缓冲池”机制)，这个对象就是一个函数指针的包装。这些创建的函数对象以属性的方式绑定在模块对象上面。</p>\n<p>最后进程对象的<code>builtins</code>指针也指向了<code>builtins</code>模块的<code>md_dict</code>域。</p>\n<p>和<code>builtins</code>模块相似，<code>sys</code>模块也是这样创建并被设置的。</p>\n<h3 id=\"sys-模块\"><a href=\"#sys-模块\" class=\"headerlink\" title=\"sys 模块\"></a>sys 模块</h3><pre><code class=\"c\">sysmod = _PySys_Init();  /* 创建并初始化sys模块 */\ninterp-&gt;sysdict = PyModule_GetDict(sysmod);\n_PyImport_FixupBuiltin(sysmod, &quot;sys&quot;);  /* 备份sys模块 */\nPyDict_SetItemString(interp-&gt;sysdict, &quot;modules&quot;, interp-&gt;modules);\n</code></pre>\n<p>创建的<code>sys</code>模块对象中主要加入了一些Python的版本信息和操作系统相关的信息，例如<code>version</code>、<code>platform</code>、<code>maxsize</code>和<code>byteorder</code>等。</p>\n<h3 id=\"模块备份\"><a href=\"#模块备份\" class=\"headerlink\" title=\"模块备份\"></a>模块备份</h3><p>在<code>builtins</code>和<code>sys</code>创建完后，都会有一个函数<code>_PyImport_FixupBuiltin();</code>，这个函数是用来备份的。</p>\n<p>因为<code>interp-&gt;modules</code>维护的是一个字典，属于可变对象，所以其中的<code>&lt;模块名，模块对象&gt;</code>很容易被删除。Python为了避免在元素删除时再次初始化模块，会将所有的扩展module通过一个全局的字典对象来进行备份维护，其调用的是<code>_PyImport_FixupExtensionObject</code>函数：</p>\n<pre><code class=\"c\">static PyObject *extensions = NULL; /* 一个全局的字典对象 */\n\nint\n_PyImport_FixupBuiltin(PyObject *mod, const char *name)\n{\n    int res;\n    PyObject *nameobj;\n    nameobj = PyUnicode_InternFromString(name);\n    res = _PyImport_FixupExtensionObject(mod, nameobj, nameobj);\n    return res;\n}\nint\n_PyImport_FixupExtensionObject(PyObject *mod, PyObject *name,\n                               PyObject *filename)\n{\n    PyObject *modules, *dict, *key;\n    struct PyModuleDef *def;\n    int res;\n    if (extensions == NULL) {\n        extensions = PyDict_New(); /* 如果没有创建，则创建字典*/\n    }\n    def = PyModule_GetDef(mod); /* 抽取module中的PyModuleDef */\n    modules = PyImport_GetModuleDict(); /* 获取interp-&gt;modules */\n    if (PyDict_SetItem(modules, name, mod) &lt; 0)\n        return -1;\n    if (_PyState_AddModule(mod, def) &lt; 0) {\n        PyDict_DelItem(modules, name);\n        return -1;\n    }\n    if (def-&gt;m_size == -1) {\n        if (def-&gt;m_base.m_copy) {\n            /* Somebody already imported the module,\n               likely under a different name.\n               XXX this should really not happen. */\n            Py_CLEAR(def-&gt;m_base.m_copy);\n        }\n        dict = PyModule_GetDict(mod); /* 抽取md_dict */\n        def-&gt;m_base.m_copy = PyDict_Copy(dict); /* 复制dict */\n    }\n    key = PyTuple_Pack(2, filename, name); /* 把名称打包作为键 */\n    res = PyDict_SetItem(extensions, key, (PyObject *)def); //\n    return 0;\n}\n</code></pre>\n<p>当Python中<code>interp-&gt;modules</code>集合中某个扩展被删除后又被重新加载时, 就不需要再次为其初始化了。只需要用<code>extensions</code>中备份的<code>PyModuleDef</code>来创建一个新的<code>module</code>对象即可。</p>\n<h3 id=\"设置模块搜索路径\"><a href=\"#设置模块搜索路径\" class=\"headerlink\" title=\"设置模块搜索路径\"></a>设置模块搜索路径</h3><p>当我们在Python中尝试导入模块时，就涉及到了一个叫”模块搜索路径“的概念，在虚拟机启动是通过下面的函数进行设置的：</p>\n<pre><code class=\"c\">......\nPySys_SetPath(Py_GetPath());\n</code></pre>\n<p>下面是<code>PySys_SetPath</code>的实现：</p>\n<pre><code class=\"c\">void\nPySys_SetPath(const wchar_t *path)\n{\n    PyObject *v;\n    if ((v = makepathobject(path, DELIM)) == NULL) /* 创建路径对象 */\n        Py_FatalError(&quot;can&#39;t create sys.path&quot;);\n    if (_PySys_SetObjectId(&amp;PyId_path, v) != 0) /* 设置路径对象到sysdict中 */\n        Py_FatalError(&quot;can&#39;t assign sys.path&quot;);\n}\n\nint\n_PySys_SetObjectId(_Py_Identifier *key, PyObject *v)\n{\n    PyThreadState *tstate = PyThreadState_GET();\n    PyObject *sd = tstate-&gt;interp-&gt;sysdict;\n    return _PyDict_SetItemId(sd, key, v);\n}\n</code></pre>\n<p>这里省略了路径的查找和路径对象的构建过程，在设置路径的过程中，Python将通过<code>makepathobject</code>构建的路径对象(一个列表)设置到了<code>interp-&gt;sysdict</code>中，而这个指针恰恰指向<code>sys</code>模块的<code>md_dict</code>域，所以我们在Python中敲入<code>sys.path</code>能够获得那个路径集合。</p>\n<p>在设置好搜索路径之后，虚拟机还进行了许多琐碎的初始化工作，例如：<code>import</code>机制初始化，异常环境初始化，输出环境和编码器等等。</p>\n<h3 id=\"main模块\"><a href=\"#main模块\" class=\"headerlink\" title=\"main模块\"></a>main模块</h3><p>另外，除了上面的<code>builtins</code>模块和<code>sys</code>模块外，虚拟机还有创建了一个特殊的模块：<code>__main__</code>模块。</p>\n<pre><code class=\"c\">static void\ninitmain(PyInterpreterState *interp)\n{\n    PyObject *m, *d, *loader, *ann_dict;\n    m = PyImport_AddModule(&quot;__main__&quot;); /* 创建名为__main__的模块 */\n    d = PyModule_GetDict(m); /* 抽取md_dict*/\n\n    if (PyDict_GetItemString(d, &quot;__builtins__&quot;) == NULL) {\n        PyObject *bimod = PyImport_ImportModule(&quot;builtins&quot;);\n        PyDict_SetItemString(d, &quot;__builtins__&quot;, bimod） /* 将__builtins__模块插入到dict中 */\n    }\n}\n</code></pre>\n<p>在<code>initmain</code>中，虚拟机先是创建了一个名为<code>__mian__</code>的模块，并将<code>__builtins__</code>添加到了该模块的<code>md_dict</code>中了。</p>\n<p>在Python中，我们经常写<code>if __name__ == __main__</code>和这又有什么关系呢？</p>\n<p>实际上，在以<code>python *.py</code>这种方式执行Python文件时，Python会沿着命名空间查找<code>__name__</code>，最后它会在<code>__main__</code>模块中，找到<code>__name__</code>对应的值是<code>__main__</code>。不过奇怪的是为什么会找到<code>__main__</code>模块的命名空间呢，不是还有<code>__builtin__</code>模块吗？这一点在下面的“命名空间”一节中有讲到。</p>\n<h3 id=\"site-packages\"><a href=\"#site-packages\" class=\"headerlink\" title=\"site-packages\"></a>site-packages</h3><p>这是一个特殊的目录，我们的安装的第三方库一般都放置在这个目录里，所以也就要求这个路径需要添加到Python的”搜索路径“中去。</p>\n<pre><code class=\"c\"> if (!Py_NoSiteFlag)\n    initsite(); /* Module site */\n</code></pre>\n<p>下面是它的实现：</p>\n<pre><code class=\"c\">static void\ninitsite(void)\n{\n    PyObject *m;\n    m = PyImport_ImportModule(&quot;site&quot;);\n}\n</code></pre>\n<p>这里设计到了Python的<code>import</code>机制，这里先跳过不讲，只需要知道<code>PyImport_ImportModule</code>会导入一个叫<code>site</code>的模块，这个模块位于<code>%PythonHome%\\Lib\\site.py</code>。</p>\n<p>在<code>site</code>模块中，Python做的事情就是：</p>\n<ul>\n<li>将<code>site-packages</code>路径加入到<code>sys.path</code>中</li>\n<li>另一个就是处理<code>site-packages</code>目录下的所有<code>.pth</code>文件中的所有路径添加到<code>sys.path</code>中</li>\n</ul>\n<p>到现在为止，Python中绝大部分的初始化动作都已经完毕，下面是初始化后的内存分布情况：</p>\n<h2 id=\"激活虚拟机\"><a href=\"#激活虚拟机\" class=\"headerlink\" title=\"激活虚拟机\"></a>激活虚拟机</h2><p>Python有两种运行方式，一是命令行下的交互环境；二是以脚本执行的方式。这两种方式都会在<code>Py_Initialize</code>之后调用<code>PyRun_AnyFileFlags</code>。</p>\n<pre><code class=\"c\">[Modules/main.c]\nint\nPy_Main(int argc, wchar_t **argv)\n{\n    Py_Initialize(); /* 初始化 */\n    ......\n    run = PyRun_AnyFileExFlags(fp, filename_str, filename != NULL, p_cf);\n    ......\n}\n</code></pre>\n<p>如果是以脚本方式执行，那么<code>fp</code>就是脚本文件，<code>filename_str</code>就是文件名，而<code>p_cf</code>是Python的编译参数；<br><br>如果是以交互式环境下执行，那么<code>fp</code>就是<code>stdin</code>输入流，而<code>filename_str</code>就是<code>&lt;stdin&gt;</code>。</p>\n<p>最后在函数<code>PyRun_AnyFileExFlags</code>中会对两种方式进行分流：</p>\n<pre><code class=\"c\">int\nPyRun_AnyFileExFlags(FILE *fp, const char *filename, int closeit,\n                     PyCompilerFlags *flags)\n{\n    if (filename == NULL)\n        filename = &quot;???&quot;;\n    /* 判断，分流 */\n    if (Py_FdIsInteractive(fp, filename)) {\n        int err = PyRun_InteractiveLoopFlags(fp, filename, flags);\n        if (closeit)\n            fclose(fp);\n        return err;\n    }\n    else\n        return PyRun_SimpleFileExFlags(fp, filename, closeit, flags);\n}\n</code></pre>\n<p>Python使用<code>Py_FdIsInteractive</code>判断输入是否是标准输入流，如果是，则代表着交互式运行环境，那么进入<code>PyRun_InteractiveLoopFlags</code>，否则使用<code>PyRun_SimpleFileExFlags</code>进行执行处理。</p>\n<h3 id=\"交互式环境\"><a href=\"#交互式环境\" class=\"headerlink\" title=\"交互式环境\"></a>交互式环境</h3><pre><code class=\"c\">int\nPyRun_InteractiveLoopFlags(FILE *fp, const char *filename_str, PyCompilerFlags *flags)\n{\n    PyObject *filename, *v;\n    int ret, err;\n    PyCompilerFlags local_flags;\n    int nomem_count = 0;\n    filename = PyUnicode_DecodeFSDefault(filename_str); /* 文件名 */\n\n    ......\n    /* 创建交互式提示符“&gt;&gt;&gt; ” */\n    v = _PySys_GetObjectId(&amp;PyId_ps1);\n    if (v == NULL) {\n        _PySys_SetObjectId(&amp;PyId_ps1, v = PyUnicode_FromString(&quot;&gt;&gt;&gt; &quot;));\n    }\n    /* 创建交互式提示符“... ” */\n    v = _PySys_GetObjectId(&amp;PyId_ps2);\n    if (v == NULL) {\n        _PySys_SetObjectId(&amp;PyId_ps2, v = PyUnicode_FromString(&quot;... &quot;));\n    }\n    err = 0;\n    do {/* 进入交互式环境 */\n        ret = PyRun_InteractiveOneObjectEx(fp, filename, flags);\n        ......\n    } while (ret != E_EOF);\n    return err;\n}\n</code></pre>\n<p>如果是在交互式运行环境下，虚拟机会在一个<code>loop</code>中循环执行。下面是<code>PyRun_InteractiveOneObjectEx</code>函数：</p>\n<pre><code class=\"c\">static int\nPyRun_InteractiveOneObjectEx(FILE *fp, PyObject *filename,\n                             PyCompilerFlags *flags)\n{\n    PyObject *m, *d, *v, *w, *oenc = NULL, *mod_name;\n    mod_ty mod;\n    PyArena *arena;\n    char *ps1 = &quot;&quot;, *ps2 = &quot;&quot;, *enc = NULL;\n    int errcode = 0;\n    _Py_IDENTIFIER(__main__);\n\n    mod_name = _PyUnicode_FromId(&amp;PyId___main__); /* borrowed */\n    ......\n    v = _PySys_GetObjectId(&amp;PyId_ps1);\n    if (v != NULL) {\n        v = PyObject_Str(v);\n        ps1 = PyUnicode_AsUTF8(v);\n    }\n    w = _PySys_GetObjectId(&amp;PyId_ps2);\n    if (w != NULL) {\n        w = PyObject_Str(w);\n        ps2 = PyUnicode_AsUTF8(w);\n    }\n    arena = PyArena_New();\n    mod = PyParser_ASTFromFileObject(fp, filename, enc,\n                                     Py_single_input, ps1, ps2,\n                                     flags, &amp;errcode, arena); /* 构造抽象语法树AST */\n    m = PyImport_AddModuleObject(mod_name); /* 导入__main__模块 */\n    d = PyModule_GetDict(m); /* 抽取main模块的md_dict */\n    v = run_mod(mod, filename, d, d, flags, arena); /* 执行用户输入的Python语句 */\n    PyArena_Free(arena);\n    flush_io();\n    return 0;\n}\n</code></pre>\n<p>在<code>PyRun_InteractiveOneObjectEx</code>中调用<code>PyParser_ASTFromFileObject</code>对交互式环境下的用户输入Python语句进行编译， 其结果是结构与Python语句一样的抽象语法树<code>AST</code>。调用<code>run_mod</code>将最终完成对输入语句的执行。这里的参数<code>d</code>就将作为当前活动的<code>frame</code>对象的<code>locals</code>名字空间和<code>globals</code>名字空间。</p>\n<h3 id=\"脚本方式执行\"><a href=\"#脚本方式执行\" class=\"headerlink\" title=\"脚本方式执行\"></a>脚本方式执行</h3><pre><code class=\"c\">\nint\nPyRun_SimpleFileExFlags(FILE *fp, const char *filename, int closeit,\n                        PyCompilerFlags *flags)\n{\n    PyObject *m, *d, *v;\n    const char *ext;\n    int set_file_name = 0, ret = -1;\n    size_t len;\n    m = PyImport_AddModule(&quot;__main__&quot;); /* 导入main模块 */\n\n    d = PyModule_GetDict(m);\n    if (PyDict_GetItemString(d, &quot;__file__&quot;) == NULL) { ./* 设置”__file__“属性 */\n        PyObject *f;\n        f = PyUnicode_DecodeFSDefault(filename);\n        yDict_SetItemString(d, &quot;__file__&quot;, f)\n        set_file_name = 1;\n    }\n    len = strlen(filename);\n    ext = filename + len - (len &gt; 4 ? 4 : 0);\n    if (maybe_pyc_file(fp, filename, ext, closeit)) { /* 尝试从pyc文件执行 */\n        ......\n        v = run_pyc_file(pyc_fp, filename, d, d, flags);\n        fclose(pyc_fp);\n    } else { /* 如果是py文件 */\n        ......\n        v = PyRun_FileExFlags(fp, filename, Py_file_input, d, d,\n                              closeit, flags);\n    }\n    ......\n}\n\nPyObject *\nPyRun_FileExFlags(FILE *fp, const char *filename_str, int start, PyObject *globals,\n                  PyObject *locals, int closeit, PyCompilerFlags *flags)\n{\n    PyObject *ret = NULL;\n    mod_ty mod;\n    PyArena *arena = NULL;\n    PyObject *filename;\n    filename = PyUnicode_DecodeFSDefault(filename_str);\n    mod = PyParser_ASTFromFileObject(fp, filename, NULL, start, 0, 0, /* 构造抽象语法树AST */\n                                     flags, NULL, arena); \n    ret = run_mod(mod, filename, globals, locals, flags, arena); /* 执行 */\n}\n\n</code></pre>\n<p>以脚本的方式和交互式运行环境相似，输入都会经过编译后，传入<code>run_mod</code>执行，将<code>main</code>模块的<code>md_dict</code>作为<code>locals</code>命名空间和<code>globals</code>命名空间传入。</p>\n<h3 id=\"run-mod\"><a href=\"#run-mod\" class=\"headerlink\" title=\"run_mod\"></a>run_mod</h3><pre><code class=\"c\">\nstatic PyObject *\nrun_mod(mod_ty mod, PyObject *filename, PyObject *globals, PyObject *locals,\n            PyCompilerFlags *flags, PyArena *arena)\n{\n    PyCodeObject *co;\n    PyObject *v;\n    co = PyAST_CompileObject(mod, filename, flags, -1, arena); /* 编译 */\n    v = PyEval_EvalCode((PyObject*)co, globals, locals); /* 执行 */\n    return v;\n}\n</code></pre>\n<p>从<code>run_mod</code>开始，虚拟机会通过传入的抽象语法树<code>AST</code>编译字节码指令序列，创建<code>PyCodeObject</code>，最后调用<code>PyEval_EvalCode</code>创建新的栈桢执行字节码对象。又回到了熟悉的地方。。。</p>\n<h3 id=\"命名空间\"><a href=\"#命名空间\" class=\"headerlink\" title=\"命名空间\"></a>命名空间</h3><p>虚拟机在执行字节码的过程中，创建了<code>PyFrameObject</code>设置了三个命名空间：<code>locals</code>，<code>globals</code>和<code>builtins</code>。</p>\n<pre><code class=\"c\">PyFrameObject *\nPyFrame_New(PyThreadState *tstate, PyCodeObject *code, PyObject *globals,\n            PyObject *locals)\n{\n    PyFrameObject *back = tstate-&gt;frame;\n    PyFrameObject *f;\n    PyObject *builtins;\n    Py_ssize_t i;\n    /* builtins命名空间 */\n    if (back == NULL || back-&gt;f_globals != globals) {/* 尝试从main模块的dict中获取__builtin__模块 */\n        builtins = _PyDict_GetItemId(globals, &amp;PyId___builtins__); \n        builtins = PyModule_GetDict(builtins); /* builtins命名空间就是builtin模块的md_dict */\n        }\n    }\n    else {\n        builtins = back-&gt;f_builtins; /* 继承上一个栈桢的builtis命名空间 */\n    }\n    f-&gt;f_builtins = builtins; \n    f-&gt;f_back = back;\n    /* globals命名空间 */\n    f-&gt;f_globals = globals;\n    /* locals命名空间 */\n    if ((code-&gt;co_flags &amp; (CO_NEWLOCALS | CO_OPTIMIZED)) ==\n        (CO_NEWLOCALS | CO_OPTIMIZED))\n        ; /* f_locals = NULL; 函数调用，不需要locals命名空间 */\n    else if (code-&gt;co_flags &amp; CO_NEWLOCALS) {\n        locals = PyDict_New();\n        f-&gt;f_locals = locals;\n    }\n    else {\n        if (locals == NULL)\n            locals = globals; /* 一般情况，locals和globals指向同一dict */\n        f-&gt;f_locals = locals;\n    }\n    return f;\n}\n</code></pre>\n<p>以主模块的方式运行的化，虚拟机传入的<code>locals</code>和<code>globals</code>命名空间都是<code>main</code>模块的<code>md_dict</code>，所以<code>__name__</code>直接就会在<code>locals</code>命名空间找到，不会命中<code>builtins</code>命名空间。</p>\n<p>在新创建的栈桢对象，它的builtins命名空间就是<code>__builtin__</code>模块的<code>md_dict</code>，所以我们能够直接在Python中使用这些内置的对象。同时也意味着：Python的所有线程共享同样的builtin名字空间。</p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-内存管理机制","url":"http://shawnz.me/posts/89298142/","content":"<p>终于来到了最后一部分: 内存管理.</p>\n<a id=\"more\"></a>\n<h2 id=\"内存架构\"><a href=\"#内存架构\" class=\"headerlink\" title=\"内存架构\"></a>内存架构</h2><p>在Python中, 当要分配内存时, 不单纯要用<code>malloc/free</code>, 而是在其基础上堆放三个独立的分层, 有效地进行分配.</p>\n<div style=\"width: 70%\"><img src=\"/images/pymemobject-1.jpg\" alt=\"\"></div>\n\n<p>第<code>0</code>层往下是<code>OS</code>的功能, 我们要讲的内存管理不涉及这一部分.</p>\n<p>第<code>0</code>层是操作系统的内存管理接口, 比如<code>C</code>运行时提供的<code>mallocl</code>和<code>free</code>接口, Python并不干涉这一层的行为.</p>\n<p>第<code>1</code>层是基于第<code>0</code>层操作系统的内存管接口包装而成的, 这一层主要是为Python提供统一的<code>raw memory</code>管理接口, 处理平台相关的内存分配. 在Python中, 第<code>1</code>的实现是一组<code>PyMem_</code>为前缀的函数族.</p>\n<pre><code class=\"c\">[obmalloc.c]\n/* 函数接口 */\nstatic void * \n_PyMem_RawMalloc(void *ctx, size_t size)\n{\n    if (size == 0)\n        size = 1;\n    return malloc(size);\n}\n......\nstatic void *\n_PyMem_RawRealloc(void *ctx, void *ptr, size_t size)\n{\n    if (size == 0)\n        size = 1;\n    return realloc(ptr, size);\n}\nstatic void\n_PyMem_RawFree(void *ctx, void *ptr) { free(ptr); }\n\n/* 宏定义 */\n[pymem.h]\n#define PyMem_MALLOC(n)         PyMem_Malloc(n)\n#define PyMem_REALLOC(p, n)     PyMem_Realloc(p, n)\n#define PyMem_FREE(p)           PyMem_Free(p)\n</code></pre>\n<p>可以看到Python只是对C中<code>malloc/realloc/free</code>等进行了一次包装. 不过由于不同操作系统针对<code>malloc(0)</code>表现不同, 有的会返回<code>NULL</code>, 有的会返回一个没有指向内存的空指针, 所以Python不允许申请大小为<code>0</code>的内存空间, 将会强制转换成申请大小为<code>1</code>字节的内存空间.</p>\n<p>Python同时提供了函数和宏两套接口, 使用宏可以提高运行效率, 不过在编写<code>C</code>扩展模块的时候, 建议使用函数接口.</p>\n<p>其实在第<code>1</code>层, Python还提供了面向Python中类型的内存分配接口:</p>\n<pre><code class=\"c\">#define PyMem_New(type, n) \\\n  ( ((size_t)(n) &gt; PY_SSIZE_T_MAX / sizeof(type)) ? NULL :    \\\n    ( (type *) PyMem_Malloc((n) * sizeof(type)) ) )\n#define PyMem_NEW(type, n) \\\n  ( ((size_t)(n) &gt; PY_SSIZE_T_MAX / sizeof(type)) ? NULL :    \\\n    ( (type *) PyMem_MALLOC((n) * sizeof(type)) ) )\n\n#define PyMem_Resize(p, type, n) \\\n  ( (p) = ((size_t)(n) &gt; PY_SSIZE_T_MAX / sizeof(type)) ? NULL :    \\\n    (type *) PyMem_Realloc((p), (n) * sizeof(type)) )\n#define PyMem_RESIZE(p, type, n) \\\n  ( (p) = ((size_t)(n) &gt; PY_SSIZE_T_MAX / sizeof(type)) ? NULL :    \\\n    (type *) PyMem_REALLOC((p), (n) * sizeof(type)) )\n</code></pre>\n<p>第<code>1</code>层只是进行内存分配的工作, 然而对于内存分配还有许多额外工作, 例如: 计数引用和<code>GC</code>, 都将在第<code>2</code>层内存管理机制中. 这一层, 是一组以<code>PyObject_</code>为前缀的函数族, 主要作为Python的对象分配器, 这些函数族又被唤作<code>Pymalloc</code>机制.</p>\n<p>而第<code>3</code>层, 则是对于Python中的常用对象, 例如: 整数对象, 字符串对象等, 提供了更高层次的内存管理策略, 主要就是缓冲池技术, 这一部分的具体分析我们在Python的内置对象时有讲过.</p>\n<h2 id=\"第1层低级内存分配器\"><a href=\"#第1层低级内存分配器\" class=\"headerlink\" title=\"第1层低级内存分配器\"></a>第1层低级内存分配器</h2><p>先看一个简单的例子:</p>\n<pre><code class=\"python\">for x in range(100):\n    print(x)\n</code></pre>\n<p>在上述脚本中, Python会把从0-99的整数对象转换成字符串对象输出, 这一过程会使用大量的一次性字符串.</p>\n<p>所以为了避免频繁的调用<code>malloc/free</code>, Python引入了一个”内存池机制”, 用于管理小块内存的申请和释放.</p>\n<p>第<code>1</code>层锁管理的内存空间结构可以分为3个层次: <code>arean -&gt; pool -&gt; block</code>, 最小单位是<code>block</code>, 返回给用户的也是<code>block</code>.</p>\n<p><img src=\"/images/pymemobject-2.png\" alt=\"\"></p>\n<h3 id=\"block\"><a href=\"#block\" class=\"headerlink\" title=\"block\"></a>block</h3><p>在底层, <code>block</code>是一个确定大小的内存块, Python中, 不同种类的<code>block</code>都有不同的大小, 这个内存大小称为<code>size class</code>. 所有的<code>block</code>块都是8字节对齐的.</p>\n<pre><code class=\"c\">#define ALIGNMENT               8               /* block对齐, must be 2^N */\n#define ALIGNMENT_SHIFT         3\n\n#define SMALL_REQUEST_THRESHOLD 512  /* block上限 */\n#define NB_SMALL_SIZE_CLASSES   (SMALL_REQUEST_THRESHOLD / ALIGNMENT)\n</code></pre>\n<p>同时, Python为<code>block</code>的大小设定了一个上限, 当申请的内存小于这个上限时, Python就可以使用不同的<code>block</code>满足对内存的要求; 当申请超过这个上限的时候, Python将内存申请的请求转交给第<code>1</code>层的内存分配机制, 即<code>PyMem_</code>函数族.</p>\n<p>根据<code>SMALL_REQUEST_THRESHOLD</code>和<code>ALIGNMENT</code>, 可以得到不同种类的<code>block</code>的<code>size class</code>分别为: 8, 16, 32, …, 512. 每个<code>size class</code>对应一个<code>size class index</code>, 这个<code>index</code>从0开始. 所以对于小于<code>512</code>字节的内存分配, 我们可以得到如下结论:</p>\n<table>\n<thead>\n<tr>\n<th>Request in bytes</th>\n<th>Size of allocated block</th>\n<th>Size class idx</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1~8</td>\n<td>8</td>\n<td>0</td>\n</tr>\n<tr>\n<td>9~16</td>\n<td>16</td>\n<td>1</td>\n</tr>\n<tr>\n<td>17~24</td>\n<td>24</td>\n<td>2</td>\n</tr>\n<tr>\n<td>…</td>\n<td>…</td>\n<td>…</td>\n</tr>\n<tr>\n<td>505~512</td>\n<td>512</td>\n<td>63</td>\n</tr>\n</tbody>\n</table>\n<p>也就是说, 当我们申请内存大小为28字节的内存时, 实际上<code>PyObject_Malloc</code>会从内存池中划分一个32字节的<code>block</code>, 这个<code>block</code>将从<code>size class index</code>为3的<code>pool</code>中划出. 下面是<code>size class</code>和<code>size class index</code>之间的相互转换公式:</p>\n<pre><code class=\"c\">/* 从size class index 转换成 size class */\n#define INDEX2SIZE(I) (((uint)(I) + 1) &lt;&lt; ALIGNMENT_SHIFT)\n/* 从size class 转换成 size class index*/\nsize = (uint)(nbytes - 1) &gt;&gt; ALIGNMENT_SHIFT;\n</code></pre>\n<p>不过这里我们说的<code>block</code>并不是一个实际存在的对象, 它只是一个概念, 在Python中, 有一个实体来管理<code>block</code>, 那就是<code>pool</code>.</p>\n<h3 id=\"pool\"><a href=\"#pool\" class=\"headerlink\" title=\"pool\"></a>pool</h3><p>一组<code>block</code>的集合称为<code>pool</code>, 换句话说, 一个<code>pool</code>管理着一堆固定大小的<code>block</code>.</p>\n<p>在Python中, <code>pool</code>的大小通常是一个系统内存页, 一个<code>pool</code>的大小定义为4KB.</p>\n<pre><code class=\"c\">#define SYSTEM_PAGE_SIZE        (4 * 1024)\n#define SYSTEM_PAGE_SIZE_MASK   (SYSTEM_PAGE_SIZE - 1)\n\n#define POOL_SIZE               SYSTEM_PAGE_SIZE        /* must be 2^N */\n#define POOL_SIZE_MASK          SYSTEM_PAGE_SIZE_MASK\n</code></pre>\n<p>另外, <code>pool</code>有对应的实体存在:</p>\n<pre><code class=\"c\">typedef uint8_t block;\n\n/* Pool for small blocks. */\nstruct pool_header {\n    union { block *_padding;\n            uint count; } ref;          /* 分配到pool里的block的数量 */\n    block *freeblock;                   /* block空闲链表的开头 */\n    struct pool_header *nextpool;       /* 指向下一个pool(双链表) */\n    struct pool_header *prevpool;       /* 指向上一个pool(双链表)　*/\n    uint arenaindex;                    /* 自己所属的arena的索引 */\n    uint szidx;                         /* 分配的block大小 */\n    uint nextoffset;                    /* 到下一个block的偏移量 */\n    uint maxnextoffset;                 /* 到能分配下一个block之前偏移 */\n};\n\ntypedef struct pool_header *poolp;\n</code></pre>\n<p>一个<code>pool</code>内分配的<code>block</code>大小是固定的, 通过<code>szidx</code>可以找到对应的<code>pool</code>.</p>\n<p>假设现在有一个4KB的内存, 来看看Python是怎么将它改造成一个管理32字节<code>block</code>的<code>pool</code>, 并返回一个第一个<code>block</code>:</p>\n<pre><code class=\"c\">[obmalloc.c convert 4k raw memory to pool]\ntypedef struct pool_header *poolp;\n#define POOL_OVERHEAD   _Py_SIZE_ROUND_UP(sizeof(struct pool_header), ALIGNMENT)\n\nblock *bp;\npoolp pool;\n...... /* pool 指向一块4KB内存 */\npool-&gt;ref.count = 1;\npool-&gt;szidx = size;  /* 设置pool的size class index */\nsize = INDEX2SIZE(size); /* 转换成size class, 比如3转化为32字节 */\nbp = (block *)pool + POOL_OVERHEAD; /* 跳过用于pool_head的内存， 并进行地址对齐 */\n/* 实际就是pool-&gt;nextoffset = POOL_OVERHEAD + size + size */\npool-&gt;nextoffset = POOL_OVERHEAD + (size &lt;&lt; 1); /* 到下一个block的偏移 */\npool-&gt;maxnextoffset = POOL_SIZE - size; /* 到能分配下一个block之前的偏移 */\npool-&gt;freeblock = bp + size;  /* block的空闲链表开头 */\n*(block **)(pool-&gt;freeblock) = NULL; /* *freeblock为NULL */\nreturn (void *)bp;\n</code></pre>\n<p>最后返回的<code>bp</code>就是从<code>pool</code>取出的第一块<code>block</code>的地址, 也就是说第一个<code>block</code>已经被分配了. 所以当前已分配的<code>block</code>数量为<code>1</code>, <code>freeblock=bp+size</code>, 下一个空闲<code>block</code>的偏移为<code>POOL_OVERHEAD + size + size</code>, 空闲链表的指向<code>bp+size</code>.</p>\n<p>对于应用程序来说, 尽管<code>bp</code>后面还有将近4k的内存可用, 但是可以肯定的是申请内存的函数只会使用<code>[bp, bp+size]</code>这个区间的内存. 被改造后的4KB内存情况如下:</p>\n<p><img src=\"/images/pymemobject-3.png\" alt=\"\"></p>\n<p>现在假设, 我们需要再申请5块28字节的内存, 由于28字节对应的<code>size class index</code>为<code>3</code>, 所以实际会在刚创建的<code>pool</code>上申请5块32字节的内存.</p>\n<pre><code class=\"c\">[onmalloc.c _PyObject_Alloc]\n if (pool != pool-&gt;nextpool) {\n    ++pool-&gt;ref.count;\n    bp = pool-&gt;freeblock; /* 下一个空闲block */\n    ......\n    if (pool-&gt;nextoffset &lt;= pool-&gt;maxnextoffset) { /* 下一次分配还有足够的空间 */\n        pool-&gt;freeblock = (block*)pool + pool-&gt;nextoffset;\n        pool-&gt;nextoffset += INDEX2SIZE(size);\n        *(block **)(pool-&gt;freeblock) = NULL;\n        return (void *)bp;\n    }\n    /* pool已满, 从used_pool中移除 */\n    next = pool-&gt;nextpool;\n    pool = pool-&gt;prevpool;\n    next-&gt;prevpool = pool;\n    pool-&gt;nextpool = next;\n    return (void *)bp;\n}\n</code></pre>\n<p>可以看到, <code>_PyObject_Alloc</code>申请<code>block</code>的过程是依赖于三个变量: </p>\n<ul>\n<li><code>freeblock</code>: 指向下一个空闲的<code>block</code>地址;</li>\n<li><code>nextoffset</code>和<code>maxnextoffset</code>: 控制着迭代申请<code>block</code>块后, 可用<code>block</code>的偏移量. 当<code>nextoffset &gt; maxnextoffset</code>时, <code>pool</code>在分配完这一次<code>block</code>结束后就已经满了, 需要从<code>used_pools</code>中移除.</li>\n</ul>\n<p>继续假设, 如果我们需要返回第2个<code>block</code>的内存, 来看看Python是怎么释放<code>block</code>的:</p>\n<pre><code class=\"c\">static void\n_PyObject_Free(void *ctx, void *p)\n{\n    poolp pool;\n    block *lastfree;\n    poolp next, prev;\n    uint size;\n\n    pool = POOL_ADDR(p); /* pool_head */\n    if (address_in_range(p, pool)) { /* 检查p指向的block是否属于pool  */\n        *(block **)p = lastfree = pool-&gt;freeblock; /* [1] */\n        pool-&gt;freeblock = (block *)p;  /* [2] */\n        ......\n    }\n}\n</code></pre>\n<p>在释放第2块<code>block</code>的时候, 为了更充分的利用<code>pool</code>的内存空间, Python通过设置<code>freeblock</code>指针构造了一个空闲<code>block</code>的离散链表:</p>\n<ul>\n<li>在上面申请<code>block</code>的过程中, 我们知道申请<code>block</code>后, <code>*freeblock</code>为<code>NULL</code>;</li>\n<li>经过[1]后, 先是将指针<code>freeblock</code>的指向的地址, 保存在我们要释放掉的那个<code>block</code>里;</li>\n<li>经过[2]后, 更新当前<code>freeblock</code>指针, 指向我们释放掉的<code>block</code>地址.</li>\n</ul>\n<p>经过这两步, 这时<code>pool</code>的内存使用情况应该如下:</p>\n<p><img src=\"/images/pymemobject-4.png\" alt=\"\"></p>\n<p>既然构造了空闲<code>block</code>的离散链表, 那么在申请<code>block</code>块的时候, 应该优先尝试使用这条离散链表, 当<code>*freeblock==NULL</code>的时候, 可以知道已经不存在这条离散链表了:</p>\n<pre><code class=\"c\">[obmalloc.c _PyObject_Alloc]\nif (pool != pool-&gt;nextpool) {\n    ++pool-&gt;ref.count;\n    bp = pool-&gt;freeblock;\n    if ((pool-&gt;freeblock = *(block **)bp) != NULL) { /* 优先尝试空闲block链表 */\n        return (void *)bp;\n    }\n    if (pool-&gt;nextoffset &lt;= pool-&gt;maxnextoffset) {\n        ......\n    }\n}    \n</code></pre>\n<h3 id=\"arena\"><a href=\"#arena\" class=\"headerlink\" title=\"arena\"></a>arena</h3><p>多个<code>pool</code>的聚合就是<code>arena</code>. <code>pool</code>的默认大小为<code>4KB</code>, 而<code>arena</code>的默认大小为<code>256KB</code>:</p>\n<pre><code class=\"c\">[obmalloc.c]\n#define ARENA_SIZE              (256 &lt;&lt; 10)     /* 256KB */\n</code></pre>\n<p>我们来看看<code>arena</code>的定义:</p>\n<pre><code class=\"c\">[obmalloc.c]\nstruct arena_object {\n    uintptr_t address; /* malloc后的arena地址 */\n    block* pool_address; /* 将arena的地址用于给pool使用而对齐的地址 */\n    uint nfreepools; /* 空闲pool数量 */\n    uint ntotalpools; /* pool总数 */\n\n    struct pool_header* freepools;  /* 连接空闲pool的单链表 */\n    struct arena_object* nextarena; \n    struct arena_object* prevarena;\n};\n</code></pre>\n<p><code>arena_object</code>结构体中有个域<code>pool_address</code>, 它指向了<code>arena</code>内的开头<code>pool</code>地址. 这里我们说<code>arena</code>的地址和<code>arena</code>内开头的<code>pool</code>地址不同, 是因为<code>pool</code>的开头地址需要按照<code>4K</code>对齐.</p>\n<p>另外还有两个域<code>nextarena</code>和<code>prevarena</code>, 这里需要注意的是, <code>arena_object</code>是被一个<code>arenas</code>数组管理的, 这就是Python通用的内存池.</p>\n<pre><code class=\"c\">[obmalloc.c]\nstatic struct arena_object* arenas = NULL;     /* arenes管理着 arena_object的集合 */\nstatic uint maxarenas = 0;  /* arenas中的元素数量 */\n</code></pre>\n<p>既然不是链表, 那么<code>nextarena</code>和<code>prevarena</code>是做什么用的呢?</p>\n<p>这得从<code>arena</code>的内存布局来讲, 我们知道<code>pool</code>在创建的时候, 意味着<code>pool</code>里的<code>block</code>也跟着分配了内存, 然而<code>arena</code>不是这样的, 当<code>arena</code>被创建时, 其内管理的<code>pool</code>可能还没有被创建.</p>\n<p>所以我们将<code>arena</code>分为两种状态: “未使用”状态和”可用”状态. 当一个<code>arena_object</code>没有和<code>pool</code>集合建立联系的时候, 我们称它为”未使用”; 一旦建立联系, <code>arena</code>就变为了”可用”状态.</p>\n<p>对于两种状态, 分别有两个链表管理着: <code>unused_arena_objects</code>和<code>usable_arenas</code>, 这些<code>arena_object</code>之间正是通过上面那两个指针连接.</p>\n<pre><code class=\"c\">static struct arena_object* unused_arena_objects = NULL; /* 单链表 */\nstatic struct arena_object* usable_arenas = NULL; /* 双链表 */\n</code></pre>\n<p>下图展示了某一时刻多个<code>arena</code>可能的状态:</p>\n<p><img src=\"/images/pymemobject-6.png\" alt=\"\"></p>\n<p>接下来, 是<code>arena</code>的创建过程:</p>\n<pre><code class=\"c\">static struct arena_object*\nnew_arena(void)\n{\n    struct arena_object* arenaobj;\n    uint excess;        /* number of bytes above pool alignment */\n    void *address;\n    static int debug_stats = -1;\n\n    if (unused_arena_objects == NULL) { /* 判断是否需要扩充unused_arena_objects链表 */\n        uint i;\n        uint numarenas;\n        size_t nbytes;\n        /* 确定本次需要申请的arena_objects 数量, 并申请内存*/\n        numarenas = maxarenas ? maxarenas &lt;&lt; 1 : INITIAL_ARENA_OBJECTS;\n        if (numarenas &lt;= maxarenas)\n            return NULL;                /* overflow */\n\n        nbytes = numarenas * sizeof(*arenas);\n        arenaobj = (struct arena_object *)PyMem_RawRealloc(arenas, nbytes);\n        if (arenaobj == NULL)\n            return NULL;\n        arenas = arenaobj;\n        /* 初始化新申请的arena_object, 并放入unused_arena_objects链表和arenas数组 */\n        for (i = maxarenas; i &lt; numarenas; ++i) {  /* 注意从maxarenas开始, 不动正在使用的arenas */\n            arenas[i].address = 0;              /* mark as unassociated */\n            arenas[i].nextarena = i &lt; numarenas - 1 ?\n                                   &amp;arenas[i+1] : NULL;\n        }\n\n        unused_arena_objects = &amp;arenas[maxarenas];\n        maxarenas = numarenas;\n    }\n    /* 从unused_arena_objects中取出一个未使用的arena_object*/*/\n    arenaobj = unused_arena_objects;\n    unused_arena_objects = arenaobj-&gt;nextarena;\n    /* 申请arena_object所管理的内存 */\n    address = _PyObject_Arena.alloc(_PyObject_Arena.ctx, ARENA_SIZE);\n    if (address == NULL) {\n        arenaobj-&gt;nextarena = unused_arena_objects;\n        unused_arena_objects = arenaobj;\n        return NULL;\n    }\n    arenaobj-&gt;address = (uintptr_t)address;\n\n    ++narenas_currently_allocated;\n    ++ntimes_arena_allocated;\n    if (narenas_currently_allocated &gt; narenas_highwater)\n        narenas_highwater = narenas_currently_allocated;\n    /* 把arena内部分割成pool  */\n    arenaobj-&gt;freepools = NULL;\n    arenaobj-&gt;pool_address = (block*)arenaobj-&gt;address;\n    arenaobj-&gt;nfreepools = ARENA_SIZE / POOL_SIZE;\n    /* pool地址对齐 */\n    excess = (uint)(arenaobj-&gt;address &amp; POOL_SIZE_MASK);\n    if (excess != 0) {\n        --arenaobj-&gt;nfreepools;\n        arenaobj-&gt;pool_address += POOL_SIZE - excess;\n    }\n    arenaobj-&gt;ntotalpools = arenaobj-&gt;nfreepools;\n\n    return arenaobj; /* 返回新的arena_object */\n}\n</code></pre>\n<p>在创建新的<code>arena</code>期间, Python首先会检查<code>unused_arena_objects</code>链表中是否还有”未使用”状态的<code>arena</code>.</p>\n<ul>\n<li>如果<code>unused_arena_objects</code>中存在未使用的<code>arena</code>, 那么直接从中取出一个<code>arena</code>, 调整<code>unused_arena_objects</code>指针, 断绝和抽取的<code>arena</code>的联系;</li>\n<li>如果<code>unused_arena_objects</code>为<code>NULL</code>, 那么Python会申请单独用于存放<code>numarenas</code>个<code>arena</code>的内存空间, 这个值在第一次的时候为<code>16</code>, 以后会翻倍. 申请内存后, 每个<code>arena</code>设置地址<code>address</code>都为<code>0</code>, 并通过指针<code>nextarena</code>将它们连接起来.</li>\n</ul>\n<p>无论哪种情况, 在从<code>unused_arena_objects</code>中获取到一个<code>arena</code>后, 会为它所管理的<code>pool</code>集合申请一块内存, <code>address</code>域就是申请的内存地址, 而<code>pool_address</code>是对开头的<code>pool</code>经过系统页对齐的地址. 到现在为止, <code>arena</code>和<code>pool</code>建立了联系, 就等着<code>usable_arenas</code>接收了.</p>\n<h2 id=\"第2层对象分配器\"><a href=\"#第2层对象分配器\" class=\"headerlink\" title=\"第2层对象分配器\"></a>第2层对象分配器</h2><p>尽管我们花了大量篇幅介绍<code>arena</code>, 然而Python申请内存时, 直接打交道的确实<code>pool</code>. 这也无可厚非, 毕竟只有通过<code>pool</code>才能找到保存固定大小的<code>block</code>块的内存.</p>\n<h3 id=\"usedpools\"><a href=\"#usedpools\" class=\"headerlink\" title=\"usedpools\"></a>usedpools</h3><p>在Python中为实现高速搜索<code>pool</code>, 使用了一个全局变量<code>usedpools</code>来保持<code>pool</code>数组. 一个 <code>pool</code>在Python运行期间, 必然处于以下三种状态中的一种:</p>\n<ul>\n<li><code>used</code>状态: <code>pool</code>中至少有一个<code>block</code>已经被使用, 并且至少一个<code>block</code>还未被使用, 这种状态受控于<code>usedpools</code>数组;</li>\n<li><code>full</code>状态: <code>pool</code>中的所有<code>block</code>都已经被使用, 这种状态的<code>pool</code>位于<code>arena</code>中, 但不在<code>arena</code>的<code>freepools</code>链表中;</li>\n<li><code>empty</code>状态: 这种状态的<code>pool</code>中的所有<code>block</code>都未使用, 处于这种状态的<code>pool</code>集合, 通过<code>pool_header</code>的<code>nextpool</code>构成的链表正好形成<code>arena</code>的<code>freepools</code>;</li>\n</ul>\n<p>下面给出了一个<code>arena</code>中包含三种状态的<code>pool</code>集合的一个可能状态:</p>\n<p><img src=\"/images/pymemobject-7.png\" alt=\"\"></p>\n<p>注意, 处于<code>full</code>状态的<code>pool</code>是独立的, 没有和其他<code>pool</code>那样会链接成链表. 所有处于<code>used</code>状态的<code>pool</code>都被受控于<code>usedpools</code>数组. <code>usedpools</code> 与<code>size class index</code>有着密切的联系, 来看一看<code>usedpools</code>的结构:</p>\n<pre><code class=\"c\">[obmalloc.c]\ntypedef struct pool_header *poolp;\n#define PTA(x)  ((poolp )((uint8_t *)&amp;(usedpools[2*(x)]) - 2*sizeof(block *)))\n#define PT(x)   PTA(x), PTA(x)\n\nstatic poolp usedpools[2 * ((NB_SMALL_SIZE_CLASSES + 7) / 8) * 8] = {\n    PT(0), PT(1), PT(2), PT(3), PT(4), PT(5), PT(6), PT(7)\n#if NB_SMALL_SIZE_CLASSES &gt; 8\n    , PT(8), PT(9), PT(10), PT(11), PT(12), PT(13), PT(14), PT(15)\n#if NB_SMALL_SIZE_CLASSES &gt; 16\n    , PT(16), PT(17), PT(18), PT(19), PT(20), PT(21), PT(22), PT(23)\n......\n#if NB_SMALL_SIZE_CLASSES &gt; 56\n    , PT(56), PT(57), PT(58), PT(59), PT(60), PT(61), PT(62), PT(63)\n......\n#endif /* NB_SMALL_SIZE_CLASSES &gt;  8 */\n};\n</code></pre>\n<p>可以看到<code>usedpools</code>是一个<code>pool_header</code>的指针型数组, 将它精简过后的形式是:</p>\n<pre><code class=\"c\">static poolp usedpools[128] = {\n    PT(0), PT(1), PT(2), PT(3), PT(4), PT(5), PT(6), PT(7)\n    , PT(8), PT(9), PT(10), PT(11), PT(12), PT(13), PT(14), PT(15)\n    , PT(16), PT(17), PT(18), PT(19), PT(20), PT(21), PT(22), PT(23)\n    ......\n    , PT(56), PT(57), PT(58), PT(59), PT(60), PT(61), PT(62), PT(63)\n};\n</code></pre>\n<p>看来<code>usedpools</code>的元素数量是<code>128</code>, 但是我们申请大小的种类类型却只有<code>64</code>种. 呈倍数关系是因为采用了双向链表连接<code>pool</code>, <code>usedpools</code>的元素被两两分为一组.</p>\n<p>而宏定义<code>PT(x)</code>定义了一个指针: 这个指针指向的位置是从一组的开头再往前”两个block指针型的大小”.</p>\n<p>懵逼…还是不太明白, 为什么非要把问题弄这么复杂, 直接将<code>usedpools</code>作为<code>pool_header</code>数组不行吗?</p>\n<p>关于这点在注释中有解释:</p>\n<blockquote>\n<p>It’s unclear why the usedpools setup is so convoluted. <br><br>/<em> usedpools的设置不知为何变得如此复杂 </em>/ <br><br>It could be to<br>minimize the amount of cache required to hold this heavily-referenced table<br>(which only <em>needs</em> the two interpool pointer members of a pool_header).<br><br>/<em> 这可能是最大限度地减少持有这个严重引用的表所需的缓存量（它只需要</em> pool_header的两个池间指针成员）*/</p>\n</blockquote>\n<p>有点懵圈, 讲了一大堆云里雾里的, 关于<code>arena</code>, <code>pool</code>和<code>block</code>也有了一个模糊的概念, 下面就具体针对两个函数<code>_PyObject_Malloc</code>和<code>_PyObject_Free</code>, 分析Python的内存分配和内存释放过程.</p>\n<h3 id=\"PyObject-Malloc\"><a href=\"#PyObject-Malloc\" class=\"headerlink\" title=\"_PyObject_Malloc\"></a>_PyObject_Malloc</h3><p>Python中的对大部分对象的内存分配都是通过这个函数<code>_PyObject_Malloc</code>完成的.</p>\n<p>这个函数有三个作用: “分配block”, “分配pool”和”分配arena”.</p>\n<p>函数的整体流程如下(为了更好的理解, 对源码进行了整理):</p>\n<pre><code class=\"c\">\nstatic void *\n_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)\n{\n    size_t nbytes;\n    block *bp;\n    poolp pool;\n    poolp next;\n    uint size;\n\n    _Py_AllocatedBlocks++;\n\n    nbytes = nelem * elsize;  /* 计算需要申请的字节数 */\n\n    if (nelem == 0 || elsize == 0)\n        goto redirect;\n    /* 申请的字节数是否小于等于512字节? */\n    if ((nbytes - 1) &lt; SMALL_REQUEST_THRESHOLD) {\n        LOCK(); /* 线程锁 */\n        size = (uint)(nbytes - 1) &gt;&gt; ALIGNMENT_SHIFT; /* 转换成索引 */\n        pool = usedpools[size + size]; /* 从usedpools中取出pool */\n        /* 检查pool是否连接到了指定索引的usedpool是的元素\n        如果连接到了那么pool和pool-&gt;nextpool地址应该不同 */\n        if (pool != pool-&gt;nextpool) { /* 返回pool内的block */\n            ++pool-&gt;ref.count; /* pool内分配的block数量加一 */\n            bp = pool-&gt;freeblock; \n            /* 尝试通过离散链表获取block(使用完毕的block) */\n            if ((pool-&gt;freeblock = *(block **)bp) != NULL) {\n                UNLOCK(); /* 解锁线程 */\n                return (void *)bp; /* 返回block */\n            }\n            /* 通过偏移量取出block(未使用的block) */\n            if (pool-&gt;nextoffset &lt;= pool-&gt;maxnextoffset) {\n                /* There is room for another block. */\n                pool-&gt;freeblock = (block*)pool +\n                                  pool-&gt;nextoffset;\n                /* 设定下一个空block的偏移量 */\n                pool-&gt;nextoffset += INDEX2SIZE(size);\n                *(block **)(pool-&gt;freeblock) = NULL;\n                UNLOCK();\n                return (void *)bp; /* 返回block*/\n            }\n            /* 该pool已满, 无法再使用, 从usedpools中移除 */\n            next = pool-&gt;nextpool;\n            pool = pool-&gt;prevpool;\n            next-&gt;prevpool = pool;\n            pool-&gt;nextpool = next;\n            UNLOCK();\n            return (void *)bp; /* 返回block */\n        }\n        /* 没有可用的arena, 调用new_arena创建新的arenas */\n        if (usable_arenas == NULL) {\n            if (narenas_currently_allocated &gt;= MAX_ARENAS) {\n                UNLOCK();\n                goto redirect;\n            }\n            usable_arenas = new_arena(); /* 分配新的一批arena_objects */\n            if (usable_arenas == NULL) {\n                UNLOCK();\n                goto redirect;\n            }\n            usable_arenas-&gt;nextarena =\n                usable_arenas-&gt;prevarena = NULL;\n        }\n\n        /* 从arean中取出空闲的pool */\n        pool = usable_arenas-&gt;freepools;\n        if (pool != NULL) { /* 检查是否存在空闲的pool */\n            usable_arenas-&gt;freepools = pool-&gt;nextpool; /* 把空闲的pool从链表中取出 */\n\n            --usable_arenas-&gt;nfreepools; /* usable_arenas可用pool数减一 */\n            if (usable_arenas-&gt;nfreepools == 0) {  /* arena中已经没有空闲pool, 将它移除 */\n\n                usable_arenas = usable_arenas-&gt;nextarena;\n                if (usable_arenas != NULL) {\n                    usable_arenas-&gt;prevarena = NULL;\n                }\n            }\n        init_pool: /* 初始化并返回pool */\n            /* 连接usedpools的开头 */\n            next = usedpools[size + size]; /* == prev */\n            pool-&gt;nextpool = next;\n            pool-&gt;prevpool = next;\n            next-&gt;nextpool = pool;\n            next-&gt;prevpool = pool;\n            pool-&gt;ref.count = 1;\n            if (pool-&gt;szidx == size) {\n                /* 比较申请的大小和pool中block的固定大小*/\n                /* 如果相同(曾经使用过, 而且size相同), 那么就不用进行初始化也无所谓 */\n                bp = pool-&gt;freeblock;\n                pool-&gt;freeblock = *(block **)bp; /* 设定下一个block地址 */\n                UNLOCK();\n                return (void *)bp; /* 返回block */\n            }\n            /* 初始化pool */\n            pool-&gt;szidx = size;\n            size = INDEX2SIZE(size);\n            bp = (block *)pool + POOL_OVERHEAD;\n            pool-&gt;nextoffset = POOL_OVERHEAD + (size &lt;&lt; 1);\n            pool-&gt;maxnextoffset = POOL_SIZE - size;\n            pool-&gt;freeblock = bp + size;\n            *(block **)(pool-&gt;freeblock) = NULL;\n            UNLOCK();\n            return (void *)bp; /* 返回block */\n        }\n        /* 初始化空的pool */\n        pool = (poolp)usable_arenas-&gt;pool_address;\n        pool-&gt;arenaindex = (uint)(usable_arenas - arenas);\n        pool-&gt;szidx = DUMMY_SIZE_IDX;\n        usable_arenas-&gt;pool_address += POOL_SIZE;\n        --usable_arenas-&gt;nfreepools;\n\n        if (usable_arenas-&gt;nfreepools == 0) { /* 如果没有可用的pool了, 那么就设定下一个arena */\n            usable_arenas = usable_arenas-&gt;nextarena;\n            if (usable_arenas != NULL) {\n                usable_arenas-&gt;prevarena = NULL;\n            }\n        }\n\n        goto init_pool;\n    }\n\n\nredirect: /* 调用原生的malloc分配内存 */\n    {\n        void *result;\n        result = PyMem_RawMalloc(nbytes);\n        return result;\n    }\n}\n</code></pre>\n<pre><code class=\"c\">static void *\n_PyObject_Malloc(size_t nbytes)\n{\n    /* 是否小于等于512字节? */\n    if ((nbytes - 1) &lt; SMALL_REQUEST_THRESHOLD) {\n        /* (A)从usedpools中取出pool */\n        if (pool != pool-&gt;nextpool) {\n           /* (B)返回pool内的block */\n        }\n        /* 是否存在可以使用的arena? */\n        if (usable_arenas == NULL) {\n            /* (C)调用new_arena */\n        }\n        /* 从arena中取出使用空闲的pool */\n        pool = usable_arenas-&gt;freepools;\n        /* 是否存在空闲的pool */\n        if (pool != NULL) {\n            /* (D)初始化空闲的pool */    \n\n            /* (E)初始化pool并返回block */\n       }\n    }\n\n  redirect:\n    {\n        /* 当大于256字节时, 使用原生的malloc申请内存 */\n        void *result;\n        result = PyMem_RawMalloc(nbytes);\n        return result;\n    }\n}\n</code></pre>\n<h3 id=\"PyObject-Free\"><a href=\"#PyObject-Free\" class=\"headerlink\" title=\"_PyObject_Free\"></a>_PyObject_Free</h3><p>和分配内存对应, <code>_PyObject_Free</code>释放用<code>_PyObject_Malloc</code>分配的内存. 这个函数主要三个作用: “释放block”, “释放pool”和”释放arena”.</p>\n<p>下面是整理过的源码和注释:</p>\n<pre><code class=\"c\">static void\n_PyObject_Free(void *ctx, void *p)\n{\n    poolp pool;\n    block *lastfree;\n    poolp next, prev;\n    uint size;\n\n    if (p == NULL)      /* 为NULL时, 不执行任何动作 */\n        return;\n\n    _Py_AllocatedBlocks--;\n\n    pool = POOL_ADDR(p); /* 从作为释放对象的地址取出所属的pool */\n    if (address_in_range(p, pool)) { /* 检查获得的pool是否正确 */\n        LOCK(); /* 线程锁 */\n\n        *(block **)p = lastfree = pool-&gt;freeblock; /* 构建使用完毕的block的离散链表 */\n        pool-&gt;freeblock = (block *)p;  /* 将block设置为freeblock头 */\n        if (lastfree) { /* 这个pool的最后free的block是否为NULL */\n            struct arena_object* ao;\n            uint nf;  /* ao-&gt;nfreepools */\n\n            if (--pool-&gt;ref.count != 0) { /* pool正在使用used, 不执行任何操作 */\n                UNLOCK();\n                return;\n            }\n\n            /* pool变成empty状态, 从usedpools中移除 */\n            /* prev &lt;-&gt; pool &lt;-&gt; next */\n            /* prev &lt;-&gt; next */\n            next = pool-&gt;nextpool;\n            prev = pool-&gt;prevpool;\n            next-&gt;prevpool = prev;\n            prev-&gt;nextpool = next;\n\n            /* 将pool返回到arena的freepools */\n            ao = &amp;arenas[pool-&gt;arenaindex];\n            pool-&gt;nextpool = ao-&gt;freepools;\n            ao-&gt;freepools = pool;\n            nf = ++ao-&gt;nfreepools;\n\n             /* 释放arena */\n            if (nf == ao-&gt;ntotalpools) { /* 当arena内全是空的pool, 就将其释放掉 */\n                /* 从usable_arenas中移除 */\n                if (ao-&gt;prevarena == NULL) {\n                    usable_arenas = ao-&gt;nextarena;\n                }\n                else {\n                    ao-&gt;prevarena-&gt;nextarena =\n                        ao-&gt;nextarena;\n                }\n                if (ao-&gt;nextarena != NULL) {\n                    ao-&gt;nextarena-&gt;prevarena =\n                        ao-&gt;prevarena;\n                }\n                /* 为了再次利用arena, 将其连接到unused_arena_objects */\n                ao-&gt;nextarena = unused_arena_objects;\n                unused_arena_objects = ao;\n\n                /* 释放掉arena维护的那块内存 */\n                _PyObject_Arena.free(_PyObject_Arena.ctx,\n                                     (void *)ao-&gt;address, ARENA_SIZE);\n                ao-&gt;address = 0;                        /* mark unassociated */\n                --narenas_currently_allocated;\n\n                UNLOCK();\n                return;\n            }\n            if (nf == 1) { /* arena中只有一个空的pool */\n                /* 这里只有一个空的pool, 意味着在这次释放pool之前, 所有pool都在使用 */\n                /* 本来没有连接到usable_arenas中, 现在需要连接到usable_arenas头 */\n                ao-&gt;nextarena = usable_arenas;\n                ao-&gt;prevarena = NULL;\n                if (usable_arenas)\n                    usable_arenas-&gt;prevarena = ao;\n                usable_arenas = ao;\n\n                UNLOCK();\n                return;\n            }\n\n            if (ao-&gt;nextarena == NULL || nf &lt;= ao-&gt;nextarena-&gt;nfreepools) {\n                /* 如果arena是最后一个arena, 或者这个arena_object中空闲的pool数量小于下一个 */\n                /* 那么不执行任何操作 */\n                UNLOCK();\n                return;\n            }\n             /* 如果不是上面两种情况, 则需要对arena按从小到大排序 */\n             /* 首先我们将这个arena从usable_arenas中拿出来 */\n            if (ao-&gt;prevarena != NULL) {\n                ao-&gt;prevarena-&gt;nextarena = ao-&gt;nextarena;\n            }\n            else {\n                usable_arenas = ao-&gt;nextarena;\n            }\n            ao-&gt;nextarena-&gt;prevarena = ao-&gt;prevarena;\n\n            /* 然后从usable_arenas中找到合适位置插入arena_object */\n            while (ao-&gt;nextarena != NULL &amp;&amp;\n                            nf &gt; ao-&gt;nextarena-&gt;nfreepools) {\n                ao-&gt;prevarena = ao-&gt;nextarena;\n                ao-&gt;nextarena = ao-&gt;nextarena-&gt;nextarena;\n            }\n\n            ao-&gt;prevarena-&gt;nextarena = ao;\n            if (ao-&gt;nextarena != NULL)\n                ao-&gt;nextarena-&gt;prevarena = ao;\n\n            UNLOCK();\n            return;\n        }\n\n        /* lastfree为NULL意味着这个pool内的所有block都已经分配完毕 */\n        /* 需要从usedpools中取出这个大小类型的pool, 并将这个pool连接到usedpools开头 */\n        --pool-&gt;ref.count;\n        size = pool-&gt;szidx;\n        next = usedpools[size + size];\n        prev = next-&gt;prevpool;\n        pool-&gt;nextpool = next;\n        pool-&gt;prevpool = prev;\n        next-&gt;prevpool = pool;\n        prev-&gt;nextpool = pool;\n        UNLOCK();\n        return;\n    }\n\nredirect:\n    /* 释放其他空间 */\n    PyMem_RawFree(p);\n}\n</code></pre>\n<h2 id=\"第3层特殊对象缓冲机制\"><a href=\"#第3层特殊对象缓冲机制\" class=\"headerlink\" title=\"第3层特殊对象缓冲机制\"></a>第3层特殊对象缓冲机制</h2><p>这一部分, 我们在前面的Python内置对象讲过, 针对一些常用的类型, Python提供了一系列的缓冲池技术.</p>\n<!-- 当申请一个32字节的`pool`时, 需要将这个`pool`放入`usedpools`. 先得到它的`size class index`, 也就是3. 然后进行`usedpools[3+3]->nextpool = pool`即可.  -->\n<!-- \n\n`PyObject_Malloc`中利用了这个技巧来判断某个`class size index`对应的`pool`是否存在于`usedpools`中.\n\n\n```c\nstatic void *\n_PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)\n{\n    size_t nbytes;\n    block *bp;\n    poolp pool;\n    poolp next;\n    uint size;\n\n    if ((nbytes - 1) < SMALL_REQUEST_THRESHOLD) {\n        LOCK();\n\n        /* 获得size class index */\n        size = (uint)(nbytes - 1) >> ALIGNMENT_SHIFT;\n        pool = usedpools[size + size];\n        if (pool != pool->nextpool) { /* usedpools是否有可用的pool */\n            ......\n        }\n      ......\n}\n```\n\n### 创建pool\n\n\n当Python启动的时候, `usedpools`这个内存池中并没有可用内存, 当我们开始申请小块内存的时候, Python才开始建立这个内存池. 假设我们申请`32`字节的内存, Python首先得到对应的`class size index=3`,  在`usedpools`对应的位置查找, 发现没有任何可用的`pool`, Python才会从`useable_arenas`链表中第一个可用的`arena`获得一个可用的`pool`. 考虑到, 这个`pool`将是用于分配`32`字节`block`的, 因此在此它需要被重新划分.\n\n```c\n[obmalloc.c]\nstatic void * _PyObject_Alloc(int use_calloc, void *ctx, size_t nelem, size_t elsize)\n{\n    ...\n  init_pool:  /* 初始化pool */\n    // 将pool放入usedpools中\n    next = usedpools[size + size];\n    pool->nextpool = next;\n    pool->prevpool = next;\n    next->nextpool = pool;\n    next->prevpool = pool;\n    pool->ref.count = 1;\n    // pool在之前就具有正确的size结构, 直接返回pool中的一个block\n    if (pool->szidx == size) {\n        bp = pool->freeblock;\n        assert(bp != NULL);\n        pool->freeblock = *(block **)bp;\n        UNLOCK();\n        if (use_calloc)\n            memset(bp, 0, nbytes);\n        return (void *)bp;\n    }\n    // 初始化pool_header, 将freeblock指向第二个block, 返回第一个block\n    pool->szidx = size;\n    size = INDEX2SIZE(size);\n    bp = (block *)pool + POOL_OVERHEAD;\n    pool->nextoffset = POOL_OVERHEAD + (size << 1);\n    pool->maxnextoffset = POOL_SIZE - size;\n    pool->freeblock = bp + size;\n    *(block **)(pool->freeblock) = NULL;\n    UNLOCK();\n    if (use_calloc)\n        memset(bp, 0, nbytes);\n    return (void *)bp;\n    ...\n}\n```\n\nPython将得到的pool放入了usedpools中. 那么在什么情况下pool从empty转为used状态呢? 假设申请的内存为size class index 为 i. 字儿usedpools[i + i] 处没有处于used状态的pool. 同时全局变量freepools中海油处于empty的pool, 那么位于freepool维护的链表中头部pool将被取出来, 放入usedpools中, 这时, 这个pool也就从empry状态转为used状态.\n\n\n```c\n[obmalloc.c _PyObject_Alloc]\npool = usable_arenas->freepools;\nif (pool != NULL) {\n    usable_arenas->freepools = pool->nextpool;\n    ...// 调整usable_arenas->nfreepools和usable_arenas自身\n\ninit_pool:\n    ...\n}\n``` -->\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-多线程机制","url":"http://shawnz.me/posts/8c8f8f97/","content":"<h2 id=\"GIL与线程调度\"><a href=\"#GIL与线程调度\" class=\"headerlink\" title=\"GIL与线程调度\"></a>GIL与线程调度</h2><p>GIL(Global Interpreter Lock), 限制线程对共享资源的访问，同一时间只会有一个获得GIL的线程在跑，其他线程则处于等待状态. Python的线程是原生操作系统线程, 它使用的线程的调度模型主要需要解决两个问题:</p>\n<ul>\n<li>在何时挂起当前线程, 选择处理等待状态的线程?</li>\n<li>在众多的等待线程中, 选择激活哪个线程?</li>\n</ul>\n<a id=\"more\"></a>\n<p>Python模拟操作系统上线程的时钟中断机制, 实现了相似的原理:</p>\n<ul>\n<li>在Python2采用<code>ticks</code>计步，当一个线程无中断地运行了粗略<code>100</code>个字节码(可以通过<code>sys.getcheckinterval()</code>查看), 会释放<code>GIL</code>;</li>\n<li>在Python3中，新的GIL实现中用一个固定的超时时间来指示当前的线程放弃全局锁。在当前线程保持这个锁，且其他线程请求这个锁时，当前线程就会在5毫秒后被强制释放该锁(可以通过<code>sys.getswitchinterval</code>查看)。</li>\n</ul>\n<p>至于选择激活哪个线程, 完全由操作系统系统决定. 这一点至关重要, Python的线程就是操作系统的原生线程, 只不过在Python维护着这些线程的状态<code>PyThreadState</code>对象, 以及在这些线程上面实现一层抽象, 提供统一的编程接口, 例如: <code>thread</code>和<code>threading</code>等.</p>\n<h2 id=\"线程创建\"><a href=\"#线程创建\" class=\"headerlink\" title=\"线程创建\"></a>线程创建</h2><p>我们来看一个简单的例子:</p>\n<pre><code class=\"python\">\n</code></pre>\n<p>在Python中我们可以使用<code>thread</code>模块或<code>threading</code>模块创建线程. <code>threading</code>模块是对<code>_thread</code>模块的封装, <code>_thread</code>是一个內建模块, 它的实现在<code>_threadmodule.c</code>:</p>\n<pre><code class=\"c\">[_threadmodule.c]\nstatic PyMethodDef thread_methods[] = {\n    {&quot;start_new_thread&quot;,        (PyCFunction)thread_PyThread_start_new_thread,\n     METH_VARARGS, start_new_doc},\n    {&quot;start_new&quot;,               (PyCFunction)thread_PyThread_start_new_thread,\n     METH_VARARGS, start_new_doc},\n    {&quot;allocate_lock&quot;,           (PyCFunction)thread_PyThread_allocate_lock,\n     METH_NOARGS, allocate_doc},\n    {&quot;allocate&quot;,                (PyCFunction)thread_PyThread_allocate_lock,\n     METH_NOARGS, allocate_doc},\n    {&quot;exit_thread&quot;,             (PyCFunction)thread_PyThread_exit_thread,\n     METH_NOARGS, exit_doc},\n    ......\n    {NULL,                      NULL}           /* sentinel */\n};\n</code></pre>\n<p><code>_thread</code>模块为用户提供的多线程编程接口十分少, 也正因如此Python的多线程编程才变得简单灵活.</p>\n<p>创建线程的函数是<code>thread_PyThread_start_new_thread</code>, 下面是它的实现:</p>\n<pre><code class=\"c\">\nstatic PyObject *\nthread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)\n{\n    PyObject *func, *args, *keyw = NULL;\n    struct bootstate *boot;\n    long ident;\n    PyArg_UnpackTuple(fargs, &quot;start_new_thread&quot;, 2, 3, &amp;func, &amp;args, &amp;keyw))\n    boot = PyMem_NEW(struct bootstate, 1); /* 创建bootstate结构 */\n\n    boot-&gt;interp = PyThreadState_GET()-&gt;interp;\n    boot-&gt;func = func;\n    boot-&gt;args = args;\n    boot-&gt;keyw = keyw;\n    boot-&gt;tstate = _PyThreadState_Prealloc(boot-&gt;interp);\n\n    PyEval_InitThreads(); /* 初始化多线程环境 */\n    ident = PyThread_start_new_thread(t_bootstrap, (void*) boot); /* 创建线程 */\n    return PyLong_FromLong(ident); /* 返回线程标识 */\n}\n</code></pre>\n<p><strong>Python在多线程机制默认是没有激活的.</strong></p>\n<p>这一点十分有意思, 在虚拟机启动的时候, Python只支持单线程, 支持多线程的数据结构和<code>GIL</code>都没有创建, 只有当用户调用<code>thread.start_new_thread</code>时, Python才会认为用户需要多线程的支持, 自动初始化多线程环境.</p>\n<h2 id=\"多线程环境\"><a href=\"#多线程环境\" class=\"headerlink\" title=\"多线程环境\"></a>多线程环境</h2><p>创建多线程环境的主要工作就是<code>GIL</code>的创建.</p>\n<pre><code class=\"c\">[pythread.h]\ntypedef void *PyThread_type_lock;\n\n[ceval.c]\nstatic PyThread_type_lock pending_lock = 0; /* for pending calls */\nstatic long main_thread = 0;\n\nvoid\nPyEval_InitThreads(void)\n{\n    if (gil_created())\n        return;\n    create_gil();\n    take_gil(PyThreadState_GET());\n    main_thread = PyThread_get_thread_ident();\n    if (!pending_lock)\n        pending_lock = PyThread_allocate_lock();\n}\n</code></pre>\n<p>Python的<code>GIL</code>是一个<code>void *</code>指针, 可以指向任意类型. Python的多线程机制是平台相关的, 在Linux和Windows下有不同的实现: </p>\n<pre><code class=\"c\">[thread.c]\n#ifdef _POSIX_THREADS  /* Linux POSIX线程 */\n#define PYTHREAD_NAME &quot;pthread&quot;\n#include &quot;thread_pthread.h&quot;\n#endif\n\n#ifdef NT_THREADS /* Windows系统 */\n#define PYTHREAD_NAME &quot;nt&quot;\n#include &quot;thread_nt.h&quot;\n#endif\n</code></pre>\n<p>在WIN32平台下, <code>GIL</code>是一个<code>NRMUTEX</code>结构体, 利用<code>Event</code>来实现线程的互斥:</p>\n<pre><code class=\"c\">[thread_nt.h]\ntypedef struct NRMUTEX {\nLONG   owned ;\nDWORD  thread_id ;\nHANDLE hevent ;\n} NRMUTEX, *PNRMUTEX ;\n</code></pre>\n<p>在Linux系统下, <code>GIL</code>利用条件机制和互斥锁<code>&lt;cond, mutex&gt;</code>保护一个锁变量作为实现(还有其他的实现: “信号量”):</p>\n<pre><code class=\"c\">[thread_pthread.h]\ntypedef struct {\n    char             locked; /* 0=unlocked, 1=locked */\n    pthread_cond_t   lock_released;\n    pthread_mutex_t  mut;  /* 利用&lt;cond, mutex&gt;获得锁, 控制线程的同步 */\n} pthread_lock;\n</code></pre>\n<p>在这里不会过多的深入线程机制具体实现, 而是以Linux平台为参考, 重点关注Python的线程调度机制. </p>\n<p>无论创建多少个线程, 多线程环境的初始化动作只执行一次(检查<code>gil_created</code>).</p>\n<p>在经过<code>PyEval_InitThreads -&gt; PyThread_allocate_lock</code>获得了<code>GIL</code>锁后, 线程调度就需要<strong>获取</strong>和<strong>释放</strong><code>GIL</code>锁.</p>\n<ul>\n<li><code>PyThread_acquire_lock()</code></li>\n<li><code>PyThread_release_lock()</code></li>\n</ul>\n<h3 id=\"GIL创建\"><a href=\"#GIL创建\" class=\"headerlink\" title=\"GIL创建\"></a>GIL创建</h3><pre><code class=\"c\">PyThread_type_lock\nPyThread_allocate_lock(void)\n{\n    pthread_lock *lock;\n    int status, error = 0;\n    if (!initialized)  /* 检查原生线程环境的初始化 */\n        PyThread_init_thread();\n    lock = (pthread_lock *) PyMem_RawMalloc(sizeof(pthread_lock));\n    memset((void *)lock, &#39;\\0&#39;, sizeof(pthread_lock)); /* 零值 */\n    lock-&gt;locked = 0; /* GIL没有被占用 */\n    status = pthread_mutex_init(&amp;lock-&gt;mut,\n                                pthread_mutexattr_default);\n    /* Mark the pthread mutex underlying a Python mutex as pure happens-before.\n       We can&#39;t simply mark the Python-level mutex as a mutex because it can be\n       acquired and released in different threads, which will cause errors. */\n    _Py_ANNOTATE_PURE_HAPPENS_BEFORE_MUTEX(&amp;lock-&gt;mut);\n    status = pthread_cond_init(&amp;lock-&gt;lock_released,\n                                pthread_condattr_default);\n    return (PyThread_type_lock) lock;\n}\n</code></pre>\n<p>在<code>GIL</code>的创建中, Python会先通过变量<code>initialized</code>检查原生线程环境是否初始化完毕(没有什么工作, 只是一个标识), 在其后就是<code>PyThread_type_lock</code>各个域的初始化, 可以看到新创建的<code>GIL</code>锁是没有被线程占有的. 这样在虚拟机初始化</p>\n<h3 id=\"GIL获取\"><a href=\"#GIL获取\" class=\"headerlink\" title=\"GIL获取\"></a>GIL获取</h3><pre><code class=\"c\">[thread_pthread.h]\n\nPyLockStatus\nPyThread_acquire_lock_timed(PyThread_type_lock lock, PY_TIMEOUT_T microseconds,\n                            int intr_flag)\n{\n    PyLockStatus success = PY_LOCK_FAILURE; /* 上锁成功或失败 */\n    pthread_lock *thelock = (pthread_lock *)lock;\n    int status, error = 0;\n\n    status = pthread_mutex_lock( &amp;thelock-&gt;mut );  /* 先获取mutex, 获得操作locked变量的权限 */\n\n    if (status == 0) {\n        if (thelock-&gt;locked == 0) { /* GIL可用 */\n            success = PY_LOCK_ACQUIRED;\n        }\n        else if (microseconds != 0) { /* GIL不可用, 尝试等待 */\n            struct timespec ts;\n            if (microseconds &gt; 0)  /* 等待microseconds时长 */\n                MICROSECONDS_TO_TIMESPEC(microseconds, ts);\n\n            while (success == PY_LOCK_FAILURE) {\n                if (microseconds &gt; 0) { /* 超时等待锁变量释放  */\n                    status = pthread_cond_timedwait(\n                        &amp;thelock-&gt;lock_released,\n                        &amp;thelock-&gt;mut, &amp;ts);\n                    if (status == ETIMEDOUT)\n                        break;\n                }\n                else { /* 无限期的等待锁变量释放 */\n                    status = pthread_cond_wait(\n                        &amp;thelock-&gt;lock_released,\n                        &amp;thelock-&gt;mut);\n                }\n\n                if (intr_flag &amp;&amp; status == 0 &amp;&amp; thelock-&gt;locked) { /* 锁不可用, 允许上层重试 */\n                    success = PY_LOCK_INTR;\n                    break;\n                }\n                else if (status == 0 &amp;&amp; !thelock-&gt;locked) { /* 成功, 其他线程释放了锁变量 */\n                    success = PY_LOCK_ACQUIRED;\n                }\n            }\n        }\n        if (success == PY_LOCK_ACQUIRED) thelock-&gt;locked = 1; /* 获取到mutex锁, 修改锁变量locked */\n        status = pthread_mutex_unlock(&amp;thelock-&gt;mut); /* 解锁mutex, 让其他线程有机会进入临界区等待GIL */\n    }\n    if (error) success = PY_LOCK_FAILURE;  /* 失败 */\n    return success;\n}\n</code></pre>\n<p><code>GIL</code>的获取过程: 线程会先获得<code>mutex</code>锁, 才可以修改锁变量<code>locked</code>. 如果获得mutex锁后, <code>locked</code>不为<code>0</code>则代表其他线程正在占用锁, 必须通过<code>pthread_cond_timedwait</code>等待其他线程将锁变量释放掉. 在获得<code>GIL</code>锁后, 设置<code>thelock-&gt;locked = 1</code>表示正在占中<code>GIL</code>锁, 线程必须释放掉<code>mutex</code>锁, 让其他线程有机会进入临界区等待锁.</p>\n<h3 id=\"GIL释放\"><a href=\"#GIL释放\" class=\"headerlink\" title=\"GIL释放\"></a>GIL释放</h3><pre><code class=\"c\">void\nPyThread_release_lock(PyThread_type_lock lock)\n{\n    pthread_lock *thelock = (pthread_lock *)lock;\n    int status, error = 0;\n\n    status = pthread_mutex_lock( &amp;thelock-&gt;mut ); /* 先获取mutex锁, 获得修改锁变量的权限 */\n    thelock-&gt;locked = 0; /* 释放GIL锁 */\n    status = pthread_cond_signal( &amp;thelock-&gt;lock_released ); /* 通知临界区的一个线程, 锁已经释放 */\n    status = pthread_mutex_unlock( &amp;thelock-&gt;mut ); /* 释放mutex锁 */\n}\n</code></pre>\n<p>释放<code>GIL</code>锁, 首先也需要先获取到<code>mutex</code>锁, 修改锁变量后, 还需要通知其他在等待<code>GIL</code>锁的线程, 最后释放掉<code>mutex</code>锁.</p>\n<p>疑问: 不是会造成死锁吗? 一个占有metex锁在等待<code>GIL</code>释放信号, 一个申请<code>mutex</code>锁, 发送<code>GIL</code>释放信号?</p>\n<p>答案: 应该是在进入<code>pthread_cond_wait</code>期间, 会将<code>thelock-&gt;mut</code>释放掉. 条件满足的时候, 又会对<code>metex</code>加锁.</p>\n<h2 id=\"创建子线程\"><a href=\"#创建子线程\" class=\"headerlink\" title=\"创建子线程\"></a>创建子线程</h2><p>现在回到创建线程的<code>thread_PyThread_start_new_thread</code>函数, 我们先来看看在初始化线程环境之前的那个<code>bootstate</code>:</p>\n<pre><code class=\"c\">boot = PyMem_NEW(struct bootstate, 1);\nboot-&gt;interp = PyThreadState_GET()-&gt;interp; /* 当前进程 */\nboot-&gt;func = func; /* 线程函数 */\nboot-&gt;args = args; /* 函数位置参数 */\nboot-&gt;keyw = keyw; /* 函数关键字参数 */\nboot-&gt;tstate = _PyThreadState_Prealloc(boot-&gt;interp); /* 创建一个空的threadstate */\n</code></pre>\n<p>这个<code>boot</code>保存了程序中定义的线程相关的信息, 在构造完<code>boot</code>结构体以及确认初始化多线程环境后, Python就会调用底层的API创建原生线程:<code>PyThread_start_new_thread(t_bootstrap, (void*) boot);</code>. 这里传递的参数是一个<code>t_bootstrap</code>函数和之前构建好的<code>boot</code>结构体.</p>\n<pre><code class=\"c\">[thread_pthread.h]\nlong\nPyThread_start_new_thread(void (*func)(void *), void *arg)\n{\n    pthread_t th; /* 线程标识 */\n    int status;\n    pthread_attr_t attrs; /* 线程属性 */\n    size_t      tss;\n    if (!initialized)  /* 检查原生线程环境的初始化 */\n        PyThread_init_thread();\n    pthread_attr_init(&amp;attrs) /* 线程属性初始化 */\n    tss = (_pythread_stacksize != 0) ? _pythread_stacksize : THREAD_STACK_SIZE;\n    pthread_attr_setstacksize(&amp;attrs, tss); /* 设置线程堆栈大小 */\n    pthread_attr_setscope(&amp;attrs, PTHREAD_SCOPE_SYSTEM); /* 设置CPU竞争模式 */\n    status = pthread_create(&amp;th, &amp;attrs, (pthread_attr_t*)NULL,\n                            (void* (*)(void *))func, (void *)arg); /* 创建原生线程 */\n    pthread_attr_destroy(&amp;attrs); /* 线程属性销毁 */\n    pthread_detach(th); /* 线程运行结束后, 自动释放内存 */\n    return (long) th;\n}\n</code></pre>\n<p>Python会调用一系列的C API来设置和创建一个原生线程, 传给<code>pthread_create</code>用来创建线程的<code>func</code>参数是<code>t_bootstrap</code>, <code>arg</code>参数是包装了线程信息的<code>boot</code>结构, 我们这里还是重点关注那个<code>t_bootstrap</code>函数:</p>\n<pre><code class=\"c\">static void\nt_bootstrap(void *boot_raw)\n{\n    struct bootstate *boot = (struct bootstate *) boot_raw;\n    PyThreadState *tstate;\n    PyObject *res;\n    tstate = boot-&gt;tstate;\n    tstate-&gt;thread_id = PyThread_get_thread_ident();\n    _PyThreadState_Init(tstate);\n    PyEval_AcquireThread(tstate); /* 获取GIL锁 */\n    nb_threads++;\n    res = PyEval_CallObjectWithKeywords(\n        boot-&gt;func, boot-&gt;args, boot-&gt;keyw); /* 执行我们的函数 */\n    ......\n    PyMem_DEL(boot_raw);\n    nb_threads--;\n    PyThreadState_Clear(tstate);\n    PyThreadState_DeleteCurrent();\n    PyThread_exit_thread(); /* 通过pthread_exit(0);退出, 保证线程的子线程不会跟着结束 */\n}\n</code></pre>\n<p>子线程和主线程的<code>GIL</code>竞争将发生在这里, <code>PyEval_AcquireThread</code>会尝试获取<code>GIL</code>锁:</p>\n<pre><code class=\"c\">void\nPyEval_AcquireThread(PyThreadState *tstate)\n{\n    assert(gil_created()); /* 检查GIL锁已被初始化 */\n    take_gil(tstate); /* 获取GIL锁 */\n    PyThreadState_Swap(tstate) /* 更新线程状态指针_PyThreadState_Current */\n}\n</code></pre>\n<p>在子线程通过<code>take_gil</code>获得GIL后, 就会开始执行我们的线程函数, <code>PyEval_CallObjectWithKeywords</code>执行结束后, 会释放GIL, 并完成销毁工作.有一点没有讲到的是关于”让步”的问题, 线程持有<code>GIL</code>后并不是直到结束才释放<code>GIL</code>锁.</p>\n<h2 id=\"线程状态保护\"><a href=\"#线程状态保护\" class=\"headerlink\" title=\"线程状态保护\"></a>线程状态保护</h2><p>我们知道线程状态对象类似线程的上下文, 里面保存着对应线程的信息, 并且有一个全局的<code>PyThreadState_Current</code>保存着当前活跃线程对应的状态对象. 这里有一个问题就是， 如何在调度线程的时候， 激活对应的线程状态对象?</p>\n<p>Python的做法是在内部通过一个单链表的形式管理所有创建的<code>PyThreadState</code>对象, 它们通过<code>next</code>指针链接在在一起.</p>\n<p>对于这个状态对象链表(线程共享的)的访问不需要<code>GIL</code>, 因为单独维护了一个<code>headmutex</code>锁, 它是在创建进程状态对象的时候创建的.</p>\n<pre><code class=\"c\">[pystate.c]\nstatic PyThread_type_lock head_mutex = NULL; /* Protects interp-&gt;tstate_head */\n#define HEAD_INIT() (void)(head_mutex || (head_mutex = PyThread_allocate_lock()))\n</code></pre>\n<p>在<code>Py_Initialize</code>运行时环境初始化的过程中有这么一步:</p>\n<pre><code class=\"c\">void\n_Py_InitializeEx_Private(int install_sigs, int install_importlib)\n{\n    interp = PyInterpreterState_New(); /* 创建进程状态对象, 并初始化headmutex锁 */\n    tstate = PyThreadState_New(interp); /* 创建线程状态对象 */\n    (void) PyThreadState_Swap(tstate); /* 更新当前线程指针 */\n    _PyGILState_Init(interp, tstate); \n    ....\n</code></pre>\n<p><code>_Py_InitializeEx_Private</code>里面会调用<code>_PyGILState_Init</code>函数, 创建<code>TLS entry</code>(TLS, Thread Local Storage), 用于存储和恢复线程状态对象.</p>\n<pre><code class=\"c\">[pystate.c]\nvoid\n_PyGILState_Init(PyInterpreterState *i, PyThreadState *t)\n{\n    assert(i &amp;&amp; t); /* must init with valid states */\n    autoTLSkey = PyThread_create_key();\n    if (autoTLSkey == -1)\n        Py_FatalError(&quot;Could not allocate TLS entry&quot;);\n    autoInterpreterState = i;\n    assert(PyThread_get_key_value(autoTLSkey) == NULL);\n    assert(t-&gt;gilstate_counter == 0);\n    _PyGILState_NoteThreadState(t);\n}\n\nstatic void\n_PyGILState_NoteThreadState(PyThreadState* tstate)\n{\n    if (!autoInterpreterState)\n        return;\n    if (PyThread_get_key_value(autoTLSkey) == NULL) {\n        PyThread_set_key_value(autoTLSkey, (void *)tstate /* 存储线程状态对象 */\n    }\n    tstate-&gt;gilstate_counter = 1;\n}\n\n[thread_pthread.h]\nint\nPyThread_create_key(void)\n{\n    pthread_key_t key;\n    int fail = pthread_key_create(&amp;key, NULL);\n    if (fail)\n        return -1;\n    if (key &gt; INT_MAX) {\n        /* Issue #22206: handle integer overflow */\n        pthread_key_delete(key);\n        errno = ENOMEM;\n        return -1;\n    }\n    return (int)key;\n}\n</code></pre>\n<p><code>PyThread_create_key</code>函数会创建一个<code>TLS entry</code>(线程本地存储), 返回一个整数<code>key</code>, 这个<code>key</code>作为全局共享的<code>autoTLSkey</code>, 所有线程都能访问.</p>\n<p>线程可以通过一系列的<code>API</code>操作和自己线程相关的数据:</p>\n<ul>\n<li><code>PyThread_get_key_value</code></li>\n<li><code>PyThread_set_key_value</code></li>\n<li>……</li>\n</ul>\n<p>不过我看这个<code>thread_pthread.h</code>中关于<code>TLS</code>的实现存储<code>tstate</code>好像也没有什么用, 不是可以通过指针<code>_PyThreadState_Current</code>获得当前线程状态对象吗? 另外也可以对<code>interp-&gt;state_head</code>遍历得到<code>tstate</code>啊.</p>\n<p>不知道是不是因为兼容其他平台的实现, 或者不光用来存储线程状态对象还存储其他东西?…</p>\n<h2 id=\"线程调度\"><a href=\"#线程调度\" class=\"headerlink\" title=\"线程调度\"></a>线程调度</h2><p>在主线程创建子线程后, <code>t_bootstrap</code>函数是在子线程中执行的, 而在<code>PyEval_AcquireThread</code>竞争<code>GIL</code>之前的线程调度属于操作系统的线程调度, 之后的等待<code>GIL</code>锁以及之后的字节码执行才属于Python的线程调度范畴.</p>\n<p>进入字节码执行阶段, Python会模拟操作系统的时钟机制来实现线程调度:</p>\n<pre><code class=\"c\">PyObject *\n_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)\n{\n    ......\n    for (;;) {\n        ......\n        if (_Py_atomic_load_relaxed(&amp;gil_drop_request)) {\n            /* Give another thread a chance */\n            if (PyThreadState_Swap(NULL) != tstate)\n                Py_FatalError(&quot;ceval: tstate mix-up&quot;);\n            drop_gil(tstate); /* 释放GIL */\n\n            /* Other threads may run now */\n\n            take_gil(tstate); /* 重新尝试GIL */\n\n            /* Check if we should make a quick exit. */\n            if (_Py_Finalizing &amp;&amp; _Py_Finalizing != tstate) {\n                drop_gil(tstate);\n                PyThread_exit_thread();\n            }\n\n            if (PyThreadState_Swap(tstate) != NULL)\n                Py_FatalError(&quot;ceval: orphan tstate&quot;);\n        }\n    ......\n}\n</code></pre>\n<p>在执行字节码的过程中, 当达到某个条件后, 会尝试释放锁<code>drop_gil(tstate);</code>, 而释放锁可能被其他线程立即获得, 主线程将会等待其他线程释放<code>GIL</code>, 因此需要重新申请<code>GIL</code>.</p>\n<h2 id=\"阻塞调度\"><a href=\"#阻塞调度\" class=\"headerlink\" title=\"阻塞调度\"></a>阻塞调度</h2><p>除了标准的线程调度外, Python还有一种阻塞调度的方式: 当线程执行<code>I/O</code>操作, 或者是睡眠<code>sleep</code>, 那么线程将会挂起, 虚拟机会唤醒正在等待的其他线程.</p>\n<p>我们以<code>time.sleep</code>为例, 分析Python的阻塞调度机制.</p>\n<pre><code class=\"c\">static PyObject *\ntime_sleep(PyObject *self, PyObject *obj)\n{\n    _PyTime_t secs; /* int64_t 的别名 */\n    if (_PyTime_FromSecondsObject(&amp;secs, obj, _PyTime_ROUND_TIMEOUT)) /* 转换成timestamp */\n        return NULL;\n    if (pysleep(secs) != 0)\n        return NULL;\n    return Py_None;\n}\n</code></pre>\n<p>下面是<code>pysleep</code>函数的实现:</p>\n<pre><code class=\"c\">static int\npysleep(_PyTime_t secs)\n{\n    _PyTime_t deadline, monotonic;\n    struct timeval timeout;\n    int err = 0;\n    deadline = _PyTime_GetMonotonicClock() + secs; /* 单调时间 */\n    do {\n        if (_PyTime_AsTimeval(secs, &amp;timeout, _PyTime_ROUND_CEILING) &lt; 0)\n            return -1; /* 将timestamp转换成struct timeval结构 */\n        Py_BEGIN_ALLOW_THREADS\n        err = select(0, (fd_set *)0, (fd_set *)0, (fd_set *)0, &amp;timeout);\n        Py_END_ALLOW_THREADS\n        if (PyErr_CheckSignals()) /* sleep was interrupted by SIGINT */\n            return -1;\n        monotonic = _PyTime_GetMonotonicClock();\n        secs = deadline - monotonic;\n        if (secs &lt; 0)\n            break;\n    } while (1); /* retry with the recomputed delay */\n    return 0;\n}\n</code></pre>\n<p>Python在这里使用<code>select</code>实现了<code>time.sleep(n)</code>的阻塞形式. 在阻塞的前后, 有两个宏定义:</p>\n<ul>\n<li><code>Py_BEGIN_ALLOW_THREADS</code>: 设置当前线程状态对象为<code>NULL</code>, 释放<code>GIL</code>, 保存线程状态对象;</li>\n<li><code>Py_END_ALLOW_THREADS</code>: 获取<code>GIL</code>锁, 重新设置当前线程对象.</li>\n</ul>\n<p>Python正是利用上面两个宏定义实现了阻塞调度机制, 只要能保证线程安全, 我们就可以使用<code>Py_BEGIN_ALLOW_THREADS</code>和<code>Py_END_ALLOW_THREADS</code>释放<code>GIL</code>.</p>\n<h2 id=\"子线程销毁\"><a href=\"#子线程销毁\" class=\"headerlink\" title=\"子线程销毁\"></a>子线程销毁</h2><p>线程执行占有<code>GIL</code>, 而当线程结束运行的时候就会释放<code>GIL</code>:</p>\n<pre><code class=\"c\">[_threadmodule.c]\nstatic void\nt_bootstrap(void *boot_raw)\n{\n    struct bootstate *boot = (struct bootstate *) boot_raw;\n    PyThreadState *tstate;\n    ......\n    PyMem_DEL(boot_raw);\n    nb_threads--;\n    PyThreadState_Clear(tstate); /* 线程状态对象清理 */\n    PyThreadState_DeleteCurrent(); /* GIL释放 */\n    PyThread_exit_thread(); /* 线程退出 */\n}\n</code></pre>\n<p>在<code>t_bootstrap</code>函数的末尾, 我们可以看见Python做了清理线程的工作, 引用计数的维护(这里没有列出)以及<code>GIL</code>的释放和线程的退出. <code>GIL</code>的释放在<code>PyThreadState_DeleteCurrent</code>函数中:</p>\n<pre><code class=\"c\">[pystate.c]\nvoid\nPyThreadState_DeleteCurrent()\n{\n    PyThreadState *tstate = GET_TSTATE(); /* 获取当前线程对象 */\n    tstate_delete_common(tstate);\n    if (autoInterpreterState &amp;&amp; PyThread_get_key_value(autoTLSkey) == tstate)\n        PyThread_delete_key_value(autoTLSkey); /* TLS中的tstate删除 */\n    SET_TSTATE(NULL); /* 设置当前线程对象为NULL */\n    PyEval_ReleaseLock(); /* 释放GIL锁 */\n}\n</code></pre>\n<h2 id=\"更多\"><a href=\"#更多\" class=\"headerlink\" title=\"更多\"></a>更多</h2><p>在Python的<code>GIL</code>机制下, 线程之间对整个Python解释器, 对Python提供的C API的访问都是互斥, 可以看作是Python内核级的互斥机制. 然而这种机制是Python程序员无法控制的, 我们还需要另外一种互斥机制—用户级互斥, 所以Python在这之上有提供了一系列的库, 例如: <code>threading</code>.</p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-import机制","url":"http://shawnz.me/posts/5a3f63f9/","content":"<h2 id=\"import指令\"><a href=\"#import指令\" class=\"headerlink\" title=\"import指令\"></a>import指令</h2><p><code>import</code>有两种形式:</p>\n<ul>\n<li><code>import ...</code></li>\n<li><code>from ... import ...</code></li>\n</ul>\n<p>我们从简单的<code>import sys</code>开始，看看背后都发生了什么：</p>\n<a id=\"more\"></a>\n<pre><code class=\"python\">import sys\n# 0 LOAD_CONST               0 (0)\n# 2 LOAD_CONST               1 (None)\n# 4 IMPORT_NAME              0 (sys)\n# 6 STORE_NAME               0 (sys)\n</code></pre>\n<p>关键的<code>IMPORT_NAME 0</code>指令：</p>\n<pre><code class=\"c\">names = co-&gt;co_names;\n\nTARGET(IMPORT_NAME) {\n    PyObject *name = GETITEM(names, oparg); /* 从co-&gt;const常量表中获取&quot;sys&quot; */\n    PyObject *fromlist = POP(); /* None */\n    PyObject *level = TOP(); /* 0 */\n    PyObject *res;\n    res = import_name(f, name, fromlist, level); /* f是frame */\n    SET_TOP(res);\n    DISPATCH();\n}\n</code></pre>\n<p>在<code>IMPORT_NAME</code>指令中首先获取到了几个参数，然后调用<code>import_name</code>导入模块，并通过<code>SET_TOP</code>将模块对象压入栈顶，最终指令<code>STORE_NAME</code>将把模块对象存入命名空间中。</p>\n<pre><code class=\"c\">static PyObject *\nimport_name(PyFrameObject *f, PyObject *name, PyObject *fromlist, PyObject *level)\n{\n    _Py_IDENTIFIER(__import__);\n    PyObject *import_func, *res;\n    PyObject* stack[5];\n    /* 获取builtins模块的__import__函数*/\n    import_func = _PyDict_GetItemId(f-&gt;f_builtins, &amp;PyId___import__);\n    /* 如果用户没有重写import_func */\n    if (import_func == PyThreadState_GET()-&gt;interp-&gt;import_func) {\n        int ilevel = _PyLong_AsInt(level);\n        res = PyImport_ImportModuleLevelObject(\n                        name,\n                        f-&gt;f_globals,\n                        f-&gt;f_locals == NULL ? Py_None : f-&gt;f_locals,\n                        fromlist,\n                        ilevel);\n        return res;\n    }\n}\n</code></pre>\n<p><code>import_name</code>函数首先从全局命名空间<code>builtins</code>(默认就是<code>builtins</code>模块的<code>md_dict</code>)中获取<code>__import__</code>函数。这个函数是对<code>builtin___import__</code>函数指针的包装，虚拟机会检查程序员是否对这个函数进行了重写, 如果没有重写(这里我们只考虑没有重写的情况), 就调用<code>PyImport_ImportModuleLevelObject</code>导入模块. </p>\n<p><code>PyImport_ImportModuleLevelObject</code>函数的实现十分复杂, 这里列出了精简后的代码:</p>\n<pre><code class=\"c\">PyObject *\nPyImport_ImportModuleLevelObject(PyObject *name, PyObject *globals,\n                                 PyObject *locals, PyObject *fromlist,\n                                 int level)\n{\n    _Py_IDENTIFIER(_find_and_load);\n    _Py_IDENTIFIER(_handle_fromlist);\n    PyObject *abs_name = NULL;\n    PyObject *final_mod = NULL;\n    PyObject *mod = NULL;\n    PyObject *package = NULL;\n    PyInterpreterState *interp = PyThreadState_GET()-&gt;interp; /* 获取进程状态对象 */\n    int has_from;\n\n    if (level &gt; 0) {\n        abs_name = resolve_name(name, globals, level); /* 解析模块的绝对路径 */\n    }\n    else {  /* level == 0 */\n        abs_name = name;\n    }\n\n    mod = PyDict_GetItem(interp-&gt;modules, abs_name); /* 尝试从全局的interp-&gt;modules中获取模块 */\n    if (mod != NULL &amp;&amp; mod != Py_None) {\n        _Py_IDENTIFIER(__spec__);\n        _Py_IDENTIFIER(_initializing);\n        _Py_IDENTIFIER(_lock_unlock_module);\n        PyObject *value = NULL;\n        PyObject *spec;\n        int initializing = 0;\n\n        spec = _PyObject_GetAttrId(mod, &amp;PyId___spec__);\n        if (spec != NULL) {\n            value = _PyObject_GetAttrId(spec, &amp;PyId__initializing);\n        }\n        if (value == NULL)\n            PyErr_Clear();\n        else {\n            initializing = PyObject_IsTrue(value);\n            if (initializing == -1)\n                PyErr_Clear();\n            if (initializing &gt; 0) {\n                value = _PyObject_CallMethodIdObjArgs(interp-&gt;importlib,\n                                                &amp;PyId__lock_unlock_module, abs_name,\n                                                NULL);\n            }\n        }\n    }\n    else { /* 模块第一次加载 */\n        mod = _PyObject_CallMethodIdObjArgs(interp-&gt;importlib,\n                                            &amp;PyId__find_and_load, abs_name,\n                                            interp-&gt;import_func, NULL);\n    }\n    /* 处理from ... import ... 形式的导入 */\n    has_from = 0;\n    if (fromlist != NULL &amp;&amp; fromlist != Py_None) {\n        has_from = PyObject_IsTrue(fromlist);\n        if (has_from &lt; 0)\n            goto error;\n    }\n    if (!has_from) { /* 不是from ... 格式 */\n        Py_ssize_t len = PyUnicode_GET_LENGTH(name);\n        if (level == 0 || len &gt; 0) {\n            Py_ssize_t dot;\n            /* 查找是否包含&quot;.&quot;, 有则返回索引,否则返回-1 */\n            dot = PyUnicode_FindChar(name, &#39;.&#39;, 0, len, 1);\n            if (dot == -1) { /* */\n                final_mod = mod;\n                goto error;\n            }\n\n            if (level == 0) {\n                PyObject *front = PyUnicode_Substring(name, 0, dot);\n                if (front == NULL) {\n                    goto error;\n                }\n\n                final_mod = PyImport_ImportModuleLevelObject(front, NULL, NULL, NULL, 0);\n            }\n            else {\n                Py_ssize_t cut_off = len - dot;\n                Py_ssize_t abs_name_len = PyUnicode_GET_LENGTH(abs_name);\n                PyObject *to_return = PyUnicode_Substring(abs_name, 0,\n                                                        abs_name_len - cut_off);\n                if (to_return == NULL) {\n                    goto error;\n                }\n\n                final_mod = PyDict_GetItem(interp-&gt;modules, to_return);\n                Py_DECREF(to_return);\n                if (final_mod == NULL) {\n                    PyErr_Format(PyExc_KeyError,\n                                 &quot;%R not in sys.modules as expected&quot;,\n                                 to_return);\n                    goto error;\n                }\n                Py_INCREF(final_mod);\n            }\n        }\n        else {\n            final_mod = mod;\n            Py_INCREF(mod);\n        }\n    }\n    else {\n        final_mod = _PyObject_CallMethodIdObjArgs(interp-&gt;importlib,\n                                                  &amp;PyId__handle_fromlist, mod,\n                                                  fromlist, interp-&gt;import_func,\n                                                  NULL);\n    }\n  error:\n    if (final_mod == NULL)\n        remove_importlib_frames();\n    return final_mod;\n}\n</code></pre>\n<p>在导入模块时, Python会先尝试从全局的<code>interp-&gt;modules</code>集合(即<code>sys.modules</code>)中获取模块. 如果模块缓存中存在, Python还会检查模块是否处于初始化状态中, 如果模块正在初始化(其它线程), 那么会调用<code>_lock_unlock_module</code>等待锁的释放(<code>import</code>动作需要加锁). </p>\n<p>我们可以看到Python3中, <code>import</code>的实现是<code>importlib</code>. 比较特殊的是在Python内部, 通过文件<code>_freeze_importlib.c</code>将以Python实现的<code>importlib/_bootstrap.py</code>转换成了字节码序列的形式在内部执行.</p>\n<pre><code class=\"c\">const unsigned char _Py_M__importlib[] = {\n    99,0,0,0,0,0,0,0,0,0,0,0,0,4,0,0,\n    ...\n}\n</code></pre>\n<p>和在<code>sys.modules</code>缓存中找到模块对应, 如果模块是第一次加载, 则会调用<code>_find_and_load</code>导入模块.</p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-类机制","url":"http://shawnz.me/posts/75b3e8d4/","content":"<h2 id=\"类型模型\"><a href=\"#类型模型\" class=\"headerlink\" title=\"类型模型\"></a>类型模型</h2><p>在Python3中所有的类都是新式类，继承自<code>&lt;type &#39;object&#39;&gt;</code>，且默认的所有类对象都是<code>&lt;type &#39;type&#39;&gt;</code>的实例。(到这里你可能会疑惑“先有鸡还是先有蛋”)</p>\n<p>在Python中它们的关系如下：</p>\n<a id=\"more\"></a>\n<p><img src=\"/images/pyclassobject-1.png\" alt=\"\"></p>\n<h2 id=\"类对象初始化\"><a href=\"#类对象初始化\" class=\"headerlink\" title=\"类对象初始化\"></a>类对象初始化</h2><p>在<code>pylifecycle.c</code>的<code>Py_Initialize()</code>中，Python内部先是会使用<code>_Py_ReadyTypes</code>完成类型系统的准备。类型体系的准备是以一个固定的顺序调用<code>PyType_Ready</code>初始化各种内置类型对象。</p>\n<p>我们来看看<code>PyType_Ready</code>都做了哪些工作：</p>\n<pre><code class=\"c\">int\nPyType_Ready(PyTypeObject *type)\n{\n    PyObject *dict, *bases;\n    PyTypeObject *base;\n    Py_ssize_t i, n;\n    /* [1].尝试获得type的tp_base指定基类，否则指定基类为`PyBaseObject_Type` */\n    base = type-&gt;tp_base;\n    if (base == NULL &amp;&amp; type != &amp;PyBaseObject_Type) {\n        base = type-&gt;tp_base = &amp;PyBaseObject_Type;\n        Py_INCREF(base);\n    }\n    /* 到现在为止，基类仍然为空的只能是PyBaseObject_Type */\n\n    /* [2].如果基类没有初始化，先初始化基类 */\n    if (base != NULL &amp;&amp; base-&gt;tp_dict == NULL) {\n        if (PyType_Ready(base) &lt; 0)\n            goto error;\n    }\n    /* [3].设置ob_type信息 */\n    if (Py_TYPE(type) == NULL &amp;&amp; base != NULL)\n        Py_TYPE(type) = Py_TYPE(base);\n    ...\n\n    /* [4].初始化tp_bases */\n    bases = type-&gt;tp_bases;\n    if (bases == NULL) {\n        if (base == NULL)\n            bases = PyTuple_New(0);\n        else\n            bases = PyTuple_Pack(1, base);\n        if (bases == NULL)\n            goto error;\n        type-&gt;tp_bases = bases;\n    }\n</code></pre>\n<p>在初始化阶段，对于指定了<code>tp_base</code>的内置类型对象，它的基类就是指定的<code>tp_base</code>，否则Python会为所有类型对象设置基类为<code>PyBaseObject_Type</code>，也就我们说的<code>&lt;type &#39;object&#39;&gt;</code>，在这一步<code>PyBaseObject_Type</code>的基类可为空的：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; object.__base__\n&gt;&gt;&gt; \n</code></pre>\n<p>接下来是检查基类是否初始化完毕，如果没有就会先初始化基类(这里的检查条件是<code>tp_dict</code>是否为空，因为初始化的过程主要就是<code>tp_dict</code>的填充)。</p>\n<p>有了基类对象，虚拟机会将所有没有指定<code>ob_type</code>的类，设置<code>ob_type</code>为基类的<code>ob_type</code>，这个<code>ob_type</code>就是我们说的<code>元类</code>。</p>\n<p>到现在为止，也就有了所有类型对象的基类是<code>PyBaseObject_Type</code>(除了<code>PyBaseObject_Type</code>本身)，所有类型对象的<code>metaclass</code>就是<code>PyBaseObject_Type</code>的<code>metaclass</code>，而在<code>PyBaseObject_Type</code>的定义中，其<code>ob_type</code>域被设定为<code>PyType_Type</code>即<code>&lt;type &#39;type&#39;&gt;</code><br>。</p>\n<p>进行到第[4]步，是对基类列表的初始化，对于<code>PyBaseObject_Type</code>来说，其基类为空，基类列表也为空。而其他类型对象，如果<code>tp_bases</code>为空，那么它的基类列表都包含它的基类。</p>\n<p>接下就进了了初始化最关键的阶段：填充<code>tp_dict</code>：</p>\n<pre><code class=\"c\">...\n/* [5]. 初始化tp_dict */\ndict = type-&gt;tp_dict;\nif (dict == NULL) {\n    dict = PyDict_New();\n    if (dict == NULL)\n        goto error;\n    type-&gt;tp_dict = dict;\n}\n\n/* Add type-specific descriptors to tp_dict */\nif (add_operators(type) &lt; 0)\n    goto error;\nif (type-&gt;tp_methods != NULL) {\n    if (add_methods(type, type-&gt;tp_methods) &lt; 0)\n        goto error;\n}\nif (type-&gt;tp_members != NULL) {\n    if (add_members(type, type-&gt;tp_members) &lt; 0)\n        goto error;\n}\n...\n</code></pre>\n<p>填充<code>tp_dict</code>这个过程十分的繁琐，它是通过<code>add_operators</code>、<code>add_methods</code>、<code>add_members</code>和<code>tp_getset</code>几个函数将方法名和函数指针添加到<code>tp_dict</code>中。具体是怎么关联的就设计到了<code>slot机制</code>。</p>\n<h2 id=\"Slot机制\"><a href=\"#Slot机制\" class=\"headerlink\" title=\"Slot机制\"></a>Slot机制</h2><p><code>slot</code>可以视为表示<code>PyTypeObject</code>中定义的操作, 在一个操作对应一个slot。但一个<code>slot</code>不止包括一个函数指针，还有一些其他的信息，在Python内部是通过<code>slotdef</code>这个结构体实现的：</p>\n<pre><code class=\"c\">typedef struct wrapperbase slotdef;\n\nstruct wrapperbase {\n    char *name; /* name 表示操作应该的名称，如“__add__” */\n    int offset; /* 表示操作的函数在PyTypeObject或PyHeapTypeObject中的偏移量 */\n    void *function; /* 指向一个称谓为slot function的函数指针 */\n    wrapperfunc wrapper;\n    char *doc;\n    int flags;\n    PyObject *name_strobj;\n};\n</code></pre>\n<p>为了定义一个slot, Python提供了多个宏来定义, 其中最基本的有两个:</p>\n<pre><code class=\"c\">#define TPSLOT(NAME, SLOT, FUNCTION, WRAPPER, DOC) \\\n    {NAME, offsetof(PyTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \\\n     PyDoc_STR(DOC)}\n\n#define `ETSLOT`(NAME, SLOT, FUNCTION, WRAPPER, DOC) \\\n    {NAME, offsetof(PyHeapTypeObject, SLOT), (void *)(FUNCTION), WRAPPER, \\\n     PyDoc_STR(DOC)}\n</code></pre>\n<p>可以看到这两个宏定义，有一个明显的区别：<code>TPSLOT</code>里面的偏移是在<code>PyTypeObject</code>上的偏移，而<code>ETSLOT</code>的偏移是在<code>PyHeapTypeObject</code>上。</p>\n<p>这一点是因为在<code>PyTypeObject</code>上，有的操作，例如<code>nb_add</code>，其函数指针是存放在<code>PyNumberMethods</code>结构体中，在<code>PyTypeObject</code>中只有一个<code>tp_as_number</code>指针指向那个结构体。所以根本无法计算函数指针在<code>PyTypeObject</code>上的偏移量。所以Python引入了<code>PyHeapTypeObject</code>：</p>\n<pre><code class=\"c\">typedef struct _heaptypeobject {\n    PyTypeObject ht_type; /* 结构体的首部是一个PyTypeObject */\n    PyAsyncMethods as_async;\n    PyNumberMethods as_number;\n    PyMappingMethods as_mapping;\n    PySequenceMethods as_sequence; \n    PyBufferProcs as_buffer;\n    PyObject *ht_name, *ht_slots, *ht_qualname;\n    struct _dictkeysobject *ht_cached_keys;\n    /* here are optional user slots, followed by the members. */\n} PyHeapTypeObject;\n</code></pre>\n<h2 id=\"Descriptor\"><a href=\"#Descriptor\" class=\"headerlink\" title=\"Descriptor\"></a>Descriptor</h2><p>然而<code>slot</code>并不是对象，它并不能放在<code>tp_dict</code>中，也不会调用(因为没有类型)，所以在<code>tp_dict</code>中与<code>__getitem__</code>对应只能是另外一个包装了<code>slot</code>的东西，在Pythono中称之为<code>descriptor</code>。</p>\n<p>与<code>PyTypeObject</code>中操作对应的就是<code>PyWrapperDescrObject</code>，它里面包含一个<code>slot</code>：</p>\n<pre><code class=\"c\">typedef struct {\n    PyObject_HEAD\n    PyTypeObject *d_type;\n    PyObject *d_name;\n    PyObject *d_qualname;\n} PyDescrObject;\n\n#define PyDescr_COMMON PyDescrObject d_common\n\ntypedef struct {\n    PyDescr_COMMON; /* 所有descriptor都有PyDescr_COMMON部分 */\n    struct wrapperbase *d_base; /* 对应一个slot */\n    void *d_wrapped; /* 对应函数指针 */\n} PyWrapperDescrObject;\n</code></pre>\n<p>这些<code>descriptor</code>通过<code>PyDescr_NewWrapper</code>创建:</p>\n<pre><code class=\"c\">PyObject *\nPyDescr_NewWrapper(PyTypeObject *type, struct wrapperbase *base, void *wrapped)\n{\n    PyWrapperDescrObject *descr;\n    descr = (PyWrapperDescrObject *)descr_new(&amp;PyWrapperDescr_Type,\n                                             type, base-&gt;name);\n    if (descr != NULL) {\n        descr-&gt;d_base = base;\n        descr-&gt;d_wrapped = wrapped;\n    }\n    return (PyObject *)descr;\n}\n\nstatic PyDescrObject *\ndescr_new(PyTypeObject *descrtype, PyTypeObject *type, const char *name)\n{\n    PyDescrObject *descr;\n    descr = (PyDescrObject *)PyType_GenericAlloc(descrtype, 0);\n    if (descr != NULL) {\n        descr-&gt;d_type = type;\n        descr-&gt;d_name = PyUnicode_InternFromString(name);\n    }\n    return descr;\n}\n</code></pre>\n<p>创建的<code>PyDescrObject</code>对象的<code>d_type</code>域被设置为参数<code>type</code>，而<code>d_wrapped</code>存放着最重要的信息：操作对应的函数指针。 比如对<code>PyList_Type</code>来说, 它的<code>tp_dict[&quot;__getitem__&quot;].d_wrapped</code>就是<code>&amp;mp_subscript</code>，而<code>slot</code>则被存放在<code>d_base</code>中。</p>\n<p><code>PyWrapperDescrObject</code>对象的类型对象是<code>PyWrapperDescr_Type</code>，这个类型对象的<code>tp_call</code>域的函数指针指向<code>wrapperdescr_call</code>，Python在”调用“一个<code>descriptor</code>时，也就会调用<code>wrapperdescr_call</code>。</p>\n<h2 id=\"建立联系\"><a href=\"#建立联系\" class=\"headerlink\" title=\"建立联系\"></a>建立联系</h2><p>在Python2中，<code>slotdefs</code>在初始化的过程<code>init_slotdefs</code>中，需要经历一次”快排“排好序，而在Python3中，<code>slotdefs</code>会以一种有序的顺序预先定义好，在<code>init_slotdefs</code>只会检查<code>slotdefs</code>里操作偏移量是递增的。</p>\n<p>现在<code>slotdefs</code>已经准备好了，在<code>add_operators</code>中会基于每个<code>slot</code>建立一个<code>descriptor</code>，然后在<code>tp_dict</code>保存操作名到<code>descriptor</code>的关联：</p>\n<pre><code class=\"c\">static int\nadd_operators(PyTypeObject *type)\n{\n    PyObject *dict = type-&gt;tp_dict;\n    slotdef *p;\n    PyObject *descr;\n    void **ptr;\n\n    init_slotdefs(); /* [1].初始化slotdefs，这个函数只会在第一次调用的时候生效 */\n    for (p = slotdefs; p-&gt;name; p++) {\n        if (p-&gt;wrapper == NULL) /* [2].如果slot没有指定wrapper，则不做处理 */\n            continue;\n        ptr = slotptr(type, p-&gt;offset); /* [3].获得slotdef对应的操作在PyTypeObject中的偏移量 */\n        if (!ptr || !*ptr)\n            continue;\n        if (PyDict_GetItem(dict, p-&gt;name_strobj))/* [4].如果tp_dict已存在同名操作名，则不作处理 */\n            continue;\n        if (*ptr == (void *)PyObject_HashNotImplemented) {\n            /* Classes may prevent the inheritance of the tp_hash\n               slot by storing PyObject_HashNotImplemented in it. Make it\n               visible as a None value for the __hash__ attribute. */\n            if (PyDict_SetItem(dict, p-&gt;name_strobj, Py_None) &lt; 0)\n                return -1;\n        }\n        else {\n            descr = PyDescr_NewWrapper(type, p, *ptr); /* [5].创建descriptor */\n            if (descr == NULL)\n                return -1;\n            /* [6].将(操作名，descriptor)放入tp_dict中 */ \n            if (PyDict_SetItem(dict, p-&gt;name_strobj, descr) &lt; 0) { \n                return -1;\n            }\n        }\n    }\n    if (type-&gt;tp_new != NULL) {\n        if (add_tp_new_wrapper(type) &lt; 0)\n            return -1;\n    }\n    return 0;\n}\n</code></pre>\n<p>在<code>add_operators</code>中一切都很简单，直观，需要注意的一点是在[4]处，如果<code>tp_dict</code>已存在同名操作名，则不作处理，意味着如果相同的操作名对应多个<code>slot</code>，那么只有定义在前面的才会填充进<code>tp_dict</code>中。例如：</p>\n<pre><code class=\"c\">MPSLOT(&quot;__getitem__&quot;, mp_subscript, slot_mp_subscript, wrap_binaryfunc, &quot;__getitem__(...&quot;),\nSQSLOT(&quot;__getitem__&quot;, sq_item, slot_sq_item, wrap_sq_item, &quot;__getitem__($...&quot;),\n</code></pre>\n<p>例如操作名<code>__getitem__</code>同时对应着两个操作，但是偏移量<code>mp_subscript</code>小于<code>sq_item</code>，前者会先被处理，虚拟机会将<code>slot_mp_subscript</code>和操作名<code>__getitem__</code>绑定。</p>\n<p>在[3]处函数<code>slotptr</code>背后，通过这个函数可以找到<code>slot</code>到<code>slot</code>对应的操作的真实函数指针转换：</p>\n<pre><code class=\"c\">static void **\nslotptr(PyTypeObject *type, int ioffset)\n{\n    char *ptr;\n    long offset = ioffset;\n\n    /* 在PyHeapTypeObject上从后往前计算指针偏移量 */\n    assert(offset &gt;= 0); /* 操作对应的函数指针偏移量必然在0~as_buffer之间 */\n    assert((size_t)offset &lt; offsetof(PyHeapTypeObject, as_buffer));\n    if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_sequence)) {\n        ptr = (char *)type-&gt;tp_as_sequence;\n        offset -= offsetof(PyHeapTypeObject, as_sequence);\n    }\n    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_mapping)) {\n        ptr = (char *)type-&gt;tp_as_mapping;\n        offset -= offsetof(PyHeapTypeObject, as_mapping);\n    }\n    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_number)) {\n        ptr = (char *)type-&gt;tp_as_number;\n        offset -= offsetof(PyHeapTypeObject, as_number);\n    }\n    else if ((size_t)offset &gt;= offsetof(PyHeapTypeObject, as_async)) {\n        ptr = (char *)type-&gt;tp_as_async;\n        offset -= offsetof(PyHeapTypeObject, as_async);\n    }\n    else {\n        ptr = (char *)type; /* 偏移量是基于PyTypeObject的 */\n    }\n    if (ptr != NULL)\n        ptr += offset;\n    return (void **)ptr;\n}\n</code></pre>\n<p>上面这种在<code>PyHeapTypeObject</code>结构体的<code>as_sequence</code>、<code>as_mapping</code>…到<code>type</code>几个域从后往前计算函数指针偏移量的方式，能够一次就保证找到真实的函数指针地址。</p>\n<p>通过<code>add_operators</code>为<code>PyType_Type</code>添加一些操作后, 还会通过<code>add_methods</code>、<code>add_members</code>和<code>add_getsets</code>添加<code>tp_methods</code>, <code>tp_members</code>和<code>tp_getset</code>函数集。虽然和<code>add_operators</code>类似, 但添加的<code>descriptor</code>不是<code>PyWrapperDescrObject</code>, 而分别是<code>PyMethodDescrObject</code>, <code>PyMemberDescrObject</code>和<code>PyGetSetDescrObject</code>。</p>\n<p><img src=\"/images/pyclassobject-2.png\" alt=\"\"></p>\n<h2 id=\"方法重写\"><a href=\"#方法重写\" class=\"headerlink\" title=\"方法重写\"></a>方法重写</h2><p>我们应该知道，<code>__repr__</code>是一个特殊的<code>magic method</code>， 当执行<code>s = &quot;%r&quot; % A()</code>的时候， 最终会调用<code>A.tp_repr</code>。 如果假设 A 是 list 类型， 那么就应该调用<code>list_repr</code>这个函数， 然而实际并不是这样的， Python知道需要对这个方法进行特殊处理，最终执行我们重写的<code>__repr__</code>函数。</p>\n<p>而Python之所以知道， 是因为<code>slot</code>， 有一条特殊的<code>TPSLOT(&quot;__repr__&quot;,tp_repr,slot_tp_repr...)</code>。虚拟机在初始化A的时候，会检查到A的<code>tp_dict</code>中是否有<code>__repr__</code>函数， 一旦找到，就会根据对应的<code>slot</code>顺藤摸瓜找到<code>tp_repr</code>， 并替换成<code>slot_tp_repr</code>， 所以后面实际执行的是<code>slot_tp_repr</code>。</p>\n<p>这个函数内部会在对象上查找<code>__repr__</code>函数， 调用。</p>\n<p>函数指针的修复，发生在<code>fixup_slot_dispatchers(PyTypeObject* type)</code>中，对于内置的class对象， 并不会进行这个操作，实际这个操作发生在自定义class对象的初始化期间。</p>\n<h2 id=\"MRO\"><a href=\"#MRO\" class=\"headerlink\" title=\"MRO\"></a>MRO</h2><p><code>MRO</code>(<code>Method Resolution Order</code>，即方法解析顺序)。对于Python这种多继承语言来说，<code>MRO</code>显得比较复杂。</p>\n<p>在这里不会讲到Python的<code>MRO</code>过去的算法，重点关注的是Python3中的<code>C3 MRO</code>。</p>\n<p>在<code>PyType_Ready</code>填充完<code>tp_dict</code>后会通过<code>mro_internal</code>函数计算类型的<code>MRO</code>循序，由于这个过程十分繁琐，这里只针对关键代码进行了分析：</p>\n<pre><code class=\"c\">static PyObject *\nmro_implementation(PyTypeObject *type)\n{\n    bases = type-&gt;tp_bases; /* type的基类列表 */\n    n = PyTuple_GET_SIZE(bases); \n    /* to_merge是一个列表的列表，前面n个元素是每个基类的mro列表，最后一个元素是基类列表 */\n    to_merge = PyList_New(n+1); \n    /* 将基类列表中每个基类的mro顺序放在to_merge中 */\n    for (i = 0; i &lt; n; i++) {\n        base = (PyTypeObject *)PyTuple_GET_ITEM(bases, i); /* 基类 */\n        base_mro_aslist = PySequence_List(base-&gt;tp_mro);  /* 基类的mro列表 */\n        PyList_SET_ITEM(to_merge, i, base_mro_aslist);\n    }\n    bases_aslist = PySequence_List(bases);\n    /* 重复基类检查 */\n    if (check_duplicates(bases_aslist) &lt; 0) {\n        goto out;\n    }\n    PyList_SET_ITEM(to_merge, n, bases_aslist); /* to_merge最后一个元素设为基类列表 */\n    result = Py_BuildValue(&quot;[O]&quot;, (PyObject *)type); /* merge结果保存在result里 */\n    res = pmerge(result, to_merge); /* 合并操作 */\n  out:\n    Py_DECREF(to_merge);\n\n    return result;\n}\n</code></pre>\n<p>其核心的<code>pmerge</code>操作：</p>\n<pre><code class=\"c\">static int\npmerge(PyObject *acc, PyObject* to_merge)\n{\n    int res = 0;\n    Py_ssize_t i, j, to_merge_size, empty_cnt;\n    int *remain;\n    to_merge_size = PyList_GET_SIZE(to_merge);\n    /* remain数组存放了第i个基类mro列表下一次取得元素的索引 */\n    remain = (int *)PyMem_MALLOC(SIZEOF_INT*to_merge_size);\n    for (i = 0; i &lt; to_merge_size; i++)\n        remain[i] = 0; /* 初始化为0 */\n\n  again:\n    empty_cnt = 0;\n    for (i = 0; i &lt; to_merge_size; i++) {\n        PyObject *candidate; /* 候选类 */\n        PyObject *cur_list = PyList_GET_ITEM(to_merge, i); /* 基类的mro列表 */\n\n        if (remain[i] &gt;= PyList_GET_SIZE(cur_list)) { /* 该基类的mro列表已取完 */\n            empty_cnt++;\n            continue;\n        }\n\n        candidate = PyList_GET_ITEM(cur_list, remain[i]); /* 从基类mro列表中确定了候选类 */\n        for (j = 0; j &lt; to_merge_size; j++) { /* 如果在其他基类列表中的”尾部“包括了候选类，则跳过*/\n            PyObject *j_lst = PyList_GET_ITEM(to_merge, j);\n            if (tail_contains(j_lst, remain[j], candidate))\n                goto skip; /* continue outer loop */\n        }\n        res = PyList_Append(acc, candidate); /* 将候选类追加到acc中 */\n        for (j = 0; j &lt; to_merge_size; j++) {\n            PyObject *j_lst = PyList_GET_ITEM(to_merge, j);\n            if (remain[j] &lt; PyList_GET_SIZE(j_lst) &amp;&amp;\n                PyList_GET_ITEM(j_lst, remain[j]) == candidate) {\n                remain[j]++; /* 索引加一 */\n            }\n        }\n        goto again;\n      skip: ;\n    }\n    if (empty_cnt != to_merge_size) { /* 处理结束后，如果还有基类的mro列表没有处理完成，则失败 */\n        set_mro_error(to_merge, remain);\n        res = -1;\n    }\n  out:\n    PyMem_FREE(remain);\n\n    return res;\n}\n</code></pre>\n<p>看完上述代码，总结其过程就是：</p>\n<p>我们把类<code>C</code>的线性化MRO记为<code>L[C] = [C1, C2,…,CN]</code>。其中<code>C1</code>称为<code>L[C]</code>的“头”，其余元素<code>[C2,…,CN]</code>称为”尾“。如果一个类<code>C</code>继承自基类<code>B1、B2、……、BN</code>，那么我们可以根据以下两步计算出<code>L[C]</code>：</p>\n<ul>\n<li><code>L[object] = [object]</code></li>\n<li><code>L[C(B1…BN)] = [C] + merge(L[B1]…L[BN], [B1]…[BN])</code></li>\n</ul>\n<p>这里的关键在于<code>merge</code>，其输入是一组列表，按照如下方式输出一个列表：</p>\n<ol>\n<li>检查第一个列表的头元素（如<code>L[B1]</code>的头），记作<code>H</code>。</li>\n<li>若<code>H</code>未出现在其它列表的“尾部”，则将其输出，并将其从所有列表中删除(其实并不删除，只是记录索引位置，不过这里方便起见，可以理解为删除)，然后回到步骤1；否则，取出下一个列表的头部记作<code>H</code>，继续该步骤。</li>\n<li>重复上述步骤，直至列表为空(对应上面所有mro列表处理完毕)，则算法结束；<br><br> 或者不能再找出可以输出的元素(结束了但是还有mro列表没有处理完)，说明无法构建继承关系，Python会抛出异常。</li>\n</ol>\n<h2 id=\"基类与子类加工\"><a href=\"#基类与子类加工\" class=\"headerlink\" title=\"基类与子类加工\"></a>基类与子类加工</h2><p>在确定好<code>mro</code>列表后，就已经知道了基类和子类的关系，在<code>PyType_Ready</code>的下一步只要就是从基类那里继承各种属性和操作：</p>\n<pre><code class=\"c\">inherit_special(type, type-&gt;tp_base);  /* Inherit special flags from dominant base */\ninherit_slots(type, (PyTypeObject *)b);  /* Initialize tp_dict properly */\n... /* All bases of statically allocated type should be statically allocated */\n... /* Sanity check for tp_free. */\n... /* Hack for tp_hash and __hash__ */\n...  /* Some more special stuff */\nadd_subclass((PyTypeObject *)b, type) &lt; 0) /* Link into each base class&#39;s list of subclasses */\n... /* All done -- set the ready flag */\n</code></pre>\n<p>到现在为止，<code>PyType_Ready</code>的工作总结起来就是：</p>\n<ul>\n<li>设置type信息和基类信息</li>\n<li>填充tp_dict</li>\n<li>确定mro列表</li>\n<li>子类继承父类的操作</li>\n<li>设置基类的子类列表tp_subclasses</li>\n</ul>\n<h2 id=\"用户自定义类\"><a href=\"#用户自定义类\" class=\"headerlink\" title=\"用户自定义类\"></a>用户自定义类</h2><p>我们以一个简单例子开始：</p>\n<pre><code class=\"python\">[class_a.py]\nclass A:\n    name = &#39;Python&#39;\n\n    def __init__(self):\n        print(&quot;A.__init__&quot;)\n\n    def f(self):\n        print(&quot;A.f&quot;)\n\n    def g(self, value):\n        self.value = value\n        print(self.value)\n\na = A()\na.f()\na.g(10)\n</code></pre>\n<p>显然对于<code>class_a.py</code>源文件，经过编译后会得到四个<code>PyCodeObject</code>，它们的关系如下：</p>\n<p><img src=\"/images/pyclassobject-3.png\" alt=\"\"></p>\n<p>来看<code>class A</code>的创建过程：</p>\n<pre><code class=\"python\">[PyCodeObject for class_a.py]\nclass A:\n0 LOAD_BUILD_CLASS\n2 LOAD_CONST               1 (&lt;code object A at 0x7f1445f840c0, file &quot;class_a.py&quot;, line 3&gt;)\n4 LOAD_CONST               2 (&#39;A&#39;)\n6 MAKE_FUNCTION            0\n8 LOAD_CONST               2 (&#39;A&#39;)\n10 CALL_FUNCTION            2\n12 STORE_NAME               1 (A)\n</code></pre>\n<p>首先，我们可以看到的是一条指令<code>LOAD_BUILD_CLASS</code>，由这条指令的注释我们可以知道：这条指令将函数<code>builtins.__build_class__</code>压入了栈中，然后被之后的<code>CALL_FUNCTION</code>指令调用，构建一个类对象。</p>\n<pre><code class=\"c\">.. opcode:: LOAD_BUILD_CLASS\n   Pushes :func:`builtins.__build_class__` onto the stack.  It is later called\n   by :opcode:`CALL_FUNCTION` to construct a class.\n</code></pre>\n<p>正如注释里所说的，在<code>LOAD_BUILD_CLASS</code>指令后面，虚拟机加载了类对应的<code>PyCodeObject</code>和函数名称<code>A</code>构建了一个函数并压入栈中，所以直到<code>CALL_FUNCTION</code>调用的时候，此时运行时栈的内存布局应该是下面这个样子的：</p>\n<p><img src=\"/images/pyclassobject-4.png\" alt=\"\"></p>\n<p>接下来就是<code>CALL_FUNCTION</code>指令的执行了，由于它的指令参数为<code>2</code>(代表两个函数参数)，所以调用的<code>func</code>应该是<code>__build_class__</code>，也就是<code>__build_class__(&lt;func A&gt;, &quot;A&quot;&gt;)</code>。</p>\n<h2 id=\"build-class\"><a href=\"#build-class\" class=\"headerlink\" title=\"build_class\"></a><strong>build_class</strong></h2><p><code>__bulid_class__</code>的作用是通过一个函数对象创建类对象。它的的调用过程比较复杂，这里删除掉了一些源码(不影响阅读)：</p>\n<pre><code class=\"c\">static PyObject *\nbuiltin___build_class__(PyObject *self, PyObject *args, PyObject *kwds)\n{\n    PyObject *func, *name, *bases, *mkw, *meta, *winner, *prep, *ns;\n    PyObject *cls = NULL, *cell = NULL;\n    Py_ssize_t nargs;\n    int isclass = 0;   /* initialize to prevent gcc warning */\n\n    nargs = PyTuple_GET_SIZE(args);\n    func = PyTuple_GET_ITEM(args, 0); /* 类的函数对象 */\n    name = PyTuple_GET_ITEM(args, 1); /* 类名 */\n    bases = PyTuple_GetSlice(args, 2, nargs); /* 如果有剩余参数的话，就作为基类 */\n    if (bases == NULL)\n        return NULL;\n\n    if (kwds == NULL) {\n        meta = NULL;\n        mkw = NULL;\n    }\n    else {\n        mkw = PyDict_Copy(kwds); /* 不修改传递进来的关键字参数 */\n        meta = _PyDict_GetItemId(mkw, &amp;PyId_metaclass); /* 尝试获取metaclass关键字参数 */\n        if (meta != NULL) {\n            isclass = PyType_Check(meta); /* 检查meta是不是类 */\n        }\n    }\n    if (meta == NULL) {\n        if (PyTuple_GET_SIZE(bases) == 0) { /* 如果没有基类，那么metaclass就是type */\n            meta = (PyObject *) (&amp;PyType_Type);\n        }\n        else { /* 否则元类就是第一个基类的元类 */\n            PyObject *base0 = PyTuple_GET_ITEM(bases, 0);\n            meta = (PyObject *) (base0-&gt;ob_type);\n        }\n        isclass = 1; /* 基类是一个类 */\n    }\n\n    if (isclass) {\n        /* 元类计算，会从所有元类中选出一个在继承关系上最底层的元类 */\n        winner = (PyObject *)_PyType_CalculateMetaclass((PyTypeObject *)meta, bases);\n        if (winner != meta) {\n            meta = winner;\n        }\n    }\n    /* 尝试调用元类的__prepare__方法，这个方法会返回一个字典作为类的dict */\n    prep = _PyObject_GetAttrId(meta, &amp;PyId___prepare__);\n    if (prep == NULL) {\n        if (PyErr_ExceptionMatches(PyExc_AttributeError)) {\n            PyErr_Clear();\n            ns = PyDict_New();\n        }\n        else {\n            return NULL;\n        }\n    }\n    else {\n        PyObject *pargs[2] = {name, bases};\n        ns = _PyObject_FastCallDict(prep, pargs, 2, mkw);\n    }\n    if (!PyMapping_Check(ns)) {\n        /* ns 必须是一个mapping类型 */\n        goto error;\n    }/* 将类的函数对象作为闭包调用 */\n    cell = PyEval_EvalCodeEx(PyFunction_GET_CODE(func), PyFunction_GET_GLOBALS(func), ns,\n                             NULL, 0, NULL, 0, NULL, 0, NULL,\n                             PyFunction_GET_CLOSURE(func)); \n    if (cell != NULL) {\n        PyObject *margs[3] = {name, bases, ns}; /* 参宿包括类名，基类列表和类的locals命名空间 */\n        cls = _PyObject_FastCallDict(meta, margs, 3, mkw); /* 接下来就是调用元类的tp_call了 */\n        if (cls != NULL &amp;&amp; PyType_Check(cls) &amp;&amp; PyCell_Check(cell)) {\n            PyObject *cell_cls = PyCell_GET(cell);\n            if (cell_cls != cls) {\n                ...\n            }\n        }\n    }\nerror:\n    return cls;\n}\n</code></pre>\n<p>大致描述一下<code>__build_class__</code>创建类的过程为：</p>\n<ol>\n<li>获取<code>metaclass</code>：虚拟机会先检查是在在类定义的是否使用关键字参数<code>metaclass</code>自定义了元类，若没有那么元类就是<code>type</code>；</li>\n<li>尝试获取并调用元类的<code>__prepare__</code>方法：通过这个可以得到一个<code>ns</code>字典，这里会存放类的动态元信息；</li>\n<li>将类对应的<code>PyCodeObject</code>作为函数执行：所以在类的第一层定义的语句都会执行一次，这样<code>ns</code>作为<code>f_locals</code>函数定义，类变量都会存在这个命名空间中；</li>\n<li>调用元类的<code>tp_call</code>创建类；</li>\n</ol>\n<h2 id=\"调用metaclass\"><a href=\"#调用metaclass\" class=\"headerlink\" title=\"调用metaclass\"></a>调用metaclass</h2><p>默认的元类是<code>PyTypeObject</code>，所以我们来到它的<code>tp_call</code>定义处：</p>\n<pre><code class=\"c\">static PyObject *\ntype_call(PyTypeObject *type, PyObject *args, PyObject *kwds)\n{\n    PyObject *obj;\n    obj = type-&gt;tp_new(type, args, kwds);\n\n    type = Py_TYPE(obj);\n    if (type-&gt;tp_init != NULL) {  /* 尝试调用类型的__init__方法，初始化类对象 */\n        int res = type-&gt;tp_init(obj, args, kwds);\n    }\n    return obj;\n}\n</code></pre>\n<p><code>tp_call</code>函数中，传递的参数<code>type</code>是基类，而<code>args</code>中包括了类名，基类列表和命名空间。在内部，真正创建类对象的函数是<code>type</code>对象<code>type_new</code>，这个函数十分复杂，依照惯例只罗列部分关键源码：</p>\n<pre><code class=\"c\">\n\n</code></pre>\n<h2 id=\"创建instance\"><a href=\"#创建instance\" class=\"headerlink\" title=\"创建instance\"></a>创建instance</h2><p>现在就可以调用<code>class</code>对象创建<code>instance</code>实例了：</p>\n<pre><code class=\"python\">a = A()\n# 14 LOAD_NAME                0 (A)\n# 16 CALL_FUNCTION            0\n# 18 STORE_NAME               1 (a)\n</code></pre>\n<p>创建实例时，执行的是<code>CALL_FUNCTION</code>指令，我们知道这条指令会执行它对应的<code>PyType_Object</code>上定义的<code>tp_call</code>操作。这里class对象的<code>type</code>就是<code>PyType_Type</code>，而对应的<code>tp_call</code>操作中会调用<code>A.tp_new</code>创建示例。</p>\n<p>在上一步<code>__build_class__</code>的过程中，class对象从<code>PyBaseObject_Type</code>那里继承了一些操作，其中就有<code>tp_new</code>。<code>PyBaseObject_Type</code>的<code>object_new</code>会调用<code>PyType_GenericAlloc</code>来为对象分配内存，其大小为：<br></p>\n<pre><code class=\"c\">#define PyObject_NEW_VAR(type, typeobj, n) \\\n( (type *) PyObject_InitVar( \\\n      (PyVarObject *) PyObject_MALLOC(_PyObject_VAR_SIZE((typeobj),(n)) ),\\\n      (typeobj), (n)) )\n\nconst size_t size = _PyObject_VAR_SIZE(type, nitems+1);\n</code></pre>\n<p>申请完内存后，回到<code>tp_call</code>中，创建完<code>instance</code>对像后，会尝试调用<code>tp_init</code>初始化对象：</p>\n<pre><code class=\"c\">type = Py_TYPE(obj);\nif (type-&gt;tp_init != NULL) {  /* 尝试调用类型的__init__方法，初始化类对象 */\n    int res = type-&gt;tp_init(obj, args, kwds);\n}\n</code></pre>\n<p>还记得，在<code>slot</code>机制一节，讲过方法的重写，如果子类重写了<code>__init__</code>方法，那么在<code>fixup_slot_dispatchers</code>中，<code>tp_init</code>会指向<code>slotdefs</code>定义的<code>slot_tp_init</code>，而这个操作会在我们自定义的类及<code>mro</code>上搜索属性<code>__init__</code>对应的操作。</p>\n<p>这里总结一下从创建类对象到创建实例对象这么一个过程：</p>\n<h2 id=\"Resources\"><a href=\"#Resources\" class=\"headerlink\" title=\"Resources\"></a>Resources</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://lucumr.pocoo.org/2014/8/16/the-python-i-would-like-to-see/\" target=\"_blank\" rel=\"noopener\">The Python I Would Like To See</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://live.julik.nl/2012/08/messages-versus-slots\" target=\"_blank\" rel=\"noopener\">The Python I Would Like To See</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://hanjianwei.com/2013/07/25/python-mro/\" target=\"_blank\" rel=\"noopener\">Python的方法解析顺序(MRO)</a></p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-函数机制","url":"http://shawnz.me/posts/c981e5e/","content":"<blockquote>\n<p>在Python中，函数是一等对象</p>\n</blockquote>\n<h2 id=\"函数对象\"><a href=\"#函数对象\" class=\"headerlink\" title=\"函数对象\"></a>函数对象</h2><a id=\"more\"></a>\n<p>在Python中函数的声明和实现的字节码是在不同<code>PyCodeObject</code>中的，它以一种嵌套的形式存储在外层<code>PyCodeObject</code>的<code>co_const</code>常量表中：</p>\n<pre><code class=\"python\">def f():\n0 LOAD_CONST               0 (&lt;code object f at 0x7ff60e613ed0&gt;)\n2 LOAD_CONST               1 (&#39;f&#39;)\n4 MAKE_FUNCTION            0\n6 STORE_NAME               0 (f)\n    print(&quot;func&quot;)\n\nf()\n8 LOAD_NAME                0 (f)\n10 CALL_FUNCTION            0\n12 POP_TOP\n14 LOAD_CONST               2 (None)\n16 RETURN_VALUE\n</code></pre>\n<p>我们说<code>PyCodeObject</code>是对源码编译的结果，存储的静态信息，例如：常量表(<code>co_const</code>)，符号表(<code>co_names</code>)以及字节码(<code>co_code</code>)。</p>\n<p>而<code>PyFunctionObject</code>则是动态产生的，确切的说是在<code>def f()</code>语句的时候创建的，体现在字节码上就是：</p>\n<pre><code class=\"python\">0 LOAD_CONST               0 (&lt;code object f at 0x7ff60e613ed0&gt;)\n2 LOAD_CONST               1 (&#39;f&#39;)\n4 MAKE_FUNCTION            0\n6 STORE_NAME               0 (f)\n</code></pre>\n<p>这四条指令先后会：将函数<code>f</code>对应的<code>PyCodeObject</code>对象压入栈；把常量表中的<code>f</code>压入栈；构建函数对象<code>PyFunctionObject</code>；以及将键<code>f</code>和值<code>PyFunctionObject</code>存入命名空间(这里<code>f_locals</code>和<code>f_globals</code>是指向同一处命名空间)。</p>\n<p>对于一段静态的代码块来说，它只会对应一个<code>PyCodeObject</code>，而可能会创建多个<code>PyFunctionObject</code>。</p>\n<p>下面是<code>PyFunctionObject</code>的定义，可以看到函数对应的<code>PyCodeObject</code>会被设置为域<code>func_code</code>：</p>\n<pre><code class=\"c\">typedef struct {\n    PyObject_HEAD\n    PyObject *func_code;    /* A code object, the __code__ attribute */\n    PyObject *func_globals;    /* A dictionary (other mappings won&#39;t do) */\n    PyObject *func_defaults;    /* NULL or a tuple */\n    PyObject *func_kwdefaults;    /* NULL or a dict */\n    PyObject *func_closure;    /* NULL or a tuple of cell objects */\n    PyObject *func_doc;        /* The __doc__ attribute, can be anything */\n    PyObject *func_name;    /* The __name__ attribute, a string object */\n    PyObject *func_dict;    /* The __dict__ attribute, a dict or NULL */\n    PyObject *func_weakreflist;    /* List of weak references */\n    PyObject *func_module;    /* The __module__ attribute, can be anything */\n    PyObject *func_annotations;    /* Annotations, a dict or NULL */\n    PyObject *func_qualname;    /* The qualified name */\n} PyFunctionObject;\n</code></pre>\n<p>创建函数对象的指令<code>MAKE_FUNCTION</code>，可以在<code>ceval.c</code>中找到对应的实现：</p>\n<pre><code class=\"c\">TARGET(MAKE_FUNCTION) {\n    PyObject *qualname = POP();\n    PyObject *codeobj = POP();\n    PyFunctionObject *func = (PyFunctionObject *)\n        PyFunction_NewWithQualName(codeobj, f-&gt;f_globals, qualname);\n    ...\n    PUSH((PyObject *)func);\n}\n</code></pre>\n<p><code>MAKE_FUNCTION</code>指令首先会从运行时栈中弹出函数的限定名称<code>qualname</code>和函数对应的字节码对象<code>codeobj</code>，并将当前命名空间<code>f_globals</code>作为函数的全局命名空间来创建函数对象(具体的初始化过程这里先不深入)，最后压入运行时栈。</p>\n<h2 id=\"无参函数调用\"><a href=\"#无参函数调用\" class=\"headerlink\" title=\"无参函数调用\"></a>无参函数调用</h2><p>创建完函数对象并存入命名空间中后，接下来就可以调用函数了。</p>\n<p>我们从最简单的无参函数调用开始，<code>CALL_FUNCTION 0</code>：</p>\n<pre><code class=\"c\">TARGET(CALL_FUNCTION) {\n    PyObject **sp, *res;\n    PCALL(PCALL_ALL);\n    sp = stack_pointer;\n    res = call_function(&amp;sp, oparg, NULL);\n    stack_pointer = sp;\n    PUSH(res);\n    ...\n}\n</code></pre>\n<p><code>CALL_FUNCTION</code>指令代码中，虚拟机只是保存了栈指针，以在函数调用过后恢复，并将函数调用的结果压入运行时栈。具体的实现在<code>call_function</code>中：</p>\n<pre><code class=\"c\">static PyObject *\ncall_function(PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)\n{\n    PyObject **pfunc = (*pp_stack) - oparg - 1;  /* 获取函数对象 */\n    PyObject *func = *pfunc;\n    PyObject *x, *w;\n    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);\n    Py_ssize_t nargs = oparg - nkwargs; /* 参数处理 */\n    PyObject **stack;\n\n    if (PyCFunction_Check(func)) {  \n        ...  /* CFucntion */\n    }\n    else {\n        if (PyMethod_Check(func) &amp;&amp; PyMethod_GET_SELF(func) != NULL) {\n            ... /* Method */\n        }\n        stack = (*pp_stack) - nargs - nkwargs;\n\n        if (PyFunction_Check(func)) {  /* Function */\n            x = fast_function(func, stack, nargs, kwnames);\n        }\n        ...\n    }\n}\n</code></pre>\n<p><code>call_function</code>不光在函数调用的时候会使用，<code>CFunction</code>和<code>Method</code>也会调用这个方法。<code>call_function</code>首先要做的就是获取栈上的函数对象，也就是通过指令<code>CALL_FUNCTION</code>前一个指令<code>LOAD_NAME 0</code>压入运行时栈的。在这里指针<code>func</code>指向的是栈顶位置-1的地方(<code>(*pp_stack) - oparg - 1</code>)。</p>\n<p>具体的参数处理我们先跳过，来看看<code>fast_function</code>是怎么调用函数的：</p>\n<pre><code class=\"c\">static PyObject *\nfast_function(PyObject *func, PyObject **stack,\n              Py_ssize_t nargs, PyObject *kwnames)\n{\n    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);  /* code对象 */\n    PyObject *globals = PyFunction_GET_GLOBALS(func); /* globals命名空间 */\n    PyObject *argdefs = PyFunction_GET_DEFAULTS(func); /* 默认参数 */\n    PyObject *kwdefs, *closure, *name, *qualname;\n    PyObject **d;\n    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);\n    Py_ssize_t nd;\n\n    PCALL(PCALL_FUNCTION);\n    PCALL(PCALL_FAST_FUNCTION);\n    /* 一般函数的快速通道 */\n    if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp;\n        co-&gt;co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE))\n    {\n        if (argdefs == NULL &amp;&amp; co-&gt;co_argcount == nargs) {\n            /* 这是我们调用f()进入的地方 */\n            return _PyFunction_FastCall(co, stack, nargs, globals);\n        }\n        else if (nargs == 0 &amp;&amp; argdefs != NULL\n                 &amp;&amp; co-&gt;co_argcount == Py_SIZE(argdefs)) {\n            stack = &amp;PyTuple_GET_ITEM(argdefs, 0);\n            return _PyFunction_FastCall(co, stack, Py_SIZE(argdefs), globals);\n        }\n    }\n\n    kwdefs = PyFunction_GET_KW_DEFAULTS(func);\n    closure = PyFunction_GET_CLOSURE(func);\n    name = ((PyFunctionObject *)func) -&gt; func_name;\n    qualname = ((PyFunctionObject *)func) -&gt; func_qualname;\n\n    if (argdefs != NULL) {\n        d = &amp;PyTuple_GET_ITEM(argdefs, 0);\n        nd = Py_SIZE(argdefs);\n    }\n    else {\n        d = NULL;\n        nd = 0;\n    }\n    return _PyEval_EvalCodeWithName((PyObject*)co, globals, (PyObject *)NULL,\n                                    ...);\n}\n</code></pre>\n<p>在<code>fast_function</code>做的大部分工作在参数处理上，而这里我们重点关注函数是怎么调用。当使用无参形式调用函数的时候，最终会进入<code>_PyFunction_FastCall</code>快速通道；其他的情况下，会使用<code>_PyEval_EvalCodeWithName</code>处理<code>code</code>对象。</p>\n<p>在<code>_PyFunction_FastCall</code>中，虚拟机会创建一个新的<code>frame</code>，并递归调用<code>PyEval_EvalFrameEx</code>来处理栈桢。而在另一条路径<code>_PyEval_EvalCodeWithName</code>，我们知道虚拟机也会创建新的栈桢，最终也是调用<code>PyEval_EvalFrameEx</code>来处理。</p>\n<p>所以函数的调用过程就是：创建新的栈桢，在新的栈桢中执行代码。在这个过程中<code>PyFunctionObject</code>只是起到打包和传递<code>code</code>对象以及<code>globals</code>的作用。</p>\n<p>下面是<code>_PyFunction_FastCall</code>的实现：</p>\n<pre><code class=\"c\">static PyObject*\n_PyFunction_FastCall(PyCodeObject *co, PyObject **args, Py_ssize_t nargs,\n                     PyObject *globals)\n{\n    PyFrameObject *f;\n    PyThreadState *tstate = PyThreadState_GET();\n    PyObject **fastlocals;\n    Py_ssize_t i;\n    PyObject *result;\n\n    PCALL(PCALL_FASTER_FUNCTION);\n    f = PyFrame_New(tstate, co, globals, NULL); /* 创建新的frame */\n    if (f == NULL) {\n        return NULL;\n    }\n    /* 处理 */\n    fastlocals = f-&gt;f_localsplus;\n\n    for (i = 0; i &lt; nargs; i++) {\n        Py_INCREF(*args);\n        fastlocals[i] = *args++;\n    }\n    result = PyEval_EvalFrameEx(f,0); /* 递归处理frame */\n\n    ++tstate-&gt;recursion_depth; /* 递归深度为什么在这里加？ */\n    Py_DECREF(f);\n    --tstate-&gt;recursion_depth;\n    return result;\n}\n</code></pre>\n<h2 id=\"函数参数\"><a href=\"#函数参数\" class=\"headerlink\" title=\"函数参数\"></a>函数参数</h2><p>上面已经分析过了函数调用的整体框架，现在让我们来加上参数传递机制。</p>\n<p>在Python中函数的参数可以分为几类：</p>\n<ul>\n<li>位置参数：<code>f(a, b)</code>，其中<code>a</code>和<code>b</code>被称为位置参数；</li>\n<li>关键字参数：<code>f(a, b, name=&quot;Python&quot;)</code>，其中<code>name</code>被称为关键字参数；</li>\n<li>扩展位置参数：<code>f(a, b, *args)</code>，可以使用<code>*</code>收集剩余的位置参数；</li>\n<li>扩展关键字参数：<code>f(a, b, **kwargs)</code>，可以使用<code>**</code>收集剩余的关键词参数；</li>\n<li>仅限关键字参数：这是Python3中新引入的，<code>f(a, b, *list, c=None, **kwargs)</code>，仅限关键参数必须位于某个<code>*</code>参数或单个<code>*</code>后面，强制使用关键字参数传递。</li>\n</ul>\n<h2 id=\"位置参数函数调用\"><a href=\"#位置参数函数调用\" class=\"headerlink\" title=\"位置参数函数调用\"></a>位置参数函数调用</h2><p>我们使用一个简单的例子来分析，Python的位置参数的传递和函数调用：</p>\n<pre><code class=\"python\">def f(name, age):\n# 0 LOAD_CONST               0 (&lt;code object f at 0x7fbd0fe3bed0&gt;)\n# 2 LOAD_CONST               1 (&#39;f&#39;)\n# 4 MAKE_FUNCTION            0\n# 6 STORE_NAME               0 (f)\n\n    print(name, age)\n    # 0 LOAD_GLOBAL              0 (print)\n    # 2 LOAD_FAST                0 (name)\n    # 4 LOAD_FAST                1 (age)\n    # 6 CALL_FUNCTION            2\n    # 8 POP_TOP\n\n    # 10 LOAD_FAST                1 (age)\n    # 12 LOAD_CONST               1 (3)\n    # 14 INPLACE_ADD\n    # 16 STORE_FAST               1 (age)\n    # 18 LOAD_CONST               0 (None)\n    # 20 RETURN_VALUE\n\nf(&quot;Python&quot;, 5)\n# 8 LOAD_NAME                0 (f)\n# 10 LOAD_CONST               2 (&#39;Python&#39;)\n# 12 LOAD_CONST               5 (5)\n# 14 CALL_FUNCTION            2\n# 16 POP_TOP\n# 18 LOAD_CONST               4 (None)\n# 20 RETURN_VALUE\n</code></pre>\n<p>和无参函数一样，首先是创建函数对象，在<code>CALL_FUNCTION</code>前会有三条<code>LOAD</code>指令，虚拟机会加载函数需要的参数压入运行时栈，入栈完成后运行时栈如下：</p>\n<p><img src=\"/images/pyfunctionobject-1.png\" alt=\"\"></p>\n<p>在<code>CALL_FUNCTION 2</code>指令中</p>\n<pre><code class=\"c\">TARGET(CALL_FUNCTION) {\n    res = call_function(&amp;sp, oparg, NULL);\n}\n\nstatic PyObject *\ncall_function(PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)\n{\n    PyObject **pfunc = (*pp_stack) - oparg - 1;  /* 获取函数对象 */\n    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);\n    Py_ssize_t nargs = oparg - nkwargs; /* 参数处理 */\n    PyObject **stack;\n    ...\n    /* stack指针将指向第一个参数 */\n    stack = (*pp_stack) - nargs - nkwargs;\n    x = fast_function(func, stack, nargs, kwnames);\n</code></pre>\n<p>可以发现<code>CALL_FUNCTION</code>指令在调用<code>call_function</code>方法时传递的参数<code>kwnames</code>是空的，这点和Python2不同，Python3中<code>CALL_FUNCTION</code>指令只会在以位置参数的方式调用函数时使用。</p>\n<p>在这里的指令参数<code>oparg</code>为<code>2</code>，代表参数的个数。将栈顶指针减2减1就可以得到我们的<code>PyFunctionObject</code>对象的指针。在处理完参数后，<code>fast_function</code>最终会调用<code>_PyFunction_FastCall</code>进行处理。</p>\n<pre><code class=\"c\">static PyObject*\n_PyFunction_FastCall(PyCodeObject *co, PyObject **args, Py_ssize_t nargs,\n                     PyObject *globals)\n{   ...\n   f = PyFrame_New(tstate, co, globals, NULL);\n    if (f == NULL) {\n        return NULL;\n    }\n    /* 新栈桢的localsplus域 */\n    fastlocals = f-&gt;f_localsplus;\n    /* 拷贝位置参数 */\n    for (i = 0; i &lt; nargs; i++) {\n        Py_INCREF(*args);\n        fastlocals[i] = *args++;\n    }\n    result = PyEval_EvalFrameEx(f,0);\n</code></pre>\n<p>在创建好新的栈桢对象<code>f</code>后，虚拟机会将加载在当前运行时栈中的位置参数<code>Python</code>和<code>5</code>拷贝到新的栈桢的<code>f_localspuls</code>域，这个域里面也包括了栈桢的运行时栈。这时<code>f</code>的运行时栈还是空的，<code>f_localsplus</code>的内存布局如下：</p>\n<p><img src=\"/images/pyfunctionobject-2.png\" alt=\"\"></p>\n<p>现在，函数参数已经放在了<code>PyFrameObject</code>的<code>f_localsplus</code>域中，那么在函数执行的时候就可以访问和操作这两个参数了。实际上，虚拟机正是通过两条指令<code>LOAD_FAST</code>和<code>STORE_FAST</code>操作<code>f_localspuls</code>这片内存区域的，在<code>_PyEval_EvalFrameDefault</code>中我们可以看到这些操作定义</p>\n<pre><code class=\"c\">fastlocals = f-&gt;f_localsplus;  /* 将fastlocals设为f_localsplus域 */\n...\n#define GETLOCAL(i)     (fastlocals[i])\n\n#define SETLOCAL(i, value)      do { PyObject *tmp = GETLOCAL(i); \\\n                                     GETLOCAL(i) = value; \\\n                                     Py_XDECREF(tmp); } while (0)\n\nTARGET(LOAD_FAST) {  /* 将fastlocals中的对象压入运行时栈 */\n    PyObject *value = GETLOCAL(oparg);\n    Py_INCREF(value);\n    PUSH(value);\n    FAST_DISPATCH();\n}\n\nTARGET(STORE_FAST) { /* 从运行时栈弹出，并存回fastlocals */\n    PyObject *value = POP();\n    SETLOCAL(oparg, value);\n    FAST_DISPATCH();\n}\n</code></pre>\n<p>这样通过位置参数的调用函数过程现在已经比较清晰了：Python会将位置参数值从左到右压入当前栈桢运行时栈，并使用指令<code>CALL_FUNCTION</code>调用函数，最终它会跳转到<code>_PyFunction_FastCall</code>方法中创建新的栈桢，并将运行时栈中的参数值依次存储在新的栈桢的<code>f_localsplus</code>域中，等待函数的执行。</p>\n<p>而在函数执行的过程中，Python并没有使用通常的按名称查找的做法，而是通过一个索引(偏移位置)来访问<code>f_localspul</code>域中存储的参数值。这也就是<code>位置参数</code>的由来。</p>\n<h2 id=\"默认参数函数调用\"><a href=\"#默认参数函数调用\" class=\"headerlink\" title=\"默认参数函数调用\"></a>默认参数函数调用</h2><p>在继续学习关键字参数之前，我们先看看Python是怎么处理默认参数的。我们猜默认参数应该是在<code>MAKE_FUNCTION</code>里处理的。果然，我们在这条指令的实现处发现了如下代码：</p>\n<pre><code class=\"c\">if (oparg &amp; 0x08) {func -&gt;func_closure = POP(); }\nif (oparg &amp; 0x04) {func-&gt;func_annotations = POP();}\nif (oparg &amp; 0x02) {func-&gt;func_kwdefaults = POP();}\nif (oparg &amp; 0x01) {func-&gt;func_defaults = POP();}\n</code></pre>\n<p>这条指令的参数<code>oparg</code>采用“掩码”的形式实现，如果值为<code>1</code>那么，它会从运行时栈中弹出默认参数，并设为函数对象的<code>func_defaults</code>域。</p>\n<p>这一点字节码可以证明，在压入<code>code</code>对象和名称<code>f</code>之前，有一条<code>LOAD_CONST</code>指令将<code>(&#39;Python&#39;, 3)</code>也一并压入了栈中：</p>\n<pre><code class=\"python\">def f(name=&quot;Python&quot;, age=3):\n# 0 LOAD_CONST               5 ((&#39;Python&#39;, 3)) \n# 2 LOAD_CONST               2 (&lt;code object f at 0x7f2e7f099ed0&gt;\n# 4 LOAD_CONST               3 (&#39;f&#39;)   \n# 6 MAKE_FUNCTION            1  \n    pass\nf()\n</code></pre>\n<p>接下来的调用，依旧是<code>fast_function</code>函数。之前我们看见除了上面的正常无参函数调用外，还有一种情况就是函数调用的时候没有传递参数，但是所有参数都有默认值，这个时候虚拟机也会走<code>_PyFunction_FastCall</code>通道。</p>\n<pre><code class=\"c\">static PyObject *\nfast_function(PyObject *func, PyObject **stack,\n              Py_ssize_t nargs, PyObject *kwnames)\n{\n    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);\n    ...\n    if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp;\n            co-&gt;co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE))\n        {   /* 正常无参函数调用 */\n            if (argdefs == NULL &amp;&amp; co-&gt;co_argcount == nargs) {\n                return _PyFunction_FastCall(co, stack, nargs, globals);\n            } /* 函数调用没有给参数，但是所有参数都有默认参数值 */\n            else if (nargs == 0 &amp;&amp; argdefs != NULL\n                    &amp;&amp; co-&gt;co_argcount == Py_SIZE(argdefs)) {\n                stack = &amp;PyTuple_GET_ITEM(argdefs, 0);  /* 栈指针指向func_defaults第一个元素 */\n                return _PyFunction_FastCall(co, stack, Py_SIZE(argdefs), globals);\n            }\n        }\n}\n</code></pre>\n<p>到现在应该很明显了，默认参数会在执行函数声明语句的时候，存储在函数对象的<code>func_defaults</code>域，在函数调用的时候使用宏定义<code>PyFunction_GET_DEFAULTS</code>获取这些参数值，并让栈指针指向它。接下来在<code>_PyFunction_FastCall</code>依然会通过<code>*arg++</code>设置好<code>f_localsplus</code>域。</p>\n<pre><code class=\"c\">#define PyFunction_GET_DEFAULTS(func) \\\n    (((PyFunctionObject *)func) -&gt; func_defaults)\n</code></pre>\n<h2 id=\"关键词参数函数调用\"><a href=\"#关键词参数函数调用\" class=\"headerlink\" title=\"关键词参数函数调用\"></a>关键词参数函数调用</h2><p>Python3中带关键词参数的函数调用指令不再是<code>CALL_FUNCTION</code>了，而是<code>CALL_FUNCTION_KW</code>，还是上一个例子，不过这里在调用函数的时候稍作修改，我们可以看到：</p>\n<pre><code class=\"python\">f(&quot;Python&quot;, age=3)\n# 8 LOAD_NAME                0 (f) \n# 10 LOAD_CONST               2 (&#39;Python&#39;)       \n# 12 LOAD_CONST               3 (3)       \n# 14 LOAD_CONST               4 ((&#39;age&#39;,)) \n# 16 CALL_FUNCTION_KW         2    \n# ...`\n</code></pre>\n<p>其他地方和使用位置参数调用函数一样，这里的<code>CALL_FUNTION_KW 2</code>之前多做的一项工作就是把常量表中的符号<code>age</code>，压入运行时栈，来到<code>CALL_FUNTION_KW</code>指令的实现处：</p>\n<pre><code class=\"c\">TARGET(CALL_FUNCTION_KW) {\n    PyObject **sp, *res, *names;\n    names = POP();  /* 弹出关键字参数名称元组 */\n    PCALL(PCALL_ALL);\n    sp = stack_pointer;\n    res = call_function(&amp;sp, oparg, names);\n    ...\n}\n</code></pre>\n<p>和<code>CALL_FUNCTION</code>没什么两样，不过是从运行时栈中弹出了最后压入的关键字参数名称。从它只会调用一次<code>POP()</code>，可以知道这些名称是以一个元组形式一起压入栈中，事实上也恰恰如此：<code>((&#39;age&#39;,))</code>。</p>\n<p>依旧还是<code>call_function</code>函数，不过现在我们有了<code>knames</code>：</p>\n<pre><code class=\"c\">static PyObject *\ncall_function(PyObject ***pp_stack, Py_ssize_t oparg, PyObject *kwnames)\n{\n    PyObject **pfunc = (*pp_stack) - oparg - 1;\n    PyObject *func = *pfunc;\n    Py_ssize_t nkwargs = (kwnames == NULL) ? 0 : PyTuple_GET_SIZE(kwnames);\n    Py_ssize_t nargs = oparg - nkwargs;\n</code></pre>\n<p>现在我们对这些参数处理有了更进一步的认识：python在传递参数的时候，无论是位置参数还是关键字参数，都会将参数值先压入运行时栈中，对于关键次参数还用<code>kwnames</code>传递关键字参数名称，这样一来虚拟机就可以把这些名称和关键字参数值一一对应起来(隐性要求就是位置参数在前)。</p>\n<p>不过这样一来在<code>fast_function</code>中，就不会走<code>_PyFunction_FastCall</code>这条通道了：</p>\n<pre><code class=\"c\">static PyObject *\nfast_function(PyObject *func, PyObject **stack,\n              Py_ssize_t nargs, PyObject *kwnames)\n{\n    if (co-&gt;co_kwonlyargcount == 0 &amp;&amp; nkwargs == 0 &amp;&amp;\n        co-&gt;co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE))\n    {\n        /* 关键字参数就不会走这条通道了 */\n        return _PyFunction_FastCall(co, stack, Py_SIZE(argdefs), globals);\n    }\n\n    kwdefs = PyFunction_GET_KW_DEFAULTS(func); /* 仅限关键字参数默认值 */\n    closure = PyFunction_GET_CL OSURE(func);  /* 闭包 */\n    name = ((PyFunctionObject*)func) -&gt; func_name;\n    qualname = ((PyFunctionObject *)func) -&gt; func_qualname;\n\n    if (argdefs != NULL) {\n        d = &amp;PyTuple_GET_ITEM(argdefs, 0); /* 熟悉的默认参数值 */\n        nd = Py_SIZE(argdefs); /* 默认值个数 */\n    }\n    else {\n        d = NULL;\n        nd = 0;\n    }\n    return _PyEval_EvalCodeWithName((PyObject*)co, globals, (PyObject *)NULL,\n            stack, nargs, /* 位置参数 */\n            nkwargs ? &amp;PyTuple_GET_ITEM(kwnames, 0) : NULL, /* 关键字参数名称*/\n            stack + nargs, /* 关键字参数值 */\n            nkwargs, 1, /* 关键字参数个数以及step */\n            d, (int)nd, kwdefs, /* 位置参数默认值， 仅限关键字参数默认值 */\n            closure, name, qualname); /* 函数信息 */\n</code></pre>\n<p>经过这一步，我们可以得到大部分的和关键字参数相关的信息，至于<code>_PyEval_EvalCodeWithName</code>具体是怎么处理这些参数的先放在一旁，继续看看扩展参数机制。</p>\n<h2 id=\"可变参数调用\"><a href=\"#可变参数调用\" class=\"headerlink\" title=\"可变参数调用\"></a>可变参数调用</h2><p>有几种不同的形式通过可变位置参数来调用函数：</p>\n<pre><code class=\"python\">f(*b)\n# 22 LOAD_NAME                2 (b)   \n# 24 CALL_FUNCTION_EX         0      \nf(a, *b)\n# 22 LOAD_NAME                1 (a)\n# 24 BUILD_TUPLE              1  \n# 26 LOAD_NAME                2 (b)    \n# 28 BUILD_TUPLE_UNPACK_WITH_CALL     2       \n# 30 CALL_FUNCTION_EX         0   \nf(*b, a)\n# 22 LOAD_NAME                2 (b) \n# 24 LOAD_NAME                1 (a)\n# 26 BUILD_TUPLE              1       \n# 28 BUILD_TUPLE_UNPACK_WITH_CALL     2         \n# 30 CALL_FUNCTION_EX         0   \nf(a, *b, c)\n# 22 LOAD_NAME                1 (a)      \n# 24 BUILD_TUPLE              1   \n# 26 LOAD_NAME                2 (b)   \n# 28 LOAD_NAME                3 (c)   \n# 30 BUILD_TUPLE              1 \n# 32 BUILD_TUPLE_UNPACK_WITH_CALL     3   \n# 34 CALL_FUNCTION_EX         0      \n</code></pre>\n<p>这几种方式的字节码大同小异，主要设计两个指令<code>BUILD_TUPLE</code>和<code>BUILD_TUPLE_UNPACK_WITH_CALL</code>，我们来看看这两条指令都是做什么用的(省略了部分实现)：</p>\n<pre><code class=\"c\">/* 从栈顶中弹出oparg个元素，来构建一个元组并压入栈中 */\nTARGET(BUILD_TUPLE) {\n    PyObject *tup = PyTuple_New(oparg);\n    while (--oparg &gt;= 0) {\n        PyObject *item = POP();\n        PyTuple_SET_ITEM(tup, oparg, item);\n    }\n    PUSH(tup);\n}\n\nTARGET(BUILD_TUPLE_UNPACK_WITH_CALL)\nTARGET(BUILD_TUPLE_UNPACK)\nTARGET(BUILD_LIST_UNPACK) {\n    int convert_to_tuple = opcode != BUILD_LIST_UNPACK;\n    Py_ssize_t i;\n    PyObject *sum = PyList_New(0);\n    PyObject *return_value;\n    for (i = oparg; i &gt; 0; i--) {\n        PyObject *none_val;\n        none_val = _PyList_Extend((PyListObject *)sum, PEEK(i)); /* 将多个列表合并成一个 */\n        /* PEEK()的定义\n        define PEEK(n)           (stack_pointer[-(n)])\n        */\n    }\n    if (convert_to_tuple) {\n        return_value = PyList_AsTuple(sum);\n    }\n    else {\n        return_value = sum;\n    }\n    while (oparg--)\n        Py_DECREF(POP()); /* 弹出栈上的元素 */\n    PUSH(return_value); /* 将构建的元组或列表压栈 */\n}\n</code></pre>\n<p>结合<code>BUILD_TUPLE</code>和<code>BUILD_TUPLE_UNPACK_WITH_CALL</code>的定义，我们知道无论以什么样的顺序使用可变参数，最终Python需要做的就是将它们打包成一个元组压入运行时栈中</p>\n<p>和可变位置参数相似，可变关键字参数也有<code>BUILD_MAP</code>和<code>BUILD_MAP_UNPACK_WITH_CALL</code>，它们达到的效果和前者一样，会将多个关键字参数和<code>**</code>参数打包成一个字典压入栈中。</p>\n<p>最后可变参数的处理函数指令都是<code>CALL_FUNCTION_EX</code>(只不过带可变关键字参数的会指令参数为<code>1</code>)。</p>\n<p>在下面的<code>CALL_FUNCTION_EX</code>中，我省略掉了大部分的异常处理和引用处理代码:</p>\n<pre><code class=\"c\">TARGET(CALL_FUNCTION_EX) {\n    PyObject *func, *callargs, *kwargs = NULL, *result;\n    if (oparg &amp; 0x01) {\n        kwargs = POP();\n    }\n    callargs = POP();\n    func = TOP();\n    result = do_call_core(func, callargs, kwargs);\n    SET_TOP(result);\n    DISPATCH();\n}\n</code></pre>\n<p>可以看到逻辑还是很清晰的：如果指令参数为1，那么会先从栈顶弹出关键字参数字典，然后弹出位置参数元组和取得函数对象，最后调用<code>do_call_core</code>执行函数。</p>\n<p>在<code>do_call_core</code>中，如果<code>func</code>是函数的话，那么最终执行的<code>PyObject_Call(func, callargs, kwdict);</code>，也就是我们的<code>PyFunction_Type</code>上定义的<code>function_call</code>函数。</p>\n<p>在<code>function_call</code>中：</p>\n<pre><code class=\"c\">static PyObject *\nfunction_call(PyObject *func, PyObject *arg, PyObject *kw)\n{\n    PyObject *result;\n    PyObject *argdefs;\n    PyObject *kwtuple = NULL;\n    PyObject **d, **k;\n    Py_ssize_t nk, nd;\n\n    argdefs = PyFunction_GET_DEFAULTS(func); /* 获取默认参数 */\n    if (argdefs != NULL &amp;&amp; PyTuple_Check(argdefs)) {\n        d = &amp;PyTuple_GET_ITEM((PyTupleObject *)argdefs, 0); /* 指向默认参数起始地址 */\n        nd = PyTuple_GET_SIZE(argdefs); /* 默认参数个数 */\n    }\n    else {\n        d = NULL;\n        nd = 0;\n    }\n\n    if (kw != NULL &amp;&amp; PyDict_Check(kw)) {\n        Py_ssize_t pos, i;\n        nk = PyDict_Size(kw);\n        kwtuple = PyTuple_New(2*nk);\n        if (kwtuple == NULL)\n            return NULL;\n        k = &amp;PyTuple_GET_ITEM(kwtuple, 0); /* 将关键字参数字典转换成元组 */\n        pos = i = 0;\n        while (PyDict_Next(kw, &amp;pos, &amp;k[i], &amp;k[i+1])) { /* 对k里面的元素初始化 */\n            Py_INCREF(k[i]);\n            Py_INCREF(k[i+1]);\n            i += 2;\n        } /* 最终k是参数名称和参数值交叉形式的元组 */\n        nk = i/2;  /* 关键字参数个数 */\n    }\n    else {\n        k = NULL;\n        nk = 0;\n    }\n    result = PyEval_EvalCodeEx(\n        PyFunction_GET_CODE(func),\n        PyFunction_GET_GLOBALS(func), (PyObject *)NULL,\n        &amp;PyTuple_GET_ITEM(arg, 0), PyTuple_GET_SIZE(arg),\n        k, nk, d, nd,\n        PyFunction_GET_KW_DEFAULTS(func),\n        PyFunction_GET_CLOSURE(func));\n    Py_XDECREF(kwtuple);\n    return result;\n}\n</code></pre>\n<p>在这个函数里面，Python获取了各种函数相关的信息，并调用<code>PyEval_EvalCodeEx</code>。</p>\n<p>比较有趣的是，这里关键字参数和指令<code>CALL_FUNCTION_KW</code>中的不一样，之前的关键字参数的名称和值是分开的，而这里以一种名称和值交叉形式的元组打包在一起。所以在<code>PyEval_EvalCodeEx</code>中，需要进一步加工：</p>\n<pre><code class=\"c\">return _PyEval_EvalCodeWithName(_co, globals, locals,\n                                args, argcount,\n                                kws, kws != NULL ? kws + 1 : NULL, /* 名称和值是相邻的 */\n                                kwcount, 2, /* step的作用指导虚拟机怎么查找下一个名称和值 */\n                                defs, defcount,\n                                kwdefs, closure,\n                                NULL, NULL);\n</code></pre>\n<p>殊途同归，最终还是到了<code>_PyEval_EvalCodeWithName</code>，所以在Python中不管函数是以什么样的方式调用(其实不包括单纯的位置参数调用方式:))，最终都会走到<code>_PyEval_EvalCodeWithName</code>这里。这也是函数处理的一个核心函数，它里面包含了<code>闭包</code>、<code>生成器</code>和<code>协程</code>等的处理。</p>\n<h2 id=\"PyEval-EvalCodeWithName\"><a href=\"#PyEval-EvalCodeWithName\" class=\"headerlink\" title=\"_PyEval_EvalCodeWithName\"></a>_PyEval_EvalCodeWithName</h2><p>在看这个函数的时候，我是有点慌的。。。</p>\n<pre><code class=\"c\">\n/* This is gonna seem *real weird*, but if you put some other code between\n   PyEval_EvalFrame() and PyEval_EvalCodeEx() you will need to adjust\n   the test in the if statements in Misc/gdbinit (pystack and pystackv). */\n\nstatic PyObject *\n_PyEval_EvalCodeWithName(PyObject *_co, PyObject *globals, PyObject *locals,\n           PyObject **args, Py_ssize_t argcount, /* 位置参数信息 */\n           PyObject **kwnames, PyObject **kwargs, /* 关键字参数信息 */\n           Py_ssize_t kwcount, int kwstep,  /* 关键字参数信息 */\n           PyObject **defs, Py_ssize_t defcount, /* 默认参数信息 */\n           PyObject *kwdefs, PyObject *closure, /* 仅限关键字信息和闭包 */\n           PyObject *name, PyObject *qualname) /* 名称 */\n{\n    PyCodeObject* co = (PyCodeObject*)_co;\n    PyFrameObject *f;\n    PyObject *retval = NULL;\n    PyObject **fastlocals, **freevars;\n    PyThreadState *tstate;\n    PyObject *x, *u;\n    /* 从code中获取签名的参数总数=位置参数个数+仅限关键字参数个数 */\n    const Py_ssize_t total_args = co-&gt;co_argcount + co-&gt;co_kwonlyargcount; \n    Py_ssize_t i, n;\n    PyObject *kwdict;\n\n    /* 创建新的栈桢 */\n    tstate = PyThreadState_GET();\n    f = PyFrame_New(tstate, co, globals, locals);\n    /* localspuls域 */\n    fastlocals = f-&gt;f_localsplus;\n    freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;\n\n    /* 有可变关键字参数，则为关键字参数创建一个字典 (**kwags) */\n    if (co-&gt;co_flags &amp; CO_VARKEYWORDS) {\n        kwdict = PyDict_New();\n        i = total_args; /* i为签名中已知的位置参数和仅限关键字参数个数 */\n        if (co-&gt;co_flags &amp; CO_VARARGS) { /* 有可变位置参数，则为可变参数预留一个空槽 */\n            i++;\n        }\n        SETLOCAL(i, kwdict); /* 将可变关键字参数字典设置在localsplus域 */\n    }\n    else {\n        kwdict = NULL;\n    }\n    /* 调用时的位置参数个数大于签名里的位置参数个数 */\n    /* Copy positional arguments into local variables */\n    if (argcount &gt; co-&gt;co_argcount) {\n        n = co-&gt;co_argcount; /* n为签名中的位置参数个数 */\n    }\n    else {\n        n = argcount;\n    }\n    for (i = 0; i &lt; n; i++) { /* 将前n个位置参数设置在localsplus域 */\n        x = args[i];\n        Py_INCREF(x);\n        SETLOCAL(i, x); /* 显然位置参数在localsplus域最前面 */\n    }\n\n    /* 把调用时多余的位置参数打包成 *args元组 */\n    if (co-&gt;co_flags &amp; CO_VARARGS) {\n        u = PyTuple_New(argcount - n);\n        SETLOCAL(total_args, u); /* 把u设置在位置参数+仅限关键字参数之后 */\n        for (i = n; i &lt; argcount; i++) {\n            x = args[i];\n            Py_INCREF(x);\n            PyTuple_SET_ITEM(u, i-n, x); /* 可变参数元组初始化值 */\n        }\n    }\n\n    /* 将关键字参数作为两个平行数组处理 */\n    kwcount *= kwstep; /* 乘以step，正确处理kwargs元组中的实际个数 */\n    for (i = 0; i &lt; kwcount; i += kwstep) {\n        PyObject **co_varnames;\n        PyObject *keyword = kwnames[i]; /* 以正确的step取得关键字参数名称 */\n        PyObject *value = kwargs[i]; /* 以正确的step取得关键字参数名称 */\n        Py_ssize_t j;\n\n        /* Speed hack: do raw pointer compares. As names are\n           normally interned this should almost always hit. */\n        /* 快速通道：在函数变量名表中查找是否出现关键字参数名称keyword */\n        co_varnames = ((PyTupleObject *)(co-&gt;co_varnames))-&gt;ob_item;\n        for (j = 0; j &lt; total_args; j++) {\n            PyObject *name = co_varnames[j];\n            if (name == keyword) {\n                goto kw_found;\n            }\n        }\n\n        /* 慢速通道：在函数变量名表中查找是否出现关键字参数名称keyword */\n        for (j = 0; j &lt; total_args; j++) {\n            PyObject *name = co_varnames[j];\n            int cmp = PyObject_RichCompareBool( keyword, name, Py_EQ);\n            if (cmp &gt; 0) {\n                goto kw_found;\n            }\n            else if (cmp &lt; 0) {\n                goto fail;\n            }\n        }\n        /* 如果没有找到keyword名称，且函数不允许可变关键字参数，那么报错 */\n        if (j &gt;= total_args &amp;&amp; kwdict == NULL) {\n            PyErr_Format(PyExc_TypeError,\n                         &quot;%U() got an unexpected keyword argument &#39;%S&#39;&quot;,\n                         co-&gt;co_name, keyword);\n            goto fail;\n        }\n        /* 如果允许可变关键字参数，且在函数变量名称表没有找到keyword，\n        则将关键字参数设置在可变关键字参数字典中 */\n        if (PyDict_SetItem(kwdict, keyword, value) == -1) {\n            goto fail;\n        }\n        continue;\n\n      kw_found:\n        /* 在名称表中位置j找到了变量名称，但是已经通过位置参数设置好了，那么会产生冲突报错 */\n        if (GETLOCAL(j) != NULL) {\n            PyErr_Format(PyExc_TypeError,\n                         &quot;%U() got multiple values for argument &#39;%S&#39;&quot;,\n                         co-&gt;co_name, keyword);\n            goto fail;\n        }\n        Py_INCREF(value);\n        /* 在localsplus相应位置设置好关键字参数 */\n        SETLOCAL(j, value);\n    }\n\n    /* 位置参数个数大于形参个数 */\n    if (argcount &gt; co-&gt;co_argcount &amp;&amp; !(co-&gt;co_flags &amp; CO_VARARGS)) {\n        too_many_positional(co, argcount, defcount, fastlocals);\n        goto fail;\n    }\n\n    /* 位置参数给少了，需要使用默认参数 */\n    if (argcount &lt; co-&gt;co_argcount) {\n        Py_ssize_t m = co-&gt;co_argcount - defcount;\n        Py_ssize_t missing = 0;\n        for (i = argcount; i &lt; m; i++) {\n            if (GETLOCAL(i) == NULL) {\n                missing++;\n            }\n        }\n        if (missing) {\n            missing_arguments(co, missing, defcount, fastlocals);\n            goto fail;\n        }\n        if (n &gt; m)\n            i = n - m;\n        else\n            i = 0;\n        /* 对于剩余没有给参数值的参数，使用默认位置参数值 */\n        for (; i &lt; defcount; i++) {\n            if (GETLOCAL(m+i) == NULL) {\n                PyObject *def = defs[i];\n                Py_INCREF(def);\n                SETLOCAL(m+i, def);\n            }\n        }\n    }\n\n    /* 对缺失的关键字参数，使用默认关键字参数值 */\n    if (co-&gt;co_kwonlyargcount &gt; 0) {\n        Py_ssize_t missing = 0;\n        for (i = co-&gt;co_argcount; i &lt; total_args; i++) {\n            PyObject *name;\n            if (GETLOCAL(i) != NULL)\n                continue;\n            name = PyTuple_GET_ITEM(co-&gt;co_varnames, i);\n            if (kwdefs != NULL) {\n                PyObject *def = PyDict_GetItem(kwdefs, name);\n                if (def) {\n                    Py_INCREF(def);\n                    SETLOCAL(i, def);\n                    continue;\n                }\n            }\n            missing++;\n        }\n        if (missing) {\n            missing_arguments(co, missing, -1, fastlocals);\n            goto fail;\n        }\n    }\n\n    /* Allocate and initialize storage for cell vars, and copy free\n       vars into frame. */\n    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_cellvars); ++i) {\n        PyObject *c;\n        int arg;\n        /* Possibly account for the cell variable being an argument. */\n        if (co-&gt;co_cell2arg != NULL &amp;&amp;\n            (arg = co-&gt;co_cell2arg[i]) != CO_CELL_NOT_AN_ARG) {\n            c = PyCell_New(GETLOCAL(arg));\n            /* Clear the local copy. */\n            SETLOCAL(arg, NULL);\n        }\n        else {\n            c = PyCell_New(NULL);\n        }\n        if (c == NULL)\n            goto fail;\n        SETLOCAL(co-&gt;co_nlocals + i, c);\n    }\n\n    /* Copy closure variables to free variables */\n    for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_freevars); ++i) {\n        PyObject *o = PyTuple_GET_ITEM(closure, i);\n        Py_INCREF(o);\n        freevars[PyTuple_GET_SIZE(co-&gt;co_cellvars) + i] = o;\n    }\n\n    /* Handle generator/coroutine/asynchronous generator */\n    if (co-&gt;co_flags &amp; (CO_GENERATOR | CO_COROUTINE | CO_ASYNC_GENERATOR)) {\n        PyObject *gen;\n        PyObject *coro_wrapper = tstate-&gt;coroutine_wrapper;\n        int is_coro = co-&gt;co_flags &amp; CO_COROUTINE;\n\n        if (is_coro &amp;&amp; tstate-&gt;in_coroutine_wrapper) {\n            assert(coro_wrapper != NULL);\n            PyErr_Format(PyExc_RuntimeError,\n                         &quot;coroutine wrapper %.200R attempted &quot;\n                         &quot;to recursively wrap %.200R&quot;,\n                         coro_wrapper,\n                         co);\n            goto fail;\n        }\n\n        /* Don&#39;t need to keep the reference to f_back, it will be set\n         * when the generator is resumed. */\n        Py_CLEAR(f-&gt;f_back);\n\n        PCALL(PCALL_GENERATOR);\n\n        /* Create a new generator that owns the ready to run frame\n         * and return that as the value. */\n        if (is_coro) {\n            gen = PyCoro_New(f, name, qualname);\n        } else if (co-&gt;co_flags &amp; CO_ASYNC_GENERATOR) {\n            gen = PyAsyncGen_New(f, name, qualname);\n        } else {\n            gen = PyGen_NewWithQualName(f, name, qualname);\n        }\n        if (gen == NULL)\n            return NULL;\n\n        if (is_coro &amp;&amp; coro_wrapper != NULL) {\n            PyObject *wrapped;\n            tstate-&gt;in_coroutine_wrapper = 1;\n            wrapped = PyObject_CallFunction(coro_wrapper, &quot;N&quot;, gen);\n            tstate-&gt;in_coroutine_wrapper = 0;\n            return wrapped;\n        }\n\n        return gen;\n    }\n\n    retval = PyEval_EvalFrameEx(f,0);\n\nfail: /* Jump here from prelude on failure */\n\n    /* decref&#39;ing the frame can cause __del__ methods to get invoked,\n       which can call back into Python.  While we&#39;re done with the\n       current Python frame (f), the associated C stack is still in use,\n       so recursion_depth must be boosted for the duration.\n    */\n    assert(tstate != NULL);\n    ++tstate-&gt;recursion_depth;\n    Py_DECREF(f);\n    --tstate-&gt;recursion_depth;\n    return retval;\n}\n</code></pre>\n<h2 id=\"闭包\"><a href=\"#闭包\" class=\"headerlink\" title=\"闭包\"></a>闭包</h2><p>名字空间与函数捆绑后的结果被称为一个闭包(closure)。</p>\n<p>Python闭包的实现和<code>PyCodeObject</code>的两个属性有关：</p>\n<ul>\n<li><code>co_cellvars</code>：通常是一个元组，保存嵌套作用域中使用的变量名集合；</li>\n<li><code>co_freevars</code>：通常是一个元组，保存使用了的外层作用域中的变量名集合。</li>\n</ul>\n<p>另外在创建栈桢对象<code>PyFrameObject</code>时也有一个属性和闭包相关，<code>f_localsplus</code>维护的那块内存大小：<br><br><code>extras=code-&gt;co_stacksize + code-&gt;co_nlocals + ncells + nfrees</code><br><br>对应着：运行时栈，局部变量，cell对象和free对象。</p>\n<p>我们来看一个简单的例子：</p>\n<pre><code class=\"python\">def get_func():\n# 0 LOAD_CONST               0 (&lt;code object get_func&gt;)\n# 2 LOAD_CONST               1 (&#39;get_func&#39;)\n# 4 MAKE_FUNCTION            0\n# 6 STORE_NAME               0 (get_func)\n\n    value = &quot;value&quot;\n    # 0 LOAD_CONST               1 (&#39;value&#39;)\n    # 2 STORE_DEREF              0 (value)\n    def inner_func():\n    # 4 LOAD_CLOSURE             0 (value)\n    # 6 BUILD_TUPLE              1\n    # 8 LOAD_CONST               2 (&lt;code object inner_func&gt;)\n    # 10 LOAD_CONST               3 (&#39;get_func.&lt;locals&gt;.inner_func&#39;)\n    # 12 MAKE_FUNCTION            8\n    # 14 STORE_FAST               0 (inner_func)\n        print(value)\n        # 0 LOAD_GLOBAL              0 (print)\n        # 2 LOAD_DEREF               0 (value)\n        # 4 CALL_FUNCTION            1\n        # 6 POP_TOP\n        # 8 LOAD_CONST               0 (None)\n        # 10 RETURN_VALUE\n\n    return inner_func\n    # 16 LOAD_FAST                0 (inner_func)\n    # 18 RETURN_VALUE\n\nshow_value = get_func()\nshow_value()\n# 14 LOAD_NAME                1 (show_value)\n# 16 CALL_FUNCTION            0\n# 18 POP_TOP\n# 20 LOAD_CONST               2 (None)\n# 22 RETURN_VALUE\n</code></pre>\n<p>我们从<code>CALL_FUNCTION</code>指令开始，闭包就是从这里还是处理的：</p>\n<pre><code class=\"c\">for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_cellvars); ++i) {\n    PyObject *c;\n    int arg;\n    /* Possibly account for the cell variable being an argument. */\n    if (co-&gt;co_cell2arg != NULL &amp;&amp;\n        (arg = co-&gt;co_cell2arg[i]) != CO_CELL_NOT_AN_ARG) {\n        c = PyCell_New(GETLOCAL(arg));\n        SETLOCAL(arg, NULL);\n    }\n    else {\n        c = PyCell_New(NULL);\n    }\n    if (c == NULL)\n        goto fail;\n    SETLOCAL(co-&gt;co_nlocals + i, c); /* 存放cell对象在locals后 */\n}\n</code></pre>\n<p>对于闭包的静态信息，经过编译后存放在<code>PyCodeObject</code>的<code>co_cellvars</code>和<code>co_freevars</code>中，而在创建新的栈桢的时候需要通过这些静态信息，创建<code>cell</code>保存到<code>f_localsplus</code>域中。要注意的是<code>cell</code>的在<code>localsplus</code>域中的位置位于局部变量后。</p>\n<p>这些<code>PyCellObject</code>对象十分简单，只有一个<code>ob_ref</code>指向一个<code>object</code>：</p>\n<pre><code class=\"c\">typedef struct {\n    PyObject_HEAD\n    PyObject *ob_ref;\n} PyCellObject;\n</code></pre>\n<p>这里我们创建的<code>PyCellObject</code>对象的<code>ob_ref</code>指针指向<code>NULL</code>：</p>\n<pre><code class=\"c\">PyObject *\nPyCell_New(PyObject *obj)\n{\n    PyCellObject *op;\n    op = (PyCellObject *)PyObject_GC_New(PyCellObject, &amp;PyCell_Type);\n    op-&gt;ob_ref = obj;\n    return (PyObject *)op;\n}\n</code></pre>\n<p>上面我们可以看到，在创建完新的栈桢对象后，<code>f_localsplus</code>区域内的这些<code>cell</code>对象的<code>ob_ref</code>依然指向一个空地址，那么是在什么时候初始化的呢？</p>\n<p>答案是在调用<code>PyEval_EvalFrameEx(f, 0)</code>执行栈桢的时候，我们可以看到在<code>get_func</code>函数执行过程中，有个字节码就是<code>2 STORE_DEREF 0</code>，这是这个字节码，将：</p>\n<pre><code class=\"c\">freevars = f-&gt;f_localsplus + co-&gt;co_nlocals; /* 指向f_localsplus中ncells第一个位置 */\n\nTARGET(STORE_DEREF) {\n    PyObject *v = POP(); /* 这里pop弹出的就是在STORE_DEREF前入栈的value */\n    PyObject *cell = freevars[oparg]; /* 从f_localsplus中获取cell对象设置ob_ref */\n    PyObject *oldobj = PyCell_GET(cell);\n    PyCell_SET(cell, v);\n}\n</code></pre>\n<p><code>STORE_DEREF</code>从运行时栈中弹出<code>value</code>符号对应的对象值，并将这个变量值和<code>cell</code>对象绑定，通过<code>cell</code>对象我们可以使用这些约束了。</p>\n<p><img src=\"/images/pyfunctionobject-3.png\" alt=\"\"></p>\n<p>我们再来看看，<code>inner_func</code>函数中是怎么使用这些“冻结”的<code>cell</code>的：在创建<code>inner_func</code>函数对象之前，有个字节码<code>4 LOAD_CLOSURE  0 (value)</code>，这个字节码的定义如下</p>\n<pre><code class=\"c\">TARGET(LOAD_CLOSURE) {\n    PyObject *cell = freevars[oparg];\n    PUSH(cell);\n}\n</code></pre>\n<p>作用很明显，从<code>f_localsplus</code>中获取指令参数指定位置的<code>cell</code>对象，并将它压入运行时栈中。</p>\n<p>而在<code>MAKE_FUNCTION</code>创建<code>inner_function</code>函数对象是指令参数为<code>8</code>，那么：</p>\n<pre><code class=\"c\">if (oparg &amp; 0x08) {\n    func -&gt;func_closure = POP(); /* 可以是一个包含多个cell对象的元组，这个例子中元组里只有一个cell */\n}\n</code></pre>\n<p>这到了”搬运工“发挥作用的时刻了，虚拟机将压入栈中的<code>cell</code>对象绑定在了新创建的函数对象<code>func_closure</code>域，现在内部函数就可以使用外部函数”冻结“的变量值了。最后这个新创建的<code>functionobject</code>被放置在栈桢对象的<code>f_localsplus</code>域。</p>\n<p><img src=\"/images/pyfunctionobject-4.png\" alt=\"\"></p>\n<p>既然内部函数的<code>func_clousre</code>域有了<code>cell</code>对象元组，那么我就可以在执行<code>inner_func</code>的时候，使用外部函数的局部变量了。还是熟悉的配方，在<code>_PyEval_EvalCodeWithName</code>创建栈桢对象过程中，由于内部函数的<code>PyCodeObject</code>有<code>co_freevars</code>，所以我们需要进行处理：</p>\n<pre><code class=\"c\">for (i = 0; i &lt; PyTuple_GET_SIZE(co-&gt;co_freevars); ++i) {\n    PyObject *o = PyTuple_GET_ITEM(closure, i); /* 这个closure就是从func对象中获取的func_closure */\n    freevars[PyTuple_GET_SIZE(co-&gt;co_cellvars) + i] = o; /* 设置co_cellvars区域后面 */\n}\n</code></pre>\n<p>所以，在将<code>PyFunctionObject</code>携带的<code>func_closure</code>中的<code>PyCellObject</code>，绑定在新的栈桢的<code>f_localsplus</code>域中的<code>free</code>变量区后，就可以引用外部函数的符号了。</p>\n<p><img src=\"/images/pyfunctionobject-5.png\" alt=\"\"></p>\n<p>和<code>STORE_DEREF</code>指令将运行时栈中的值存放在<code>cell</code>变量区相似，Python也有一个指令<code>LOAD_DEREF</code>从<code>free</code>变量区加载到运行时栈中：</p>\n<pre><code class=\"c\">TARGET(LOAD_DEREF) {\n    PyObject *cell = freevars[oparg];\n    PyObject *value = PyCell_GET(cell);\n    PUSH(value);\n}\n</code></pre>\n<p>总结一下“闭包”的处理，几个关键的变量和属性：</p>\n<ul>\n<li>在<code>PyCodeObject</code>中的<code>co_cellvars</code>和<code>co_freevars</code>；</li>\n<li><code>FunctionObject</code>中的<code>func_closure</code>，传递<code>PyCellObject</code>给内部函数；</li>\n<li><code>PyFrameObject</code>中的<code>f_localsplus</code>的<code>cell</code>变量区和<code>free</code>变量区；</li>\n</ul>\n<h2 id=\"装饰器\"><a href=\"#装饰器\" class=\"headerlink\" title=\"装饰器\"></a>装饰器</h2><p>装饰器就是”闭包“的一种运用，然后Python在加上装饰器<code>语法糖</code>。</p>\n<pre><code class=\"python\">@decorator\ndef func():\n    pass\n# 等价于\ndecorator(func)\n</code></pre>\n<h2 id=\"未完，待续。。。\"><a href=\"#未完，待续。。。\" class=\"headerlink\" title=\"未完，待续。。。\"></a>未完，待续。。。</h2><h2 id=\"Resources\"><a href=\"#Resources\" class=\"headerlink\" title=\"Resources\"></a>Resources</h2>","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-虚拟机和字节码","url":"http://shawnz.me/posts/eab2cd72/","content":"<p>这篇博客主要记录Python源代码是怎么转换成一系列的机器指令并执行的。这里说的Python指的是CPython实现。</p>\n<p>在我们通过<code>python *.py</code>运行一个Python程序时，CPython解释器首先会对源代码进行<code>编译</code>，产生一组<code>字节码</code>(Byte Code)，然后将编译的结果交给Python的<code>虚拟机</code>(PVM)，由虚拟机一条一条的执行字节码来运行程序。所以说Python解释器包含两个部分：编译器和虚拟机。</p>\n<a id=\"more\"></a>\n<p><img src=\"/images/python-interpreter.png\" alt=\"\"></p>\n<h2 id=\"PyCodeObject\"><a href=\"#PyCodeObject\" class=\"headerlink\" title=\"PyCodeObject\"></a>PyCodeObject</h2><p>”编译“的结果就是<code>PyCodeObject</code>对象，而<code>.pyc</code>文件是这个对象在硬盘上的表现形式。</p>\n<pre><code class=\"c\">/* Bytecode object */\ntypedef struct {\n    PyObject_HEAD\n    int co_argcount;        /* #arguments, except *args */\n    int co_kwonlyargcount;    /* #keyword only arguments */\n    int co_nlocals;        /* #local variables */\n    int co_stacksize;        /* #entries needed for evaluation stack */\n    int co_flags;        /* CO_..., see below */\n    int co_firstlineno;   /* first source line number */\n    PyObject *co_code;        /* instruction opcodes */\n    PyObject *co_consts;    /* list (constants used) */\n    PyObject *co_names;        /* list of strings (names used) */\n    PyObject *co_varnames;    /* tuple of strings (local variable names) */\n    PyObject *co_freevars;    /* tuple of strings (free variable names) */\n    PyObject *co_cellvars;      /* tuple of strings (cell variable names) */\n    /* The rest aren&#39;t used in either hash or comparisons, except for co_name,\n       used in both. This is done to preserve the name and line number\n       for tracebacks and debuggers; otherwise, constant de-duplication\n       would collapse identical functions/lambdas defined on different lines.\n    */\n    unsigned char *co_cell2arg; /* Maps cell vars which are arguments. */\n    PyObject *co_filename;    /* unicode (where it was loaded from) */\n    PyObject *co_name;        /* unicode (name, for reference) */\n    PyObject *co_lnotab;    /* string (encoding addr&lt;-&gt;lineno mapping) See\n                   Objects/lnotab_notes.txt for details. */\n    void *co_zombieframe;     /* for optimization only (see frameobject.c) */\n    PyObject *co_weakreflist;   /* to support weakrefs to code objects */\n    /* Scratch space for extra data relating to the code object.\n       Type is a void* to keep the format private in codeobject.c to force\n       people to go through the proper APIs. */\n    void *co_extra;\n} PyCodeObject;\n</code></pre>\n<p>Python编译时，对于代码中的每一个<code>Code Block</code>(进入一个新的名字空间)都会对应一个<code>PyCodeObject</code>对象，和名字空间一样，<code>PyCodeObject</code>也可以嵌套，嵌套在<code>co_consts</code>域。</p>\n<p>可以看到字节码对象<code>PyCodeObject</code>有许多的域，其中包含了Python源代码的一切有用<code>静态</code>信息，例如字符串，常量值以及字节码指令(操作)等。</p>\n<h2 id=\"pyc\"><a href=\"#pyc\" class=\"headerlink\" title=\".pyc\"></a>.pyc</h2><p><code>.pyc</code>文件是<code>PyCodeObject</code>对象在硬盘上的表现形式，在Python3中，这些文件位于<code>__pycache__</code>文件夹下。我们可以发现通过<code>python *.py</code>的方式运行Python程序时，并不会生成<code>.pyc</code>文件，那么这个文件是什么时候创建的呢？</p>\n<p>在通过<code>import</code>机制对<code>module</code>动态加载的时候，Python会先尝试去查找<code>.pyc</code>文件。如果没有这些文件，Python会将<code>*.py</code>文件编译成相应的<code>PyCodeObject</code>对象，然后再创建<code>*.pyc</code>文件，并将<code>PyCodeObject</code>和一些信息写入到文件中。接下来才是<code>import</code>动作，将<code>*.pyc</code>文件中的<code>PyCodeObject</code>对象在内存中复制出来。</p>\n<p>在Python中提供了许多类库，允许完成<code>.pyc</code>文件的生成：</p>\n<pre><code class=\"python\">[generate_pyc.py]\nimport imp\nimport sys\ndef generate_pyc(name):\n    fp, pathname, description = imp.find_module(name)\n    try:\n        imp.load_module(name, fp, pathname, description)    \n    finally:\n        if fp:\n            fp.close()\nif __name__ == &#39;__main__&#39;:\n    generate_pyc(sys.argv[1])\n</code></pre>\n<p>一个<code>.pyc</code>文件包含三个部分：<code>magic number</code>、<code>pyc文件的创建时间</code>和<code>PyCodeObject对象</code>。</p>\n<p>一般不同版本的Python会定义不同<code>magic number</code>，主要是用来保证兼容性，下面是Python3.5所定义的<code>magic number</code>：</p>\n<pre><code class=\"c\">MAGIC_NUMBER = (3379).to_bytes(2, &#39;little&#39;) + b&#39;\\r\\n&#39;\n_RAW_MAGIC_NUMBER = int.from_bytes(MAGIC_NUMBER, &#39;little&#39;)  # For import.c\n</code></pre>\n<h2 id=\"字节码\"><a href=\"#字节码\" class=\"headerlink\" title=\"字节码\"></a>字节码</h2><p>在<code>PyCodeObject</code>对象的<code>co_code</code>就保存着字节码指令序列，以<code>PyStringObject</code>类型存在，在C底层真正存储字节码的就是一个<code>char []</code>数组。</p>\n<p>Python3定义了117条字节码指令，大于或等于90的指令需要参数：</p>\n<pre><code class=\"c\">[opcode.c]\n#define POP_TOP                   1\n#define ROT_TWO                   2\n...\n#define HAVE_ARGUMENT            90\n...\n#define BUILD_CONST_KEY_MAP     156\n#define BUILD_STRING            157\n#define BUILD_TUPLE_UNPACK_WITH_CALL 158\n/* 判断一条指令是否需要参数 */\n#define HAS_ARG(op) ((op) &gt;= HAVE_ARGUMENT)\n</code></pre>\n<p>Python标准库提供了用来生成字节码的工具<code>dis</code>，使用<code>dis</code>可以对代码进行性能分析。</p>\n<h2 id=\"执行环境\"><a href=\"#执行环境\" class=\"headerlink\" title=\"执行环境\"></a>执行环境</h2><p><code>.py</code>文件被编译后，Python虚拟机会从<code>PyCodeObject</code>中一条一条读取字节码指令，并在当前上下文环境中执行。</p>\n<p>在讲上下文环境之前，我们先弄懂什么是”执行环境“？<code>PyCodeObject</code>中包含了程序运行的静态信息和字节码，而一些动态捕捉和维护的信息就保存在<code>PyFrameObject</code>对象中，这就是执行环境。</p>\n<pre><code class=\"c\">typedef struct _frame {\n    PyObject_VAR_HEAD\n    struct _frame *f_back;      /* previous frame, or NULL */\n    PyCodeObject *f_code;       /* PyCodeObject对象 */\n    PyObject *f_builtins;       /* builtin名字空间(PyDictObject) */\n    PyObject *f_globals;        /* global名字空间(PyDictObject) */\n    PyObject *f_locals;         /* local名字空间(PyDictObject) */\n    PyObject **f_valuestack;    /* 运行时栈的栈底位置 */\n    PyObject **f_stacktop;      /* 运行时栈的栈顶位置*/\n    PyObject *f_trace;          /* 记录异常处理 */\n    PyObject *f_exc_type, *f_exc_value, *f_exc_traceback;\n    /* Borrowed reference to a generator, or NULL */\n    PyObject *f_gen;\n    int f_lasti;                /* 当前字节码位置 */\n    int f_lineno;               /* 当前行号 */\n    int f_iblock;               /* 一些局部代码块f_blockstack */\n    char f_executing;           /* 当前栈桢是否还在执行 */\n    PyTryBlock f_blockstack[CO_MAXBLOCKS]; /* for try and loop blocks */\n    PyObject *f_localsplus[1];  /* 动态内存维护：locals+stack */\n} PyFrameObject;\n</code></pre>\n<p>在Python程序运行的时候，会创建一个又一个的<code>PyFrameObject</code>对象，它们之间通过<code>f_back</code>链接起来。所以对于Python虚拟机引擎来说它面对的就是<code>PyFrameObject</code>对象，相当于对C语言中“栈帧”的模拟，但又不仅仅是C语言中的“栈桢”，它还包括一些其他的信息，例如：</p>\n<ul>\n<li><code>f_code</code>：待执行的<code>PyCodeObject</code>对象，虚拟机从这里面读取并执行字节码；</li>\n<li><code>f_builtins</code>、<code>f_globals</code>和<code>f_locals</code>：维护着三个动态的名字空间，是以<code>PyDictObject</code>的形式维护<code>name</code>和<code>value</code>的映射；</li>\n<li><code>f_localsplus</code>：维护一段变长内存，里面就包括了<code>PyFrameObject</code>对象所维护的”运行时栈“(这个”栈“才是和C语言中的那个栈空间相对应的概念)以及一部分额外的内存(供<code>PyCodeObject</code>对象存储的那些<code>co_names</code>, <code>co_freevars</code>和<code>co_cellvals</code>使用，涉及“闭包”的实现)。</li>\n</ul>\n<p>下面是一个新创建的<code>PyFrameObject</code>对象，它的”栈顶“和“栈底”位置重叠在一起：</p>\n<p><img src=\"/images/python_frame_structure.png\" alt=\"\"></p>\n<h2 id=\"命名空间\"><a href=\"#命名空间\" class=\"headerlink\" title=\"命名空间\"></a>命名空间</h2><p>在<code>PyFrameObject</code>中，我们可以看到三个独立的命名空间：<code>local</code>、<code>global</code>和<code>builtin</code>命名空间。</p>\n<p><strong>作用域和命名空间</strong></p>\n<ul>\n<li>作用域：是指一段程序文本的某一段区域，它决定这约束是否起作用，Python是具有静态作用域的；</li>\n<li>命名空间：名字和对象的映射，一段文本定义作用域在Python程序运行时会转换成对应的命名空间，例如，在执行函数<code>f</code>的时候会创建一个命名空间。</li>\n</ul>\n<p>*Note：在Python中<code>if</code>语句和<code>for</code>语句不会引入新的作用域，另外在Python3中，针对推导式和生成器会引入新的局部作用域，不用担心变量泄露的问题：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; i = 1\n&gt;&gt;&gt; for i in range(10):\n...    pass\n...\n&gt;&gt;&gt; i\n9   # i产生了变化9\n&gt;&gt;&gt; [i for i in range(3)]\n[0, 1, 2]\n&gt;&gt;&gt; i\n9   # 没有改变i\n</code></pre>\n<p><strong>赋值语句</strong></p>\n<p>在Python中赋值语句(更切确的说是具有赋值行为的语句)，做的就是绑定或重绑定工作，不会产生拷贝。</p>\n<p>除了常见的<code>=</code>显示赋值，在Python中<code>import a</code>、<code>class A:</code>和<code>def f():</code>这样的语句都是赋值语句，它们会创建约束并放在命名空间(<code>dict</code>)中。</p>\n<p>函数的参数传递？</p>\n<p>鉴于这样的行为，能够很好的解释Python的动态类型(名字只是一个符号，用来查找对象，类型的信息都在对象上存储着)以及为什么Python没有函数重载(因为重载需要根据参数签名来决定，而Python只保存了一个名称)。</p>\n<p><strong>引用语句</strong></p>\n<p>既然赋值语句是建立约束，那么引用语句可以看做是访问(查找)约束。Python的引用分为两种：</p>\n<ul>\n<li>属性引用：一个对象的名字空间中的所有名字称为对象的属性，那么我们可以通过属性引用的方式访问对象的属性；</li>\n<li>名字引用：位于一个作用域中的代码能够直接访问出现在作用域中的代码。</li>\n</ul>\n<p><strong>LEGB规则</strong></p>\n<p>要是名字引用访问没有出现在作用域中的名字，Python会怎么处理呢？</p>\n<p>这里有一个<code>最内层嵌套作用域规则</code>：由一个赋值语句引入的名字在赋值语句所在的作用域是<code>可见的</code>，而且在其内部嵌套的作用域也是可见的，除非被嵌套作用域引入了的同一名字的另一个赋值语句所<code>遮蔽</code>。</p>\n<p>Python使用一个<code>LEGB</code>的顺序来查找符号对应的对象：</p>\n<blockquote>\n<p><code>locals</code> –&gt; <code>enclosing</code> –&gt; <code>globals</code> –&gt; <code>builtins</code></p>\n</blockquote>\n<p>一个例子就是<code>闭包</code>的实现：</p>\n<pre><code class=\"python\">a = 1\n\ndef f():\n    a = 2\n    def g():\n        print(a) # a 位于外部嵌套函数的命名空间\n    return g\n\nfunc = f()\nfunc()  # 输出 2\n</code></pre>\n<p><strong>global和nonlocal</strong></p>\n<ul>\n<li><code>global</code>：用来声明一系列变量，这些变量会引用到当前模块的全局命名空间的变量（module－level namespace），如果该变量没有定义，也会在全局空间中添加这个变量。</li>\n<li><code>nonlocal</code>：从声明处从里到外的namespace去搜寻这个变量（the nearest enclosing scope），直到模块的全局域（不包括全局域），不会在当前scope的namespace字典中加入一个key-value对。</li>\n</ul>\n<h2 id=\"运行时环境\"><a href=\"#运行时环境\" class=\"headerlink\" title=\"运行时环境\"></a>运行时环境</h2><p>在Python启动后，真正有意义的初始化动作是从<code>pylifecyle</code>中的<code>Py_Initialize</code>开始的，<code>Py_Initialzie</code>最终调用的是<code>_Py_InitializeEx_Private</code>，在这里面主要完成加载多个基础模块(<code>bulitins, __main__和sys</code>)，类型系统和异常系统的初始化以及一些其他工作。</p>\n<p>Python有自己的一套线程模型，虚拟机在运行的时候，一般是一个或多个线程轮流使用一个字节码执行引擎(具体的多线程机制这里并不涉及)。针对线程和进程，Python分别抽象出了两个状态对象：<code>PyThreadState</code>和<code>PyInterpreterState</code>。</p>\n<pre><code class=\"c\">typedef struct _is {\n    struct _is *next;\n    struct _ts *tstate_head;\n    PyObject *modules;\n    ...\n    PyObject *builtins;\n    PyObject *importlib;\n    int codecs_initialized;\n    int fscodec_initialized;\n    PyObject *builtins_copy;\n    PyObject *import_func;\n    /* Initialized to PyEval_EvalFrameDefault(). */\n    _PyFrameEvalFunction eval_frame;\n} PyInterpreterState;\n\ntypedef struct _ts {\n    struct _ts *prev;\n    struct _ts *next;\n    PyInterpreterState *interp;\n    struct _frame *frame;\n    int recursion_depth;\n    ...\n    PyObject *dict;  /* Stores per-thread state */\n    int gilstate_counter;\n    PyObject *async_exc; /* Asynchronous exception to raise */\n    long thread_id; /* Thread id where this tstate was created */\n    ...\n    PyObject *async_gen_finalizer;\n} PyThreadState;\n</code></pre>\n<p>可以看到这么一个结构，在进程<code>_is</code>中维护着一个<code>tstate_head</code>线程列表，而在线程<code>_ts</code>中维护着当前线程的栈桢列表<code>frame</code>。</p>\n<p>在Python虚拟机开始执行时，它会将当前线程状态对象的<code>frame</code>设置为当前的执行环境，并执行字节码。在当前栈桢执行完毕后，会创建一个新的<code>PyFrameObject</code>，并从<code>tstate</code>中取得<code>frame</code>构建成一条链表，开始新的征途。</p>\n<p>在某一时刻，虚拟机的运行时的内存布局会是下面这种形式：</p>\n<p><img src=\"/images/python_runtime_env.png\" alt=\"\"></p>\n<h2 id=\"执行引擎\"><a href=\"#执行引擎\" class=\"headerlink\" title=\"执行引擎\"></a>执行引擎</h2><p>当虚拟机的字节码执行引擎在<code>_PyEval_EvalFrameDefault</code>函数里，首先会初始化一批和<code>PyCodeObject</code>有关的变量以及让栈的指针指向<code>f-&gt;f_stacktop</code>：</p>\n<p>在设置好各个变量后，执行引擎会从头遍历整个<code>PyCodeObject</code>的<code>co_code</code>域，依次处理字节码。其中有三个变量和字节码遍历有关：</p>\n<ul>\n<li><code>first_instr</code>：永远指向字节码序列的开始位置；</li>\n<li><code>next_instr</code>：指向下一条待执行的字节码指令；</li>\n<li><code>f_lasti</code>：上一条已执行的字节码在co_code中的索引。</li>\n</ul>\n<p>字节码的处理是在一个<code>for loop</code>中，以<code>switch</code>的方式分发到相应的宏定义上处理各种字节码。一条字节码处理完成过后会跳转到<code>for</code>循环或者是<code>fast_next_opcode</code>执行下一条。其中有个变量<code>why</code>，它保存着结束字节码执行时的状态码信息，是正常还是异常退出。</p>\n<pre><code class=\"c\">PyObject *\n_PyEval_EvalFrameDefault(PyFrameObject *f, int throwflag)\n{\n    ...\n    co = f-&gt;f_code;\n    names = co-&gt;co_names;\n    consts = co-&gt;co_consts;\n    fastlocals = f-&gt;f_localsplus;\n    freevars = f-&gt;f_localsplus + co-&gt;co_nlocals;\n    first_instr = (_Py_CODEUNIT *) PyBytes_AS_STRING(co-&gt;co_code);\n    next_instr = first_instr;\n    if (f-&gt;f_lasti &gt;= 0) {\n        next_instr += f-&gt;f_lasti / sizeof(_Py_CODEUNIT) + 1;\n    }\n    stack_pointer = f-&gt;f_stacktop;\n\n    why = WHY_NOT;\n    for (;;) {\n        ...\n\n        fast_next_opcode:\n            f-&gt;f_lasti = INSTR_OFFSET();\n            ...\n\n        dispatch_opcode:\n            switch (opcode) {\n\n                TARGET(NOP)\n                    FAST_DISPATCH();\n\n                TARGET(LOAD_FAST) {\n                    ...\n                }\n                ...\n            }\n    }\n\n</code></pre>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"[LeetCode]32. Longest Valid Parentheses","url":"http://shawnz.me/posts/fbe1b588/","content":"<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n    }\n});\nconsole.log(\"======================\")\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i=0; i < all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';                 \n    }       \n});\n</script>\n\n<p><link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"></p>\n<script src=\"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n\n<h2 id=\"问题描述\"><a href=\"#问题描述\" class=\"headerlink\" title=\"问题描述\"></a>问题描述</h2><p>对于一个给定的只包含“(”和“)”的字符串，找出它的最长合法括号。例如：</p>\n<blockquote>\n<p>“(()” =&gt; 2  # 最长合法括号为“()”，长度为2<br><br>“)()())” =&gt; 4  # 最长合法括号为“()()“，长度为4</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"暴力解法\"><a href=\"#暴力解法\" class=\"headerlink\" title=\"暴力解法\"></a>暴力解法</h2><p>很容易想到的解法是，穷举出所有的子串，然后一一验证每个子串是否是合法的(<code>Valid Parentheses</code>)。</p>\n<p><strong>复杂度分析</strong></p>\n<ul>\n<li>时间复杂度：$O(n^3)$。穷举所有子串为$O(n^2)$，使用栈验证一个长度为n的子串需要$O(n)$</li>\n<li>空间复杂度：$O(n)$。使用栈验证字符串需要一定的空间。</li>\n</ul>\n<h2 id=\"Stack\"><a href=\"#Stack\" class=\"headerlink\" title=\"Stack\"></a>Stack</h2><p>这是一道括号题，和<code>Valid Parenthese</code>一样，可以尝试使用栈。</p>\n<p>从左到右遍历字符串，如果是<code>(</code>，那么进行“压栈”操作；如果是<code>)</code>，若它是一个合法的括号匹配，那么必然可以和栈顶的<code>(</code>抵消。</p>\n<p>不过在这里，我们要求的是“长度”，所以在遍历过程中，应该记录长度或者是索引的信息。</p>\n<ol>\n<li>使用<code>stack</code>来记录上一个<code>valid</code>串的停止位置，刚开始为<code>-1</code>；</li>\n<li>在从左到右的遍历过程中，碰到左括号<code>(</code>，把它的索引<code>i</code>压栈；</li>\n<li>碰到右括号<code>)</code>，则需要弹出栈顶元素尝试抵消：<ul>\n<li>如果栈顶不是<code>(</code>(也就是弹出元素后<code>stack</code>为空)，那么当前这个<code>valid</code>串到这为止，开始查找新的<code>valid</code>串，重置哨兵为当前位置<code>i</code>；</li>\n<li>如果能够抵消，那么<code>valid</code>串就会变长</li>\n</ul>\n</li>\n</ol>\n<pre><code class=\"python\">class Solution:\n    def longestValidParentheses(self, s):\n        &quot;&quot;&quot;\n        :type s: str\n        :rtype: int\n        &quot;&quot;&quot;\n        n = len(s)\n        stack = [-1]\n        maxLen = 0\n        for i in range(n):\n            if s[i] == &#39;(&#39;:\n                stack.append(i)\n            else:\n                stack.pop()\n                if not stack:\n                    stack.append(i)\n                else:\n                    maxLen = max(maxLen, i-stack[-1])\n        return maxLen\n</code></pre>\n<p><strong>复杂度分析</strong></p>\n<ul>\n<li>时间复杂度：$O(n)$，遍历一次长度为<code>n</code>的字符串。</li>\n<li>空间复杂度：$O(n)$。使用栈保存索引，如果一直是左括号<code>(</code>，那么栈的大小为<code>n+1</code>。</li>\n</ul>\n<h2 id=\"DP\"><a href=\"#DP\" class=\"headerlink\" title=\"DP\"></a>DP</h2><p>我们发现一个最长<code>valid</code>串能够由一个子<code>valid</code>串构成，可以尝试着从动态规划的角度去理解这个问题。</p>\n<p>从右到左，对于以<code>i</code>结尾的字符串分几种情形：</p>\n<ul>\n<li>如果<code>s[i]==(</code>，那么显然它不是一个<code>valid</code>串，则<code>dp[i] = 0</code>。例如<code>()(</code>；</li>\n<li>如果<code>s[i]==)</code>，那么：<ul>\n<li>如果<code>s[i-1]==&quot;(&quot;</code>，，那么<code>dp[i] = dp[i-2] + 2</code>。例如<code>()()</code>；</li>\n<li>如果<code>s[i-1]==&quot;)&quot;</code>：<ul>\n<li>像<code>()(())</code>这种，<code>dp[i]=dp[i-1] + 2 + dp[i-dp[i-1]-2]</code></li>\n<li>像<code>)())</code>或<code>())</code>这种，<code>dp[i]=0</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>设<code>dp[i-1]</code>的最长<code>valid</code>串的前一位为<code>j=i-dp[i-1]-1</code>，整理一下可以得到它的状态方程：</p>\n<p>$$dp[i] = \\begin{cases}<br>0, &amp;if\\ s[i]==’(‘\\ or\\ j&lt;0\\ or\\ s[j]==’)’\\<br>dp[i-1] + 2, &amp;if\\ s[j]==’(‘\\ and\\ j=0\\<br>dp[i-1] + 2 + dp[j-1], &amp;if\\ s[j]==’(‘\\ and\\ j&gt;0\\<br>\\end{cases}$$</p>\n<pre><code class=\"python\">class Solution:\n    def longestValidParentheses(self, s):\n        &quot;&quot;&quot;\n        :type s: str\n        :rtype: int\n        &quot;&quot;&quot;\n        n = len(s)\n        dp = [0] * n\n        maxLen = 0\n        for i in range(1, n):\n            j = i - dp[i-1] - 1\n            if j &gt;= 0 and s[j] == &#39;(&#39;:\n                dp[i] = dp[i-1] + 2 + (dp[j-1] if j &gt; 0 else 0)\n                maxLen = max(maxLen, dp[i])\n        return maxLen\n</code></pre>\n<p><strong>复杂度分析</strong></p>\n<ul>\n<li>时间复杂度：$O(n)$，遍历一次长度为<code>n</code>的字符串。</li>\n<li>空间复杂度：$O(n)$。</li>\n</ul>\n","categories":[],"tags":["算法","LeetCode"]},{"title":"回溯算法(Backtracking)","url":"http://shawnz.me/posts/1b888408/","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>在许多情况下，回溯算法相当于“穷举搜索”的巧妙实现。主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯算法一个重要特性就是问题的解空间一般在搜索的过程中动态的构建。</p>\n<p>在思考回溯算法，一般需要明确几点：</p>\n<ul>\n<li><code>裁剪(pruning)</code>：在当前局面所有的可能的尝试，删除掉一批不可能尝试；</li>\n<li><code>分支限定(bounding)</code>：使用限定条件避免掉一些不必要的尝试；</li>\n<li><code>回溯(backtrack)</code>：使用深度优先的递归方式尝试每种选择，在不满足条件的情况下能够很好的回溯；</li>\n<li><code>结束(termination)</code>：若是求解所有解，则需要回溯到<code>根</code>，且<code>根</code>的所有<code>子树</code>都已经搜索完毕；若是求解任一解，那么只要找到一个解就可以结束。</li>\n</ul>\n<p>下面将从几个具体的例子来理解回溯算法。<br><a id=\"more\"></a></p>\n<h2 id=\"问题实例\"><a href=\"#问题实例\" class=\"headerlink\" title=\"问题实例\"></a>问题实例</h2><h3 id=\"Permutations\"><a href=\"#Permutations\" class=\"headerlink\" title=\"Permutations\"></a>Permutations</h3><blockquote>\n<p>Given a collection of <code>distinct</code> numbers, return all possible permutations.<br><br>For example, [1,2,3] have the following permutations:<br><br>[<br>  [1,2,3],<br>  [1,3,2],<br>  [2,1,3],<br>  [2,3,1],<br>  [3,1,2],<br>  [3,2,1]<br>]  </p>\n</blockquote>\n<p><strong>解法一：回溯+递归</strong></p>\n<p>以<code>{1, 2, 3}</code>为例，找出它的全排列。一个直接的想法是依序穷举每一个位置，针对每个位置填充不同的元素，需要注意的是同一个元素不能使用两次。</p>\n<p>可以使用<code>DFS</code>从左到右填充元素，每次填充的时候可能的尝试是<code>1, 2, 3</code>，但是当一个位置填充的是<code>1</code>的时候，那么在这次构建序列中<code>1</code>就不能再使用了，所以下面我们引入一个限定条件检查元素不包含在当前排列中。</p>\n<pre><code class=\"python\">class Solution:\n    def permute(self, nums):\n        &quot;&quot;&quot;\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        &quot;&quot;&quot;\n        if not nums:\n            return []\n\n        res = []\n        tmp = []\n        self.backtrack(nums, tmp, res)\n        return res\n\n    def backtrack(self, nums, tmp, res):\n        if len(tmp) == len(nums):\n            res.append(tmp[:])\n            return \n\n        for i in range(len(nums)):\n            if nums[i] in tmp:\n                continue\n\n            tmp.append(nums[i])\n            self.backtrack(nums, tmp, res)\n            tmp.pop()\n</code></pre>\n<p>复杂度：</p>\n<ul>\n<li>时间复杂度：$O(n!)$，第一个位置有<code>n</code>种选择，第二个位置有<code>n-2</code>个选择，则<code>n*(n-1)*...*2*1=n!</code></li>\n<li>空间复杂度：$O(n!)$，输出需要<code>n!</code>的存储空间。</li>\n</ul>\n<p><strong>解法二：*插入法</strong></p>\n<p>这道题的另外一种思路是使用“插入法”：<br><br><code>P(1) = [1]</code><br><br><code>P(1,2) = [[2, 1], [1, 2]]</code><br><br><code>P(1,2,3) = [[3, 2, 1], [2, 3, 1], [2, 1, 3], [3, 1, 2], [1, 3, 2], [1, 2, 3]]</code><br><br>我们可以把<code>P(1, 2)</code>看作是把<code>2</code>插入到<code>P(1)</code>中所有可能的位置，<code>P(1, 2, 3)</code>看作是把<code>3</code>插入到<code>P(1, 2)</code>中能够插入的位置。</p>\n<pre><code class=\"python\">class Solution:\n    def permute(self, nums):\n        &quot;&quot;&quot;\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        &quot;&quot;&quot;\n        if not nums: return []\n        perms = [[]]\n        for idx, num in enumerate(nums):\n            new_perms = []\n            for perm in perms:\n                for i in range(idx+1):\n                    tmp = perm[:]\n                    tmp.insert(i, num)  # 插入元素\n                    new_perms.append(tmp)\n            perms = new_perms\n        return perms\n</code></pre>\n<p>复杂度分析：</p>\n<ul>\n<li>时间复杂度：$O(n<em>n!)$，第一层和第三层的<code>for</code>循环为`n</em>n<code>，第二层循环为</code>(n-1)!`。</li>\n<li>空间复杂度：$O(n!)$，输出需要<code>n!</code>的存储空间。</li>\n</ul>\n<p><strong>* Follow up</strong></p>\n<p>一个升级版就是对于有<code>重复</code>元素的数组，例如<code>{1, 1, 2}</code>怎么计算它的所有<code>不同</code>排列。</p>\n<p>这种重复元素问题的常见解决思路就是，先排序一次，在判断前后两个元素是否相等，再做相应的处理(跳过)。</p>\n<p>在使用回溯算法的实现中，我们先是对数组进行一次排序，并引进了一个<code>used[]</code>数组记录元素是否访问过，在这里有两种方式都能够消除重复元素：<code>used[i-1]</code>和<code>!used[i-1]</code>。</p>\n<p>下面使用递归树的方式描述了这个过程，可以看到在有重复元素的时候<code>used[i-1]</code>和<code>!used[i-1]</code>是怎么处理的。假设我们对三个重复元素<code>2</code>排序完后进行编号：<code>2(1),2(2),2(3)</code>：</p>\n<p><img src=\"/images/backtrack.jpg\" alt=\"\"></p>\n<ul>\n<li><code>used[i-1]</code>：只有在前一个元素使用的情况下才会加入排列，那么最终只会形成<code>2(1),2(2),2(3)</code>这种顺序的排列；</li>\n<li><code>!used[i-1]</code>：只有在前一个元素没有使用的情况下才会加入排列，那么只会形成<code>2(3),2(2),2(1)</code>降序排列。</li>\n</ul>\n<p>当然，还有一个前提就是<code>if used[i]: continue</code>，跳过已经处理过的元素。我们可以发现<code>used[i-1]</code>和<code>!used[i-1]</code>都能消除重复元素，那它们的区别在哪呢？</p>\n<p>答案就是使用<code>!used[i-1]</code>的话，中间不会进行一些不必要的处理，例如<code>used[i-1]</code>会进行<code>2(2),2(1)</code>再到<code>2(2),2(1),2(3)</code>的尝试，而<code>!used[i-1]</code>就不会，所以它更高效一点，在LeetCode上可以很明显的看到时间性能的提升。</p>\n<pre><code class=\"python\">class Solution:\n    def permuteUnique(self, nums):\n        &quot;&quot;&quot;\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        &quot;&quot;&quot;\n        if not nums: return []\n        res = []\n        nums.sort()\n        n = len(nums)\n        used = [False] * n\n        curr = []\n        self.backtrack(nums, used, curr, res)\n        return res\n\n\n    def backtrack(self, nums, used, curr, res):\n        if len(curr) == len(nums):\n            res.append(curr[:])\n            return \n\n        for i in range(len(nums)):\n            if used[i]:\n                    continue\n            # 这两种方式都可以消除重复元素   \n            if i &gt; 0 and nums[i] == nums[i-1] and not used[i-1]:\n                continue\n            # if i &gt; 0 and nums[i] == nums[i-1] and used[i-1]:\n            #     continue\n\n            used[i] = True\n            curr.append(nums[i])\n            self.backtrack(nums, used, curr, res)\n            used[i] = False\n            curr.pop()\n</code></pre>\n<p>下面是使用“插入法”在有重复元素时的实现：</p>\n<pre><code class=\"python\">class Solution:\n    def permuteUnique(self, nums):\n        &quot;&quot;&quot;\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        &quot;&quot;&quot;\n\n        if not nums:\n            return []\n\n        n = len(nums)\n        nums.sort()\n        perms = [[nums[0]]]\n\n        for i in range(1, n):\n\n            new_perms = []\n            for perm in perms:\n                for j in range(i+1):\n                    tmp = perm[:]\n                    tmp.insert(j, nums[i])\n                    new_perms.append(tmp)\n                    if j &lt; len(perm) and perm[j] == nums[i]:  # 这里的跳过逻辑可以好好想想\n                        break\n            perms = new_perms\n        return perms\n</code></pre>\n<h3 id=\"Subsets\"><a href=\"#Subsets\" class=\"headerlink\" title=\"Subsets\"></a>Subsets</h3><p><strong>问题描述</strong></p>\n<p>列举子集合。这里示范：列举出{0,1,2,3,4}的所有子集合。</p>\n<pre><code class=\"python\">class Solution:\n    def subsets(self, nums):\n        &quot;&quot;&quot;\n        :type nums: List[int]\n        :rtype: List[List[int]]\n        &quot;&quot;&quot;\n        if not nums: return []\n        n = len(nums)\n        res = []\n        self.backtrack(nums, res, [], 0)\n        return res\n\n    def backtrack(self, nums, res, tmp, start):\n        res.append(tmp[:])\n        for i in range(start, len(nums)):\n            tmp.append(nums[i])\n            self.backtrack(nums, res, tmp, i+1)\n            tmp.pop()\n</code></pre>\n<h3 id=\"八皇后问题\"><a href=\"#八皇后问题\" class=\"headerlink\" title=\"八皇后问题\"></a>八皇后问题</h3><p><strong>问题描述</strong></p>\n<p>在一个N×N的（国际）棋盘上，放置N个棋子（皇后），使得N个”皇后“中任意2个都不在同一行、同一列以及同一斜线。 问：放置这N个”皇后“的方法共有多少种？(或者列举解)</p>\n<p><img src=\"/images/八皇后问题.png\" alt=\"\"></p>\n<p><strong>解决思路</strong></p>\n<p>通过回溯算法，逐行暴力搜索每行能够放置“皇后”的位置，找到第i行的解的前提是前i-1行已经放置好了皇后，直到第N行时结束。</p>\n<p>在搜索的过程中使用<code>pos[n]</code>记录棋盘第i行、第j列的“皇后”位置。</p>\n<p><strong>实现</strong></p>\n<p>我们来看看递归的实现：</p>\n<pre><code class=\"python\">class Solution:\n    def solveNQueens(self, n):\n        &quot;&quot;&quot;\n        :type n: int\n        :rtype: List[List[str]]\n        &quot;&quot;&quot;\n        res = []\n        pos = [-1] * n\n        self.backtrack(pos, 0, [], res)\n        return res\n\n    def backtrack(self, pos, row, path, res):\n        if row == len(pos):\n            res.append(path)\n            return  # backtracking\n\n        for col in range(len(pos)):\n            if self.is_valid(pos, row, col):  # pruning\n                tmp = &#39;.&#39; * len(pos)\n                pos[row] = col\n                self.backtrack(pos, row+1, path + [tmp[:col] + &#39;Q&#39; + tmp[col+1:]], res)\n\n    def is_valid(self, pos, row, col):\n        for i in range(row):\n            if pos[i] == col or pos[i] - col == i - row or pos[i] - col == row - i:\n                return False\n        return True\n</code></pre>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><h2 id=\"资源\"><a href=\"#资源\" class=\"headerlink\" title=\"资源\"></a>资源</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://github.com/zhsj/nqueen/blob/master/N%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98.md\" target=\"_blank\" rel=\"noopener\">N皇后问题</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">51. N-Queens</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">52. N-Queens II</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">39. Combination Sum</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">40. Combination Sum II</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">216. Combination Sum III</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">46. Permutations</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">47. Permutations II</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">78. Subsets</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">90. Subsets II</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">131. Palindrome Partitioning</a><br></p>\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n    }\n});\nconsole.log(\"======================\")\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i=0; i < all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';                 \n    }       \n});\n</script>\n\n<p><link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"></p>\n<script src=\"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n\n\n\n","categories":["算法"],"tags":["算法"]},{"title":"Python源码阅读-Dict","url":"http://shawnz.me/posts/92346aeb/","content":"<h2 id=\"存储策略\"><a href=\"#存储策略\" class=\"headerlink\" title=\"存储策略\"></a>存储策略</h2><p>Python中字典的实现策略:</p>\n<ol>\n<li>底层使用散列表进行存储</li>\n</ol>\n<a id=\"more\"></a>\n<ol>\n<li>开放定址发检测冲突<ul>\n<li>插入：发生冲突，通过二次探测算法，寻找下一个位置，直到找到可用位置，插入元素(构成一条”探测链“)。</li>\n<li>查找：需要遍历“探测链”；</li>\n<li>删除：如果对象在“探测链”上，不能直接删除元素，会导致探测链上的下个元素找不到，采用标记删除技术。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h2><h3 id=\"PyDictEntry\"><a href=\"#PyDictEntry\" class=\"headerlink\" title=\"PyDictEntry\"></a>PyDictEntry</h3><p>Python2中使用<code>PyDictEntry</code>定义一对<code>key-value</code>键值对：</p>\n<pre><code class=\"c\">typedef struct {\n    /* Cached hash code of me_key.  Note that hash codes are C longs.\n     * We have to use Py_ssize_t instead because dict_popitem() abuses\n     * me_hash to hold a search finger.\n     */\n    Py_ssize_t me_hash;\n    PyObject *me_key;\n    PyObject *me_value;\n} PyDictEntry;\n</code></pre>\n<p>在一个<code>PyDictEntry</code>的生存变化过程中，<code>entey</code>会在几个状态之间切换：</p>\n<ul>\n<li><p><code>Unused</code>：当一个<code>entry</code>的<code>me_key</code>和<code>me_value</code>都是<code>NULL</code>时，<code>entry</code>处于<code>Unused</code>态。每个<code>entry</code>初始化时会处于这个状态，而且只有<code>Unused</code>态下，<code>me_key</code>才会为<code>NULL</code>。</p>\n</li>\n<li><p><code>Active</code>：当<code>entry</code>中存储着一对<code>me_key</code>和<code>me_value</code>时，<code>entry</code>处于<code>Active</code>态，在这个状态下，<code>me_key</code>和<code>me_value</code>都不能为<code>NULL</code>。</p>\n</li>\n<li><p><code>Dummy</code>：当删除一个键值对时，<code>entry</code>不能直接删除，这个时候<code>me_key</code>指向<code>dummy</code>对象，<code>entry</code>进入<code>Dummy</code>态。</p>\n</li>\n</ul>\n<h3 id=\"PyDictObject\"><a href=\"#PyDictObject\" class=\"headerlink\" title=\"PyDictObject\"></a>PyDictObject</h3><p>Python2中字典的实现是<code>PyDictObject</code>，它是一堆<code>PyDictEntry</code>集合：</p>\n<pre><code class=\"c\">typedef struct _dictobject PyDictObject;\nstruct _dictobject {\n    PyObject_HEAD\n    Py_ssize_t ma_fill;  /* 元素个数 Active + # Dummy */\n    Py_ssize_t ma_used;  /* 元素个数 Active */\n\n    /* The table contains ma_mask + 1 slots, and that&#39;s a power of 2.\n    * We store the mask instead of the size because the mask is more\n    * frequently needed.\n    */\n    Py_ssize_t ma_mask;\n\n    /* ma_table points to ma_smalltable for small tables, else to\n    * additional malloc&#39;ed memory.  ma_table is never NULL!  This rule\n    * saves repeated runtime null-tests in the workhorse getitem and\n    * setitem calls.\n    */\n    PyDictEntry *ma_table;\n    PyDictEntry *(*ma_lookup)(PyDictObject *mp, PyObject *key, long hash);\n    PyDictEntry ma_smalltable[PyDict_MINSIZE];\n};\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><code>ma_fill</code>：维护着从<code>PyDictObject</code>创建开始直到现在，曾经及正处于<code>Active</code>态的<code>entry</code>；</li>\n<li><code>ma_used</code>：维护着当期处于<code>Active</code>态的<code>entry</code>；</li>\n<li><code>ma_smalltable</code>：当一个<code>PyDictObject</code>对象创建时，至少有<code>PyDict_MINSIZE</code>(8)个<code>entry</code>同时创建；</li>\n<li><code>ma_table</code>：指向一片作为<code>PyDictEntry</code>集合的内存开始地址。Python对于一个小<code>dict</code>(即<code>entry</code>少于8个)，<code>ma_table</code>指向<code>ma_smalltable</code>，否则会申请一片额外的内存，并将<code>ma_table</code>指向它。(这个策略可以避免对<code>ma_table</code>的有效性检查);</li>\n<li><code>ma_mask</code>：字典拥有的<code>entry</code>数量减一， 在将hash值映射到散列表上需要用到这个值；</li>\n<li><code>ma_lookup</code>：字典的搜索策略。</li>\n</ul>\n<h2 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h2><pre><code class=\"c\">[Objects/dictobject.c]\n#define INIT_NONZERO_DICT_SLOTS(mp) do {                \\\n    (mp)-&gt;ma_table = (mp)-&gt;ma_smalltable;                \\\n    (mp)-&gt;ma_mask = PyDict_MINSIZE - 1;                \\\n    } while(0)\n\n#define EMPTY_TO_MINSIZE(mp) do {                    \\\n    memset((mp)-&gt;ma_smalltable, 0, sizeof((mp)-&gt;ma_smalltable));    \\\n    (mp)-&gt;ma_used = (mp)-&gt;ma_fill = 0;                \\\n    INIT_NONZERO_DICT_SLOTS(mp);                    \\\n    } while(0)\n\nPyObject *\nPyDict_New(void)\n{\n    register dictobject *mp;\n    /* dummy key */\n    if (dummy == NULL) { /* Auto-initialize dummy */\n        dummy = PyString_FromString(&quot;&lt;dummy key&gt;&quot;);\n        if (dummy == NULL)\n            return NULL;\n    }\n    /* 缓冲池机制 */\n    if (num_free_dicts) { /* 从缓冲池中去最后一个空闲对象 */\n        mp = free_dicts[--num_free_dicts];\n        _Py_NewReference((PyObject *)mp);\n        if (mp-&gt;ma_fill) {\n            EMPTY_TO_MINSIZE(mp);\n        } else {\n            /* 3. ma_table -&gt; ma_smalltable */\n            /* 4. ma_mask = PyDict_MINSIZE - 1 = 7 */\n            INIT_NONZERO_DICT_SLOTS(mp);\n        }\n    } else { /* 创建PyDictObject对象 */\n        mp = PyObject_GC_New(dictobject, &amp;PyDict_Type);\n        if (mp == NULL)\n            return NULL;\n        EMPTY_TO_MINSIZE(mp);\n    }\n    mp-&gt;ma_lookup = lookdict_string;\n\n    _PyObject_GC_TRACK(mp);\n    return (PyObject *)mp;\n}\n</code></pre>\n<p>可以看到Python在创建<code>PyDictObject</code>会确保<code>dummy</code>的存在(这是一个特殊字符串)</p>\n<p>和列表相同，字典也使用了缓冲池机制，如果缓冲池有空闲对象，就会从里面获取一个并进行清空操作：</p>\n<ul>\n<li><code>EMPTY_TO_MINSIZE</code>：将<code>small_table</code>清零，<code>ma_size=ma_fill=0</code>。</li>\n<li><code>INIT_NONZERO_DICT_SLOTS</code>：将<code>ma_table</code>指向<code>small_table</code>，并设置<code>ma_mask=7</code>；</li>\n</ul>\n<p>在创建的最后，<code>lookdict_string</code>赋予给了<code>ma_lookup</code>，它指定了字典的搜索策略。</p>\n<h2 id=\"搜索策略\"><a href=\"#搜索策略\" class=\"headerlink\" title=\"搜索策略\"></a>搜索策略</h2><p>Python 为字典提供了两种搜索策略：<code>lookdict</code>和<code>lookdict_string</code>(针对<code>PyStringObject</code>对象的特殊形式)。由于把字符串作为字典的键十分普遍，Python将<code>lookdict_string</code>作为字典的默认搜索策略。</p>\n<p>在这里，我们还是看更一般的<code>lookdict</code>的实现：</p>\n<pre><code class=\"c\">\nstatic dictentry *\nlookdict(dictobject *mp, PyObject *key, register long hash)\n{\n    register size_t i;\n    register size_t perturb;\n    register dictentry *freeslot;\n    register size_t mask = (size_t)mp-&gt;ma_mask;\n    dictentry *ep0 = mp-&gt;ma_table;\n    register dictentry *ep;\n    register int cmp;\n    PyObject *startkey;\n\n    /* [1].将散列值与mask做位与运算，保证了i落在范围内 */\n    i = (size_t)hash &amp; mask;\n    ep = &amp;ep0[i]; /* 找到散列表上该位置的元素 */\n    /* [2].entry处于Unused态或者key相等(同一个内存地址)，直接返回 */\n    if (ep-&gt;me_key == NULL || ep-&gt;me_key == key)\n        return ep; /* 包含两种情况：没找到和第一次散列就找到了 */\n    /* [3].Dummy态，设置freeslot */\n    if (ep-&gt;me_key == dummy)\n        freeslot = ep;\n    else {\n        if (ep-&gt;me_hash == hash) {\n            startkey = ep-&gt;me_key;\n            Py_INCREF(startkey);\n            cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);\n            Py_DECREF(startkey);\n            if (cmp &lt; 0)\n                return NULL;\n            if (ep0 == mp-&gt;ma_table &amp;&amp; ep-&gt;me_key == startkey) {\n                if (cmp &gt; 0)\n                    return ep;\n            }\n            else {\n                /* The compare did major nasty stuff to the\n                    * dict:  start over.\n                    * XXX A clever adversary could prevent this\n                    * XXX from terminating.\n                    */\n                return lookdict(mp, key, hash);\n            }\n        }\n        freeslot = NULL;\n    }\n\n    /* In the loop, me_key == dummy is by far (factor of 100s) the\n        least likely outcome, so test for that last. */\n    for (perturb = hash; ; perturb &gt;&gt;= PERTURB_SHIFT) {\n        i = (i &lt;&lt; 2) + i + perturb + 1;\n        ep = &amp;ep0[i &amp; mask];\n        if (ep-&gt;me_key == NULL)\n            return freeslot == NULL ? ep : freeslot;\n        if (ep-&gt;me_key == key)\n            return ep;\n        if (ep-&gt;me_hash == hash &amp;&amp; ep-&gt;me_key != dummy) {\n            startkey = ep-&gt;me_key;\n            Py_INCREF(startkey);\n            cmp = PyObject_RichCompareBool(startkey, key, Py_EQ);\n            Py_DECREF(startkey);\n            if (cmp &lt; 0)\n                return NULL;\n            if (ep0 == mp-&gt;ma_table &amp;&amp; ep-&gt;me_key == startkey) {\n                if (cmp &gt; 0)\n                    return ep;\n            }\n            else {\n                /* The compare did major nasty stuff to the\n                    * dict:  start over.\n                    * XXX A clever adversary could prevent this\n                    * XXX from terminating.\n                    */\n                return lookdict(mp, key, hash);\n            }\n        }\n        else if (ep-&gt;me_key == dummy &amp;&amp; freeslot == NULL)\n            freeslot = ep;\n    }\n    assert(0);    /* NOT REACHED */\n    return 0;\n}\n</code></pre>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-List","url":"http://shawnz.me/posts/1d425055/","content":"<p>和前面的整数,字符串不同的是,List除了是一个变长对象,也需要动态的调整其所维护的内存和元素,所以,他还是一个可变对象.</p>\n<p>在这篇(以及后续的博客)里面只会对Python3的源码进行分析.</p>\n<a id=\"more\"></a>\n<h2 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h2><pre><code class=\"c\">[include/listobject.c]\ntypedef struct {\n    PyObject_VAR_HEAD\n    /* Vector of pointers to list elements.  list[0] is ob_item[0], etc. */\n    PyObject **ob_item;\n\n    /* ob_item contains space for &#39;allocated&#39; elements.  The number\n     * currently in use is ob_size.\n     * Invariants:\n     *     0 &lt;= ob_size &lt;= allocated\n     *     len(list) == ob_size\n     *     ob_item == NULL implies ob_size == allocated == 0\n     * list.sort() temporarily sets allocated to -1 to detect mutations.\n     *\n     * Items must normally not be NULL, except during construction when\n     * the list is not yet visible outside the function that builds it.\n     */\n    Py_ssize_t allocated;\n} PyListObject;\n</code></pre>\n<p>从<code>PyListObject</code>的定义和注释中我们可以知道:</p>\n<ul>\n<li><code>ob_item</code>:指向一个内部的元素列表的内存块首地址,所以注释里会有<code>list[0] is ob_item[0]</code>.</li>\n<li><code>allocated</code>:元素列表可容纳的元素总数.这一点需要和<code>ob_size</code>区分,<code>ob_size</code>是实际使用的元素数量.所以有:<br><br>  <code>0 &lt;= ob_size &lt;= allocated</code><br><br>  <code>len(list) == ob_size</code><br><br>  <code>ob_item == NULL 意味着 ob_size == allocated == 0</code></li>\n</ul>\n<p>在许多行为上,Python中的list和C++中的<code>vector</code>十分相像.</p>\n<h2 id=\"创建\"><a href=\"#创建\" class=\"headerlink\" title=\"创建\"></a>创建</h2><p>Python中创建列表只有通过一种方式,那就是<code>PyList_New</code>,其中<code>size</code>指示初始的元素个数.</p>\n<pre><code class=\"c\">[Objects/listobject.c]\nPyObject *\nPyList_New(Py_ssize_t size)\n{\n    PyListObject *op;\n#ifdef SHOW_ALLOC_COUNT\n    static int initialized = 0;\n    if (!initialized) {\n        Py_AtExit(show_alloc);\n        initialized = 1;\n    }\n#endif\n\n    if (size &lt; 0) {\n        PyErr_BadInternalCall();\n        return NULL;\n    }\n    /* 缓冲池机制 */\n    if (numfree) {  /* 可用 */\n        numfree--;\n        op = free_list[numfree];\n        _Py_NewReference((PyObject *)op);\n#ifdef SHOW_ALLOC_COUNT\n        count_reuse++;\n#endif\n    } else {  /* 不可用,创建PyListObject对象本身 */\n        op = PyObject_GC_New(PyListObject, &amp;PyList_Type);\n        if (op == NULL)\n            return NULL;\n#ifdef SHOW_ALLOC_COUNT\n        count_alloc++;\n#endif\n    }\n    if (size &lt;= 0)\n        op-&gt;ob_item = NULL;\n    else {  /* 为内部的元素列表分配内存 */\n        op-&gt;ob_item = (PyObject **) PyMem_Calloc(size, sizeof(PyObject *));\n        if (op-&gt;ob_item == NULL) {  /* 内存溢出 */\n            Py_DECREF(op);\n            return PyErr_NoMemory();\n        }\n    }\n    /* 设置值 */\n    Py_SIZE(op) = size;\n    op-&gt;allocated = size;\n    _PyObject_GC_TRACK(op);\n    return (PyObject *) op;\n}\n</code></pre>\n<p>通过源代码可以看到,<code>List</code>的创建分为两个部分:</p>\n<ul>\n<li><code>PyListObject</code>本身的创建:又到了熟悉的地方,对象缓冲池机制(具体实现思路在后面会讲到).</li>\n<li>为所维护的元素列表申请内存:申请大小为<code>size * sizeof(PyObjetc *)</code>的内存.</li>\n</ul>\n<p>创建结束会有:</p>\n<ul>\n<li><code>PyListObject.ob_size == size</code></li>\n<li><code>PyListObject.allocated == size</code></li>\n</ul>\n<h2 id=\"设置\"><a href=\"#设置\" class=\"headerlink\" title=\"设置\"></a>设置</h2><p>假设我们第一次通过<code>PyList_New(6)</code>创建一个<code>PyListObject</code>对象,它的内存分配如下(正常情况下,不会有<code>NULL</code>):</p>\n<p><img src=\"/images/pylistobject1.png\" alt=\"\"></p>\n<p>如果尝试把一个整数对象<code>100</code>放到第4个位置,也就是<code>list[3]=100</code>,Python内部会调用:</p>\n<pre><code class=\"c\">[Objects/listobject.c]\n\nint\nPyList_SetItem(PyObject *op, Py_ssize_t i,\n               PyObject *newitem)\n{\n    PyObject **p;\n      /* 类型检查 */\n    if (!PyList_Check(op)) {\n        Py_XDECREF(newitem);\n        PyErr_BadInternalCall();\n        return -1;\n    }\n    /* 索引检查 */\n    if (i &lt; 0 || i &gt;= Py_SIZE(op)) {\n        Py_XDECREF(newitem);\n        PyErr_SetString(PyExc_IndexError,\n                        &quot;list assignment index out of range&quot;);\n        return -1;\n    }\n    /* 引用调整 */\n    p = ((PyListObject *)op) -&gt; ob_item + i;\n    Py_XSETREF(*p, newitem);\n    return 0;\n}\n</code></pre>\n<p>在Python中运行<code>list[3] = 100</code>时,首先会进行类型检查和索引有效性检查,如果通过就会把对象<code>100</code>的<code>PyObject *</code>指针:</p>\n<pre><code class=\"c\">#define Py_XSETREF(op, op2)                     \\\n    do {                                        \\\n        PyObject *_py_tmp = (PyObject *)(op);   \\\n        (op) = (op2);                           \\\n        Py_XDECREF(_py_tmp);                    \\\n    } while (0)\n</code></pre>\n<p>这里的<code>do while(0)</code>结构不代表循环, 这是编写宏的小技巧, 在以后的源码阅读中经常会出现. </p>\n<p>可以看到指针修改的过程又分为两步:</p>\n<ul>\n<li>先是把新的对象<code>100</code>的指针放在了该位置上</li>\n<li>调用<code>Py_XDECREF</code>将原来存放的对象的引用减一, 可能会遇到原来对象是<code>NULL</code>的情况.</li>\n</ul>\n<p>现在,<code>PyListObject</code>的情形应该变成这样了:</p>\n<p><img src=\"/images/pylistobject2.png\" alt=\"\"></p>\n<h2 id=\"插入\"><a href=\"#插入\" class=\"headerlink\" title=\"插入\"></a>插入</h2><p>插入和设置不同,插入会导致<code>ob_item</code>维护的内存发生变化.</p>\n<pre><code class=\"c\">[Objects/listobject.c]\nint\nPyList_Insert(PyObject *op, Py_ssize_t where, PyObject *newitem)\n{\n    if (!PyList_Check(op)) {  /* 类型检查 */\n        PyErr_BadInternalCall();\n        return -1;\n    }\n    return ins1((PyListObject *)op, where, newitem);\n}\n\n\nstatic int\nins1(PyListObject *self, Py_ssize_t where, PyObject *v)\n{\n    Py_ssize_t i, n = Py_SIZE(self);\n    PyObject **items;\n    if (v == NULL) {  /* 插入元素为NULL */\n        PyErr_BadInternalCall();\n        return -1;\n    }\n    if (n == PY_SSIZE_T_MAX) { /* 内存已满 */\n        PyErr_SetString(PyExc_OverflowError,\n            &quot;cannot add more objects to list&quot;);\n        return -1;\n    }\n    /* 调整元素列表容量 */\n    if (list_resize(self, n+1) &lt; 0)\n        return -1;\n    /* 对索引进行修正 */\n    if (where &lt; 0) {\n        where += n;\n        if (where &lt; 0)\n            where = 0;\n    }\n    if (where &gt; n)\n        where = n;\n    /* 插入元素 */\n    items = self-&gt;ob_item;\n    for (i = n; --i &gt;= where; )\n        items[i+1] = items[i];\n    Py_INCREF(v);\n    items[where] = v;\n    return 0;\n}\n</code></pre>\n<p>Python在内部使用<code>PyList_Insert</code>执行插入操作,而<code>PyList_Insert</code>实际调用的是<code>insl</code>,在插入元素时,Python会先做一些类型检查以及<code>list</code>大小是否达到<code>PY_SSIZE_T_MAX</code>.</p>\n<p>为确保<code>list</code>中有足够的位置容纳新的元素,Python会通过<code>list_resize</code>调整列表大小.</p>\n<pre><code class=\"c\">static int\nlist_resize(PyListObject *self, Py_ssize_t newsize)\n{\n    PyObject **items;\n    size_t new_allocated;\n    Py_ssize_t allocated = self-&gt;allocated;\n\n    /* 不需要重新分配内存 */\n    if (allocated &gt;= newsize &amp;&amp; newsize &gt;= (allocated &gt;&gt; 1)) {\n        assert(self-&gt;ob_item != NULL || newsize == 0);\n        Py_SIZE(self) = newsize;\n        return 0;\n    }\n\n    /* 计算一个增长趋势 */\n    new_allocated = (newsize &gt;&gt; 3) + (newsize &lt; 9 ? 3 : 6);\n\n    /* 检查是否数值溢出 */\n    if (new_allocated &gt; SIZE_MAX - newsize) {\n        PyErr_NoMemory();\n        return -1;\n    } else {\n        new_allocated += newsize;\n    }\n\n    if (newsize == 0)\n        new_allocated = 0;\n    /* 需要重新分配内存 */\n    items = self-&gt;ob_item;\n    if (new_allocated &lt;= (SIZE_MAX / sizeof(PyObject *)))\n        PyMem_RESIZE(items, PyObject *, new_allocated);\n    else\n        items = NULL;\n    if (items == NULL) {\n        PyErr_NoMemory();\n        return -1;\n    }\n    self-&gt;ob_item = items;\n    Py_SIZE(self) = newsize;\n    self-&gt;allocated = new_allocated;\n    return 0;\n}\n\n</code></pre>\n<p>在<code>list_resize</code>在很多对列表的修改中都会调用,它调整列表分两种情况:</p>\n<ul>\n<li><code>new_size</code>在<code>[allocated/2, allocated]</code>区间内,Python不会修改内存,只是简单的将<code>ob_size</code>修改为<code>new_size</code>;</li>\n<li>如果不在这个区间,会调用<code>realloc</code>重新分配内存.其中<code>new_size&lt;allocated/2</code>会导致列表的内存空间收缩.<br><br>  Python在计算新申请的内存时使用式子<code>(newsize &gt;&gt; 3) + (newsize &lt; 9 ? 3 : 6)</code>来保证内存开辟有一个温和的增长趋势, 避免频繁的调用<code>realloc</code>.</li>\n</ul>\n<p>现在回到元素的插入上来,在<code>list_resize</code>调整列表大小过后,Python会对传进来的索引位置<code>n</code>进行修正,也就是我们可以使用”负索引”:<br>对于<code>list:l[n]</code>,<code>l[-1]</code>也就相当于<code>l[n-1]</code>.</p>\n<p>和C中的<code>vector</code>的插入一样,会把插入位置以及之后的所有元素往后移一位,插入位置设置为我们需要插入的元素.</p>\n<p>所以对于<code>PyList_New(6)</code>创建的<code>list</code>,执行一次插入<code>PyList_Insert()</code>操作后:<code>allocated=10  ob_size=7</code></p>\n<h2 id=\"追加\"><a href=\"#追加\" class=\"headerlink\" title=\"追加\"></a>追加</h2><p>和插入操作一样,Python中列表的<code>append()</code>操作对应<code>PyList_Append</code>,在内部也会调用一个函数<code>app1</code>:</p>\n<pre><code class=\"c\">[Objects/listobject.c]\nstatic int\napp1(PyListObject *self, PyObject *v)\n{\n    Py_ssize_t n = PyList_GET_SIZE(self);\n    /* 省略掉了检查 */ \n    if (list_resize(self, n+1) &lt; 0) /* 调整大小 */\n        return -1;\n    Py_INCREF(v); /* 引用计数加一 */\n    PyList_SET_ITEM(self, n, v); /* 设置操作 */\n    return 0;\n}\n</code></pre>\n<p>在进行append操作时,也会先调用<code>list_size</code>调整列表大小,然后使用设置操作在<code>ob_size</code>设置值(不是<code>allocated</code>).</p>\n<h2 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h2><p>删除也是一个常用操作,当Python执行<code>remove</code>时,<code>PyListObject</code>中的<code>listremove</code>操作会被激活:</p>\n<pre><code class=\"c\">[Objects/listobject.c]\nstatic PyObject *\nlistremove(PyListObject *self, PyObject *v)\n{\n    Py_ssize_t i;\n    for (i = 0; i &lt; Py_SIZE(self); i++) {\n        int cmp = PyObject_RichCompareBool(self-&gt;ob_item[i], v, Py_EQ);\n        if (cmp &gt; 0) {\n            if (list_ass_slice(self, i, i+1,\n                               (PyObject *)NULL) == 0)\n                Py_RETURN_NONE;\n            return NULL;\n        }\n        else if (cmp &lt; 0)\n            return NULL;\n    }\n    PyErr_SetString(PyExc_ValueError, &quot;list.remove(x): x not in list&quot;);\n    return NULL;\n}\n</code></pre>\n<p>删除操作会遍历整个列表,将待删除元素和每一个元素比较,若果找到就删除该元素,否则返回错误.</p>\n<p>内部的删除操作是调用<code>list_ass_slice</code>完成的:</p>\n<pre><code class=\"c\">/* a[ilow:ihigh] = v if v != NULL.\n * del a[ilow:ihigh] if v == NULL.\n *\n * Special speed gimmick:  when v is NULL and ihigh - ilow &lt;= 8, it&#39;s\n * guaranteed the call cannot fail.\n */\nstatic int\nlist_ass_slice(PyListObject *a, Py_ssize_t ilow, Py_ssize_t ihigh, PyObject *v)\n</code></pre>\n<p>这个函数不仅仅用来删除元素, 当传入进来的参数<code>v==NULL</code>时,会进行删除(<code>remove</code>)操作(通过<code>memmove</code>内存搬移实现); 当<code>v!=NULL</code>时, 会进行替换(<code>replace</code>)操作. Python中的切片赋值就执行这个操作:</p>\n<pre><code class=\"python\">&gt;&gt;&gt; l = [1, 2, 3,4]\n&gt;&gt;&gt; l[1:3] = [&#39;a&#39;, &#39;b&#39;]\n&gt;&gt;&gt; l[1:2] = []\n&gt;&gt;&gt; l\n[1, &#39;b&#39;, 4]\n</code></pre>\n<h2 id=\"销毁和对象缓冲池\"><a href=\"#销毁和对象缓冲池\" class=\"headerlink\" title=\"销毁和对象缓冲池\"></a>销毁和对象缓冲池</h2><p>在创建<code>PyListObject</code>对象的时候, 我们提过”对象缓冲池”的概念.</p>\n<pre><code class=\"c\">[Objects/listobject.c]\n#ifndef PyList_MAXFREELIST\n#define PyList_MAXFREELIST 80\n#endif\nstatic PyListObject *free_list[PyList_MAXFREELIST];\nstatic int numfree = 0;\n\nPyObject *\nPyList_New(Py_ssize_t size)\n{   \n    ....\n    if (numfree) {\n        numfree--;\n        op = free_list[numfree];\n        _Py_NewReference((PyObject *)op);\n    #ifdef SHOW_ALLOC_COUNT\n        count_reuse++;\n    #endif\n    }\n    ...\n</code></pre>\n<p>可以看到<code>free_list</code>中维护一个缓冲池(最大为80), 创建对象的时候会先检查里面是否有空闲对象<code>numfree&gt;0</code>, 若有就直接从里面获取, 不会新建一个<code>PyListObject</code>.</p>\n<p>那么<code>PyListObject</code>对象是什么时候加入到缓冲池中去的呢? 答案是销毁一个<code>PyListObject</code>时, 下面是它的<code>list_dealloc</code>方法:</p>\n<pre><code class=\"c\">static void\nlist_dealloc(PyListObject *op)\n{\n    Py_ssize_t i;\n    PyObject_GC_UnTrack(op);\n    Py_TRASHCAN_SAFE_BEGIN(op)\n    if (op-&gt;ob_item != NULL) {\n        /* Do it backwards,  for Christian Tismer.\n           There&#39;s a simple test case where somehow this reduces\n           thrashing when a *very* large list is created and\n           immediately deleted. */\n        i = Py_SIZE(op);\n        while (--i &gt;= 0) {\n            Py_XDECREF(op-&gt;ob_item[i]);\n        }\n        PyMem_FREE(op-&gt;ob_item);\n    }\n    if (numfree &lt; PyList_MAXFREELIST &amp;&amp; PyList_CheckExact(op))\n        free_list[numfree++] = op;\n    else\n        Py_TYPE(op)-&gt;tp_free((PyObject *)op);\n    Py_TRASHCAN_SAFE_END(op)\n}\n</code></pre>\n<p>和创建一个<code>PyListObject</code>相对应的, 在调用<code>list_dealloc</code>也分为两步:</p>\n<ul>\n<li>会先减少里面保存的元素的引用计数, 对于引用计数减到<code>0</code>的对象, 自然会触发对象的销毁机制. 这一部分, 在”垃圾回收篇”还会讲到.</li>\n<li>第二步是<code>PyListObject</code>自身的去留: 如果<code>free_list</code>没有满, 并且是<code>list</code>对象, 那么这个对象会被加入到缓存<code>free_list</code>中去, 供循环利用; 否则会使用<code>tp_free</code>释放掉这块内存.</li>\n</ul>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>列表对象有<code>ob_size</code>和<code>allocated</code>两个概念;</li>\n<li>列表对象本身的缓冲池<code>free_list</code>;</li>\n<li>列表的大小的调整</li>\n</ul>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码阅读-字符串","url":"http://shawnz.me/posts/d117ac07/","content":"<h2 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h2><p><code>PyStringObject</code>是一个变长对象，其中有几个变量以及一段注释：</p>\n<ul>\n<li><code>ob_sval</code>：柔性数组，作为一个字符指针指向一段内存，这段内存保存着这个字符串对象实际所维护的实际字符串。而这段内存的实际长度(字节)由<code>ob_size</code>维护。比如“Python”，ob_size值为6。这是Python中所有变长对象的实现机制。<br><br>  另外，和C字符串一样，<code>PyStringObject</code>内部维护的字符串必须以<code>\\0</code>结尾，即<code>ob_val</code>实际指向的是一段长度为<code>ob_size+1</code>个字节的内存，且<code>ob_val[ob_size]=&quot;\\0&quot;</code>。</li>\n<li><code>ob_shash</code>：缓存该对象的<code>hash</code>值，这样可以避免每次都重新计算字符串对象的<code>hash</code>值，对于还没有计算过<code>hash</code>值的字符串该值为<code>-1</code>。</li>\n<li><code>ob_sstate</code>：标记该对象是否已经过<code>intern</code>机制的处理。</li>\n</ul>\n<a id=\"more\"></a>\n<pre><code class=\"c\">typedef struct {\n    PyObject_VAR_HEAD\n    long ob_shash;\n    int ob_sstate;\n    char ob_sval[1];\n    /* Invariants:\n     *     ob_sval contains space for &#39;ob_size+1&#39; elements.\n     *     ob_sval[ob_size] == 0.\n     *     ob_shash is the hash of the string or -1 if not computed yet.\n     *     ob_sstate != 0 iff the string object is in stringobject.c&#39;s\n     *       &#39;interned&#39; dictionary; in this case the two references\n     *       from &#39;interned&#39; to this object are *not counted* in ob_refcnt.\n     */\n} PyStringObject;\n</code></pre>\n<p>下面是Python2中计算字符串<code>hash</code>值的函数：</p>\n<pre><code class=\"c\">static long\nstring_hash(PyStringObject *a)\n{\n    register Py_ssize_t len;\n    register unsigned char *p;\n    register long x;\n\n    if (a-&gt;ob_shash != -1)\n        return a-&gt;ob_shash;\n    len = a-&gt;ob_size;\n    p = (unsigned char *) a-&gt;ob_sval;\n    x = *p &lt;&lt; 7;\n    while (--len &gt;= 0)\n        x = (1000003*x) ^ *p++;\n    x ^= a-&gt;ob_size;\n    if (x == -1)\n        x = -2;\n    a-&gt;ob_shash = x;\n    return x;\n}\n</code></pre>\n<h2 id=\"字符串对象创建\"><a href=\"#字符串对象创建\" class=\"headerlink\" title=\"字符串对象创建\"></a>字符串对象创建</h2><p>创建字符串的最一般方法<code>PyString_FromString</code>：</p>\n<pre><code class=\"c\">[stringobject.c]\nPyObject *\nPyString_FromString(const char *str)\n{\n    register size_t size;\n    register PyStringObject *op;\n\n    assert(str != NULL);\n    /* 判断字符串长度 */\n    size = strlen(str);\n    /* 溢出 */\n    if (size &gt; PY_SSIZE_T_MAX - sizeof(PyStringObject)) {\n        PyErr_SetString(PyExc_OverflowError,\n            &quot;string is too long for a Python string&quot;);\n        return NULL;\n    }\n    /* 空字符串,且nullstring已定义 */\n    if (size == 0 &amp;&amp; (op = nullstring) != NULL) {\n#ifdef COUNT_ALLOCS\n        null_strings++;\n#endif\n        Py_INCREF(op);\n        return (PyObject *)op;\n    }\n    /* 字符缓冲池逻辑 */\n    /* 长度=1, 且characters[*str &amp; UCHAR_MAX]字符已定义 */\n    if (size == 1 &amp;&amp; (op = characters[*str &amp; UCHAR_MAX]) != NULL) {\n#ifdef COUNT_ALLOCS\n        one_strings++;\n#endif\n        Py_INCREF(op);\n        return (PyObject *)op;\n    }\n\n    /* 创建新的PyStringObject,并初始化 */\n    /* 申请内存 */\n    op = (PyStringObject *)PyObject_MALLOC(sizeof(PyStringObject) + size);\n    if (op == NULL)\n        return PyErr_NoMemory();\n    PyObject_INIT_VAR(op, &amp;PyString_Type, size);\n    op-&gt;ob_shash = -1;\n    op-&gt;ob_sstate = SSTATE_NOT_INTERNED;\n    Py_MEMCPY(op-&gt;ob_sval, str, size+1);\n    /* 共享字符串 */\n    if (size == 0) {\n        PyObject *t = (PyObject *)op;\n        PyString_InternInPlace(&amp;t);\n        op = (PyStringObject *)t;\n        nullstring = op;\n        Py_INCREF(op);\n    } else if (size == 1) {\n        PyObject *t = (PyObject *)op;\n        PyString_InternInPlace(&amp;t);\n        op = (PyStringObject *)t;\n        characters[*str &amp; UCHAR_MAX] = op;\n        Py_INCREF(op);\n    }\n    return (PyObject *) op;\n}\n</code></pre>\n<p>Python的字符串创建过程经历了以下步骤:</p>\n<ol>\n<li>检查字符串:使用了<code>PY_SSIZE_T_MAX</code>,这个值定义为<code>(size_t)-1)&gt;&gt;1</code>,而<code>size_t</code>就是<code>sys.maxsize</code>,也就是说在32位机器上字符串的最大长度为<code>(2**32-1)/2 -</code>,换算一下就是.</li>\n<li>如果是一个空字符串而且<code>nullstring</code>指针不为空,那么会直接返回<code>nullstring</code>的引用.</li>\n<li>一个字符的字符串,且缓冲池中已定义,那么直接返回.</li>\n<li>创建字符串对象: 申请内存空间,设置<code>ob_shash</code>为<code>-1</code>,标记没有经过<code>intern</code>机制,最后将<code>str</code>指向的字符数组内的字符内容拷贝到<code>ob_sval</code>维护的内存空间上.</li>\n<li>如果创建的空字符串对象,那么Python会创建一个<code>PyStirngObject</code>对象<code>nullstring</code>,并通过<code>intern</code>机制共享这个对象.</li>\n<li>如果创建的是一个字符的字符串对象,那么Python会创建一个<code>PyStirngObject</code>对象,并初始化字符缓冲池相应的位置,通过<code>intern</code>机制共享这个对象.</li>\n<li>返回对象指针</li>\n</ol>\n<p><img src=\"/images/pystringobject1.png\" alt=\"\"></p>\n<h2 id=\"intern机制\"><a href=\"#intern机制\" class=\"headerlink\" title=\"intern机制\"></a>intern机制</h2><p>在字符串的创建过程中,如果字符数组为0或者1,需要经历一个特殊的步骤<code>PyString_InternInPlace</code>,这就是<code>intern</code>机制:</p>\n<pre><code class=\"c\">[stringobject.c]\nvoid\nPyString_InternInPlace(PyObject **p)\n{\n    register PyStringObject *s = (PyStringObject *)(*p);\n    PyObject *t;\n    /* 检查s是不是字符串对象或空指针 */\n    if (s == NULL || !PyString_Check(s))\n        Py_FatalError(&quot;PyString_InternInPlace: strings only please!&quot;);\n    if (!PyString_CheckExact(s))\n        return;\n    /* 检查s是否已经interned */\n    if (PyString_CHECK_INTERNED(s))\n        return;\n    /* 若interned字典没有初始化,则初始化 */\n    if (interned == NULL) {\n        interned = PyDict_New();\n        if (interned == NULL) {\n            PyErr_Clear(); /* Don&#39;t leave an exception */\n            return;\n        }\n    }\n    /* 在interned字典中已存在, 修改引用计数, 返回 */\n    t = PyDict_GetItem(interned, (PyObject *)s);\n    if (t) {\n        Py_INCREF(t);\n        Py_DECREF(*p);\n        *p = t;\n        return;\n    }\n    /* 加入interned字典 */\n    if (PyDict_SetItem(interned, (PyObject *)s, (PyObject *)s) &lt; 0) {\n        PyErr_Clear();\n        return;\n    }\n    /* 修改引用计数 */\n    s-&gt;ob_refcnt -= 2;\n    /* 设置标志位 */\n    PyString_CHECK_INTERNED(s) = SSTATE_INTERNED_MORTAL;\n}\n</code></pre>\n<p>在<code>intern</code>过程中会进行两项检查:</p>\n<ul>\n<li>检查传入的对象是不是<code>PyStringObject</code>,也不会作用在派生类上;</li>\n<li>检查传入的对象是不是已经被<code>intern</code>机制处理过,Python不会对同一个对象<code>intern</code>两次.</li>\n</ul>\n<p>对一个<code>PyStringObject a</code>的<code>intern</code>的过程实际是:</p>\n<ul>\n<li>维护一个<code>PyDictObject</code>(相当于Python中的<code>dict</code>,如果不存在则会先创建)<code>interned</code></li>\n<li>首先检查dict中是否有这么一个对象<code>t</code>满足:<code>t</code>中维护的原生字符串和<code>s</code>相同:<ul>\n<li>如果存在,那么指向<code>s</code>的指针将指向<code>t</code>,而<code>s</code>的引用计数减一,<code>t</code>的引用计数加一;</li>\n<li>若果不存在,就将<code>s</code>记录到<code>interned</code>中.<br>  由于将<code>s</code>的指针以<code>key-value</code>添加进字典,会导致<code>s</code>的引用计数加2,然而这不应该算作有效引用,所以需要减2进行调整.<br>  并将<code>s.ob_sstate</code>域设置为<code>SSTATE_INTERNED_MORTAL</code></li>\n</ul>\n</li>\n</ul>\n<p>这是当字符串<code>Python</code>在<code>interned</code>中存在时,指针的变化:</p>\n<p><img src=\"/images/stringintern.png\" alt=\"\"> </p>\n<p>除了在字符串的创建过程中使用到了<code>intern</code>机制,另外还有其他的地方使用到了:</p>\n<pre><code class=\"c\">/* SSTATE_INTERNED_IMMORTAL表示永远不会被销毁 */\nvoid\nPyString_InternImmortal(PyObject **p)\n{\n    PyString_InternInPlace(p);\n    if (PyString_CHECK_INTERNED(*p) != SSTATE_INTERNED_IMMORTAL) {\n        PyString_CHECK_INTERNED(*p) = SSTATE_INTERNED_IMMORTAL;\n        Py_INCREF(*p);\n    }\n}\n/* SSTATE_INTERNED_MORTAL,当计数为0时会被回收 */\nPyObject *\nPyString_InternFromString(const char *cp)\n{\n    PyObject *s = PyString_FromString(cp);\n    if (s == NULL)\n        return NULL;\n    PyString_InternInPlace(&amp;s); \n    return s;\n}\n</code></pre>\n<p>现在会过头来看字符串的<code>intern</code>机制, 我们会发现直接调用<code>PyString_InternFromString</code>来构建字符串对象, 面临着一个问题那就是: <strong>需要创建一个<code>PyObjectString s</code>, 然后再去通过<code>intern</code>机制判断在<code>interned</code>字典中是否已经存在”有相同的原始字符部分”的另一个<code>PyObjectString t</code>.</strong></p>\n<p>在这个过程中, 如果存在那么一个<code>t</code>, 那<code>intern</code>机制就会减少<code>s</code>的引用计数, <code>s</code>对象就会因为引用计数为<code>0</code>而被销毁, 返回<code>t</code>.<br><br>而Python之所以先创建一个字符串对象然后销毁, 是因为<code>interned</code>是<code>PyDictObject</code>, 而字典必须以<code>PyObject*</code>指针作为键.</p>\n<p>需要注意的是, 对于那些含有空格类的字符串, Python不会使用<code>intern</code>机制.</p>\n<pre><code class=\"python\">&gt;&gt;&gt; a = &#39;hello world&#39;\n&gt;&gt;&gt; b = &#39;hello world&#39;\n&gt;&gt;&gt; a is b\nFalse\n&gt;&gt;&gt; a = &#39;helloworld&#39;\n&gt;&gt;&gt; b = &#39;helloworld&#39;\n&gt;&gt;&gt; a is b\nTrue\n</code></pre>\n<h2 id=\"字符缓冲池\"><a href=\"#字符缓冲池\" class=\"headerlink\" title=\"字符缓冲池\"></a>字符缓冲池</h2><p>出了<code>intern</code>机制外, Python对于单字符字符串对象还提供了”缓冲池”的概念: <code>static PyStringObject *characters[UCHAR_MAX + 1];</code>这是一个指针变量数组, 大小为<code>UCHAR+1</code>(这是一个平台相关变量, WIN32下是<code>255+1</code>), 在初始化时里面都所有<code>PyStringObject</code>指针为<code>NULL</code>.</p>\n<p>在创建一个字节的字符串对象时, 如果不在字符缓冲池,那么就会创建一个, 并放入对应位置:</p>\n<pre><code class=\"c\">if (size == 1) {\n    PyObject *t = (PyObject *)op;\n    PyString_InternInPlace(&amp;t); /* 与此同时, 字符也会使用intern机制 */\n    op = (PyStringObject *)t;\n    characters[*str &amp; UCHAR_MAX] = op;\n    Py_INCREF(op);\n}\n</code></pre>\n<h2 id=\"性能\"><a href=\"#性能\" class=\"headerlink\" title=\"性能\"></a>性能</h2><ul>\n<li>对于操作符<code>+</code>连接字符串对象, Python内部会创建一个新的<code>PyStringObject</code>, 然后将字符内容拷贝到新的对象上;</li>\n<li>对于连接符<code>join</code>(例如<code>list</code>上), Python会先统计一遍这些<code>PyStringObject</code>的字符串长度, 然后申请内存, 并将字符串内容拷贝到新开辟的内存空间.</li>\n</ul>\n<h2 id=\"Python3\"><a href=\"#Python3\" class=\"headerlink\" title=\"Python3\"></a>Python3</h2><p>在Python2中, 字符串对象是一个<code>char []</code>类型的数组, 即<code>ASCII</code>码中的字符使用一个字节的<code>char</code>, 而其他的字符则需要多个<code>char</code>表示.</p>\n<p>例如, 字符串<code>你好</code>, 经过终端编码(Linux编码设置<code>LANG=en_US.UTF-8</code>)成一串字节<code>e4 bd a0 e5 a5 bd 0a</code>, 所以Python接收到这串字节码, 存储在<code>char</code>数组中. 而这个时候, 我们看到的字符串长度是<code>6</code>.</p>\n<p>在Python3中, 使用宽字符的概念实现了<code>Unicode</code>字符串, 并兼容<code>ASCII</code>码(依旧占一个字节).</p>\n<p>具体实现, 先放在一旁, 以后在补吧….</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li><code>characters</code>字符缓存池以及<code>nullstring</code>;</li>\n<li><code>intern</code>机制;</li>\n<li>Python3中的<code>Unicode</code>字符串;</li>\n</ul>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码学习-整数","url":"http://shawnz.me/posts/34d7e996/","content":"<p>Python2和Python3整数的实现有很大的区别, 在这里将两者的源码进行对比学习. 我们先来看看Python2中整数的实现. </p>\n<h2 id=\"定义\"><a href=\"#定义\" class=\"headerlink\" title=\"定义\"></a>定义</h2><p>在Python2中, 整型默认是<code>int</code>类型, 当溢出的时候就会转为<code>long</code>. 如下：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; import sys\n&gt;&gt;&gt; type(sys.maxint)\n&lt;type &#39;int&#39;&gt;\n&gt;&gt;&gt; type(sys.maxint + 1)\n&lt;type &#39;long&#39;&gt;\n</code></pre>\n<a id=\"more\"></a>\n<p><code>PyIntObject</code>是一个定长对象, 它内部使用C的<code>long</code>表示数值, 这与系统的最大整数一致(32位机器上位宽32,64位机器上位宽64)：</p>\n<pre><code class=\"c\">/* include/intobject.h */\ntypedef struct {\n    PyObject_HEAD\n    long ob_ival;\n} PyIntObject;\n</code></pre>\n<pre><code class=\"c\">/*  Object/intobject.c */\nPyTypeObject PyInt_Type = {\n    PyObject_HEAD_INIT(&amp;PyType_Type)\n    0,\n    &quot;int&quot;,\n    sizeof(PyIntObject),\n    0,\n    (destructor)int_dealloc,        /* tp_dealloc */\n    (printfunc)int_print,            /* tp_print */\n    0,                    /* tp_getattr */\n    0,                    /* tp_setattr */\n    (cmpfunc)int_compare,            /* tp_compare */\n    (reprfunc)int_repr,            /* tp_repr */\n    &amp;int_as_number,                /* tp_as_number */ /* 定义作为数值对象能进行的操作集合 */\n    ...\n</code></pre>\n<h2 id=\"对象的操作\"><a href=\"#对象的操作\" class=\"headerlink\" title=\"对象的操作\"></a>对象的操作</h2><p>在整数类型对象<code>PyInt_Type</code>上定义了许多<code>PyIntObject</code>所支持的操作, 例如<code>int_dealloc</code>(对象的析构操作), <code>int_hash</code>(获取HASH值)和<code>int_as_number</code>(数值操作集合)等等. 而在<code>int_as_number</code>这个域定义了<code>PyIntObject</code>作为数值对象能够进行的所有可选操作, 这些操作包括加法、减法、乘法和模运算等. 下面是<code>PyIntObject</code>的加法<code>int_add</code>定义：</p>\n<pre><code class=\"c\">static PyObject *\nint_add(PyIntObject *v, PyIntObject *w)\n{\n    register long a, b, x;\n    CONVERT_TO_LONG(v, a);\n    CONVERT_TO_LONG(w, b);\n    x = a + b;  /* 执行C的长整形加法运算, 并将结果赋予x */\n    if ((x^a) &gt;= 0 || (x^b) &gt;= 0)  /* 检查结果是否溢出 */\n        return PyInt_FromLong(x);\n    return PyLong_Type.tp_as_number-&gt;nb_add((PyObject *)v, (PyObject *)w);\n}\n</code></pre>\n<p><code>PyIntObject</code>的加法定义很简单：从整数对象上获取<code>ob_ival</code>域, 执行C的<code>long</code>加法运算获取结果. 这里比较有意思的是在检查结果是否溢出时使用的：<code>(x^a) &gt;= 0 || (x^b) &gt;= 0</code><br><br>如果发生溢出的话, 返回的结果就是调用<code>PyLong_Type</code>的加法运算的执行结果(对应着Python中的<code>long</code>类型). </p>\n<h2 id=\"对象创建和维护\"><a href=\"#对象创建和维护\" class=\"headerlink\" title=\"对象创建和维护\"></a>对象创建和维护</h2><p>在Python的实现中, 几乎所有的內建对象都是调用C API来创建实例对象的. 对于整数对象来说有以下几种方式：</p>\n<ul>\n<li><code>PyAPI_FUNC(PyObject *) PyInt_FromString(char*, char**, int);</code></li>\n<li><code>PyAPI_FUNC(PyObject *) PyInt_FromUnicode(Py_UNICODE*, Py_ssize_t, int);</code></li>\n<li><code>PyAPI_FUNC(PyObject *) PyInt_FromLong(long);</code></li>\n</ul>\n<p>而上面两种<code>PyInt_FromString</code>和<code>PyInt_FromUnicode</code>只是进行类型转换后, 调用的<code>PyInt_FromLong</code>. <br><br><code>PyInt_FromLong</code>方法是Python整数对象创建的核心. 在讨论它的实现之前, 我们先弄清Python的整数对象体系, Python将整数对象分成了两部分：小整数对象和通用整数对象. </p>\n<h3 id=\"小整数对象\"><a href=\"#小整数对象\" class=\"headerlink\" title=\"小整数对象\"></a>小整数对象</h3><p>我们来看看Python在<code>Objects/intobject.c</code>中定义的几个和小整数对象相关的宏：</p>\n<pre><code class=\"c\">#ifndef NSMALLPOSINTS\n#define NSMALLPOSINTS        257\n#endif\n#ifndef NSMALLNEGINTS\n#define NSMALLNEGINTS        5\n#endif\n#if NSMALLNEGINTS + NSMALLPOSINTS &gt; 0\nstatic PyIntObject *small_ints[NSMALLNEGINTS + NSMALLPOSINTS];\n#endif\n#ifdef COUNT_ALLOCS\nint quick_int_allocs, quick_neg_int_allocs;\n#endif\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><code>NSMALLPOSINTS</code>和<code>NSMALLNEGINTS</code>：定义小整数对象的数值范围[-5, 257), 通过修改这两个值可以伸缩小整数范围</li>\n<li><code>small_ints</code>：这是一个指针数组(小整数对象池), 对于小整数对象Python直接将它们缓存在内存中, 并将指针存放在<code>small_ints</code>中. </li>\n<li><code>quick_int_allocs</code>和<code>quick_neg_int_allocs</code>：正小整数对象引用数和负小整数对象引用数. </li>\n</ul>\n<p><img src=\"/images/PyInt_smallints.png\" alt=\"\"></p>\n<h3 id=\"通用整数对象\"><a href=\"#通用整数对象\" class=\"headerlink\" title=\"通用整数对象\"></a>通用整数对象</h3><p>而对于其他的整数, Python的做法是申请一块内存空间, 这些内存空间供大整数轮流使用. </p>\n<pre><code class=\"c\">/* Objects/intobject.c */\n#define BLOCK_SIZE    1000    /* 1K less typical malloc overhead */\n#define BHEAD_SIZE    8    /* Enough for a 64-bit pointer */\n#define N_INTOBJECTS    ((BLOCK_SIZE - BHEAD_SIZE) / sizeof(PyIntObject))\n\nstruct _intblock {\n    struct _intblock *next;\n    PyIntObject objects[N_INTOBJECTS];\n};\n\ntypedef struct _intblock PyIntBlock;\n\nstatic PyIntBlock *block_list = NULL;\nstatic PyIntObject *free_list = NULL;\n</code></pre>\n<p>其中：</p>\n<ul>\n<li><p>Python定义了一个结构体<code>PyIntBlock</code>(大小为1000位)</p>\n<ul>\n<li>它维护着一个<code>next指针</code>：Python为这个指针预留了8位, 保证在64位机器上使用；</li>\n<li>一个<code>PyIntObject</code>数组<code>objects</code>：里面存储大整数对象, 这个数组的大小为:<code>(1000-8)/sizeof(PyIntObject)</code>. 这在32    位机器上为82, 在64位机器上为41. </li>\n</ul>\n</li>\n<li><p><code>block_list</code>：指针, 指向一个<code>PyIntBlock</code>的单项链表, 初始时指向<code>NULL</code>；</p>\n</li>\n<li><code>free_list</code>：指针, 指向一个空闲的<code>PyIntObject</code>链表的头部</li>\n</ul>\n<p><img src=\"/images/PyIntBlock.png\" alt=\"\"></p>\n<h3 id=\"对象的创建\"><a href=\"#对象的创建\" class=\"headerlink\" title=\"对象的创建\"></a>对象的创建</h3><p>Python使用<code>PyInt_FromLong</code>来创建整数对象：</p>\n<pre><code class=\"c\">PyObject *\nPyInt_FromLong(long ival)\n{\n    register PyIntObject *v;\n    /* 1.尝试使用小整数对象池 */\n#if NSMALLNEGINTS + NSMALLPOSINTS &gt; 0\n    if (-NSMALLNEGINTS &lt;= ival &amp;&amp; ival &lt; NSMALLPOSINTS) {\n        v = small_ints[ival + NSMALLNEGINTS];\n        Py_INCREF(v);\n#ifdef COUNT_ALLOCS\n        if (ival &gt;= 0)\n            quick_int_allocs++;\n        else\n            quick_neg_int_allocs++;\n#endif\n        return (PyObject *) v;\n    }\n#endif\n    /* 2.为通用整数对象池申请新的内存空间 */\n    if (free_list == NULL) {\n        if ((free_list = fill_free_list()) == NULL)\n            return NULL;  /* 申请失败*/\n    }\n    /* 3.使用通用整数对象池 */\n    v = free_list;\n    free_list = (PyIntObject *)v-&gt;ob_type;\n    PyObject_INIT(v, &amp;PyInt_Type);\n    v-&gt;ob_ival = ival;\n    return (PyObject *) v;\n}\n</code></pre>\n<p>很明显, <code>PyInt_FromLong</code>创建一个整数对象的过程分为三种情况：</p>\n<ol>\n<li>尝试使用小整数对象池：<br><br> <code>#if NSMALLNEGINTS + NSMALLPOSINTS &gt; 0</code>：Python认为小整数对象池机制被激活<br><br> <code>if (-NSMALLNEGINTS &lt;= ival &amp;&amp; ival &lt; NSMALLPOSINTS)</code>：如果参数<code>ival</code>是一个小整数, 直接从<code>small_ints</code>池中返回该小整数对象. </li>\n<li><p>空闲内存不够, 需要通用整数对象池申请新的内存空间：<br><br> 在<code>PyInt_FromLong</code>首次调用, 或者一个<code>PyIntBlock</code>块用完了的时候, Python会尝试申请一个新的<code>block</code>：</p>\n<pre><code class=\"c\"> static PyIntObject *\n fill_free_list(void)\n {\n     PyIntObject *p, *q;\n     /* 申请大小为sizeof(PyIntBlock)的内存空间p */\n     p = (PyIntObject *) PyMem_MALLOC(sizeof(PyIntBlock));\n     if (p == NULL)  /* 申请失败 */\n         return (PyIntObject *) PyErr_NoMemory();\n     /* 把p链接到已有的block_list的头部 */\n     ((PyIntBlock *)p)-&gt;next = block_list;\n     block_list = (PyIntBlock *)p;\n     /* p是block里面的objects数组的头地址*/\n     p = &amp;((PyIntBlock *)p)-&gt;objects[0];\n     /* q是block里面数组的尾地址*/\n     q = p + N_INTOBJECTS;\n     /* 刚进入循环的时候减一才使指针q需要指向数组最后一个元素的头部*/\n     /* 从最后一个元素开始, 利用ob_type这个指针指向前一个元素 */\n     /* 构建一个单向链表, 头部是数组的最后一个元素, 链表的最后一个元素的ob_type指向NULL */\n     while (--q &gt; p)\n         q-&gt;ob_type = (struct _typeobject *)(q-1);\n     q-&gt;ob_type = NULL;\n     /* 返回单向链表的第一个元素的头地址 */\n     /* 也相当于objects数组最后一个元素的头地址 */\n     return p + N_INTOBJECTS - 1; \n }\n</code></pre>\n<p> 在申请内存空间的过程中, Python会将<code>PyIntBlock</code>中的<code>PyIntObject.ob_type</code>作为指针使用(不在具备原来的用途), 将<code>PyIntBlock.objects</code>数组构建成单向链表. 在构建完成后会返回<code>free_list</code>, 从<code>free_list</code>开始, 沿着指针<code>ob_type</code>就可以获得刚刚创建的<code>PyIntBlock</code>中准备的所有空闲内存：</p>\n<p> <img src=\"/images/PyIntBlock1.png\" alt=\"\"></p>\n<p> 当一个<code>block</code>的内存用完时, <code>free_list</code>会指向<code>NULL</code>, 这个时候就会再申请一个新的<code>block</code>. 并把新加入的<code>PyIntBlock</code>链接到已有的<code>block_list</code>中去：</p>\n<p> <img src=\"/images/PyIntBlock2.png\" alt=\"\"></p>\n</li>\n<li><p>使用通用整数对象池：</p>\n<ul>\n<li>获取当前<code>free_list</code>指向的空闲内存, 并使<code>free_list</code>指向链表的下一个元素. </li>\n<li>使用获取到的空闲内存构建整数对象, 并初始化. </li>\n</ul>\n</li>\n</ol>\n<h3 id=\"对象的销毁\"><a href=\"#对象的销毁\" class=\"headerlink\" title=\"对象的销毁\"></a>对象的销毁</h3><p>当整数对象的引用为0时, 就会调用<code>PyInt_Type</code>类型对象上的<code>int_dealloc</code>：</p>\n<pre><code class=\"c\">static void\nint_dealloc(PyIntObject *v)\n{\n    /* 如果销毁的是一个整数对象, 那么就对象加入free_list单向链表表头 */\n    if (PyInt_CheckExact(v)) {\n        v-&gt;ob_type = (struct _typeobject *)free_list;\n        free_list = v;\n    }\n    else /* 如果是整数的派生类对象, 就简单地调用派生类型定义的tp_free */\n        v-&gt;ob_type-&gt;tp_free((PyObject *)v);\n}\n</code></pre>\n<p>Python在销毁一个整数对象时, 会把空间交给<code>free_list</code>, 这是为了更好地利用内存. 过程如下：</p>\n<p><img src=\"/images/int_dealloc.jpg\" alt=\"\"></p>\n<p><code>block_list</code>维护着<code>PyIntBlock</code>链表, 在源代码对<code>block_list</code>注释是：</p>\n<pre><code class=\"c\">PyIntBlocks are never returned to the\n   system before shutdown (PyInt_Fini).\n</code></pre>\n<p>对象销毁的时候, 仅仅只是将内存重新加入到<code>free_list</code>链表中, 在<code>int_dealloc</code>中永远不会向系统堆交还任何内存. <br><br><code>block_list</code>维护的<code>PyIntBlock</code>链表, 一旦被申请直至Python结束之前, 永远被不会释放. <br><br>这也是Python2中range(1000000), 虽然运行结束, 但是内存依旧占用着的原因. </p>\n<h3 id=\"小整数对象池的初始化\"><a href=\"#小整数对象池的初始化\" class=\"headerlink\" title=\"小整数对象池的初始化\"></a>小整数对象池的初始化</h3><p>在之前的<code>PyInt_FromLong</code>中首先会尝试使用小整数对象池, <code>small_ints</code>里面存放的只是指针, 那么必然有个地方需要在这之前对小整数对象池进行初始化. 那么初始化的地方就在<code>_PyInt_Init</code>中：</p>\n<pre><code class=\"c\">int\n_PyInt_Init(void)\n{\n    PyIntObject *v;\n    int ival;\n#if NSMALLNEGINTS + NSMALLPOSINTS &gt; 0\n    for (ival = -NSMALLNEGINTS; ival &lt; NSMALLPOSINTS; ival++) {\n        if (!free_list &amp;&amp; (free_list = fill_free_list()) == NULL)\n            return 0;\n        v = free_list;\n        free_list = (PyIntObject *)v-&gt;ob_type;\n        PyObject_INIT(v, &amp;PyInt_Type);\n        v-&gt;ob_ival = ival;\n        small_ints[ival + NSMALLNEGINTS] = v;\n    }\n#endif\n    return 1;\n}\n</code></pre>\n<p>从小整数对象的初始化过程可以发现, 这些小整数对象也是生存在<code>block_list</code>维护的内存上, 在<code>small_ints</code>里面保有着它们的指针. </p>\n<h2 id=\"Python3\"><a href=\"#Python3\" class=\"headerlink\" title=\"Python3\"></a>Python3</h2><p>在Python3中, 只有一种整数类型<code>int</code>, 相当于Python2中“长整形”, 它不存在溢出问题, 可以存放任意大小的数值. </p>\n<p>来看Python3源码中整数对象<code>PyLongObject</code>的定义：</p>\n<pre><code class=\"c\">/* include/longobject.h */\ntypedef struct _longobject PyLongObject; /* Revealed in longintrepr.h */\n\n/* include/longintrepr.h */\n#if PYLONG_BITS_IN_DIGIT == 30\ntypedef uint32_t digit;\ntypedef int32_t sdigit; /* signed variant of digit */\ntypedef uint64_t twodigits;\ntypedef int64_t stwodigits; /* signed variant of twodigits */\n#define PyLong_SHIFT    30\n#define _PyLong_DECIMAL_SHIFT    9 /* max(e such that 10**e fits in a digit) */\n#define _PyLong_DECIMAL_BASE    ((digit)1000000000) /* 10 ** DECIMAL_SHIFT */\n#elif PYLONG_BITS_IN_DIGIT == 15\ntypedef unsigned short digit;\ntypedef short sdigit; /* signed variant of digit */\ntypedef unsigned long twodigits;\ntypedef long stwodigits; /* signed variant of twodigits */\n#define PyLong_SHIFT    15\n#define _PyLong_DECIMAL_SHIFT    4 /* max(e such that 10**e fits in a digit) */\n#define _PyLong_DECIMAL_BASE    ((digit)10000) /* 10 ** DECIMAL_SHIFT */\n#else\n#error &quot;PYLONG_BITS_IN_DIGIT should be 15 or 30&quot;\n#endif\n#define PyLong_BASE    ((digit)1 &lt;&lt; PyLong_SHIFT)\n#define PyLong_MASK    ((digit)(PyLong_BASE - 1))\n\n#if PyLong_SHIFT % 5 != 0\n#error &quot;longobject.c requires that PyLong_SHIFT be divisible by 5&quot;\n#endif\n/* Long integer representation.\n   The absolute value of a number is equal to\n       SUM(for i=0 through abs(ob_size)-1) ob_digit[i] * 2**(SHIFT*i)\n   Negative numbers are represented with ob_size &lt; 0;\n   zero is represented by ob_size == 0.\n   In a normalized number, ob_digit[abs(ob_size)-1] (the most significant\n   digit) is never zero.  Also, in all cases, for all valid i,\n       0 &lt;= ob_digit[i] &lt;= MASK.\n   The allocation function takes care of allocating extra memory\n   so that ob_digit[0] ... ob_digit[abs(ob_size)-1] are actually available.\n\n   CAUTION:  Generic code manipulating subtypes of PyVarObject has to\n   aware that ints abuse  ob_size&#39;s sign bit.\n*/\nstruct _longobject {\n    PyObject_VAR_HEAD\n    digit ob_digit[1];\n};\n</code></pre>\n<p>在Python内部使用一个柔性数组<code>ob_digit</code>保存数值, 待存储的数值的低位信息放于低位下标, 高位信息放于高下标. </p>\n<p>在对象初始化时, 会为<code>ob_digit</code>分配空间, 并确定其长度保存在不定长头部的<code>ob_size</code>中, <code>ob_size</code>的正负表示整数对象的正负.<br>一个<code>digit</code>能保存多大的数决定于<code>PYLONG_BITS_IN_DIGIT</code>, 该值只能是15或30. </p>\n<p>源码中的注释告诉了我们几个信息:</p>\n<ul>\n<li>整数的绝对值为<code>SUM(for i=0 through abs(ob_size)-1) ob_digit[i] * 2**(SHIFT*i)</code>;</li>\n<li>整数的符号取决于ob_size的符号, 即负整数的<code>ob_size &lt; 0</code>;</li>\n<li>对于一个正常整数, <code>ob_digit[abs(ob_size)-1]</code>非<code>0</code>;</li>\n<li>在任何情况下, 对于有效的下标<code>i</code>, 有<code>0 &lt;= ob_digit[i] &lt;= MASK</code>;</li>\n</ul>\n<p>为进一步的理解对整型对象是怎么工作的, 我们对<code>long_to_decimal_string_internal</code>进行改动, 打印出一些变量的详情:</p>\n<pre><code class=\"c\">static int\nlong_to_decimal_string_internal(PyObject *aa,\n                                PyObject **p_output,\n                                _PyUnicodeWriter *writer)\n{\n    PyLongObject *scratch, *a;\n    PyObject *str;\n    Py_ssize_t size, strlen, size_a, i, j;\n    digit *pout, *pin, rem, tenpow;\n    int negative;\n    enum PyUnicode_Kind kind;\n    a = (PyLongObject *)aa;\n    printf(&quot;==== Hack Code ====\\n&quot;);\n    printf(&quot;ob_size     = %d\\n&quot;, Py_SIZE(a));\n    for (int ob_i = 0; ob_i &lt; Py_SIZE(a); ++ob_i)\n    {\n        printf(&quot;ob_digit[%d] = %d\\n&quot;, ob_i, a-&gt;ob_digit[ob_i]);\n    }\n    printf(&quot;====    End    ====\\n&quot;);\n}\n</code></pre>\n<p>输出:</p>\n<pre><code class=\"python\">&gt;&gt;&gt; 2**60+2*2**30+4\n==== Hack Code ====\nob_size     = 3\nob_digit[0] = 4\nob_digit[1] = 2\nob_digit[2] = 1\n====    End    ====\n1152921506754330628\n</code></pre>\n<p>通过这个例子可以看到<code>1152921506754330628</code>的内部表示为:</p>\n<ul>\n<li><code>ob_size</code>为<code>3</code>, 代表数组<code>ob_digit</code>大小为<code>3</code>;</li>\n<li><code>ob_digit</code>数组为<code>[4, 2, 1]</code>;</li>\n</ul>\n<p>也就是说在Python内部, 整数<code>1152921506754330628</code>表述为: $4<em>(2^{30})^0 + 2</em>(2^{30})^1 + 1*(2^{30})^2$, 这个过程实质就是十进制和<code>2**30</code>进制的转换过程.</p>\n<p>此外, Python2中的小整数对象池依旧在Python3中沿用.</p>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><ul>\n<li>小整数对象的缓冲池<code>small_ints</code>;</li>\n<li>所有的整数对象都存在于<code>PyIntBlock</code>上, 这些<code>block</code>构成一个链表<code>block_list</code>.</li>\n<li>整数对象<code>PyInt_Object</code>之间通过<code>ob_type</code>组成链表, <code>free_list</code>指向<code>block</code>内部为整数对象分配的空闲内存.</li>\n<li>Python3中变长整数对象的实现: 柔性数组. </li>\n</ul>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://www.wklken.me/posts/2014/08/06/python-source-int.html\" target=\"_blank\" rel=\"noopener\">PYTHON 源码阅读 - INT</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"http://yikun.github.io/2015/12/21/Python3%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0-%E6%95%B4%E5%9E%8B/\" target=\"_blank\" rel=\"noopener\">Python3源码学习-整型</a></p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Python源码学习-对象","url":"http://shawnz.me/posts/8c2cc9bc/","content":"<h2 id=\"Become-a-better-Pythoner\"><a href=\"#Become-a-better-Pythoner\" class=\"headerlink\" title=\"Become a better Pythoner\"></a><strong>Become a better Pythoner</strong></h2><p>最近在整理Python知识体系的时候，发现还是有许多的迷惑。</p>\n<p>于是准备从源码的角度去了解Python。参考《Python源码剖析》，这书是根据Python2写的。</p>\n<p><code>&gt;&gt;&gt;</code> Python3.6.4源码 + 『Python源码剖析』 + 几乎为零的C水平</p>\n<p>这篇博客主要分析的是Python的对象机制。</p>\n<a id=\"more\"></a>\n<h2 id=\"PyObject\"><a href=\"#PyObject\" class=\"headerlink\" title=\"PyObject\"></a>PyObject</h2><p>在Python中所有东西都是对象，而所有的对象都有一些相同的东西，这部分定义在<code>PyObject</code>中，它是整个Python对象机制的核心。</p>\n<pre><code class=\"c\">/* object.h */\ntypedef struct _object {\n    _PyObject_HEAD_EXTRA\n    Py_ssize_t ob_refcnt;\n    struct _typeobject *ob_type;\n} PyObject;\n</code></pre>\n<p><code>PyObject</code>里面很简单，只包括一个<code>_PyObject_HEAD_EXTRA</code>，和两个额外的两个成员变量：</p>\n<ul>\n<li><code>ob_refcnt</code>：维护一个引用计数的计数器。</li>\n<li><code>ob_type</code>：一个指向对象类型对象的指针。</li>\n</ul>\n<p>另外，Python使用<code>PyVarObject</code>表示 <strong>变长对象</strong> ：</p>\n<pre><code class=\"c\">/* object.h */\ntypedef struct {\n    PyObject ob_base;\n    Py_ssize_t ob_size; /* Number of items in variable part */\n} PyVarObject;\n</code></pre>\n<p>可以看到<code>PyVarObject</code>和<code>PyObject</code>相比，只增加了一个新的数据成员：</p>\n<ul>\n<li><code>ob_size</code>：表示变长对象容纳了多少个元素。</li>\n</ul>\n<p>另外<code>_PyObject_HEAD_EXTRA</code>是一个宏定义，它维护<code>next</code>和<code>prev</code>指针，用来支持双链表把堆中所有对象串起来：</p>\n<pre><code class=\"c\">#define _PyObject_HEAD_EXTRA            \\\n    struct _object *_ob_next;           \\\n    struct _object *_ob_prev;\n</code></pre>\n<p><strong>C指针指向的是对象边界，而所有对象都有相同的头部定义<code>PyObject</code>，即只需要一个泛型指针<code>PyObject*</code>就可以引用任何一个对象。</strong></p>\n<h2 id=\"类型对象\"><a href=\"#类型对象\" class=\"headerlink\" title=\"类型对象\"></a>类型对象</h2><p><code>PyObject</code>中的指针<code>*ob_type</code>指向对象的类型，在<code>object.h</code>中找到定义处：</p>\n<pre><code class=\"c\">/*  object.h */\ntypedef struct _typeobject {\n    PyObject_VAR_HEAD  /* 表示这是一个变长对象 */\n    const char *tp_name; /* For printing, in format &quot;&lt;module&gt;.&lt;name&gt;&quot; */\n    Py_ssize_t tp_basicsize, tp_itemsize; /* For allocation */\n    /* 一大堆函数指针 */\n    destructor tp_dealloc;\n    printfunc tp_print;\n    ...    \n} PyTypeObject;\n</code></pre>\n<p><code>PyTypeObject</code>中包含了许多的信息，主要分为4类：</p>\n<ul>\n<li>类型名，<code>*tp_name</code>，主要是Python内部以及调试使用；</li>\n<li>创建类型的对象需要分配的内存大小，<code>tp_basicsize</code>和<code>tp_itemsize</code>；</li>\n<li>与类型对象相关联的操作(如<code>tp_print</code>这样的函数指针)；</li>\n<li>类型信息</li>\n</ul>\n<p>一个<code>PyTypeObject</code>结构体变量就相当于Python中“类”这个概念的实现，称之为”类型对象“。例如<code>PyLong_Type</code>就是整数对象的类型对象，<code>PyList_Type</code>是列表对象的类型对象。</p>\n<p>在<code>PyTypeObject</code>头部，我们还发现了<code>PyObject_VAR_HEAD</code>，这意味着 <strong>Python中的类型也是一种对象。</strong> <br><br>既然Python对象可以通过<code>*ob_type</code>找到对象的类型，那么类型对象的<code>*ob_type</code>是什么呢？<br><br>答案是：<code>PyType_Type</code>，它相当于Python中的<code>type</code>类型：</p>\n<pre><code class=\"c\">/* Objects/typeobject.c */\nPyTypeObject PyType_Type = {\n    PyVarObject_HEAD_INIT(&amp;PyType_Type, 0)      /* 它的ob_type指向本身 */\n    &quot;type&quot;,                                     /* tp_name */\n    sizeof(PyHeapTypeObject),                   /* tp_basicsize */\n    sizeof(PyMemberDef),                        /* tp_itemsize */\n    (destructor)type_dealloc,                   /* tp_dealloc */\n    0,                                          /* tp_print */\n    ...\n};\n</code></pre>\n<p>以整数对象为例：</p>\n<ul>\n<li>整数对象的类型为<code>PyLong_Type</code>；</li>\n<li><code>PyLong_Type</code>是类型对象，其类型是<code>PyType_Type</code>；</li>\n<li><code>PyType_Type</code>也是类型对象，其类型是它本身。</li>\n</ul>\n<p>这样以来就很好地理解了 <strong>Python“类型的类型”默认是<code>type</code>，这个类称为元类(<code>metaclass</code>)，它的类型为它本身。</strong> <br><br>一个简单的例子：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; class A(object):\n...    pass\n...\n&gt;&gt;&gt; A.__class__\n&lt;type &#39;type&#39;&gt;\n&gt;&gt;&gt; A.__class__.__class__\n&lt;type &#39;type&#39;&gt;\n&gt;&gt;&gt; type.__class__\n&lt;type &#39;type&#39;&gt;\n</code></pre>\n<h2 id=\"对象的创建\"><a href=\"#对象的创建\" class=\"headerlink\" title=\"对象的创建\"></a>对象的创建</h2><p>Python的对象创建有两种方式：</p>\n<ul>\n<li><p>通过Python的C API，而这些API又分为两种：</p>\n<ul>\n<li>泛型API，AOL(Abstract Object API)。这类API都具有注入PyObject_<em>**的形式，可以应用到任何Python对象上。例如：<br><br>  `PyObject</em> intobj = PyObject_New(PyObject，&amp;PyLong_Type)`</li>\n<li>类型相关的API，COL(Co Object API)。Python为内建对象提供这样一组的API。例如：<br><br>  <code>PyObject* intobj = PyLong_FromLong(10)</code></li>\n</ul>\n</li>\n<li>使用类型对象创建。</li>\n</ul>\n<p>在Python中，<code>int(10)</code>来创建一个<code>int</code>对象，实际是因为Python完成环境初始化后，符号<code>int</code>对应着內建类型对象<code>PyLong_Type</code>，所以我们可以使用它创建对象。例如：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; int_type = __builtins__.dict[&#39;int&#39;]\n&gt;&gt;&gt; a = int_type(10)  # 获取內建的int类型对象来创建一个int对象\n&gt;&gt;&gt; a\n10\n</code></pre>\n<p>那么<code>PyLong_Type</code>又是怎么创建<code>int</code>对象的呢？</p>\n<p>我们知道对象创建需要经历<code>__new__</code>和<code>__init__</code>方法的调用。在结构体类型<code>PyTypeObject</code>中定义了许多的函数指针，这些指针可以视为类型对象中所定义的操作。其中两个特殊的函数指针：<code>newfunc tp_new;</code>和<code>initproc tp_init;</code>与Python中的<code>__new__</code>和<code>__init__</code>相对应。</p>\n<h2 id=\"多态性\"><a href=\"#多态性\" class=\"headerlink\" title=\"多态性\"></a>多态性</h2><p>在Python中创建一个对象时，会分配内存，进行初始化。然后在Python内部会用一个<code>PyObject*</code>变量来保存和维护指针，这个对象是什么类型需要通过<code>ob_type</code>进行解析得到，正是这个域实现了Python的多态机制。例如，一个<code>Print</code>函数：</p>\n<pre><code class=\"c\">void Print(PyObject* object) {\n    object-&gt;ob_type-&gt;tp_print(object)\n}\n</code></pre>\n<p>如果传给<code>Print</code>的指针<code>PyObject</code> 是<code>PyLongObject</code>对象，那么就会调用<code>PyLong_Type</code>中定义的<code>tp_print</code>；<br><br>如果传给<code>Print</code>的指针<code>PyObject</code> 是<code>PyStringObject</code>对象，那么就会调用<code>PyString_Type</code>中定义的<code>tp_print</code>；<br></p>\n<h2 id=\"引用计数\"><a href=\"#引用计数\" class=\"headerlink\" title=\"引用计数\"></a>引用计数</h2><p>Python的垃圾收集机制是通过引用计数实现的。</p>\n<p>在所有对象的头部都维护着一个变量<code>ob_refcnt</code>作为引用计数器。</p>\n<ul>\n<li>Pyhton初始化对象的时候使用<code>_Py_NewReference</code>设置<code>ob_refcnt</code>为<code>1</code></li>\n<li><code>Py_INCREF(ob)</code>和<code>Py_DECREF(ob)</code>两个宏函数可以增加和减少一个对象的引用。</li>\n<li>当引用计数器减少到0后，<code>Py_DECREF</code>会调用对象的类型对象上定义的<code>tp_dealloc</code>(相当于C++中的析构函数)。</li>\n</ul>\n<p>有一点需要注意的是，调用析构不意味着调用<code>free</code>释放内存，Python会使用内存池技术避免频繁申请和释放内存空间。</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/downloads/release/python-364/\" target=\"_blank\" rel=\"noopener\">Python3.6.4源码</a><br><br><code>&gt;&gt;&gt;</code> <a href=\"\">Python源码剖析</a></p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"百度脑图","url":"http://shawnz.me/posts/cc9966a1/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"节点操作\"><a href=\"#节点操作\" class=\"headerlink\" title=\"节点操作\"></a>节点操作</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>指令解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Enter</td>\n<td>插入兄弟节点</td>\n</tr>\n<tr>\n<td>Tab,Insert</td>\n<td>插入子节点</td>\n</tr>\n<tr>\n<td>Shift+Tab</td>\n<td>插入父节点</td>\n</tr>\n<tr>\n<td>Delete</td>\n<td>删除节点</td>\n</tr>\n<tr>\n<td>Up,Down,Left,Right</td>\n<td>节点导航</td>\n</tr>\n<tr>\n<td>Alt+Up,Down</td>\n<td>向上/向下调整顺序</td>\n</tr>\n<tr>\n<td>/</td>\n<td>展开/收起节点</td>\n</tr>\n<tr>\n<td>F2</td>\n<td>编辑节点</td>\n</tr>\n<tr>\n<td>Shift+Enter</td>\n<td>文本换行</td>\n</tr>\n<tr>\n<td>Ctrl+A</td>\n<td>全选节点</td>\n</tr>\n<tr>\n<td>Ctrl+C</td>\n<td>复制节点</td>\n</tr>\n<tr>\n<td>Ctrl+X</td>\n<td>剪切节点</td>\n</tr>\n<tr>\n<td>Ctrl+V</td>\n<td>粘贴节点</td>\n</tr>\n<tr>\n<td>Ctrl+B</td>\n<td>加粗</td>\n</tr>\n<tr>\n<td>Ctrl+I</td>\n<td>斜体</td>\n</tr>\n<tr>\n<td>Ctrl+F</td>\n<td>查找节点</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"视野控制\"><a href=\"#视野控制\" class=\"headerlink\" title=\"视野控制\"></a>视野控制</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>指令解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Alt+拖动,右键移动</td>\n<td>拖动视野</td>\n</tr>\n<tr>\n<td>滚轮,触摸板</td>\n<td>视野移动</td>\n</tr>\n<tr>\n<td>空白处双击,Ctrl+Enter</td>\n<td>居中根节点</td>\n</tr>\n<tr>\n<td>Ctrl + ‘+’,’-‘</td>\n<td>放大,缩小视野</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"布局\"><a href=\"#布局\" class=\"headerlink\" title=\"布局\"></a>布局</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>指令解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+Shift+L</td>\n<td>整理布局</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"后悔药\"><a href=\"#后悔药\" class=\"headerlink\" title=\"后悔药\"></a>后悔药</h2><table>\n<thead>\n<tr>\n<th>快捷键</th>\n<th>指令解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Ctrl+Z</td>\n<td>撤销</td>\n</tr>\n<tr>\n<td>Ctrl+Y</td>\n<td>重做</td>\n</tr>\n</tbody>\n</table>\n","categories":["工具"],"tags":["工具","快捷键"]},{"title":"Django源码阅读:整体流程","url":"http://shawnz.me/posts/1470b96d/","content":"<h2 id=\"服务器启动\"><a href=\"#服务器启动\" class=\"headerlink\" title=\"服务器启动\"></a>服务器启动</h2><p>在上一节中，我们知道了<code>runserver</code>命令的实现在<code>django.core.management.commands</code>下，这里面的<code>Command</code>类重写了<code>handle()</code>方法：<br><a id=\"more\"></a></p>\n<pre><code class=\"python\">def handle(self, *args, **options):\n    from django.conf import settings\n\n    if not settings.DEBUG and not settings.ALLOWED_HOSTS:\n        raise CommandError(&#39;You must set settings.ALLOWED_HOSTS if DEBUG is False.&#39;)\n\n    self.use_ipv6 = options[&#39;use_ipv6&#39;]\n    if self.use_ipv6 and not socket.has_ipv6:\n        raise CommandError(&#39;Your Python does not support IPv6.&#39;)\n    self._raw_ipv6 = False\n    if not options[&#39;addrport&#39;]:\n        self.addr = &#39;&#39;\n        self.port = self.default_port\n    else:\n        m = re.match(naiveip_re, options[&#39;addrport&#39;])\n        if m is None:\n            raise CommandError(&#39;&quot;%s&quot; is not a valid port number &#39;\n                                &#39;or address:port pair.&#39; % options[&#39;addrport&#39;])\n        self.addr, _ipv4, _ipv6, _fqdn, self.port = m.groups()\n        if not self.port.isdigit():\n            raise CommandError(&quot;%r is not a valid port number.&quot; % self.port)\n        if self.addr:\n            if _ipv6:\n                self.addr = self.addr[1:-1]\n                self.use_ipv6 = True\n                self._raw_ipv6 = True\n            elif self.use_ipv6 and not _fqdn:\n                raise CommandError(&#39;&quot;%s&quot; is not a valid IPv6 address.&#39; % self.addr)\n    if not self.addr:\n        self.addr = self.default_addr_ipv6 if self.use_ipv6 else self.default_addr\n        self._raw_ipv6 = self.use_ipv6\n    self.run(**options)\n</code></pre>\n<p>这里面很简单，获取一些参数和配置信息直接调用<code>self.run(**options)</code>方法，<code>run()</code>方法也十分简洁，除了调用<code>inner_run()</code>之外，还检查配置判断是否启用<code>auto reload</code>机制。这一点可<code>werkzeug</code>相似，都是单独开一个线程检查代码修改。在<code>inner_run()</code>里：</p>\n<pre><code class=\"python\">def inner_run(self, *args, **options):\n    # 省略掉了部分代码\n    try:\n        handler = self.get_handler(*args, **options)\n        run(self.addr, int(self.port), handler,\n            ipv6=self.use_ipv6, threading=threading, server_cls=self.server_cls)\n    except socket.error as e:\n        # 省略掉部分异常打印\n        # Need to use an OS exit because sys.exit doesn&#39;t work in a thread\n        os._exit(1)\n    except KeyboardInterrupt:\n        if shutdown_message:\n            self.stdout.write(shutdown_message)\n        sys.exit(0)\n\ndef get_handler(self, *args, **options):\n    &quot;&quot;&quot;Return the default WSGI handler for the runner.&quot;&quot;&quot;\n    return get_internal_wsgi_application()\n</code></pre>\n<p>首先<code>inner_run</code>尝试获取一个<code>handler</code>，通过查看内部的实现，发现在里层是通过<code>django.core.server.basehttp</code>模块的<code>get_wsgi_application</code>返回一个<code>WSGIHandler</code>实例。这一步工作和我们在<code>settings</code>文件配置<code>wsgi</code>模块路径，调用<code>get_wsgi_application</code>创建WSGI应用程序<code>app</code>效果是一样的。</p>\n<p>我们先跳过<code>WSGIRequest</code>来看<code>run</code>是怎么启动应用服务器的。</p>\n<pre><code class=\"python\">def run(addr, port, wsgi_handler, ipv6=False, threading=False, server_cls=WSGIServer):\n    server_address = (addr, port)\n    if threading:\n        httpd_cls = type(&#39;WSGIServer&#39;, (socketserver.ThreadingMixIn, server_cls), {})\n    else:\n        httpd_cls = server_cls\n    httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6)\n    if threading:\n        httpd.daemon_threads = True\n    # 启动WSGI服务器，并设置app\n    httpd.set_app(wsgi_handler)\n    httpd.serve_forever()\n</code></pre>\n<p><code>run()</code>方法有几个参数：</p>\n<ul>\n<li><code>addr</code>和<code>port</code>：服务器启动监听的地址和端口</li>\n<li><code>wsgi_handler</code>：应用程序，处理请求</li>\n<li><code>ipv6</code>和<code>threading</code>：是否使用ipv6和是否使用多线程处理请求</li>\n<li><code>server_cls</code>：服务器类，这个类的基类是<code>http.server.HTTPServer</code></li>\n</ul>\n<p>用<code>http_cls</code>创建了服务器<code>httpd</code>后，调用<code>serve_forever</code>一直运行，等待请求的带来。当请求到来的时候，会调用<code>wsgi_handler</code>也就是我们的<code>app</code>处理请求。具体<code>http.server</code>底层是怎么实现的，这里就不做深入了。</p>\n<p>到目前为止，Django服务器已经运行起来了。。。</p>\n<h2 id=\"一个新的请求\"><a href=\"#一个新的请求\" class=\"headerlink\" title=\"一个新的请求\"></a>一个新的请求</h2><p>现在，假设一条新的请求进来了，Django是怎么从请求地址解析到正确的处理函数的呢？</p>\n<p>我们来看看Django是怎么接收请求并生成响应的。</p>\n<p>来到<code>django.core.handlers.wsgi</code>模块的<code>WSGIHandler</code>，这里是服务器调用我们应用程序的入口：</p>\n<pre><code class=\"python\">class WSGIHandler(base.BaseHandler):\n    # 请求类\n    request_class = WSGIRequest\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # 加载中间件\n        self.load_middleware()\n\n    def __call__(self, environ, start_response):\n        set_script_prefix(get_script_name(environ))\n        signals.request_started.send(sender=self.__class__, environ=environ)\n        # 构建WSGIRequest对象\n        request = self.request_class(environ)\n        # 生成响应\n        response = self.get_response(request)\n\n        response._handler_class = self.__class__\n\n        status = &#39;%d %s&#39; % (response.status_code, response.reason_phrase)\n        response_headers = list(response.items())\n        for c in response.cookies.values():\n            response_headers.append((&#39;Set-Cookie&#39;, c.output(header=&#39;&#39;)))\n        # 发送状态码和响应头\n        start_response(status, response_headers)\n        # 生成响应\n        return response\n</code></pre>\n<p>可以看到这个类是一个可调用对象，调用参数为<code>environ</code>和<code>start_response</code>，显然这是一个标准的WSGI应用程序。</p>\n<p>在它的<code>__init__()</code>方法中有个<code>load_middleware()</code>方法，它继承自<code>django.core.handlers.base.BaseHandler</code>：</p>\n<pre><code class=\"python\">class BaseHandler:\n    def load_middleware(self):\n        # 省略掉了异常处理部分\n        self._request_middleware = []\n        self._view_middleware = []\n        self._template_response_middleware = []\n        self._response_middleware = []\n        self._exception_middleware = []\n        # _get_response进行请求处理，先包装一层处于“洋葱”结构最里层\n        handler = convert_exception_to_response(self._get_response)\n        # 这里使用reversed：settings中最低层定义的中间件处于“洋葱”结构的里层\n        # 即请求阶段从外至里，中间件从顶至下，响应阶段从里到外，中间件从下至上\n        for middleware_path in reversed(settings.MIDDLEWARE):\n            middleware = import_string(middleware_path)\n            # 中间件对于请求和响应的处理在调用它的时候\n            mw_instance = middleware(handler)\n\n            # 而这几个钩子函数是添加到相应队列，在其他地方调用\n            if hasattr(mw_instance, &#39;process_view&#39;):\n                self._view_middleware.insert(0, mw_instance.process_view)\n            if hasattr(mw_instance, &#39;process_template_response&#39;):\n                self._template_response_middleware.append(mw_instance.process_template_response)\n            if hasattr(mw_instance, &#39;process_exception&#39;):\n                self._exception_middleware.append(mw_instance.process_exception)\n\n            handler = convert_exception_to_response(mw_instance)\n\n        self._middleware_chain = handler\n</code></pre>\n<p><code>convert_exception_to_response</code>是一个装饰器，它以“洋葱”的结构将<code>WSGIHandler</code>处理请求和中间件一层一层的包裹起来，并对里层的异常进行了捕获和转换。</p>\n<p>中间件需要遵循一定的协议，必须具有指定的方法：</p>\n<ul>\n<li><code>process_view</code>：视图中间件</li>\n<li><code>process_template_response</code>：模板中间件</li>\n<li><code>process_exception</code>：异常中间件</li>\n<li><code>__init__(get_response)</code>：接受一个参数的初始化方法</li>\n<li><code>__call__(request)</code>：可调用对象，接收请求对象</li>\n</ul>\n<p>中间件的加载工作发生在应用启动的时候，只会发生一次。</p>\n<p>继续回到<code>WSGIHandler.__call__(environ, start_response)</code>中。首先Django会通过<code>environ</code>构建<code>WSGIRequest</code>对象<code>request</code>，其中包含了从请求中解析出来的各种信息。</p>\n<p>请求对象有了，接下来就是怎么生成响应了，<code>get_response()</code>继承自<code>BaseHandler</code>：</p>\n<pre><code class=\"python\">def get_response(self, request):\n    # 设置URL解析器\n    set_urlconf(settings.ROOT_URLCONF)\n    response = self._middleware_chain(request)\n    response._closable_objects.append(request)\n    # If the exception handler returns a TemplateResponse that has not\n    # been rendered, force it to be rendered.\n    if not getattr(response, &#39;is_rendered&#39;, True) and callable(getattr(response, &#39;render&#39;, None)):\n        response = response.render()\n    return response\n</code></pre>\n<p>可以看到生成响应的第一步，就是设置URL解析器，关于URL路由部分，我们先跳过。</p>\n<p>在配置好URL解析器号，Django以中间件链的形式传入<code>request</code>对象，生成响应。在刚刚中间件介绍的时候，我们知道中间件链的最里层是<code>_get_response</code>，这个方法也是继承自<code>BaseHandler</code>：</p>\n<pre><code class=\"python\">def _get_response(self, request):\n    response = None\n    # 这一部分是有关于路由的，先不管\n    if hasattr(request, &#39;urlconf&#39;):\n        urlconf = request.urlconf\n        set_urlconf(urlconf)\n        resolver = get_resolver(urlconf)\n    else:\n        resolver = get_resolver()\n\n    resolver_match = resolver.resolve(request.path_info)\n    # 可以先简单的认为，callback为视图函数，后面两个为函数参数\n    callback, callback_args, callback_kwargs = resolver_match\n    request.resolver_match = resolver_match\n\n    # 应用视图中间件\n    for middleware_method in self._view_middleware:\n        response = middleware_method(request, callback, callback_args, callback_kwargs)\n        if response:\n            break\n    if response is None:\n        wrapped_callback = self.make_view_atomic(callback)\n        try:\n            response = wrapped_callback(request, *callback_args, **callback_kwargs)\n        except Exception as e:\n            response = self.process_exception_by_middleware(e, request)\n    if response is None:\n        # 省略对于没有返回响应的异常处理\n        ...\n    # 应用模板中间件\n    elif hasattr(response, &#39;render&#39;) and callable(response.render):\n        for middleware_method in self._template_response_middleware:\n            response = middleware_method(request, response)\n            if response is None:\n                # 省略对于没有返回响应的异常处理\n                ...\n        try:\n            response = response.render()\n        except Exception as e:\n            response = self.process_exception_by_middleware(e, request)\n\n    return response\n</code></pre>\n<p>抛除URL路由，从请求到响应的流程大致就先分析到这里了。</p>\n<h2 id=\"URL路由\"><a href=\"#URL路由\" class=\"headerlink\" title=\"URL路由\"></a>URL路由</h2><p>在学习Django URL路由之前，先回顾一下Flask的URL路由。</p>\n<p>Flask的URL路由是基于<code>werkzeug</code>的<code>Rule</code>和<code>Map</code>的。使用装饰器，在应用启动的添加<code>Rule</code>到<code>Map</code>中并对URL规则进行预编译，以加快后面的匹配速度。</p>\n<p>当请求来到时，Flask把<code>Map</code>和请求路径信息进行绑定生成一个<code>MapAdapter</code>实例，使用它可以进行路由匹配。<code>werkzeug</code>负责匹配的是URL地址和<code>endpoint</code>，至于<code>endpoit</code>和<code>view_func</code>是通过一个<code>view_funcs</code>字典映射的。这样Flask就找到合适的视图处理函数。</p>\n<p>相比较于Flask这种松散式的路由，Django提倡的是集中式的配置管理。</p>\n<p>在<code>&lt;project&gt;/settings.py</code>文件中，有这么一个配置项：<code>ROOT_URLCONF = &#39;mysite.urls&#39;</code>。</p>\n<p>Djanog URL源码主要有两个重要模块：</p>\n<ul>\n<li><code>django.urls.conf</code>：包括<code>path()</code>, <code>include()</code>, <code>re_path()</code>三个主要方法，用于创建url相关类的实例。</li>\n<li><code>django.urls.urlresolvers</code>：包括Django URL的所有类结构<code>URLPattern</code>, <code>URLResolver</code>, <code>ResolverMatch</code>以及url匹配逻辑。</li>\n</ul>\n<p>在继续学习之前，先弄懂Django URL路由的几个概念：</p>\n<ul>\n<li>URL模式（URL Pattern）：一条最基本的URL配置规则。</li>\n<li>URL分解器（URL Resolve）：包含多条URLPattern或嵌套包含其他URLResolver。</li>\n<li>匹配结果（Resolver Match）：由处理函数、可选的参数和可选的位置参数组成。</li>\n</ul>\n<p>首先来看怎么在Django项目中配置url：</p>\n<pre><code class=\"python\"># Examples:\n# Function views\n#     1. Add an import:  from my_app import views\n#     2. Add a URL to urlpatterns:  path(&#39;&#39;, views.home, name=&#39;home&#39;)\n# Class-based views\n#     1. Add an import:  from other_app.views import Home\n#     2. Add a URL to urlpatterns:  path(&#39;&#39;, Home.as_view(), name=&#39;home&#39;)\n# Including another URLconf\n#     1. Import the include() function: from django.urls import include, path\n#     2. Add a URL to urlpatterns:  path(&#39;blog/&#39;, include(&#39;blog.urls&#39;))\nfrom django.contrib import admin\nfrom django.urls import path\n\nurlpatterns = [\n    path(&#39;admin/&#39;, admin.site.urls),\n]\n\n</code></pre>\n<p>在Django 2.0中使用<code>path</code>配置一条URL规则，它和<code>url</code>的区别是它不支持正则的命名元组：</p>\n<pre><code class=\"python\">def url(regex, view, kwargs=None, name=None):\n    return re_path(regex, view, kwargs, name)\n\nre_path = partial(_path, Pattern=RegexPattern)\npath = partial(_path, Pattern=RoutePattern)\n</code></pre>\n<p><code>_path</code>函数接收几个参数：<code>route</code>(路由路径)，<code>view</code>(处理视图或列表)，<code>kwargs</code>(可选的函数默认参数)，<code>name</code>(可选的端点名称)以及<code>Pattern</code>(使用那种匹配模式)：</p>\n<pre><code class=\"python\">def _path(route, view, kwargs=None, name=None, Pattern=None):\n    if isinstance(view, (list, tuple)):\n        # For include(...) processing.\n        pattern = Pattern(route, is_endpoint=False)\n        urlconf_module, app_name, namespace = view\n        return URLResolver(\n            pattern,\n            urlconf_module,\n            kwargs,  # 默认参数可以传递进去\n            app_name=app_name,\n            namespace=namespace,\n        )\n    elif callable(view):\n        pattern = Pattern(route, name=name, is_endpoint=True)\n        return URLPattern(pattern, view, kwargs, name)\n    else:\n        raise TypeError(&#39;view must be a callable or a list/tuple in the case of include().&#39;)\n</code></pre>\n<p>接下来是根据<code>view</code>参数的对象类型来调用不同的对象进行解析：</p>\n<ul>\n<li><p><code>list/tuple</code>：如果是这两种类型之一，会创建<code>URLResolver</code>。Django在这里的实现十分的灵活：<br><br>  可以使用<code>path(&#39;admin/&#39;, admin.site.urls)</code>，<code>admin.site</code>指向<code>django.contrib.sites.AdminSite</code>：</p>\n<pre><code class=\"python\">  class AdminSite:\n      @property\n      def urls(self):\n          return self.get_urls(), &#39;admin&#39;, self.name\n\n      def get_urls(self):\n          urlpatterns = [\n              path\n              ...\n          ]\n          return urlpatterns\n</code></pre>\n<p>  也可以使用<code>path(&#39;admin/&#39;, include(&#39;blog.urls&#39;))</code>，甚至是<code>include(extra_patterns)</code>(其中<code>extra_patterns</code>是一个<code>path</code>列表)。<br><br>  这是因为在<code>include</code>中，如果传入的是字符串，它会尝试导入模块并找到<code>urlpatterns</code>，否则会尝试直接从<code>urlconf_module</code>上获取属性<code>urlpatterns</code>且默认值为<code>urlconf_module</code>本身，最后会返回一个三元组：</p>\n<pre><code class=\"python\">  def include(arg, namespace=None):\n      app_name = None\n      if isinstance(arg, tuple):\n          try:\n              urlconf_module, app_name = arg\n          except ValueError:\n              # 省略异常处理\n      else:\n          urlconf_module = arg\n\n      if isinstance(urlconf_module, str):\n          urlconf_module = import_module(urlconf_module)\n      patterns = getattr(urlconf_module, &#39;urlpatterns&#39;, urlconf_module)\n      app_name = getattr(urlconf_module, &#39;app_name&#39;, app_name)\n      if namespace and not app_name:\n          # 省略异常处理\n      namespace = namespace or app_name\n      # 省略部分patterns检查\n      return (urlconf_module, app_name, namespace)\n</code></pre>\n<p>  如此以来<code>include</code>会一致的返回一个三元组，在判断参数<code>view</code>为<code>list/tuple</code>类型时，进行一次拆包，就构建一个<code>URLResolver</code>实例。</p>\n</li>\n<li><code>callable</code>：如果参数<code>view</code>是一个可调用对象，那么Django会直接构建<code>URLPattern</code>。</li>\n</ul>\n<p>现在我们知道了<code>urlpatterns</code>里面只能是<code>path</code>或者<code>re_path</code>的产物。并且<code>settings</code>配置文件里有个选项<code>ROOT_UTLCONF</code>，它指向我们的<code>urlpatterns</code>所在的模块路径。</p>\n<p>回到<code>BaseHandler</code>中，来看看在请求到来时，Django是怎么使用这个配置选项做路由的。</p>\n<pre><code class=\"python\">class BaseHandler:\n    def get_response(self, request):\n        # 设置URL解析器\n        set_urlconf(settings.ROOT_URLCONF)\n        ...\n        response = self._middleware_chain(request)\n        ...\n\n    def _get_response(self, request):\n        response = None\n        if hasattr(request, &#39;urlconf&#39;):\n            # 用户自定义url解析器\n            urlconf = request.urlconf\n            set_urlconf(urlconf)\n            resolver = get_resolver(urlconf)\n        else:\n            resolver = get_resolver()\n        # 调用解析器匹配地址\n        resolver_match = resolver.resolve(request.path_info)\n        # 返回callback为视图函数，后面两个为函数参数\n        callback, callback_args, callback_kwargs = resolver_match\n        request.resolver_match = resolver_match\n        ...\n\n# in djanog.urls.base.py\n# Overridden URLconfs for each thread are stored here.\nfrom threading import local\n_urlconfs = local()\ndef set_urlconf(urlconf_name):\n    if urlconf_name:\n        _urlconfs.value = urlconf_name\n    else:\n        if hasattr(_urlconfs, &quot;value&quot;):\n            del _urlconfs.value\n\n# in django.urls.resolvers.py\n@functools.lru_cache(maxsize=None)\ndef get_resolver(urlconf=None):\n    if urlconf is None:\n        from django.conf import settings\n        urlconf = settings.ROOT_URLCONF\n    return URLResolver(RegexPattern(r&#39;^/&#39;), urlconf)\n</code></pre>\n<p>在请求刚进入<code>get_response</code>的时候，Django就设置本地线程变量<code>_urlconfs</code>值为<code>settings.ROOT_URLCONF</code>，这个值在其他的地方也有用到。</p>\n<p><code>get_resolver()</code>获取到URL解析器后，接下来的工作就是调<code>resolver.resolver(request.path_info)</code>找到匹配的URL处理函数。</p>\n<p>所以直接来到<code>URLResolver</code>的<code>resolver()</code>方法：</p>\n<pre><code class=\"python\"> def resolve(self, path):\n    path = str(path)  # path may be a reverse_lazy object\n    tried = []\n    match = self.pattern.match(path)\n    if match:\n        new_path, args, kwargs = match\n        for pattern in self.url_patterns:\n            try:\n                sub_match = pattern.resolve(new_path)\n            except Resolver404 as e:\n                sub_tried = e.args[0].get(&#39;tried&#39;)\n                if sub_tried is not None:\n                    tried.extend([pattern] + t for t in sub_tried)\n                else:\n                    tried.append([pattern])\n            else:\n                if sub_match:\n                    sub_match_dict = dict(kwargs, **self.default_kwargs)\n                    # Update the sub_match_dict with the kwargs from the sub_match.\n                    sub_match_dict.update(sub_match.kwargs)\n                    # If there are *any* named groups, ignore all non-named groups.\n                    # Otherwise, pass all non-named arguments as positional arguments.\n                    sub_match_args = sub_match.args\n                    if not sub_match_dict:\n                        sub_match_args = args + sub_match.args\n                    return ResolverMatch(\n                        sub_match.func,\n                        sub_match_args,\n                        sub_match_dict,\n                        sub_match.url_name,\n                        [self.app_name] + sub_match.app_names,\n                        [self.namespace] + sub_match.namespaces,\n                    )\n                tried.append([pattern])\n        raise Resolver404({&#39;tried&#39;: tried, &#39;path&#39;: new_path})\n    raise Resolver404({&#39;path&#39;: path})\n</code></pre>\n<p><code>URLResolver</code>的整个匹配流程的核心代码是嵌套其他<code>URLResolver.resolve()</code>或者<code>URLPattern.resolve()</code>。</p>\n<p><code>URLPattern.resolve()</code>逻辑比较简单，根据传入的<code>path</code>匹配，匹配成功就返回相应的callback。而<code>URLResolver</code>也会匹配path，但会返回<code>urlconf_module</code>子模块的匹配结果，递归流程，直到找到叶子模块<code>URLPattern</code>，然后将匹配结果层层返回。</p>\n<p>而匹配结果是<code>ResolverMatch</code>的实例，由于它重写了魔法方法<code>__getitem__(self, index)</code>，所以可以进行拆包得到<code>callback</code>，<code>args</code>和<code>kwargs</code>。</p>\n<pre><code class=\"python\">class ResolverMatch(object):\n    def __getitem__(self, index):\n        return (self.func, self.args, self.kwargs)[index]\n</code></pre>\n","categories":["Python"],"tags":["Python","Django","源码"]},{"title":"Django源码阅读:命令行工具集","url":"http://shawnz.me/posts/372ad3fc/","content":"<h2 id=\"创建一个项目\"><a href=\"#创建一个项目\" class=\"headerlink\" title=\"创建一个项目\"></a>创建一个项目</h2><p><code>Django</code> 使用<code>django-admin startproject [projectname]</code>创建项目，并会在项目根目录下生成<code>manage.py</code>文件。从现在开始，我们有了两个<code>Django</code>命令行入口：<br><a id=\"more\"></a></p>\n<pre><code class=\"bash\">$ django-admin &lt;command&gt; [options]\n$ ./manage.py &lt;command&gt; [options]\n</code></pre>\n<h2 id=\"django-admin和manage-py\"><a href=\"#django-admin和manage-py\" class=\"headerlink\" title=\"django-admin和manage.py\"></a>django-admin和manage.py</h2><p><code>django-admin.py</code>源码：</p>\n<pre><code class=\"python\">#!/usr/bin/env python\nfrom django.core import management\n\nif __name__ == &quot;__main__&quot;:\n    management.execute_from_command_line()\n</code></pre>\n<p><code>manage.py</code>源码</p>\n<pre><code class=\"python\">#!/usr/bin/env python\nimport os\nimport sys\n\nif __name__ == &quot;__main__&quot;:\n    os.environ.setdefault(&quot;DJANGO_SETTINGS_MODULE&quot;, &quot;djangodemo.settings&quot;)\n    try:\n        from django.core.management import execute_from_command_line\n    except ImportError as exc:\n        raise ImportError() from exc\n    execute_from_command_line(sys.argv)\n</code></pre>\n<p>两者的相同之处是：底层都使用<code>execute_from_command_line</code>方法执行命令。</p>\n<p>不同的之处是：<code>manage.py</code>设置了<code>DJANGO_SETTINGS_MODULE</code>这个环境变量为当期项目的配置文件(它告诉<code>Django</code>到哪找到配置文件)。</p>\n<p>这两种形式本质上一样的。如果环境变量<code>DJANGO_SETTINGS_MODULE</code>已经配置好了，我们也可以使用<code>django-admin</code>达到和<code>manage.py</code>相同的效果(前提是设置模块处于Python的<code>导入查找路径</code>中)：</p>\n<pre><code class=\"bash\">$ export DJANGO_SETTINGS_MODULE=djangodemo.settings\n$ django-admin runserver\n</code></pre>\n<h2 id=\"Django-Management\"><a href=\"#Django-Management\" class=\"headerlink\" title=\"Django Management\"></a>Django Management</h2><p><code>execute_from_command_line()</code>方法在内部调用了<code>django.core.management.ManagementUtility</code>的入口方法<code>excute()</code>：</p>\n<pre><code class=\"python\">def execute_from_command_line(argv=None):\n    &quot;&quot;&quot;Run a ManagementUtility.&quot;&quot;&quot;\n    utility = ManagementUtility(argv)\n    utility.execute()\n</code></pre>\n<p><code>ManagementUtility</code>是Django的命令行工具集的入口，读取命令行参数，解析出应该执行那个子命令，并创建合适的解析器来执行命令：</p>\n<pre><code class=\"python\"> def execute(self):\n    try:\n        subcommand = self.argv[1]  # 获取子命令名称\n    except IndexError:\n        subcommand = &#39;help&#39;  # 如果没有提供，默认help命令\n\n    # CommandParser继承自ArgumentParser，一个内置的命令行解析工具\n    # 在这里主要进行预处理选项配置\n    # 我们可以直接从命令行设置settings和pythonpath\n    # 这写参数会影响到可用命令，需要尽早处理\n    parser = CommandParser(None, usage=&quot;%(prog)s subcommand [options] [args]&quot;, add_help=False)\n    parser.add_argument(&#39;--settings&#39;)\n    parser.add_argument(&#39;--pythonpath&#39;)\n    parser.add_argument(&#39;args&#39;, nargs=&#39;*&#39;)  # catch-all\n    try:\n        options, args = parser.parse_known_args(self.argv[2:])\n        handle_default_options(options)\n    except CommandError:\n        pass  # Ignore any option errors at this point.\n    # 这里setting是django.conf.LazySettings的一个实例\n    # 如果尝试获取`INSTALLED_APPS`，而没有找到配置文件会抛出异常\n    try:\n        settings.INSTALLED_APPS\n    except ImproperlyConfigured as exc:\n        self.settings_exception = exc\n\n    if settings.configured:\n        # 这里会尝试启动服务器，无论如何都会保证setup已经调用过\n        # setup负责初始化日志模块和应用加载\n        if subcommand == &#39;runserver&#39; and &#39;--noreload&#39; not in self.argv:\n            try:\n                autoreload.check_errors(django.setup)()\n            except Exception:\n                apps.all_models = defaultdict(OrderedDict)\n                apps.app_configs = OrderedDict()\n                apps.apps_ready = apps.models_ready = apps.ready = True\n        else:\n            django.setup()\n\n    self.autocomplete()\n\n    if subcommand == &#39;help&#39;:\n        if &#39;--commands&#39; in args:\n            sys.stdout.write(self.main_help_text(commands_only=True) + &#39;\\n&#39;)\n        elif len(options.args) &lt; 1:\n            sys.stdout.write(self.main_help_text() + &#39;\\n&#39;)\n        else:\n            self.fetch_command(options.args[0]).print_help(self.prog_name, options.args[0])\n    elif subcommand == &#39;version&#39; or self.argv[1:] == [&#39;--version&#39;]:\n        sys.stdout.write(django.get_version() + &#39;\\n&#39;)\n    elif self.argv[1:] in ([&#39;--help&#39;], [&#39;-h&#39;]):\n        sys.stdout.write(self.main_help_text() + &#39;\\n&#39;)\n    else:\n        # 找到子命令并传入参数执行\n        self.fetch_command(subcommand).run_from_argv(self.argv)\n</code></pre>\n<p>Django使用<code>fetch_command</code>从以下两个路径查找对应的<code>Command</code>类：</p>\n<ul>\n<li>django.core.management.commands模块下</li>\n<li>应用模块下的management.commands模块下</li>\n</ul>\n<p>到现在为止，Django的命令执行过程就比较清晰了：__</p>\n<ul>\n<li>首先从命令行参数解析出子命令名称:<br><br>  <code>subcommand = self.argv[1]</code></li>\n<li>调用fetch_command找到对应的子命令Command类：<br><br>  <code>self.fetch_command(subcommand)</code></li>\n<li>根据返回的subcommand实例，执行run_from_argv()方法:<br><br>  <code>self.fetch_command(subcommand).run_from_argv(self.argv)</code></li>\n<li>从django.core.management.base.BaseCommand中可知run_from_argv()方法的调用过程为：<br><br>  <code>run_from_argv() -&gt; execute() -&gt; handle()</code></li>\n<li><code>handle()</code>方法的执行结果就是命令的返回。</li>\n</ul>\n<h2 id=\"扩展自定义命令\"><a href=\"#扩展自定义命令\" class=\"headerlink\" title=\"扩展自定义命令\"></a>扩展自定义命令</h2><p>知道了Django的命令解析原理，扩展自定义<code>Command</code>就很容易了。我们可以创建一个<code>app</code>并加入<code>settings.INSTALLED_APPS</code>中，在<code>app</code>下面新建一个包<code>management.commands</code>，并创建一个模块<code>hello.py</code>。于是：</p>\n<pre><code class=\"python\">from django.core.management.base import BaseCommand\n\nclass Command(BaseCommand):\n\n    def handle(self, *args, **kwargs):\n        print(&quot;Hello, World!&quot;)\n</code></pre>\n<p>运行：</p>\n<pre><code class=\"bash\">$ python manage.py hello\nHello, World!\n</code></pre>\n","categories":["Python"],"tags":["Python","Django","源码"]},{"title":"WSGI协议的原理和实现","url":"http://shawnz.me/posts/68384a74/","content":"<!--  -->\n<a id=\"more\"></a>\n<blockquote>\n<p>This document specifies a proposed standard interface between web servers and Python web applications or frameworks, to promote web application portability across a variety of web servers.</p>\n</blockquote>\n<h2 id=\"What-is-WSGI\"><a href=\"#What-is-WSGI\" class=\"headerlink\" title=\"What is WSGI?\"></a>What is WSGI?</h2><p><code>WSGI</code>，是Python <code>Web Server Gateway Interface</code>的简称，这是一种规范，描述了<code>web server</code>如何与<code>web application</code>交互、<code>web application</code>如何处理请求。如今WSGI已经成为Python的一种标准协议<a href=\"https://www.python.org/dev/peps/pep-0333/\" target=\"_blank\" rel=\"noopener\">PEP333</a>。当前运行在<code>WSGI协议</code>之上的Python WEB框架有Flask，Django和Tornado。</p>\n<p><code>WSGI协议</code>分为两个部分：</p>\n<ul>\n<li><code>server/gateway</code>: 即 HTTP Server，处理 HTTP 协议，接受用户 HTTP 请求和提供并发。调用 <code>web application</code> 处理业务逻辑，返回application提供的response给客户端。如，apache, nginx 和 IIS。</li>\n<li><code>web application/framework</code>: 专注业务逻辑的 python 应用或者框架。接收从<code>server</code>转发的<code>request</code>，处理请求，并将<code>response</code>返回给<code>server</code>。</li>\n</ul>\n<p><img src=\"/images/wsgi-1.png\" alt=\"\"></p>\n<h2 id=\"WSGI工作原理\"><a href=\"#WSGI工作原理\" class=\"headerlink\" title=\"WSGI工作原理\"></a>WSGI工作原理</h2><p><img src=\"/images/wsgi-2.png\" alt=\"\"></p>\n<h3 id=\"Application-Side\"><a href=\"#Application-Side\" class=\"headerlink\" title=\"Application Side\"></a>Application Side</h3><p>应用程序端必须定义一个满足一下条件的<code>callable object</code>：</p>\n<ul>\n<li>接受两个参数：<code>字典</code>(environ)，回调函数(start_response，返回 HTTP status，headers 给 web server)</li>\n<li>返回一个可迭代的值</li>\n</ul>\n<h3 id=\"Server-Side\"><a href=\"#Server-Side\" class=\"headerlink\" title=\"Server Side\"></a>Server Side</h3><p>上面提到的<code>environ</code>和<code>start_response</code>都是由服务器提供的。服务器必须调用<code>application</code>：</p>\n<ul>\n<li>接收 HTTP 请求，但是不关心 HTTP url, HTTP method 等，为 <code>environ</code> 提供必要的参数</li>\n<li>实现一个回调函数 <code>start_response</code>。</li>\n<li>调用 <code>callable object</code>并传递参数<code>environ</code>和<code>start_response</code>。</li>\n</ul>\n<h3 id=\"Middleware-Components-that-Play-Both-Sides\"><a href=\"#Middleware-Components-that-Play-Both-Sides\" class=\"headerlink\" title=\"Middleware: Components that Play Both Sides\"></a>Middleware: Components that Play Both Sides</h3><p><code>Middleware</code> 处于 <code>server</code>和 <code>application</code>之间。</p>\n<p>每个 <code>middleware</code> 实现不同的功能，我们通常根据需求选择相应的 <code>middleware</code> 并组合起来，实现所需的功能。</p>\n<h3 id=\"使用wsgiref模块\"><a href=\"#使用wsgiref模块\" class=\"headerlink\" title=\"使用wsgiref模块\"></a>使用wsgiref模块</h3><p><a href=\"https://docs.python.org/2/library/wsgiref.html\" target=\"_blank\" rel=\"noopener\">wsgiref</a> 是 PEP 333 定义的 wsgi 规范的范例实现。</p>\n<p>我们使用wsgiref编写一个样例：</p>\n<pre><code class=\"python\">from wsgiref.simple_server import make_server\n\ndef application(environ, start_response):\n    start_response(&#39;200 OK&#39;, [(&#39;CONTENT-TYPE&#39;, &#39;text/plain&#39;)])\n    return [&#39;This is a response!&#39;]\n\nif __name__ == &#39;__main__&#39;:\n    server = make_server(&#39;&#39;, 8000, application)\n    server.serve_forever()\n</code></pre>\n<p>其中的<code>application</code>就是客户端<code>application</code>。<code>wsgiref</code>封装了服务器的实现。</p>\n<p>在这个例子中，运行结果：</p>\n<pre><code class=\"bash\">curl 127.0.0.1:8000\nThis is a response!%                                                            \ncurl 127.0.0.1:8000/any   \nThis is a response!%\n</code></pre>\n<h2 id=\"简单实现WSGI-Server\"><a href=\"#简单实现WSGI-Server\" class=\"headerlink\" title=\"简单实现WSGI Server\"></a>简单实现WSGI Server</h2><pre><code class=\"python\">#!/usr/bin/env python\n# -*- coding: utf-8 -*-\n\nimport socket\nimport StringIO\nimport sys\n\nclass WSGIServer(object):\n\n    address_family = socket.AF_INET\n    socket_type = socket.SOCK_STREAM\n    request_queue_size = 1\n\n    def __init__(self, server_address):\n\n        # 创建socket，利用socket获取客户端的请求\n        self.listen_socket = listen_socket = socket.socket(self.address_family, self.socket_type)\n        # 设置socket的工作模式\n        listen_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        # 绑定socket地址\n        listen_socket.bind(server_address)\n        # socket active， 监听文件描述符\n        listen_socket.listen(self.request_queue_size)\n\n        # 获得serve的host name和port\n        host, port = self.listen_socket.getsockname()[:2]\n        self.server_name = socket.getfqdn(host)\n        self.server_port = port\n\n        self.headers_set = []\n\n    def set_app(self, application):\n        self.application = application \n\n    #启动WSGI server服务，不停的监听并获取socket数据。\n    def serve_forever(self):\n        listen_socket = self.listen_socket\n        while True:\n            self.client_connection, client_address = listen_socket.accept() #接受客户端请求\n            #处理请求\n            self.handle_one_request()\n\n    def handle_one_request(self):\n        self.request_data = request_data = self.client_connection.recv(1024)\n        self.parse_request(request_data)\n        # print(&#39;&#39;.join(\n  # &#39;&lt; {line}\\n&#39;.format(line=line)\n  # for line in request_data.splitlines()\n  # ))\n          # Construct environment dictionary using request data\n        env = self.get_environ()\n\n        #给flask\\tornado传递两个参数，environ，start_response\n        result = self.application(env, self.start_response)\n        self.finish_response(result)\n\n    #处理socket的http协议\n    def parse_request(self, data):\n        format_data = data.splitlines()\n        if len(format_data):\n            request_line = data.splitlines()[0]\n            request_line = request_line.rstrip(&#39;\\r\\n&#39;)\n            (self.request_method, self.path, self.request_version) = request_line.split() ## [&#39;GET&#39;, &#39;/&#39;, &#39;HTTP/1.1&#39;]\n\n    # 获取environ数据并设置当前server的工作模式\n    def get_environ(self):\n        env = {}\n        env[&#39;wsgi.version&#39;]      = (1, 0)\n        env[&#39;wsgi.url_scheme&#39;]   = &#39;http&#39;\n        env[&#39;wsgi.input&#39;]        = StringIO.StringIO(self.request_data)\n        env[&#39;wsgi.errors&#39;]       = sys.stderr\n        env[&#39;wsgi.multithread&#39;]  = False\n        env[&#39;wsgi.multiprocess&#39;] = False\n        env[&#39;wsgi.run_once&#39;]     = False\n        # Required CGI variables\n        env[&#39;REQUEST_METHOD&#39;]    = self.request_method    # GET\n        env[&#39;PATH_INFO&#39;]         = self.path              # /hello\n        env[&#39;SERVER_NAME&#39;]       = self.server_name       # localhost\n        env[&#39;SERVER_PORT&#39;]       = str(self.server_port)  # 8888\n        return env\n\n    def start_response(self, status, response_headers, exc_info=None):\n        server_headers = [(&#39;Date&#39;, &#39;Tue, 31 Mar 2015 12:54:48 GMT&#39;), (&#39;Server&#39;, &#39;WSGIServer 0.2&#39;)]\n        self.headers_set = [status, response_headers + server_headers]\n\n    #把application返回给WSGI的数据返回给客户端。\n    def finish_response(self, result):\n        try:\n            status, response_headers = self.headers_set\n            response = &#39;HTTP/1.1 {status}\\r\\n&#39;.format(status=status)\n            for header in response_headers:\n                response += &#39;{0}: {1}\\r\\n&#39;.format(*header)\n            response += &#39;\\r\\n&#39;\n            for data in result:\n                response += data\n            self.client_connection.sendall(response)\n            print(&#39;&#39;.join(\n                &#39;&gt; {line}\\n&#39;.format(line=line)\n                for line in response.splitlines()\n            ))\n        finally:\n            self.client_connection.close()\n\nSERVER_ADDRESS = (HOST, PORT) = &#39;&#39;, 8888\n\ndef make_server(server_address, application):\n    server = WSGIServer(server_address)\n    server.set_app(application)\n    return server\n\n\nif __name__ == &#39;__main__&#39;:\n    if len(sys.argv) &lt; 2:\n        sys.exit(&#39;Provide a WSGI application object as module:callable&#39;)\n    app_path = sys.argv[1]\n    module, application = app_path.split(&#39;:&#39;) # 第一个参数是文件名，第二个参数时长文件内app的命名\n    module = __import__(module)\n    application = getattr(module, application) # getattr(object, name[, default]) -&gt; value\n    httpd = make_server(SERVER_ADDRESS, application)\n    print(&#39;WSGIServer: Serving HTTP on port {port} ...\\n&#39;.format(port=PORT))\n    httpd.serve_forever()\n\n</code></pre>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://cizixs.com/2014/11/09/dive-into-wsgiref\" target=\"_blank\" rel=\"noopener\">wsgiref 源码解析</a></p>\n","categories":["Python"],"tags":["Python"]},{"title":"werkzeug源码阅读","url":"http://shawnz.me/posts/e09df7aa/","content":"<h2 id=\"What-is-Werkzeug\"><a href=\"#What-is-Werkzeug\" class=\"headerlink\" title=\"What is Werkzeug?\"></a>What is Werkzeug?</h2><p><strong>Werkzeug is a WSGI utility library for Python.</strong></p>\n<a id=\"more\"></a>\n<h3 id=\"Werkzeug-is-Simple-and-Powerful\"><a href=\"#Werkzeug-is-Simple-and-Powerful\" class=\"headerlink\" title=\"Werkzeug is Simple and Powerful\"></a>Werkzeug is Simple and Powerful</h3><ul>\n<li>一个交互式调试器，允许在堆栈中的任何帧中使用交互式解释器检查浏览器中的堆栈跟踪和源代码。</li>\n<li>一个全功能的请求对象与对象交互标题，查询参数，表单数据，文件和cookie。</li>\n<li>一个响应对象，可以包装其他WSGI应用程序并处理流数据。 </li>\n<li>用于将URL与端点匹配并为端点生成URL的路由系统，具有用于从URL捕获变量的可扩展系统。</li>\n<li>HTTP实用程序来处理实体标签，缓存控制，日期，用户代理，cookie，文件等等。</li>\n<li>在本地开发应用程序时使用的线程WSGI服务器。</li>\n<li>用于在测试期间模拟HTTP请求的测试客户端，无需运行服务器。</li>\n</ul>\n<h2 id=\"WSGI服务器\"><a href=\"#WSGI服务器\" class=\"headerlink\" title=\"WSGI服务器\"></a>WSGI服务器</h2><p><code>werkzeug</code>实现了一个调试环境下的WSGI服务器，构建在Python的<code>socketserver</code>上。</p>\n<p>使用<code>werkzeug</code>搭建简单的HTTP服务器：</p>\n<pre><code class=\"python\">from werkzeug.wrappers import Request, Response\n\n@Request.application\ndef application(request):\n    return Response(&#39;Hello World!&#39;)\n\nif __name__ == &#39;__main__&#39;:\n    from werkzeug.serving import run_simple\n    run_simple(&#39;localhost&#39;, 4000, application)\n</code></pre>\n<p>在这里，我们可以发现这个<code>application</code>函数和<code>WSGI协议</code>标准形式有所不同，这是因为<a href=\"mailto:`@Request.application\" target=\"_blank\" rel=\"noopener\">`@Request.application</a>`。</p>\n<pre><code class=\"python\">@classmethod\ndef application(cls, f):\n    def application(*args):\n        request = cls(args[-2])\n        with request:\n            return f(*args[:-2] + (request,))(*args[-2:])\n    return update_wrapper(application, f)\n</code></pre>\n<p>装饰器<a href=\"mailto:`@Request.application\" target=\"_blank\" rel=\"noopener\">`@Request.application</a><code>拦截了我们调用函数时的倒数第二个参数，即</code>environ<code>，构建了</code>request<code>对象，并删除后两个参数</code>environ<code>和</code>start_response<code>，并使用这两个参数调用我们定义的函数返回(</code>Response`)对象。</p>\n<p>接下来我们看下<code>run_simple</code>函数，这是整个模块的入口，其中的核心代码是<code>make_server()</code>。</p>\n<pre><code class=\"python\">def run_simple(hostname, port, application, use_reloader=False,\n               threaded=False, processes=1, request_handler=None,\n               passthrough_errors=False, ssl_context=None):\n    # 根据入参可能或启用中间件\n\n    def log_startup(sock):\n        &#39;&#39;&#39; 启动日志打印 &#39;&#39;&#39;\n        pass\n\n    def inner():\n        try:\n            fd = int(os.environ[&#39;WERKZEUG_SERVER_FD&#39;])\n        except (LookupError, ValueError):\n            fd = None\n        srv = make_server(hostname, port, application, threaded,\n                          processes, request_handler,\n                          passthrough_errors, ssl_context,\n                          fd=fd)\n        if fd is None:\n            log_startup(srv.socket)\n        srv.serve_forever()\n\n    if use_reloader:\n        # 热重启\n        pass\n    else:\n        inner()\n</code></pre>\n<p>在这个函数里面根据参数实例化了<code>BaseWSGIServer</code>或<code>ThreadedWSGIServer</code>或<code>ForkingWSGIServer</code>。在这个函数里面还用到了一项特别的技巧：<code>热重启</code>。</p>\n<p>接下来就是<code>BaseWSGIHTTPServer</code>和<code>WSGIRequestHandler</code>的实现，基于<code>socketserver</code>。</p>\n<p><code>BaseWSGIHTTPServer</code>添加了对<code>SSL</code>的支持，通过使用<code>server_forever()</code>启动服务器。</p>\n<pre><code class=\"python\">def serve_forever(self):\n    self.shutdown_signal = False\n    try:\n        HTTPServer.serve_forever(self)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        self.server_close()\n</code></pre>\n<p>具体对请求的处理在<code>WSGIRequestHandler</code>中。在<code>BaseHTTPRequestHandler</code>的官方文档中描述：</p>\n<blockquote>\n<p>The handler will parse the request and the headers, then call a method specific to the request type. The method name is constructed from the request. For example, for the request method SPAM, the do_SPAM() method will be called with no arguments.</p>\n</blockquote>\n<p><code>WSGIRequestHandler</code>的处理请求的流程和<code>BaseHTTPRequestHandler</code>是一致的。</p>\n<ul>\n<li>首先调用<code>handle()</code>处理请求。在这步和只是调用父类的<code>handle()</code>方法，在父类中会判断<code>close_connection</code>来启用持久连接，然后调用<code>handle_one_request()</code>。</li>\n<li>在<code>handle_one_request()</code>中：从<code>rfile</code>(HTTP报文)中读取数据，然后调用<code>parse_request</code>解析HTTP报文头。和<code>BaseHTTPRequestHandler</code>不同的是，在<code>handle_one_request</code>中没有区分请求方法的处理。所有请求方法的处理都在<code>run_wsgi</code>中。<pre><code class=\"python\">def handle_one_request(self):\n  self.raw_requestline = self.rfile.readline()\n  if not self.raw_requestline:\n      self.close_connection = 1\n  elif self.parse_request():\n      return self.run_wsgi()\n</code></pre>\n</li>\n<li><p><code>run_wsgi()</code>中的处理流程：</p>\n<pre><code class=\"python\">   def run_wsgi(self):\n      if self.headers.get(&#39;Expect&#39;, &#39;&#39;).lower().strip() == &#39;100-continue&#39;:\n          self.wfile.write(b&#39;HTTP/1.1 100 Continue\\r\\n\\r\\n&#39;)\n\n      self.environ = environ = self.make_environ()\n      headers_set = []\n      headers_sent = []\n\n      def write(data):\n          assert headers_set, &#39;write() before start_response&#39;\n          if not headers_sent:\n              status, response_headers = headers_sent[:] = headers_set\n              try:\n                  code, msg = status.split(None, 1)\n              except ValueError:\n                  code, msg = status, &quot;&quot;\n              self.send_response(int(code), msg)\n              header_keys = set()\n              for key, value in response_headers:\n                  self.send_header(key, value)\n                  key = key.lower()\n                  header_keys.add(key)\n              if &#39;content-length&#39; not in header_keys:\n                  self.close_connection = True\n                  self.send_header(&#39;Connection&#39;, &#39;close&#39;)\n              if &#39;server&#39; not in header_keys:\n                  self.send_header(&#39;Server&#39;, self.version_string())\n              if &#39;date&#39; not in header_keys:\n                  self.send_header(&#39;Date&#39;, self.date_time_string())\n              self.end_headers()\n\n          assert isinstance(data, bytes), &#39;applications must write bytes&#39;\n          self.wfile.write(data)\n          self.wfile.flush()\n\n      def start_response(status, response_headers, exc_info=None):\n          if exc_info:\n              try:\n                  if headers_sent:\n                      reraise(*exc_info)\n              finally:\n                  exc_info = None\n          elif headers_set:\n              raise AssertionError(&#39;Headers already set&#39;)\n          headers_set[:] = [status, response_headers]\n          return write\n\n      def execute(app):\n          application_iter = app(environ, start_response)\n          try:\n              for data in application_iter:\n                  write(data)\n              if not headers_sent:\n                  write(b&#39;&#39;)\n          finally:\n              if hasattr(application_iter, &#39;close&#39;):\n                  application_iter.close()\n              application_iter = None\n\n      try:\n          execute(self.server.app)\n      except (socket.error, socket.timeout) as e:\n          self.connection_dropped(e, environ)\n      except Exception:\n          if self.server.passthrough_errors:\n              raise\n          from werkzeug.debug.tbtools import get_current_traceback\n          traceback = get_current_traceback(ignore_system_exceptions=True)\n          try:\n              # if we haven&#39;t yet sent the headers but they are set\n              # we roll back to be able to set them again.\n              if not headers_sent:\n                  del headers_set[:]\n              execute(InternalServerError())\n          except Exception:\n              pass\n          self.server.log(&#39;error&#39;, &#39;Error on request:\\n%s&#39;,\n                          traceback.plaintext)\n</code></pre>\n<ul>\n<li>首先是对HTTP头的一个协议版本的判断；</li>\n<li><code>make_environ</code>解析HTTP头，包装城<code>envrion</code>；</li>\n<li>接下来是在最底层的<code>try-catch</code>块中，调用了<code>execute(self.server.app)</code>，这个<code>app</code>就是<code>run_simple</code>传入的<code>application</code>。</li>\n<li>在<code>excute()</code>中调用应用程序<code>application</code>，并传入包装好的<code>environ</code>和<code>start_response</code>函数对象。<br>  在上面的代码中，我们可以看到调用<code>app(environ, start_response)</code>返回的是一个可迭代对象，这是因为在我们的应用程序代码中。使用<a href=\"mailto:`@Request.application\" target=\"_blank\" rel=\"noopener\">`@Request.application</a><code>装饰时，返回的是</code>return f(<em>args[:-2] + (request,))(</em>args[-2:])`。</li>\n<li><code>start_response</code>允许应用程序发送<code>状态码</code>和<code>响应头</code>，这些信息保存在变量<code>header_set</code>中，还没有被写入<code>wfile</code>。</li>\n<li>对于应用程序的返回<code>application_iter</code>。通过<code>write()</code>将各项信息写入<code>wfile</code>。</li>\n<li>对于异常或者超时，则在<code>catch</code>块进行输出处理。</li>\n</ul>\n</li>\n</ul>\n<p>整个请求处理的流程大致如下(网上找的)：</p>\n<!-- ![](/images/werkzeug-server-flow.png) -->\n<h2 id=\"热重启\"><a href=\"#热重启\" class=\"headerlink\" title=\"热重启\"></a>热重启</h2><p><code>auto reload</code>机制的原理很简单：<strong>就是不停的检测目录下的文件更改，比较文件的最近修改时间，如果有更新，就重启服务</strong>。</p>\n<p>在看过<code>werkzeug</code>的热重启实现后，自己也实现了一个简单的<code>auto reload</code>机制：</p>\n<pre><code class=\"python\">import os\nimport sys\nimport time\nfrom threading import Thread\nimport subprocess\nfrom http.server import HTTPServer, BaseHTTPRequestHandler\n\n\ndef serve_forever():\n    server = HTTPServer((&#39;&#39;, 8080), BaseHTTPRequestHandler)\n    print(&#39;Server started at localhost:8080...&#39;)\n    server.serve_forever()\n\n\ndef run():\n    mtimes = {}\n\n    while 1:\n        filename = __file__\n        mtime = os.stat(filename).st_mtime\n        old_time = mtimes.get(filename)\n        if old_time is None:\n            mtimes[filename] = mtime\n        elif mtime &gt; old_time:\n            print(&#39;* Detected change in {}, reloading&#39;.format(filename))\n            sys.exit(3)\n        time.sleep(1)\n\n\ndef restart_with_reloader():\n    while 1:\n        env = os.environ.copy()\n        env[&#39;WERKZEUG_RUN_MAIN&#39;] = &#39;true&#39;\n        exit_code = subprocess.call([sys.executable]+sys.argv, env=env)\n        if exit_code != 3:\n            break\n\n\ndef run_with_reloader():\n    if os.environ.get(&#39;WERKZEUG_RUN_MAIN&#39;) == &#39;true&#39;:\n        t = Thread(target=serve_forever, args=())\n        t.setDaemon(True)\n        t.start()\n        run()\n    else:\n        sys.exit(restart_with_reloader())\n\n\nif __name__ == &#39;__main__&#39;:\n    run_with_reloader()\n</code></pre>\n<h2 id=\"路由规则\"><a href=\"#路由规则\" class=\"headerlink\" title=\"路由规则\"></a>路由规则</h2><p><code>werkzeug</code>的<code>routing</code>模块主要用来解析和匹配请求信息中的URL，并触发URL对应的视图函数，以生成响应。大致分为三个部分：<code>Rule</code>、<code>Map</code>和<code>MapAdapter</code>。</p>\n<pre><code class=\"python\">url_map = Map([\n    Rule(&#39;/&#39;, endpoint=&#39;new_url&#39;),\n    Rule(&#39;/&lt;short_id&gt;&#39;, endpoint=&#39;follow_short_link&#39;),\n    Rule(&#39;/&lt;short_id&gt;+&#39;, endpoint=&#39;short_link_details&#39;)\n])\n</code></pre>\n<p>首先，我们创建一个包含三个<code>Rule</code>规则的<code>Map</code>对象。</p>\n<h3 id=\"Rule\"><a href=\"#Rule\" class=\"headerlink\" title=\"Rule\"></a>Rule</h3><p>这个类主要用来构造URL地址，以下是它的构造方法签名中有两个重要参数：</p>\n<ul>\n<li><code>string</code>：预先定义的URL地址。</li>\n<li><code>endponit</code>：主要用来反向查询URL。</li>\n</ul>\n<p>在这个类中实现了<code>bind</code>方法，用来和<code>Map</code>进行绑定：</p>\n<pre><code class=\"python\">def bind(self, map, rebind=False):\n    if self.map is not None and not rebind:\n        raise RuntimeError(&#39;url rule %r already bound to map %r&#39; %\n                            (self, self.map))\n    self.map = map\n    if self.strict_slashes is None:\n        self.strict_slashes = map.strict_slashes\n    if self.subdomain is None:\n        self.subdomain = map.default_subdomain\n    self.compile()\n</code></pre>\n<p>和<code>Map</code>绑定过后，<code>Rule</code>可以使用<code>Map</code>的属性来完善自己的配置。在这一步还对<code>URL</code>规则进行了<code>预编译</code>，以便加快后期<code>match()</code>的匹配。</p>\n<h3 id=\"Map\"><a href=\"#Map\" class=\"headerlink\" title=\"Map\"></a>Map</h3><p>在该类的实例中，保存了许多的<code>Rule</code>实例，存储所有的<code>URL规则</code>，还有一些配置参数。主要实现以下方法：</p>\n<ul>\n<li><code>add()</code>：这个方法在构造Map实例的时候就会调用，它会在所有传入Map类中的Rule实例上调用<code>bind()</code>和该Map实例<code>self</code>进行绑定：<pre><code class=\"python\">  def add(self, rulefactory):\n      for rule in rulefactory.get_rules(self):\n          rule.bind(self)\n          self._rules.append(rule)\n          self._rules_by_endpoint.setdefault(rule.endpoint, []).append(rule)\n      self._remap = True\n</code></pre>\n</li>\n<li><p><code>bind()</code>：这个方法会通过传递一些参数来构建一个<code>MapAdapter</code>实例：</p>\n<pre><code class=\"python\">  def bind(self, server_name, script_name=None, subdomain=None,\n              url_scheme=&#39;http&#39;, default_method=&#39;GET&#39;, path_info=None,\n              query_args=None):\n      server_name = server_name.lower()\n      if self.host_matching:\n          if subdomain is not None:\n              raise RuntimeError(&#39;host matching enabled and a &#39;\n                                  &#39;subdomain was provided&#39;)\n      elif subdomain is None:\n          subdomain = self.default_subdomain\n      if script_name is None:\n          script_name = &#39;/&#39;\n      try:\n          server_name = _encode_idna(server_name)\n      except UnicodeError:\n          raise BadHost()\n      return MapAdapter(self, server_name, script_name, subdomain,\n                          url_scheme, path_info, default_method, query_args)\n</code></pre>\n</li>\n<li><code>bind_to_environ()</code>：这个方法在内部也是调用<code>bind()</code>，不同的是，它是通过WSGI协议中<code>environ</code>来获取一些URL基本信息。</li>\n</ul>\n<h3 id=\"MapAdapter\"><a href=\"#MapAdapter\" class=\"headerlink\" title=\"MapAdapter\"></a>MapAdapter</h3><p><code>MapAdapter</code>由<code>Map</code>绑定<code>URL路径</code>基本参数后创建，用来做<code>URL匹配</code>，主要有三个方法：</p>\n<ul>\n<li><code>match()</code>：该方法将会进行具体的URL匹配工作。它会将请求中的<code>URL路径</code>和属性<code>map</code>中的所有<code>Rule</code>进行匹配，如果有匹配成功的，则返回该<code>Rule</code>对应的<code>endpoint</code>和一些参数<code>rv</code>：<br>  其中核心代码是<code>rv = rule.match(path, method)</code>，构建<code>path</code>，然后在<code>Rule</code>对象上进行正则匹配。</li>\n<li><code>build()</code>：该方法和<code>match()</code>对应，传入<code>endpoint</code>和对应<code>参数</code>，返回<code>path_info</code>。</li>\n<li><p><code>dispatch()</code>：该方法会使用<code>match()</code>方法找到对应的<code>endpoint</code>和相关<code>参数</code>，然后再把这个<code>endpoint</code>作为参数传入<code>views</code>视图函数，返回一个<code>view_func</code>对象：</p>\n<pre><code class=\"python\">  from werkzeug.wrappers import Request, Response\n  from werkzeug.wsgi import responder\n  from werkzeug.routing import Map, Rule\n\n  def on_index(request):\n      return Response(&#39;Hello from the index&#39;)\n\n  url_map = Map([Rule(&#39;/&#39;, endpoint=&#39;index&#39;)])\n  views = {&#39;index&#39;: on_index}\n\n  @responder\n  def application(environ, start_response):\n      request = Request(environ)\n      urls = url_map.bind_to_environ(environ)\n      return urls.dispatch(lambda e, v: views[e](request, **v),\n                              catch_http_exceptions=True)\n</code></pre>\n<p>  从这可以看出， <strong><code>werkzeug</code>是不维护<code>endpoint</code>和<code>view_func</code>的映射的。</strong></p>\n</li>\n</ul>\n<p>###　其他</p>\n<h2 id=\"线程局部变量\"><a href=\"#线程局部变量\" class=\"headerlink\" title=\"线程局部变量\"></a>线程局部变量</h2><p>对于传统的WEB框架来说，大多数采用多线程处理请求的方式，“线程安全”就是一个需要关注的问题。</p>\n<p>我们编写应用程序代码的时候，可以采用这种一下这种方式：</p>\n<pre><code class=\"python\">def handle_request():\n    l = &#39;foo&#39;  # 线程安全的\n    l  # 进行引用\n</code></pre>\n<p>然而框架或者是多线程共享的对象属性需要一种特殊的机制，来实现“线程安全”。</p>\n<pre><code class=\"python\">import threading\n\nl = threading.local()  # 线层安全的\n\ndef handle_request():\n    l  # 进行引用\n</code></pre>\n<p>在上面的<code>l</code>全局变量是线程隔离的。利用这个原理，我们(框架)可以暴露出一个接口供应用程序调用，而且是“线程安全的”。</p>\n<h3 id=\"Local\"><a href=\"#Local\" class=\"headerlink\" title=\"Local\"></a>Local</h3><p><code>werkzeug</code>的<code>Local</code>类实现了一种数据结构，来保存线程的私有变量。在这一点和<code>threading.local</code>相似，不过<code>Local</code>添加了对与<code>协程</code>的支持。</p>\n<pre><code class=\"python\">class Local(object):\n    __slots__ = (&#39;__storage__&#39;, &#39;__ident_func__&#39;)\n\n    def __init__(self):\n        object.__setattr__(self, &#39;__storage__&#39;, {})\n        object.__setattr__(self, &#39;__ident_func__&#39;, get_ident)\n</code></pre>\n<p>可以看到<code>Local</code>有两个属性：</p>\n<ul>\n<li><code>__storage__</code>：一个字典，用来存储不同线程标识和对应线程中的数据</li>\n<li><code>__ident_func</code>：一个函数，用来标识线程或协程。<code>from greenlet import getcurrent as get_ident</code>支持协程标识。</li>\n</ul>\n<h3 id=\"LocalStack\"><a href=\"#LocalStack\" class=\"headerlink\" title=\"LocalStack\"></a>LocalStack</h3><p><code>LocalStack</code>和<code>Local</code>类似，和<code>Local</code>在使用<code>字典</code>保存当前线程信息不同的是<code>LocalStack</code>实现了<code>栈</code>数据结构。</p>\n<pre><code class=\"python\">def __init__(self):\n    self._local = Local()\n\ndef push(self, obj):\n    rv = getattr(self._local, &#39;stack&#39;, None)\n    if rv is None:\n        self._local.stack = rv = []\n    rv.append(obj)\n    return rv\n</code></pre>\n<p>在初始化的时候，会创建一个<code>Local</code>实例，并在<code>_local</code>属性上通过<code>列表</code>维护一个<code>栈</code>数据结构，实现<code>push</code>、<code>pop</code>和<code>top</code>操作。</p>\n<pre><code class=\"python\">def __call__(self):\n    def _lookup():\n        rv = self.top\n        if rv is None:\n            raise RuntimeError(&#39;object unbound&#39;)\n        return rv\n    return LocalProxy(_lookup)\n</code></pre>\n<p>使用<code>栈</code>，给人的直观感受是：多线程环境下，任一时刻<code>栈</code>里只有一个内容<code>self.top</code>。</p>\n<h3 id=\"LocalProxy\"><a href=\"#LocalProxy\" class=\"headerlink\" title=\"LocalProxy\"></a>LocalProxy</h3><p><code>LocalProxy</code>使用<code>代理模式</code>，用于代理<code>Local</code>或<code>LocalStack</code>对象。我们先看下<code>LocalProxy</code>的用法：</p>\n<pre><code class=\"python\">from werkzeug.local import Local\nl = Local()\n\n# these are proxies\nrequest = l(&#39;request&#39;)\nuser = l(&#39;user&#39;)\n\n\n\n</code></pre>\n<p>实际上，在<code>Local</code>和<code>LocalStack</code>的<code>__call__()</code>方法，返回的都是一个<code>LocalProxy</code>对象。这种方式和下面这种形式达成的效果是相同的：</p>\n<pre><code class=\"python\">l = Local()\nrequest = LocalProxy(l, &#39;request&#39;)\n</code></pre>\n<p><strong><code>LocalProxy</code></strong>的实现原理：</p>\n<pre><code class=\"python\">@implements_bool\nclass LocalProxy(object):\n    __slots__ = (&#39;__local&#39;, &#39;__dict__&#39;, &#39;__name__&#39;, &#39;__wrapped__&#39;)\n\n    def __init__(self, local, name=None):\n        object.__setattr__(self, &#39;_LocalProxy__local&#39;, local)\n        object.__setattr__(self, &#39;__name__&#39;, name)\n        if callable(local) and not hasattr(local, &#39;__release_local__&#39;):\n            # &quot;local&quot; is a callable that is not an instance of Local or\n            # LocalManager: mark it as a wrapped function.\n            object.__setattr__(self, &#39;__wrapped__&#39;, local)\n\n    def _get_current_object(self):\n        if not hasattr(self.__local, &#39;__release_local__&#39;):\n            return self.__local()\n        try:\n            return getattr(self.__local, self.__name__)\n        except AttributeError:\n            raise RuntimeError(&#39;no object bound to %s&#39; % self.__name__)\n\n    @property\n    def __dict__(self):\n        try:\n            return self._get_current_object().__dict__\n        except RuntimeError:\n            raise AttributeError(&#39;__dict__&#39;)\n\n    def __repr__(self):\n        try:\n            obj = self._get_current_object()\n        except RuntimeError:\n            return &#39;&lt;%s unbound&gt;&#39; % self.__class__.__name__\n        return repr(obj)\n\n    def __bool__(self):\n        try:\n            return bool(self._get_current_object())\n        except RuntimeError:\n            return False\n\n    def __unicode__(self):\n        try:\n            return unicode(self._get_current_object())  # noqa\n        except RuntimeError:\n            return repr(self)\n\n    def __dir__(self):\n        try:\n            return dir(self._get_current_object())\n        except RuntimeError:\n            return []\n\n    def __getattr__(self, name):\n        if name == &#39;__members__&#39;:\n            return dir(self._get_current_object())\n        return getattr(self._get_current_object(), name)\n\n    def __setitem__(self, key, value):\n        self._get_current_object()[key] = value\n\n    def __delitem__(self, key):\n        del self._get_current_object()[key]\n\n    if PY2:\n        __getslice__ = lambda x, i, j: x._get_current_object()[i:j]\n\n        def __setslice__(self, i, j, seq):\n            self._get_current_object()[i:j] = seq\n\n        def __delslice__(self, i, j):\n            del self._get_current_object()[i:j]\n\n    # 其他部分的Magic Method代理实现\n    __setattr__ = lambda x, n, v: setattr(x._get_current_object(), n, v)\n</code></pre>\n<ul>\n<li>在<code>LocalProxy</code>的<code>__init__</code>方法中，参数<code>local</code>绑定在<code>_LocalProxy__local</code>属性上，可以通过<code>self.__local</code>进行访问(这是因为<code>__foo</code>会被解释器替换为<code>_classname__foo</code>的形式进行访问)</li>\n<li><p><code>LocalProxy</code>通过<code>_get_current_object</code>来获取代理对象。在这里分两种情况：</p>\n<ul>\n<li><p>若<code>self.__local</code>是<code>Local</code>，即在<code>Local</code>类<code>call</code>方法的返回<code>return LocalProxy(self, name)</code>。重载的其他操作相当于在<code>Local</code>对象上的相应操作：</p>\n<pre><code class=\"python\">  from werkzeug.local import Local\n  l = Local()\n  l.request = &#39;this is a request&#39;\n\n  request_1 = l.request\n  # request_2 和 request_3 通过代理获取值\n  request_2 = l(&#39;request&#39;)\n  request_3 = LocalProxy(l, &#39;request&#39;)\n  print(request_1)\n  print(request_2)\n  print(request_3)\n  # 三者等价\n  # 输出\n  # this is a request\n  # this is a request\n  # this is a request\n</code></pre>\n</li>\n<li>若<code>self.__local</code>是<code>LocalStack</code>，即在<code>LocalStack</code>类<code>call</code>方法的返回<code>return LocalProxy(_lookup)</code>。相当于获取<code>LocalStack</code>的栈顶对象：<pre><code class=\"python\">  from werkzeug.local import LocalStack\n  _response_local = LocalStack()\n  _response_local.push(&#39;this is a request&#39;)\n  reponse_1 = _response_local.top\n  # 通过代理获取栈顶对象\n  response_2 = _response_local()\n  response_3 = LocalProxy(lambda: _response_local.top)\n  print(response_1)\n  print(response_2)\n  print(response_3)\n  # 三者等价，输出\n  # this is a response\n  # this is a response\n  # this is a response\n</code></pre>\n</li>\n<li>否则调用<code>self.__local</code>来获取当前对象,<code>LocalStack</code>的就是通过这种机制实现获取栈顶元素。</li>\n</ul>\n</li>\n<li>重载操作符的时候，都是通过<code>_get_current_object</code>获取被代理的对象，再在对象上进行操作。</li>\n</ul>\n<p><strong>而<code>LocalProxy</code>能做的就是通过一个函数可以动态的获取<code>Local</code>或<code>LocalProxy</code>中的元素。</strong><br>试想一下，在WEB请求来到时，我们每回通过<code>LocalProxy</code>获取的都是当前的栈顶线程的信息。(并发处理？)</p>\n<h3 id=\"LocalManager\"><a href=\"#LocalManager\" class=\"headerlink\" title=\"LocalManager\"></a>LocalManager</h3><p><code>LocalManager</code>用来管理<code>Local</code>对象，可以清除<code>Local</code>中对应的内容。</p>\n<p>其核心内容是通过<code>release_local</code>调用<code>Local</code>或<code>LocalStack</code>的<code>__release_local__</code>。对于<code>LocalStack</code>尽管可以这么做，但还是建议使用<code>pop</code>的方法释放。</p>\n<p>另外<code>LocalManager</code>实现了WSGI中间件，确保在请求结束后清楚<code>Local</code>中对应的内容。</p>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://werkzeug.pocoo.org/docs/0.13/\" target=\"_blank\" rel=\"noopener\">Werkzeug文档</a></p>\n","categories":["Python"],"tags":["Python","源码"]},{"title":"Flask源码阅读","url":"http://shawnz.me/posts/f034d9c0/","content":"<h2 id=\"Flask简介\"><a href=\"#Flask简介\" class=\"headerlink\" title=\"Flask简介\"></a>Flask简介</h2><blockquote>\n<p>Flask is a micro web development framework for Python.</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>FLask相比其他的Python WEB框架的特点是：简单且可扩展。</p>\n<p>Flask主要有两个依赖<code>werkzeug</code>和<code>jinja</code>，而<code>werkzeug</code>又是核心。</p>\n<h3 id=\"werkzeug\"><a href=\"#werkzeug\" class=\"headerlink\" title=\"werkzeug\"></a>werkzeug</h3><p><strong>Werkzeug is an HTTP and WSGI utility library for Python.</strong></p>\n<p><code>werkzeug</code>负责核心的逻辑模块，比如路由、请求和应答的封装、WSGI 相关的函数等。</p>\n<p><code>werkzeug</code>提供了Python WEB WSGI开发相关的功能：</p>\n<ul>\n<li>路由处理：怎么根据请求中的 url 找到它的处理函数；</li>\n<li>request 和 response 封装：可以更好地读取 request 的数据，也容易生成响应；</li>\n<li>一个自带的 WSGI server，可以用来测试环境运行自己的应用。</li>\n<li>还实现了很多非常有用的数据结构和函数。</li>\n</ul>\n<h3 id=\"jinja\"><a href=\"#jinja\" class=\"headerlink\" title=\"jinja\"></a>jinja</h3><p><code>jinja</code>负责模板的渲染，主要用来渲染返回给用户的 html 文件内容。</p>\n<p>Flask大部分功能基于<code>werkzeug</code>实现。在继续阅读之前，假设大家已经清楚<code>WSGI协议</code>和<code>werkzeug</code>的原理。</p>\n<h3 id=\"在这之前\"><a href=\"#在这之前\" class=\"headerlink\" title=\"在这之前\"></a>在这之前</h3><p>在这篇博客里，假设大家已经清楚了<code>WSGI协议</code>和<code>werkzeug</code>，会省略一部分相关的技术原理。</p>\n<p>若有疑问，建议结合阅读之前的两篇博客，更好的理解Flask原理：</p>\n<ul>\n<li><a href=\"/posts/68384a74/\" title=\"WSGI协议的原理和实现\">WSGI协议的原理和实现</a>。</li>\n<li><a href=\"/posts/e09df7aa/\" title=\"werkzeug源码阅读\">werkzeug源码阅读</a>。</li>\n</ul>\n<h2 id=\"应用启动流程\"><a href=\"#应用启动流程\" class=\"headerlink\" title=\"应用启动流程\"></a>应用启动流程</h2><p>我们先来看看Flask的官方<code>Hello World</code>示例:</p>\n<pre><code class=\"python\">from flask import Flask\napp = Flask(__name__)\n\n@app.route(&#39;/&#39;)\ndef hello_world():\n    return &#39;Hello World!&#39;\n\nif __name__ == &#39;__main__&#39;:\n    app.run()\n</code></pre>\n<p>很简单的，我们编写了一个<code>application</code>，并使用Flask内置的(<code>werkzeug</code>)<code>HTTPServer</code>运行起来了。</p>\n<p>我们来看看<code>run</code>的内部：</p>\n<pre><code class=\"python\">def run(self, host=None, port=None, debug=None, **options):\n        from werkzeug.serving import run_simple\n        if host is None:\n            host = &#39;127.0.0.1&#39;\n        if port is None:\n            server_name = self.config[&#39;SERVER_NAME&#39;]\n            if server_name and &#39;:&#39; in server_name:\n                port = int(server_name.rsplit(&#39;:&#39;, 1)[1])\n            else:\n                port = 5000\n        if debug is not None:\n            self.debug = bool(debug)\n        options.setdefault(&#39;use_reloader&#39;, self.debug)\n        options.setdefault(&#39;use_debugger&#39;, self.debug)\n        try:\n            run_simple(host, port, self, **options)\n        finally:\n            self._got_first_request = False\n</code></pre>\n<p>在这里，我们可以看到Flask简单的处理了一下参数，然后调用<code>werkzeug</code>的<code>run_simple()</code>，传递的<code>application</code>即<code>Flask</code>类本身实例<code>self</code>。</p>\n<p>在上一篇博客<code>werkzeug源码阅读</code>中，我们知道<code>run_simple()</code>在请求到来时，会执行<code>application(envrion, start_response)</code>。所以我们来看<code>Flask.__call__()</code>方法：</p>\n<pre><code class=\"python\">def wsgi_app(self, environ, start_response):\n    ctx = self.request_context(environ)\n    ctx.push()\n    error = None\n    try:\n        try:\n            response = self.full_dispatch_request()\n        except Exception as e:\n            error = e\n            response = self.handle_exception(e)\n        except:\n            error = sys.exc_info()[1]\n            raise\n        return response(environ, start_response)\n    finally:\n        if self.should_ignore_error(error):\n            error = None\n        ctx.auto_pop(error)\n\ndef __call__(self, environ, start_response):\n    return self.wsgi_app(environ, start_response)\n</code></pre>\n<p>在上面的<code>wsgi_app</code>中的执行流程大致分为三步：</p>\n<ul>\n<li>处理<code>environ</code>参数，这是和<code>context</code>上下文有关的，可以先放在一旁；</li>\n<li><code>full_dispatch_requst()</code>是关键，请求转发处理的具体逻辑在这里面；</li>\n<li>最后是返回响应，以及上下文清除。</li>\n</ul>\n<p>进入<code>full_dispatch_request()</code>我们可以看到:</p>\n<pre><code class=\"python\">def full_dispatch_request(self):\n    self.try_trigger_before_first_request_functions()\n    try:\n        request_started.send(self)\n        rv = self.preprocess_request()\n        if rv is None:\n            rv = self.dispatch_request()\n    except Exception as e:\n        rv = self.handle_user_exception(e)\n    return self.finalize_request(rv)\n</code></pre>\n<p>这个部分可以清晰的看到整个请求的处理流程：</p>\n<ul>\n<li><code>try_trigger_before_first_request_functions</code>：第一个请求的触发器；</li>\n<li><code>proprocess_request</code>：请求预处理。若是有响应，则不进入下一步请求转发了；</li>\n<li><code>dispatch_request</code>：路由转发到具体的处理函数；</li>\n<li><code>handle_user_exception</code>：异常处理；</li>\n<li><code>finalize_request</code>：将请求转换成响应。</li>\n</ul>\n<p>在继续了解Flask的路由机制之前，我们先列举一下Flask的<code>WEB Hook</code>函数：</p>\n<ul>\n<li><code>before_first_request</code>：注册一个函数，在处理第一个请求之前运行。</li>\n<li><code>before_request</code>：注册一个函数，在每次请求之前运行。其中一个函数作出响应后，其它函数将不再调用。</li>\n<li><code>after_request</code>：注册一个函数，如果没有未处理的异常抛出，在每次请求之后运行。试图函数返回值会转换成一个实际响应对象交给它处理。</li>\n<li><code>teardown_request</code>：注册一个函数，即使有未处理的异常抛出，也在每次请求之后运行。</li>\n</ul>\n<p>我们可以通过使用这些装饰器，把我们需要的钩子函数注册到<code>Flask</code>相应的字典或列表中，在相应的处理阶段等待调用。</p>\n<h2 id=\"路由\"><a href=\"#路由\" class=\"headerlink\" title=\"路由\"></a>路由</h2><p>对于路由的过程，就是 <strong>APP应用需要根据请求的路径转发到相应的处理函数上。</strong> </p>\n<p>在看Flask路由机制之前，我们可以很容易的想到：通过装饰器原理，在字典中注册<code>url</code>和<code>func</code>的映射，来实现简单路由。</p>\n<p>Flask的路由基于<code>werkzeug</code>的<code>Rule</code>、<code>Map</code>和<code>MapAdapter</code>。</p>\n<p>分析源码可以从两个方向着手：路由规则的注册以及请求路径的匹配映射。</p>\n<h3 id=\"路由规则注册\"><a href=\"#路由规则注册\" class=\"headerlink\" title=\"路由规则注册\"></a>路由规则注册</h3><p>在Flask中，我们可以通过三种形式注册路由：</p>\n<ul>\n<li><code>app.route()</code>装饰器；</li>\n<li><code>app.add_url_route()</code>方法；</li>\n<li>直接操作<code>app.url_map</code>数据结构。</li>\n</ul>\n<p>在Flaksk内部，这三种方式从下到下其实是一种包装关系。<code>route()</code>装饰器内部调用<code>app.add_url_route()</code>，而后者直接操作<code>url_map</code>数据结构。我们可以直接来看<code>add_url_map()</code>方法源码：</p>\n<pre><code class=\"python\">@setupmethod\ndef add_url_rule(self, rule, endpoint=None, view_func=None, **options):\n    # 省略了endpoint和method处理\n    methods = options.pop(&#39;methods&#39;, None)\n\n    rule = self.url_rule_class(rule, methods=methods, **options)\n\n    self.url_map.add(rule)\n    if view_func is not None:\n        old_func = self.view_functions.get(endpoint)\n        if old_func is not None and old_func != view_func:\n            raise AssertionError(&#39;View function mapping is overwriting an &#39;\n                                    &#39;existing endpoint function: %s&#39; % endpoint)\n        self.view_functions[endpoint] = view_func\n</code></pre>\n<p>在这里省略了<code>endpoint</code>和<code>method</code>的处理，<code>add_url_rule</code>主要工作是：</p>\n<ul>\n<li>使用<code>url_rule_class</code>构造了<code>werkzeug</code>的<code>Rule</code>对象，并添加到<code>url_map</code>数据结构中，这是<code>werkzeug</code>中的<code>Map</code>实例,在应用启用之前就已经实例化。</li>\n<li>在<code>werkzeug</code>路由分析中，我们知道<code>werkzeug</code>是不维护<code>endpoint</code>和<code>view_func</code>的映射的，在Flask中通过<code>view_functions</code>的字典来维护这种映射关系。注意：这里<code>endpoint</code>不同重复。</li>\n</ul>\n<h3 id=\"请求路径映射\"><a href=\"#请求路径映射\" class=\"headerlink\" title=\"请求路径映射\"></a>请求路径映射</h3><p>在之前的<code>应用启动流程</code>分析到<code>dispatch_request</code>转发请求，继续往下看：</p>\n<pre><code class=\"python\"> def dispatch_request(self):\n    req = _request_ctx_stack.top.request\n    if req.routing_exception is not None:\n        self.raise_routing_exception(req)\n    rule = req.url_rule\n    if getattr(rule, &#39;provide_automatic_options&#39;, False) \\\n        and req.method == &#39;OPTIONS&#39;:\n        return self.make_default_options_response()\n    return self.view_functions[rule.endpoint](**req.view_args)\n</code></pre>\n<p>请求URL分发到具体处理函数上，大致分为两个部分：</p>\n<ul>\n<li>从<code>请求上下文</code>中获取请求对象，其中包含匹配到的<code>Rule</code>实例。</li>\n<li>通过<code>view_functions</code>通过<code>rule.endpoint</code>反向查询到处理函数<code>view_func</code>，处理请求并返回响应。</li>\n</ul>\n<p>还有问题的是<code>请求上下文</code>以及如何从请求信息中找到匹配的<code>Rule</code>？</p>\n<p>在<code>wsgi_app</code>中，找到如下代码：</p>\n<pre><code class=\"python\">def wsgi_app(self, environ, start_response):\n    ctx = self.request_context(environ)\n    ctx.push()\n    pass\n\ndef request_context(self, environ):\n    return RequestContext(self, environ)\n</code></pre>\n<p>在每回请求到来的时候，Flask首先会构建请求上下文，在<code>RequestContext</code>中，首先在<code>url_map</code>通过绑定一些请求的路径参数来构建<code>MapAdapter</code>。有了<code>url_adapter</code>就可以通过<code>match()</code>找到匹配的<code>url_rule</code>和<code>view_args</code>(请求参数)。</p>\n<p>其中相关代码如下：</p>\n<pre><code class=\"python\">def create_url_adapter(self, request):\n    if request is not None:\n        return self.url_map.bind_to_environ(request.environ,\n            server_name=self.config[&#39;SERVER_NAME&#39;])\n    if self.config[&#39;SERVER_NAME&#39;] is not None:\n        return self.url_map.bind(\n            self.config[&#39;SERVER_NAME&#39;],\n            script_name=self.config[&#39;APPLICATION_ROOT&#39;] or &#39;/&#39;,\n            url_scheme=self.config[&#39;PREFERRED_URL_SCHEME&#39;])\n\ndef match_request(self):\n    try:\n        url_rule, self.request.view_args = \\\n            self.url_adapter.match(return_rule=True)\n        self.request.url_rule = url_rule\n    except HTTPException as e:\n        self.request.routing_exception = e\n</code></pre>\n<p>在请求路由过程中，怎么通过视图函数签名从请求信息中获取具体函数需要的请求参数？怎么进行URL的正则匹配？</p>\n<h2 id=\"Context机制\"><a href=\"#Context机制\" class=\"headerlink\" title=\"Context机制\"></a>Context机制</h2><p>Flask提供两种上下文环境，一个是应用上下文(Application Context)，二是请求上下文(Request Context)。</p>\n<p>Flask的全局变量定义在<code>globals.py</code>中，另外在<code>ctx.py</code>中实现了相应的上下文：</p>\n<pre><code class=\"python\">from functools import partial\nfrom werkzeug.local import LocalStack, LocalProxy\n\ndef _lookup_req_object(name):\n    top = _request_ctx_stack.top\n    if top is None:\n        raise RuntimeError(_request_ctx_err_msg)\n    return getattr(top, name)\n\ndef _lookup_app_object(name):\n    top = _app_ctx_stack.top\n    if top is None:\n        raise RuntimeError(_app_ctx_err_msg)\n    return getattr(top, name)\n\ndef _find_app():\n    top = _app_ctx_stack.top\n    if top is None:\n        raise RuntimeError(_app_ctx_err_msg)\n    return top.app\n\n_request_ctx_stack = LocalStack()\n_app_ctx_stack = LocalStack()\ncurrent_app = LocalProxy(_find_app)\nrequest = LocalProxy(partial(_lookup_req_object, &#39;request&#39;))\nsession = LocalProxy(partial(_lookup_req_object, &#39;session&#39;))\ng = LocalProxy(partial(_lookup_app_object, &#39;g&#39;))\n</code></pre>\n<p>Flask通过<code>werkzeug</code>的<code>LocalStack</code>实现了两个栈结构：</p>\n<ul>\n<li><code>_request_ctx_stack</code>：保存请求上下文<code>RequestContext</code>，演化出全局变量<code>request</code>和<code>session</code>。</li>\n<li><code>_app_ctx_stack</code>：存储应用上下文<code>AppContext</code>，衍生出全局变量<code>current_app</code>和<code>g</code>。</li>\n</ul>\n<p>Note：在这里再次回顾一点，<code>LocalStack</code>的<code>push</code>、<code>top</code>以及<code>pop</code>都是对于当前线程维护的一个栈上的操作。</p>\n<p>了解过<code>werkzeug</code>后，我们知道使用<code>LocalStack</code>和<code>LocalProxy</code>，<code>current_app</code>、<code>g</code>、<code>request</code>和<code>session</code>四个虽然是全局变量，但是可以在多线程的环境下线程安全的访问，每个线程获取的都是当前上下文中的内容。</p>\n<h3 id=\"请求上下文\"><a href=\"#请求上下文\" class=\"headerlink\" title=\"请求上下文\"></a>请求上下文</h3><p>我们先来看<code>RequestContext</code>的实现：</p>\n<pre><code class=\"python\">def __init__(self, app, environ, request=None):\n    self.app = app\n    if request is None:\n        request = app.request_class(environ)\n    self.request = request\n    self.url_adapter = app.create_url_adapter(self.request)\n    self.flashes = None\n    self.session = None\n    # 省略部分\n    self.match_request()\n\ndef _get_g(self):\n        return _app_ctx_stack.top.g\ndef _set_g(self, value):\n    _app_ctx_stack.top.g = value\ng = property(_get_g, _set_g)\ndel _get_g, _set_g\n\ndef __enter__(self):\n    _request_ctx_stack.push(self)\n\ndef __exit__(self, exc_type, exc_value, tb):\n    self.auto_pop(exc_value)\n    if BROKEN_PYPY_CTXMGR_EXIT and exc_type is not None:\n        reraise(exc_type, exc_value, tb)\n</code></pre>\n<p>由上面的实现的可知：</p>\n<ul>\n<li><code>RequestContext</code>对象有一些属性，存储了请求的全部信息。例如<code>app</code>、<code>request</code>、<code>session</code>、<code>g</code>。还有一个<code>url_adapter</code>属性以及<code>match_request</code>方法，用于URL匹配。</li>\n<li>另外它实现了<code>with</code>上下文管理协议，在<code>__enter__</code>中压栈，<code>__exit__</code>中出栈。</li>\n</ul>\n<p>我们知道当请求到达时，会执行一次请求上下文压栈操作：</p>\n<pre><code class=\"python\">def push(self):\n    app_ctx = _app_ctx_stack.top\n    if app_ctx is None or app_ctx.app != self.app:\n        app_ctx = self.app.app_context()\n        app_ctx.push()\n        self._implicit_app_ctx_stack.append(app_ctx)\n    else:\n        self._implicit_app_ctx_stack.append(None)\n\n    if hasattr(sys, &#39;exc_clear&#39;):\n        sys.exc_clear()\n\n    _request_ctx_stack.push(self)\n\n    self.session = self.app.open_session(self.request)\n    if self.session is None:\n        self.session = self.app.make_null_session()\n</code></pre>\n<p>当要将一个“请求上下文”推入<code>_request_ctx_stack</code>栈中的时候，会先检查另一个栈<code>_app_ctx_stack</code>的栈顶是否存在“应用上下文”对象或者栈顶的“应用上下文”对象的应用是否是当前应用。如果不存在或者不是当前对象，Flask会自动生成一个“应用上下文”对象，并将其推入<code>_app_ctx_stack</code>中。</p>\n<p>在离开上下文的时候：</p>\n<pre><code class=\"python\">def pop(self, exc=_sentinel):\n    app_ctx = self._implicit_app_ctx_stack.pop()\n    try:\n        clear_request = False\n        if not self._implicit_app_ctx_stack:\n            self.app.do_teardown_request(exc)\n\n            request_close = getattr(self.request, &#39;close&#39;, None)\n            if request_close is not None:\n                request_close()\n            clear_request = True\n    finally:\n        rv = _request_ctx_stack.pop()\n        if clear_request:\n            rv.request.environ[&#39;werkzeug.request&#39;] = None\n        if app_ctx is not None:\n            app_ctx.pop(exc)\n</code></pre>\n<p>当要离开以上“请求上下文”环境的时候，Flask会先将“请求上下文”对象从<code>_request_ctx_stack</code>栈中销毁，之后会根据实际的情况确定销毁“应用上下文”对象，并做清尾工作。</p>\n<p>以上这种逻辑的实现使得请求的处理始终在一个上下文环境，并且<code>LocalStack</code>可以很好的实现线程/协程的安全隔离。</p>\n<h3 id=\"应用上下文\"><a href=\"#应用上下文\" class=\"headerlink\" title=\"应用上下文\"></a>应用上下文</h3><p>先来看看<code>AppContext</code>的实现：</p>\n<pre><code class=\"python\">def __init__(self, app):\n    self.app = app\n    self.url_adapter = app.create_url_adapter(None)\n    self.g = app.app_ctx_globals_class()\n    self._refcnt = 0\n\ndef __enter__(self):\n    self.push()\n    return self\n\ndef __exit__(self, exc_type, exc_value, tb):\n    self.pop(exc_value)\n    if BROKEN_PYPY_CTXMGR_EXIT and exc_type is not None:\n        reraise(exc_type, exc_value, tb)\n</code></pre>\n<p>和请求上下文相似，应用上下文也实现了上下文管理协议，<code>push()</code>和<code>pop()</code>方法操作<code>_app_ctx_stack</code>。也有<code>app</code>、<code>url_adapter</code>和<code>g</code>属性。“应用上下文”存在的一个主要功能就是确定请求所在的应用。</p>\n<p>有两种方式创建应用上下文：</p>\n<ul>\n<li><p>第一种是隐式的：无论何时当一个请求上下文被压栈时， 如果有必要的话一个应用上下文会被一起创建。由于这个原因，你可以忽略应用上下文的存在，除非你需要它。在<code>RequestContext</code>的<code>push()</code>方法中找到了一下代码:</p>\n<pre><code class=\"python\">  app_ctx = _app_ctx_stack.top\n  if app_ctx is None or app_ctx.app != self.app:\n      app_ctx = self.app.app_context()\n      app_ctx.push()\n      self._implicit_app_ctx_stack.append(app_ctx)\n  else:\n      self._implicit_app_ctx_stack.append(None)\n</code></pre>\n</li>\n<li><p>第二种是显式地调用 <code>app.app_context()</code> 方法：</p>\n<pre><code class=\"python\">  rom flask import Flask, current_app\n  app = Flask(__name__)\n  with app.app_context():\n      # within this block, current_app points to app.\n      print current_app.name\n</code></pre>\n</li>\n</ul>\n<h3 id=\"思考\"><a href=\"#思考\" class=\"headerlink\" title=\"思考\"></a>思考</h3><p><strong>问题一：既然有了<code>RequestContext</code>，并且能够通过<code>_request_ctx_stack.top.app</code>获取到应用信息，为什么还需要<code>AppContext</code>?</strong></p>\n<p><strong>问题二：Web应用运行期间，一个线程只能处理一个请求，那么<code>req_ctx_stack</code>和<code>_app_ctx_stack</code>肯定只有一个栈顶元素，那么为什么还要使用“栈”数据结构呢?</strong></p>\n<p><strong>答：</strong> </p>\n<ul>\n<li><code>多App共存</code>：当在一个应用的请求上下文环境中，需要嵌套处理另一个应用的相关操作时，“请求上下文”显然就不能很好地解决问题了。在过去的做法是显示的传递应用，然而这种方式对于不是使用这种理念设计的库时遇到问题。通过使用<code>current_app</code>这种代理对象可以动态地通过当前应用上下文获取应用。</li>\n<li><code>非Web Runtime</code>：离线脚本或者测试这类非 Web 环境和和 Web 环境不同 —— 前者一般只在主线程运行。所以<code>App Context</code> 应该和 <code>Request Context</code> 分离。</li>\n</ul>\n<p>设想，在一个离线环境下，需要操作两个Flask APP关联的上下文，应该怎么办么？这个时候，栈这个数据结构的特性就体现出来了：</p>\n<pre><code class=\"python\">from biubiu.app import create_app\nfrom biubiu.admin.app import create_app as create_admin_app\n\napp = create_app()\nadmin_app = create_admin_app()\n\ndef copy_data():\n    with app.app_context():\n        data = read_data()  # fake function for demo\n        with admin_app.app_context():\n            write_data(data)  # fake function for demo\n        mark_data_copied()  # fake function for demo\n</code></pre>\n<h2 id=\"Flask对象\"><a href=\"#Flask对象\" class=\"headerlink\" title=\"Flask对象\"></a>Flask对象</h2><h3 id=\"Request\"><a href=\"#Request\" class=\"headerlink\" title=\"Request\"></a>Request</h3><p>在请求到来时，Flask将WSGI服务器传入的<code>environ</code>参数用<code>werkzeug</code>的<code>Request</code>类包装构造请求对象。生成<code>request</code>对象后，将它绑定在当前请求上下文上：<code>self.request = request</code>。这样就可以通过Context机制，暴露一个全局的访问当前请求对象的接口。</p>\n<h3 id=\"Response\"><a href=\"#Response\" class=\"headerlink\" title=\"Response\"></a>Response</h3><p>在<code>full_dispatch_request()</code>中，Flask通过路由执行相应的<code>view_func</code>获取返回，接下来调用了<code>finalize_request(rv)</code>来包装成响应。</p>\n<pre><code class=\"python\">\ndef finalize_request(self, rv, from_error_handler=False):\n    response = self.make_response(rv)\n    response = self.process_response(response)\n    request_finished.send(self, response=response)\n    return response\n</code></pre>\n<ol>\n<li><code>make_response(rv)</code>：根据视图函数返回值生成response对象。在内部可以根据不同的输入得到不同的输出，接收<code>str/unicode</code>、<code>tuple</code>、<code>WSGI function</code>和<code>Response</code>实例等等。</li>\n<li><code>process_response(response)</code>：在response发送给WSGI服务器前执行当前请求的后续<code>Hooks函数</code>(<code>after_request</code>和<code>after_app_request</code>)，还有就是<code>session</code>处理。</li>\n<li><code>request_finished.send(self, response=response)</code>：向特定的订阅者发送响应信息。</li>\n</ol>\n<h3 id=\"Session\"><a href=\"#Session\" class=\"headerlink\" title=\"Session\"></a>Session</h3><p><code>Session</code>需要在服务器保存客户端信息，将多次请求识别为一次会话。</p>\n<p>经过前面的分析，我们知道Flask有个全局变量<code>session</code>，它也是放在请求上下文中的。既然是多次请求，也就是说是不同的请求上下文，那么Flask是怎么保存<code>session</code>的呢？</p>\n<p>在<code>RequestContext.push()</code>的最后有这么一段代码：</p>\n<pre><code class=\"python\">self.session = self.app.open_session(self.request)\nif self.session is None:\n    self.session = self.app.make_null_session()\n</code></pre>\n<p>在上面Flask先是试图从请求中打开一个<code>session</code>，如果<code>session</code>不存在，那么将打开一个空的<code>session</code>。这个<code>NullSession</code>实例不能执行任何读写操作，否则将报异常。所有有关<code>session</code>的操作都转发到<code>self.session_interface</code>的方法调用上(对于用户来讲，可以扩展自<code>SessionInterface</code>定义自己的会话行为)。这里的<code>open_session()</code>默认转发到<code>SecureCookieSessionInterface.open_session()</code>上做处理，我们来到这里看具体实现：</p>\n<pre><code class=\"python\"> def open_session(self, app, request):\n    # 获取session签名的算法\n    s = self.get_signing_serializer(app)\n    if s is None:\n        return None\n    # 使用app中设置的session_cookie_name，从cookies中获取session标识\n    val = request.cookies.get(app.session_cookie_name)\n    if not val:\n        return self.session_class()\n    # 使用签名算法验证cookie，以及session有效性\n    max_age = total_seconds(app.permanent_session_lifetime)\n    try:\n        data = s.loads(val, max_age=max_age)\n        return self.session_class(data)\n    except BadSignature:\n        return self.session_class()\n</code></pre>\n<p>对于Flaks 的session处理有以下几个问题：</p>\n<ul>\n<li>怎么使用签名算法将<code>cookie</code>转化为<code>session</code>？</li>\n<li><code>session</code>是怎么构建的？</li>\n<li>怎么保存一个会话？</li>\n</ul>\n<p>对于第一个问题，签名算法是怎么工作的？我们在<code>get_signing_serializer</code>中找到了做加解密的具体实现。</p>\n<pre><code class=\"python\">def get_signing_serializer(self, app):\n    if not app.secret_key:\n        return None\n    signer_kwargs = dict(\n        key_derivation=self.key_derivation,\n        digest_method=self.digest_method\n    )\n    return URLSafeTimedSerializer(app.secret_key, salt=self.salt,\n                                serializer=self.serializer,\n                                signer_kwargs=signer_kwargs)\n</code></pre>\n<p>Flask默认使用<code>itsdangerous</code>模块中的<code>URLSafeTimedSerializer</code>类，这里需要许多参数：</p>\n<ul>\n<li><code>secret_key</code>：密钥。这个是必须的，如果没有配置 secret_key 就直接使用 session 会报错。</li>\n<li><code>salt</code>：盐。</li>\n<li><code>serializer</code>：序列化算法。</li>\n<li><code>signer_kwargs</code>：其他参数，包括摘要算法（默认是 sha1）和 签名算法（默认是 hmac）</li>\n</ul>\n<p>在<code>itsdangerous</code>模块中，有许多关于数据安全相关的算法实现以及各种做序列化<code>Serializer</code>。<code>URLSafeTimedSerializer</code>是使用Mixin模式实现的。</p>\n<p>对于第二个问题，Flask中<code>session</code>是<code>SecureCookieSession</code>的实例。</p>\n<pre><code class=\"python\">class SecureCookieSession(CallbackDict, SessionMixin):\n    def __init__(self, initial=None):\n        def on_update(self):\n            self.modified = True\n        CallbackDict.__init__(self, initial, on_update)\n        self.modified = False\n</code></pre>\n<p>可以看到，<code>SecureCookieSession</code>采用Mixin模式，继承自<code>CallbackDict</code>和<code>SessionMixin</code>。</p>\n<p>其中比较有趣的是，<code>CallbackDict</code>在数据更新的时候会回调<code>on_update()</code>，来表示<code>session</code>是否被修改了。对于应用程序来讲可以简单的把<code>session</code>当做字典处理。</p>\n<p>最后，我们来看下Flask是怎么保存一个<code>session</code>的。</p>\n<p>在<code>finalize_request</code>中会有个阶段对相应进行加工：<code>self.process_response(response)</code>，而这里面就会设计到<code>session</code>的保存：</p>\n<pre><code class=\"python\">if not self.session_interface.is_null_session(ctx.session):\n    self.save_session(ctx.session, response)\n</code></pre>\n<p>Flask首先会检查当前<code>session</code>是否为空，如果不为空，则保存<code>session</code>。<code>save_session()</code>和<code>open_session()</code>是对应的：</p>\n<pre><code class=\"python\">def save_session(self, app, session, response):\n    domain = self.get_cookie_domain(app)\n    path = self.get_cookie_path(app)\n\n    # 如果 session 被清空了，Flask 会直接删除对应的 cookie\n    if not session:\n        if session.modified:\n            response.delete_cookie(app.session_cookie_name,\n                                    domain=domain, path=path)\n        return\n\n    # 用户可以 `SESSION_REFRESH_EACH_REQUEST` 变量控制是否要设置 cookie\n    if not self.should_set_cookie(app, session):\n        return\n\n    # 若是 session 发生了变化，那么需要更新 cookie\n    httponly = self.get_cookie_httponly(app)\n    secure = self.get_cookie_secure(app)\n    expires = self.get_expiration_time(app, session)\n    val = self.get_signing_serializer(app).dumps(dict(session))\n    response.set_cookie(app.session_cookie_name, val,\n                        expires=expires,\n                        httponly=httponly,\n                        domain=domain, path=path, secure=secure)\n</code></pre>\n<p>这段代码主要是从<code>app</code>和<code>session</code>中获取相关信息，最后通过在响应中，保存<code>Cookie</code>，发送给客户端。</p>\n<p>从Flask对于<code>session</code>的处理，我们可以知道Flask的会话是基于Cookie实现的。这种方式和传统的使用Cookie保存会话标识（<code>session_id</code>）不同，Flask的会话是不在服务端保存用户数据的，所有的信息都在<code>Cookie</code>中，更像是<code>JWT</code>，符合”无状态“特性。不过需要权衡的是安全性问题。<code>flask-session</code> 这个三方的库，它就把数据保存在服务器端（本地文件、redis、memcached），客户端只拿到一个 <code>sessionid</code>。</p>\n<h2 id=\"Flask多应用，App-Factory\"><a href=\"#Flask多应用，App-Factory\" class=\"headerlink\" title=\"Flask多应用，App Factory\"></a>Flask多应用，App Factory</h2><h2 id=\"Flask-ext原理\"><a href=\"#Flask-ext原理\" class=\"headerlink\" title=\"Flask-ext原理\"></a>Flask-ext原理</h2><h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://docs.jinkan.org/docs/flask/index.html\" target=\"_blank\" rel=\"noopener\">Flask中文档</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://cizixs.com/2017/01/10/flask-insight-introduction\" target=\"_blank\" rel=\"noopener\">Flask源码解析</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://www.jianshu.com/p/7a7efbb7205f\" target=\"_blank\" rel=\"noopener\">Flask的Context机制</a></p>\n","categories":["Python"],"tags":["Python","源码","Flask"]},{"title":"一致性哈希算法","url":"http://shawnz.me/posts/b33c725c/","content":"<h2 id=\"背景\"><a href=\"#背景\" class=\"headerlink\" title=\"背景\"></a>背景</h2><p>在使用<code>n</code>台缓存服务器时，对资源<code>object</code>的请求使用<code>hash(object) mod n</code>来映射到某一台缓存服务器。</p>\n<p>当增加或减少一台缓存服务器时,由于<code>n</code>的改变导致缓存映射到另一台服务器上<code>hash(object) mod n&#39;</code>。也就意味着所有的缓存都失效了，这会使得缓存服务器大量集中地向原始内容服务器更新缓存。</p>\n<p>一致性hash的思想早在1997年就由MIT的Karger及其合作者提出来了,目标就是解决互联网中热点问题(缓存问题)。</p>\n<a id=\"more\"></a>\n<h2 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h2><p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义：</p>\n<ul>\n<li><p><code>平衡性(Balance)</code>：平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</p>\n</li>\n<li><p><code>单调性(Monotonicity)</code>：单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 </p>\n</li>\n<li><p><code>分散性(Spread)</code>：在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 </p>\n</li>\n<li><p><code>负载(Load)</code>：负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</p>\n</li>\n</ul>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>为了了解它的运作方式，我们先想像有一个 <code>hash values</code> 的空间 (Space)，其范围是 <code>0 ~ 2^32-1</code>，也就相当于 <code>4字节的无符号整数</code>(Unsigned integer) 的范围。我们把此 Space 看作一个依照顺时针方向递增的环 (<code>Consistent Hash Ring</code>)，如下图：</p>\n<p><img src=\"/images/consistent-hash-1.png\" alt=\"\"></p>\n<p>我们假设有三台服务器：<code>ServiceNode-1</code>，<code>ServiceNode-2</code>和<code>ServiceNode-3</code>。现在我们将这三台服务器以某种形式（一般情况下通过hash函数计算名称的key值）放在这个<code>Consistent Hash Ring</code>上，如图：</p>\n<p><img src=\"/images/consistent-hash-2.png\" alt=\"\"></p>\n<p>接下来我们关注的问题是：对于某个数据，通过它对应的一个key值找一个存放的缓存服务器。我们将数据的key以同样的hash函数映射到<code>Consistent Hash Ring</code>上，如下图绿色标识部分：</p>\n<p><img src=\"/images/consistent-hash-3.png\" alt=\"\"></p>\n<p>接着，<code>Consistent Hash</code>的做法是：<strong>沿着顺时针的方向走，遇到第一个Node</strong>。在这里我们沿着顺时针方向走，遇到的第一个节点是<code>ServiceNode-2</code>，即找到了这份数据对应的缓存服务器，如图土黄色标识部分：</p>\n<p><img src=\"/images/consistent-hash-4.png\" alt=\"\"></p>\n<p>现在，我们再来讨论增加和删除服务器节点的情况。</p>\n<p>假设，我们<code>增加</code>了一个新的缓存服务器结点<code>ServiceNode-4</code>，这种情况下，只有图中黄色区间的keys会因为新节点的加入而找到不同的服务器：</p>\n<p><img src=\"/images/consistent-hash-5.png\" alt=\"\"></p>\n<p>假设，我们<code>删除</code>了节点<code>ServiceNode-2</code>，那么只有图中黄色区间的keys因为节点的删除而映射到不同的服务器上：</p>\n<p><img src=\"/images/consistent-hash-6.png\" alt=\"\"></p>\n<p>如果服务器节点数很少，而它们的分布可能不均。如图所示，绿色区间的keys都映射到<code>ServiceNode-1</code>，只有一少部分keys映射到了<code>ServiceNode-2</code>：</p>\n<p><img src=\"/images/consistent-hash-7.png\" alt=\"\"></p>\n<p>经过上面的图解分析，我们知道一致性哈希算法满足了<code>单调性</code>和<code>负载均衡的特性</code>以及一般hash算法的<code>分散性</code>，但还缺乏一个重要的特性：<code>平衡性</code>。</p>\n<p><code>Consistent Hash</code>通过引入了<code>“虚拟节点”</code>的概念：</p>\n<p><code>“虚拟节点”</code>(virtual node)是实际节点(机器)在 hash 空间的复制品(replica)，一实际个节点(机器)对应了若干个<code>“虚拟节点”</code>，这个对应个数也成为“复制个数”，<code>“虚拟节点”</code>在 hash 空间中以hash值排列。</p>\n<p>在实际应用中，我们经常会搭配一些<code>虚拟节点</code>。</p>\n<p>在上面那种分布不均的情况下，我们假设每个节点都有四个复制品(replicas)，对于多出来的<code>虚拟节点</code>我们采用同样的方式映射到<code>Consistent Hash Ringing</code>上，那么多出来的区间实际还是映射到原有的服务器上：</p>\n<p><img src=\"/images/consistent-hash-8.png\" alt=\"\"></p>\n<h2 id=\"Python实现\"><a href=\"#Python实现\" class=\"headerlink\" title=\"Python实现\"></a>Python实现</h2><pre><code class=\"python\">import md5\nclass HashRing(object):\n    def __init__(self, nodes=None, replicas=3):\n        &quot;&quot;&quot;Manages a hash ring.\n        `nodes` is a list of objects that have a proper __str__ representation.\n        `replicas` indicates how many virtual points should be used pr. node,\n        replicas are required to improve the distribution.\n        &quot;&quot;&quot;\n        self.replicas = replicas\n        self.ring = dict()\n        self._sorted_keys = []\n        if nodes:\n            for node in nodes:\n                self.add_node(node)\n    def add_node(self, node):\n        &quot;&quot;&quot;Adds a `node` to the hash ring (including a number of replicas).\n        &quot;&quot;&quot;\n        for i in xrange(0, self.replicas):\n            key = self.gen_key(&#39;%s:%s&#39; % (node, i))\n            self.ring[key] = node\n            self._sorted_keys.append(key)\n        self._sorted_keys.sort()\n    def remove_node(self, node):\n        &quot;&quot;&quot;Removes `node` from the hash ring and its replicas.\n        &quot;&quot;&quot;\n        for i in xrange(0, self.replicas):\n            key = self.gen_key(&#39;%s:%s&#39; % (node, i))\n            del self.ring[key]\n            self._sorted_keys.remove(key)\n    def get_node(self, string_key):\n        &quot;&quot;&quot;Given a string key a corresponding node in the hash ring is returned.\n        If the hash ring is empty, `None` is returned.\n        &quot;&quot;&quot;\n        return self.get_node_pos(string_key)[0]\n    def get_node_pos(self, string_key):\n        &quot;&quot;&quot;Given a string key a corresponding node in the hash ring is returned\n        along with it&#39;s position in the ring.\n        If the hash ring is empty, (`None`, `None`) is returned.\n        &quot;&quot;&quot;\n        if not self.ring:\n            return None, None\n        key = self.gen_key(string_key)\n        nodes = self._sorted_keys\n        for i in xrange(0, len(nodes)):\n            node = nodes[i]\n            if key &lt;= node:\n                return self.ring[node], i\n        return self.ring[nodes[0]], 0\n    def get_nodes(self, string_key):\n        &quot;&quot;&quot;Given a string key it returns the nodes as a generator that can hold the key.\n        The generator is never ending and iterates through the ring\n        starting at the correct position.\n        &quot;&quot;&quot;\n        if not self.ring:\n            yield None, None\n        node, pos = self.get_node_pos(string_key)\n        for key in self._sorted_keys[pos:]:\n            yield self.ring[key]\n        while True:\n            for key in self._sorted_keys:\n                yield self.ring[key]\n    def gen_key(self, key):\n        &quot;&quot;&quot;Given a string key it returns a long value,\n        this long value represents a place on the hash ring.\n        md5 is currently used because it mixes well.\n        &quot;&quot;&quot;\n        m = md5.new()\n        m.update(key)\n        return long(m.hexdigest(), 16)\n</code></pre>\n","categories":["算法"],"tags":["Hash","算法"]},{"title":"Nginx反向代理","url":"http://shawnz.me/posts/dfa9b87c/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"反向代理\"><a href=\"#反向代理\" class=\"headerlink\" title=\"反向代理\"></a>反向代理</h2><p>反向代理（Reverse Proxy）方式是指用代理服务器来接受 internet 上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给 internet 上请求连接的客户端，此时代理服务器对外就表现为一个反向代理服务器。</p>\n<p>反向代理的典型用途是将防火墙后面的服务器提供给 Internet 用户访问，加强安全防护。反向代理还可以为后端的多台服务器提供负载均衡，或为后端较慢的服务器提供 缓冲 服务。另外，反向代理还可以启用高级 URL 策略和管理技术，从而使处于不同 web 服务器系统的 web 页面同时存在于同一个 URL 空间下。</p>\n<pre><code class=\"code\">                                                                   +-------------------+\n                                                                   |                   |\n                                                            +------&gt;   server 1        |\n+-------------+                                             |      |                   |\n|             +----------+                                  |      |                   |\n|  client 1   |          |                                  |      +-------------------+\n|             |          |                                  |\n+-------------+          |                                  |\n                         |         +------------------+     |      +-------------------+\n                         |         |                  |     |      |                   |\n+-------------+          |         |                  |     |      |   server 2        |\n|             |          |         |                  +------------&gt;                   |\n|  clent 2    +--------------------&gt;  reverse proxy   |     |      |                   |\n|             |          |         |                  |     |      +-------------------+\n+-------------+          |         |                  |     |\n                         |         |                  |     |               .\n      .                  |         |                  |     |               .\n      .                  |         +------------------+     |               .\n      .                  |                                  |\n                         |                                  |      +--------------------+\n+-------------+          |                                  |      |                    |\n|             |          |                                  |      |   server m         |\n|  client n   +----------+                                  +------&gt;                    |\n|             |                                                    |                    |\n+-------------+                                                    +--------------------+\n\n</code></pre>\n<p>Nginx 的其中一个用途是做 HTTP 反向代理，下面简单介绍 Nginx 作为反向代理服务器的方法。</p>\n<h2 id=\"简单的HTTP代理服务器\"><a href=\"#简单的HTTP代理服务器\" class=\"headerlink\" title=\"简单的HTTP代理服务器\"></a>简单的HTTP代理服务器</h2><pre><code class=\"Nginx\">user www www;\nworker_processes 8;\nerror_log /var/log/nginx/error.log info;\npid /var/run/nginx.pid;\nworker_rlimit_nofile 65535;\n\nevents\n{\n    use epoll;\n    worker_connections 65535;\n}\n\nhttp{\n\n    include mime.types; \n\n    client_header_buffer_size 16k;\n    large_client_header_buffers 4 32k;\n\n    sendfile on; \n\n    keepalive_timeout 120; \n\n    upstream { \n        server 192.168.80.121:80 weight=3; \n        server 192.168.80.122:80 weight=2; \n        server 192.168.80.123:80 weight=3;\n    }\n\n    server{ \n        listen 80;\n        server_name localhost; \n        default_type application/octet-stream; \n\n        charset utf-8; \n        location / { \n            root html; \n            index index.html index.htm; \n            // deny all; 拒绝请求，返回403 \n            // allow all; 允许请求\n        }\n\n        location /test/ { \n            deny all;\n        }\n\n        location ~/test/.+.jsp$ { \n            proxy_pass http://192.168.1.62:8080; \n        }\n\n        location ~.jsp$ { \n            proxy_pass http://192.168.1.61:8080; \n        }\n\n    }\n    error_page 404 /404.html;\n\n    error_page 500 502 503 504 /50x.html; \n    location = /50x.html { root html; }\n\n    error_page 403 @page403; \n    location @page403 { \n        proxy_pass http://http://www.baidu.com; \n    }\n\n}\n</code></pre>\n<h3 id=\"代理模块\"><a href=\"#代理模块\" class=\"headerlink\" title=\"代理模块\"></a>代理模块</h3><p><a href=\"http://shouce.jb51.net/nginx/\" target=\"_blank\" rel=\"noopener\">ngx_http_proxy_module模块配置选项</a></p>\n<h3 id=\"上游服务器\"><a href=\"#上游服务器\" class=\"headerlink\" title=\"上游服务器\"></a>上游服务器</h3><p>upstream定义一组上游服务器，实现负载均衡。</p>\n<p>指令：</p>\n<ul>\n<li><code>ip_hash</code>：这个指令将基于客户端连接的IP地址来分发请求。</li>\n<li><code>keepalive</code>：每个进程缓存到上游服务器的连接数。</li>\n<li><code>least_conn</code>：启用最少连接负载均衡算法。</li>\n<li><code>server</code>：为upstream定义一个服务器地址和可选的参数。<ul>\n<li><code>weight</code>：设置服务器权重，默认为1。</li>\n<li><code>max_fails</code>：在一定时间内（这个时间在fail_timeout参数中设置）检查这个服务器是否可用时产生的最多失败请求数，默认为1，将其设置为0可以关闭检查。</li>\n<li><code>fail_timeout</code>：指定了服务器不可用的时间（在下一次尝试连接请求发起之前），默认为10秒。</li>\n<li><code>down</code>：标记服务器处于离线状态，通常和<code>ip_hash</code>一起使用。</li>\n<li><code>backup</code>：(0.6.7或更高)如果所有的非备份服务器都宕机或繁忙，则使用本服务器（无法和ip_hash指令搭配使用）。</li>\n</ul>\n</li>\n</ul>\n<p>示例：</p>\n<pre><code class=\"Nginx\">upstream  backend  {\n    server   backend1.example.com    weight=5;\n    server   127.0.0.1:8080          max_fails=3  fail_timeout=30s;\n    server   unix:/tmp/backend3;\n}\n</code></pre>\n<h3 id=\"if控制\"><a href=\"#if控制\" class=\"headerlink\" title=\"if控制\"></a>if控制</h3><h3 id=\"错误页面\"><a href=\"#错误页面\" class=\"headerlink\" title=\"错误页面\"></a>错误页面</h3><p>可以使用错误页面来处理upstream的问题：</p>\n<pre><code class=\"Nginx\">http {\n    proxy_intercept_errors on;  #支持error_page指定400或更大的代码转向\n\n    upstream app {\n        server 127.0.0.1:9001;\n        server 107.0.0.1:9002;\n    }\n\n    server {\n        location / {\n            error_page 500 502 503 504 = @fallback;\n            error_page 400 403 404  /40x.html\n            proxy_pass http://app;\n        }\n\n        location @fallback {\n            proxy_pass http://www.baidu.com;\n        }\n\n        location /40x.html {\n            root /share/examples/nginx/html;\n        }\n    }\n}\n</code></pre>\n<h3 id=\"传递客户端信息\"><a href=\"#传递客户端信息\" class=\"headerlink\" title=\"传递客户端信息\"></a>传递客户端信息</h3><p>在使用代理服务器时，上游服务器不能直接从客户端获取信息。</p>\n<pre><code class=\"Nginx\">proxy_set_header X-Real-IP $remote_addr;\nproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\nproxy_ser_header Host $host;\n</code></pre>\n<h2 id=\"反向代理高级话题\"><a href=\"#反向代理高级话题\" class=\"headerlink\" title=\"反向代理高级话题\"></a>反向代理高级话题</h2><h3 id=\"安全\"><a href=\"#安全\" class=\"headerlink\" title=\"安全\"></a>安全</h3><p>Nginx可以通过编译选项<code>--with_http_ssl_module</code>支持<code>SSL连接</code>。</p>\n<p>示例</p>\n<pre><code class=\"Nginx\">server {\n    listen 80 default ssl;  # 激活SSL模块\n    server_name www.example.com;\n\n    ssl_prefer_server_ciphers on;\n    ssl_protocols TLSv1 SSLv3;\n    ssl_chiphers RC4:HIGH:!aNULL:!MD5:@STRENGTH;  #指定了希望客户端选择使用的密码列表\n    ssl_session_cacha shared:WEB:10m;  #shared(以便所有的worker进程能够从一次昂贵的SSL自动协商获益):缓存名称:大小\n    ssl_certificate /usr/local/etc/nginx/www.example.com.crt;  #指定证书\n    ssl_certificate_key /usr/local/etc/nginx/www.example.com.key;  #指定key\n\n    location / {\n        proxy_set_header X-FORWARDED-PROTO https;  # 为了使上游服务器认识到客户端使用了ssl\n        proxy_pass http://upstream;\n        # proxy_pass https://upstream 对上游服务器和代理使用SSL连接\n    }\n}\n</code></pre>\n<h3 id=\"性能\"><a href=\"#性能\" class=\"headerlink\" title=\"性能\"></a>性能</h3><h4 id=\"缓冲\"><a href=\"#缓冲\" class=\"headerlink\" title=\"缓冲\"></a>缓冲</h4><h4 id=\"缓存\"><a href=\"#缓存\" class=\"headerlink\" title=\"缓存\"></a>缓存</h4><h4 id=\"存储\"><a href=\"#存储\" class=\"headerlink\" title=\"存储\"></a>存储</h4><p>对于，这些文件不会改变的话，Nignx可以提供<strong>存储</strong>来更快的提供大的、静态文件。</p>\n<p>示例</p>\n<pre><code class=\"Nginx\">http {\n    proxy_tmp_path /var/www/tmp;\n\n    server {\n        root /var/www/data;\n\n        location /img {  #将会从/var/www/data/img下查找文件\n            error_page 404 = @store;  #如果没有找到，那么@store将会调用\n        }\n\n        location @store {\n            internal;\n            proxy_store on; #启用存储文件\n            proxy_store_access group:r all:r; #从上游服务器root路径查找，访问上游服务器后会在本地存储一份副本\n            proxy_pass http://upstream;\n        }\n    }\n}\n</code></pre>\n<h4 id=\"压缩\"><a href=\"#压缩\" class=\"headerlink\" title=\"压缩\"></a>压缩</h4><p>优化带宽可以减少响应的传输时间。<code>gzip</code>模块默认启用。</p>\n<p>示例</p>\n<pre><code class=\"Nginx\">http {\n    gzip on; #启用压缩\n    gzip_min_length 1024; #仅对大于1024字节文件压缩\n    gzip_buffers 40 4k; #默认缓冲值32个4k或16个8k，这里代表不能压缩大于40*4*1024=163840字节大小的文件\n    gzip_http_version 1.0; #高于该级别http版本启用压缩\n    gzip_comp_level 4; #压缩级别\n    gzip_types text/plain application/x-javascript application/json; #设置被压缩的MIME类型\n}\n</code></pre>\n","categories":["Linux"],"tags":["Linux","Nginx"]},{"title":"Nignx安装配置","url":"http://shawnz.me/posts/c2c092fa/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h2><h3 id=\"使用包管理器\"><a href=\"#使用包管理器\" class=\"headerlink\" title=\"使用包管理器\"></a>使用包管理器</h3><ul>\n<li><p>Linux(基于deb)</p>\n<p>  <code>sudo apt-get install nginx</code></p>\n</li>\n<li><p>Linux(基于rpm)</p>\n<p>  <code>sudo yum install nginx</code></p>\n</li>\n<li><p>FreeBSD</p>\n<p>  <code>sudo pkg_install -r nginx</code></p>\n</li>\n</ul>\n<h3 id=\"从源代码安装\"><a href=\"#从源代码安装\" class=\"headerlink\" title=\"从源代码安装\"></a>从源代码安装</h3><p>可以从<a href=\"http://nginx.org/en/download.html\" target=\"_blank\" rel=\"noopener\">http://nginx.org/en/download.html</a>下载Nignx<code>.tar.gz</code>安装包</p>\n<ol>\n<li><p>确认安装<code>gcc</code></p>\n</li>\n<li><p>安装<code>pcre</code>(Perl Compatible Regular Expression), 这是由于nginx <code>rewrite</code>和<code>HTTP</code>模块会使用到正则</p>\n<pre><code class=\"Nginx\"> yum list installed|grep pcre            #确认pcre是否安装\n yum list installed|grep pcre-devel        #确认pcre-devel是否安装\n\n yum install pcre                        #安装pcre \n yum install pcre-devel                    #安装pcre-devel\n</code></pre>\n</li>\n<li><p>安装<code>zlib</code></p>\n<pre><code class=\"Nginx\"> yum list installed|grep zlib            #确认zlib是否安装\n yum list installed|grep zlib-devel        #确认zlib-devel是否安装\n\n yum install zlib                        #安装zlib\n yum install zlib-devel                    #安装zlib-devel\n</code></pre>\n</li>\n<li><p>安装<code>openssl</code></p>\n<pre><code class=\"Nginx\"> yum list installed|grep openssl            #确认openssl是否安装\n yum list installed|grep openssl-devel    #确认openssl-devel是否安装\n\n yum install openssl                        #安装openssl\n yum install openssl-devel                #安装openssl-devel\n</code></pre>\n</li>\n<li><p>下载并解压缩nginx源码包, 这里使用的是 <code>nginx-1.8.0.tar.gz</code></p>\n</li>\n<li><p>配置(configuration), 编译(compilation)和安装(installation),这里我们采用默认方式</p>\n<pre><code class=\"Nginx\"> ./configure\n make &amp;&amp; make install\n</code></pre>\n</li>\n<li><p>配置环境变量. 在/<code>etc/profile</code>文件中添加，nginx 默认安装在 <code>/usr/local/nginx</code>, 配置文件默认为 <code>$NGINX/conf/nginx.conf</code></p>\n<pre><code class=\"Nginx\"> NGINX_HOME=/usr/local/nginx\n PATH=$PATH:$NGINX_HOME/sbin\n</code></pre>\n</li>\n</ol>\n<h2 id=\"编译选项\"><a href=\"#编译选项\" class=\"headerlink\" title=\"编译选项\"></a>编译选项</h2><h3 id=\"通用配置选项\"><a href=\"#通用配置选项\" class=\"headerlink\" title=\"通用配置选项\"></a>通用配置选项</h3><table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–prefix=\\&lt;path></td>\n<td>Nginx安装的根路径,所有其它路径都要依赖该选项</td>\n</tr>\n<tr>\n<td>–sbin-path=\\&lt;path></td>\n<td>指定nginx二进制文件的路径,没指定的话 这个路径依赖–prefix选项</td>\n</tr>\n<tr>\n<td>–conf-path=\\&lt;path></td>\n<td>如果在命令行未指定配置文件,那么将会通过这里指定的路径,nginx将会去那里查找他的配置文件</td>\n</tr>\n<tr>\n<td>–error-log-path=\\&lt;path></td>\n<td>错误文件路径,nginx写入错误日志文件地址,除非有其他配置</td>\n</tr>\n<tr>\n<td>–pid-path=\\&lt;path></td>\n<td>nginx master进程pid写入的文件位置,通常在var/run下</td>\n</tr>\n<tr>\n<td>–lock-path=\\&lt;path></td>\n<td>共享存储器互斥锁文件路径</td>\n</tr>\n<tr>\n<td>–user=\\&lt;user></td>\n<td>worker进程运行的用户</td>\n</tr>\n<tr>\n<td>–group=\\&lt;group></td>\n<td>worker进程运行的组</td>\n</tr>\n<tr>\n<td>–with-file-aio.</td>\n<td>为freeBSD4.3+和linux2.6.22+系统启用异步io</td>\n</tr>\n<tr>\n<td>–width-debug</td>\n<td>启用调试日志,生产环境不推荐</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"优化编译选项\"><a href=\"#优化编译选项\" class=\"headerlink\" title=\"优化编译选项\"></a>优化编译选项</h3><table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–with-cc=\\&lt;path></td>\n<td>如果想设置一个不在默认path下的c编译器</td>\n</tr>\n<tr>\n<td>–with-cpp=\\&lt;path></td>\n<td>设置c预处理器的相对路径</td>\n</tr>\n<tr>\n<td>–with-cc-opt=\\&lt;options></td>\n<td>指定必要的include文件路径</td>\n</tr>\n<tr>\n<td>–with-ld-opt=\\&lt;options></td>\n<td>包含连接库的路径和运行路径</td>\n</tr>\n<tr>\n<td>-with-cpu-opt=\\&lt;cpu></td>\n<td>通过该选项为特定cpu构建nginx</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"邮件代理的配置选项\"><a href=\"#邮件代理的配置选项\" class=\"headerlink\" title=\"邮件代理的配置选项\"></a>邮件代理的配置选项</h3><table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–with-mail</td>\n<td>激活POP3/IMAP4/SMTP代理模块,默认未激活</td>\n</tr>\n<tr>\n<td>–with-mail_ssl_module</td>\n<td>允许ngx_mail_ssl_module模块 这个模块使得POP3／IMAP／SMTP可以使用SSL／TLS.配置已经定义了HTTP SSL模块，但是不支持客户端证书检测</td>\n</tr>\n<tr>\n<td>–without-mail_pop3_module</td>\n<td>启用mail模块后,单独禁用pop3模块</td>\n</tr>\n<tr>\n<td>–without-mail_imap_module</td>\n<td>启用mail模块后,单独禁用imap模块</td>\n</tr>\n<tr>\n<td>–without-mail_smtp_module</td>\n<td>启用mail模块后,单独禁用smtp模块</td>\n</tr>\n<tr>\n<td>–without-http</td>\n<td>完全禁用http模块,如果只想支持mall,可以使用此项设置</td>\n</tr>\n<tr>\n<td>–with-openssl=DIR</td>\n<td>设定OpenSSL库文件路径</td>\n</tr>\n</tbody>\n</table>\n<p><strong>对于典型的mail代理，推荐的Nignx配置为：</strong></p>\n<p><code>./configure --with-mail  --with-mail_ssl_module  --with-openssl=${BUILD_DIR}/openssl-1.0.1c</code></p>\n<h3 id=\"指定路径的配置选项\"><a href=\"#指定路径的配置选项\" class=\"headerlink\" title=\"指定路径的配置选项\"></a>指定路径的配置选项</h3><table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–without-http-cache</td>\n<td>在使用upstream模块时,nginx能够配置本地缓存内容,此选项可禁用缓存</td>\n</tr>\n<tr>\n<td>–with-http_perl_module</td>\n<td>这个模块允许nginx使用SSI调用perl或直接执行perl(使用会降低性能)</td>\n</tr>\n<tr>\n<td>–with-perl_modules_path=PATH</td>\n<td>设置perl模块路径(perl解析器路径)</td>\n</tr>\n<tr>\n<td>–with-perl_modules_path=PATH</td>\n<td>设置perl模块路径</td>\n</tr>\n<tr>\n<td>–http-log-path=PATH</td>\n<td>设置access log文件路径</td>\n</tr>\n<tr>\n<td>–http-client-body-temp-path=PATH</td>\n<td>设置客户端请求临时文件路径，如果WebDAV启用,推荐设置该路径为同一文件系统上的目录作为最终的目的地</td>\n</tr>\n<tr>\n<td>–http-proxy-temp-path=PATH</td>\n<td>使用代理后,设置http proxy临时文件路径</td>\n</tr>\n<tr>\n<td>–http-fastcgi-temp-path=PATH</td>\n<td>设置FastCGI临时文件路径</td>\n</tr>\n<tr>\n<td>–http-uwsgi-temp-path=PATH</td>\n<td>设置uWSGI临时文件目录</td>\n</tr>\n<tr>\n<td> –http-scgi-temp-path=PATH</td>\n<td>设置SCGI临时文件目录</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"使用各种模块\"><a href=\"#使用各种模块\" class=\"headerlink\" title=\"使用各种模块\"></a>使用各种模块</h3><table>\n<thead>\n<tr>\n<th>选项</th>\n<th>解释</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>–with-http_ssl_module</td>\n<td>如果需要对流量加密.可使用此选项,在urls中开始部分将会是https(需要openssl库)</td>\n</tr>\n<tr>\n<td>–with-http_realip_module</td>\n<td>允许ngx_http_realip_module模块(mod_rpaf)<br>此模块支持显示真实来源IP地址，主要用于NGINX做前端负载均衡服务器使用,<br>如果你的nginx在七层负载均衡器或者其它设备之后,它们将Http头中的客户端ip地址传递,这时需要启用此模块,在多个客户处于一个ip地址的情况下使用</td>\n</tr>\n<tr>\n<td>–with-http_addition_module</td>\n<td>作为一个输出过滤器,使你能够在请求经过一个location前或后时在该location本身添加内容</td>\n</tr>\n<tr>\n<td>–with-http_xslt_module</td>\n<td>这个模块是一个过滤器，它可以通过XSLT模板转换XML应答</td>\n</tr>\n<tr>\n<td>–with-http_image_filter_module</td>\n<td>图像过滤器,在将图像投递到客户之前进行处理(需要libgd库)</td>\n</tr>\n<tr>\n<td>–with-http_geoip_module</td>\n<td>使用该模块,能够设置设置个中变量以便在配置区段中使用</td>\n</tr>\n<tr>\n<td>–with-http_sub_module</td>\n<td>允许ngx_http_sub_module模块<br>这个模块可以能够在nginx的应答中搜索并替换文本</td>\n</tr>\n<tr>\n<td>–with-http_dav_module</td>\n<td>允许ngx_http_dav_module模块(mod_dav)<br>为文件和目录指定权限，限制不同类型的用户对于页面有不同的操作权限</td>\n</tr>\n<tr>\n<td>–with-http_flv_module</td>\n<td>允许ngx_http_flv_module模块(mod_flvx)<br>这个模块支持对FLV（flash）文件的拖动播放</td>\n</tr>\n<tr>\n<td>–with-http_mp4_module</td>\n<td>支持H.264/AAC文件为伪流媒体</td>\n</tr>\n<tr>\n<td>-with-http_gzip_static_module</td>\n<td>允许ngx_http_gzip_static_module模块(mod_dflate)<br>这个模块在一个预压缩文件传送到开启Gzip压缩的客户端之前检查是否已经存在以“.gz”结尾的压缩文件，这样可以防止文件被重复压缩</td>\n</tr>\n<tr>\n<td>–with-http_gunzip_module</td>\n<td>对于不支持gzip编码的客户,该模块用于为客户解压缩预压缩内容</td>\n</tr>\n<tr>\n<td>–with-http_random_index_module</td>\n<td>允许ngx_http_random_index_module模块(mod_autoindex)，从目录中选择一个随机主页</td>\n</tr>\n<tr>\n<td>–with-http_secure_link_module</td>\n<td>该模块提供一种机制,它会将一个哈希值链接到一个url中,因此,只有那些使用正确的密码能够计算链接</td>\n</tr>\n<tr>\n<td>–with-http_stub_status_module</td>\n<td>这个模块可以取得一些nginx的运行状态，如果是工业状况，可以直接取消<br>输出的状态信息科使用RRDtool或类似的工具绘制成图</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"启动和停止\"><a href=\"#启动和停止\" class=\"headerlink\" title=\"启动和停止\"></a>启动和停止</h2><p>nginx操作命令通过 -s 来指定: </p>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>nginx -c /path/to/nginx.conf</td>\n<td>启动nginx</td>\n</tr>\n<tr>\n<td>nginx -s reload</td>\n<td>修改配置后重新加载生效</td>\n</tr>\n<tr>\n<td>nginx -s reopen</td>\n<td>重新打开日志文件</td>\n</tr>\n<tr>\n<td>nginx -t -c /path/to/nginx.conf</td>\n<td>测试nginx配置文件是否正确</td>\n</tr>\n<tr>\n<td>nginx -s stop</td>\n<td>快速停止nginx</td>\n</tr>\n<tr>\n<td>nginx -s quit</td>\n<td>完整有序的停止nginx</td>\n</tr>\n<tr>\n<td>kill -TERM 主进程号</td>\n<td>快速停止nginx</td>\n</tr>\n<tr>\n<td>kill -QUIT 主进程号</td>\n<td>从容停止Nginx</td>\n</tr>\n<tr>\n<td>pkill -9 nginx</td>\n<td>强制停止Nginx</td>\n</tr>\n<tr>\n<td>kill -HUP 主进程号</td>\n<td>平滑重启nginx</td>\n</tr>\n</tbody>\n</table>\n<p><strong>注意: nginx命令执行前都会解析配置文件,判断是否有效.因此当无效的情况下, nginx命令会执行不了. 比如停止命令如果配置文件有误则可能停止不了nginx, 这可以通过kill或killall命令来停止nginx进程</strong></p>\n<h2 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h2><h3 id=\"Nignx-配置文件\"><a href=\"#Nignx-配置文件\" class=\"headerlink\" title=\"Nignx 配置文件\"></a>Nignx 配置文件</h3><p>基本的Nginx配置文件由若干部分组成，每个部分都由下列方法定义：</p>\n<pre><code>&lt;section&gt; {\n    &lt;directive&gt; &lt;parameters&gt;\n}\n</code></pre><p>Nginx配置是有一系列指令(Directive)组成的。指令以分号(;)分隔。指令可以被分块(block)，这被称为模块。模块用大括号包裹，模块可以递归包含模块 。<code>include</code>指令可以将配置分散到不同的文件中。指令可以继承和覆盖(即子模块可以继承父模块的指令, 也可以覆盖父模块的指令)</p>\n<p>nginx配置文件主要分为六个区域，每个部分都包含若干指令： </p>\n<ul>\n<li><code>main</code>：main部分设置的指令将影响其它所有部分的设置，相当于全局设置；</li>\n<li><code>events</code>：指定nginx的工作模式和工作模式及连接数上限</li>\n<li><code>http</code>：负责HTTP服务器相关属性的配置<ul>\n<li><code>sever</code>：主要用于指定主机和端口，设置网站，例如虚拟主机</li>\n<li><code>location</code>：用于匹配网页位置，就是匹配网页的路径，匹配到的路径可以做一些事情，例如反代。</li>\n<li><code>upstream</code>：主要用于负载均衡，设置一系列的后端服务器；</li>\n</ul>\n</li>\n</ul>\n<p>最外面的块是 <code>main</code>，<code>main</code> 包含 <code>events</code>和<code>http</code>，<code>http</code>包含 <code>upstream</code> 和多个 <code>server</code>，<code>server</code>又包含多个<code>location</code>。</p>\n<p>其中<code>server</code>继承<code>main</code>，<code>location</code>继承<code>server</code>，<code>upstream</code>既不会继承其他设置也不会被继承。</p>\n<p>同时每个部分还可以使用其他<code>http</code>模块指令，例如<code>http ssl</code>模块、<code>http gzip static</code>模块和<code>http addition</code>模块等。</p>\n<p><img src=\"/images/nignx-configuration.png\" alt=\"\"></p>\n<h3 id=\"通用\"><a href=\"#通用\" class=\"headerlink\" title=\"通用\"></a>通用</h3><p>配置文件样板<code>nginx.conf</code>：</p>\n<pre><code class=\"Nginx\">#定义Nginx运行的用户和用户组\nuser www www;\n\n#nginx进程数，建议设置为等于CPU总核心数。\nworker_processes 8;\n\n#全局错误日志定义类型，[ debug | info | notice | warn | error | crit ]\nerror_log /var/log/nginx/error.log info;\n\n#进程文件\npid /var/run/nginx.pid;\n\n#一个nginx进程打开的最多文件描述符数目，\n#理论值应该是最多打开文件数（系统的值ulimit -n）与nginx进程数相除，\n#但是nginx分配请求并不均匀，所以建议与ulimit -n的值保持一致。\nworker_rlimit_nofile 65535;\n\n#工作模式与连接数上限\nevents\n{\n    #参考事件模型，use [ kqueue | rtsig | epoll | /dev/poll | select | poll ];\n    #epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型，如果跑在FreeBSD上面，就用kqueue模型。\n    use epoll;\n    #单个进程最大连接数（最大连接数=连接数*进程数）\n    worker_connections 65535;\n}\n\n#设定http服务器\nhttp\n{\n    include mime.types; #文件扩展名与文件类型映射表\n    default_type application/octet-stream; #默认文件类型\n    #charset utf-8; #默认编码\n    server_names_hash_bucket_size 128; #服务器名字的hash表大小\n    client_header_buffer_size 32k; #上传文件大小限制\n    large_client_header_buffers 4 64k; #设定请求缓\n    client_max_body_size 8m; #设定请求缓\n    #开启高效文件传输模式，sendfile指令指定nginx是否调用sendfile函数来输出文件，对于普通应用设为 on，\n    #如果用来进行下载等应用磁盘IO重负载应用，可设置为off，以平衡磁盘与网络I/O处理速度，降低系统的负载。\n    #注意：如果图片显示不正常把这个改成off。\n    sendfile on; \n    autoindex on; #开启目录列表访问，合适下载服务器，默认关闭。\n    tcp_nopush on; #防止网络阻塞\n    tcp_nodelay on; #防止网络阻塞\n    keepalive_timeout 120; #长连接超时时间，单位是秒\n\n    #FastCGI相关参数是为了改善网站的性能：减少资源占用，提高访问速度。下面参数看字面意思都能理解。\n    fastcgi_connect_timeout 300;\n    fastcgi_send_timeout 300;\n    fastcgi_read_timeout 300;\n    fastcgi_buffer_size 64k;\n    fastcgi_buffers 4 64k;\n    fastcgi_busy_buffers_size 128k;\n    fastcgi_temp_file_write_size 128k;\n\n    #gzip模块设置\n    gzip on; #开启gzip压缩输出\n    gzip_min_length 1k; #最小压缩文件大小\n    gzip_buffers 4 16k; #压缩缓冲区\n    gzip_http_version 1.0; #压缩版本（默认1.1，前端如果是squid2.5请使用1.0）\n    gzip_comp_level 2; #压缩等级\n    gzip_types text/plain application/x-javascript text/css application/xml;\n    #压缩类型，默认就已经包含text/html，所以下面就不用再写了，写上去也不会有问题，但是会有一个warn。\n    gzip_vary on;\n    #limit_zone crawler $binary_remote_addr 10m; #开启限制IP连接数的时候需要使用\n\n    upstream opstrip.com {\n        #upstream的负载均衡，weight是权重，可以根据机器配置定义权重。\n        #weigth参数表示权值，权值越高被分配到的几率越大。\n        server 10.12.80.121:80 weight=3;\n        server 10.12.80.122:80 weight=2;\n        server 10.12.80.123:80 weight=3;\n    }\n\n    #虚拟主机的配置\n    server\n    {\n        #监听端口\n        listen 80;\n        #域名可以有多个，用空格隔开\n        server_name opstrip.com www.opstrip.com;\n        index index.html index.htm index.php;\n        root /var/www/opstrip.com;\n        location ~ .*.(php|php5)?$\n        {\n            fastcgi_pass 127.0.0.1:9000;\n            fastcgi_index index.php;\n            include fastcgi.conf;\n        }\n        #图片缓存时间设置\n        location ~ .*.(gif|jpg|jpeg|png|bmp|swf)$\n        {\n            expires 10d;\n        }\n        #JS和CSS缓存时间设置\n        location ~ .*.(js|css)?$\n        {\n            expires 1h;\n        }\n        #日志格式设定\n        log_format access &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;\n        &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;\n        &#39;&quot;$http_user_agent&quot; $http_x_forwarded_for&#39;;\n        #定义本虚拟主机的访问日志\n        access_log /var/log/nginx/ha97access.log access;\n\n        #对 &quot;/&quot; 启用反向代理\n        location / {\n            proxy_pass http://127.0.0.1:88;\n            proxy_redirect off;\n            proxy_set_header X-Real-IP $remote_addr;\n            #后端的Web服务器可以通过X-Forwarded-For获取用户真实IP\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            #以下是一些反向代理的配置，可选。\n            proxy_set_header Host $host;\n            client_max_body_size 10m; #允许客户端请求的最大单文件字节数\n            client_body_buffer_size 128k; #缓冲区代理缓冲用户端请求的最大字节数，\n            proxy_connect_timeout 90; #nginx跟后端服务器连接超时时间(代理连接超时)\n            proxy_send_timeout 90; #后端服务器数据回传时间(代理发送超时)\n            proxy_read_timeout 90; #连接成功后，后端服务器响应时间(代理接收超时)\n            proxy_buffer_size 4k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小\n            proxy_buffers 4 32k; #proxy_buffers缓冲区，网页平均在32k以下的设置\n            proxy_busy_buffers_size 64k; #高负荷下缓冲大小（proxy_buffers*2）\n            proxy_temp_file_write_size 64k;\n            #设定缓存文件夹大小，大于这个值，将从upstream服务器传\n        }\n\n        #设定查看Nginx状态的地址\n        location /NginxStatus {\n            stub_status on;\n            access_log on;\n            auth_basic &quot;NginxStatus&quot;;\n            auth_basic_user_file conf/htpasswd;\n            #htpasswd文件的内容可以用apache提供的htpasswd工具来产生。\n        }\n\n        #本地动静分离反向代理配置\n        #所有jsp的页面均交由tomcat或resin处理\n        location ~ .(jsp|jspx|do)?$ {\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_pass http://127.0.0.1:8080;\n        }\n        #所有静态文件由nginx直接读取不经过tomcat或resin\n        location ~ .*.(htm|html|gif|jpg|jpeg|png|bmp|swf|ioc|rar|zip|txt|flv|mid|doc|ppt|pdf|xls|mp3|wma)$\n        { expires 15d; }\n        location ~ .*.(js|css)?$\n        { expires 1h; }\n    }\n}\n</code></pre>\n<h3 id=\"main模块\"><a href=\"#main模块\" class=\"headerlink\" title=\"main模块\"></a>main模块</h3><p>main区域，他是一个全局的设置，这一部分应该放在<code>nginx.conf</code>最顶部。</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>user</td>\n<td>使用这个参数来配置worker进程的用户和组。<br>如果忽略group，那么group的名字等于该参数指定的用户的用户组</td>\n</tr>\n<tr>\n<td>worker_processes</td>\n<td>指定worker进程启动的数量。这些进程用于处理客户的连接。<br>选择一个正确的数量取决于服务器环境、磁盘子系统和网络基础设施。<br>一个好的经验法则是设置该参数的值与CPU绑定的负载处理器核心的数量相同，并用1.5～2之间的数乘以这个数作为I/O密集型负载</td>\n</tr>\n<tr>\n<td>error_log</td>\n<td>error_log是所有错误写入的文件。如果在其他区段中没有设置其他的error_log，那么这个日志文件将会记录所有的错误。<br>该指令的第二个参数指定了被记录错误的级别（debug，info，notice，warn，error，crit，alert，emerg）。<br>注意，debug级别的错误只有在编译时配置了–with-debug选项才可以使用</td>\n</tr>\n<tr>\n<td>pid</td>\n<td>设置记录主进程ID的文件，这个配置将会覆盖编译时的默认配置</td>\n</tr>\n<tr>\n<td>use</td>\n<td>该指令用于指示使用什么样的连接方法，这个配置将会覆盖编译时的默认配置，如果配置该指令，那么需要一个events区段。<br>通常不需要覆盖，除非是当编译时的默认值随着时间的推移产生错误时才需要被覆盖设置</td>\n</tr>\n<tr>\n<td>worker_connections</td>\n<td>该指令配置一个工作进程能够接受并发连接的最大数。这个连接包括，客户连接和向上游服务器的连接，但并不限于此。<br>这对于反向代理服务器尤为重要，为了达到这个并发性连接数量，需要在操作系统层面进行一些额外调整</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"event模块\"><a href=\"#event模块\" class=\"headerlink\" title=\"event模块\"></a>event模块</h3><p>events模块来用指定nginx的工作模式和工作模式及连接数上限，一般是这样：</p>\n<h3 id=\"http模块\"><a href=\"#http模块\" class=\"headerlink\" title=\"http模块\"></a>http模块</h3><p>http模块可以说是最核心的模块，这部分指令用于处理HTTP连接，负责HTTP服务器相关属性的配置。<br>将这些指令划分为不同的类型</p>\n<h4 id=\"客户端指令\"><a href=\"#客户端指令\" class=\"headerlink\" title=\"客户端指令\"></a>客户端指令</h4><p>用于处理客户端连接本身的各个方面，以及不同类型的客户端</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>chunked_transfer_encoding</td>\n<td>在发给客户端的响应中允许禁用http/1.1标准的块传输编码</td>\n</tr>\n<tr>\n<td>client_body_buffer_size</td>\n<td>为了阻止临时文件写到磁盘，可以通过该指令为客户端请求体设置缓存大小，默认的缓存大小为两个内存页面</td>\n</tr>\n<tr>\n<td>client_body_in_file_only</td>\n<td>用于调试或者是进一步处理客户端请求体。该指令能够将客户端请求体强制写入到磁盘文件</td>\n</tr>\n<tr>\n<td>client_body_in_single_buffer</td>\n<td>为了减少拷贝的操作，使用该指令强制Nginx将整个客户端请求体保存到单个缓存中</td>\n</tr>\n<tr>\n<td>client_body_temp_path</td>\n<td>定义一个命令路径用于保存客户端请求体</td>\n</tr>\n<tr>\n<td>clent_body_timeout</td>\n<td>指定客户端成功读取的两个操作之间的时间间隔</td>\n</tr>\n<tr>\n<td>client_header_buffer_size</td>\n<td>为客户端请求头指定一个缓存大小，当请求头大于1kB时会用到这个设置。</td>\n</tr>\n<tr>\n<td>client_header_timeout</td>\n<td>读取整个客户端头的超时时间</td>\n</tr>\n<tr>\n<td>client_max_body_size</td>\n<td>定义允许最大的客户端请求头，如果大于该值，那么客户端将会是413（request entity too large）错误</td>\n</tr>\n<tr>\n<td>keepalive_disable</td>\n<td>对某些类型的客户端禁用keep-alive请求功能。</td>\n</tr>\n<tr>\n<td>keepalive_requests</td>\n<td>定义在一个keep-alive关闭之前可以接收多少个请求</td>\n</tr>\n<tr>\n<td>keepalive_timeout</td>\n<td>指定keep-alive连接持续多久。第二个参数用于在响应头中这只”Keep-Alive”头</td>\n</tr>\n<tr>\n<td>large_client_header_buffers</td>\n<td>定义最大数量和最大客户端请求头的大小</td>\n</tr>\n<tr>\n<td>msie_padding</td>\n<td>为了填充响应的大小至512字节，对于MSIE客户端，大于400的状态码会被添加注释以便满足512字节，通过启用该命令可以阻止这种行为</td>\n</tr>\n<tr>\n<td>msie_refresh</td>\n<td>对于MSIE客户端，可启用发送一个refresh头</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"文件I-O指令\"><a href=\"#文件I-O指令\" class=\"headerlink\" title=\"文件I/O指令\"></a>文件I/O指令</h4><p>用于控制Nginx如何投递静态文件。</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>aio</td>\n<td>启用异步文件I/O。FreeBSD系统下，该值可能被用于sendfile预加载数据。Linux下需要directio指令，自动禁用sendfile</td>\n</tr>\n<tr>\n<td>directio</td>\n<td>用于启用操作系统特定的标识或者功能提供大于给定参数的文件。Linux下使用aio时需要使用该指令。</td>\n</tr>\n<tr>\n<td>directio_alignment</td>\n<td>设置directio算法。默认值是512，通常已经足够，但是在Linux的XFS下推荐增加至4K</td>\n</tr>\n<tr>\n<td>open_file_cache</td>\n<td>配置一个缓存用于存放打开的文件描述符、目录查询和文件查询错误</td>\n</tr>\n<tr>\n<td>open_file_cache_errors</td>\n<td>按照open_file_cache，启用文件查询错误缓存</td>\n</tr>\n<tr>\n<td>open_file_cache_min_uses</td>\n<td>open_file_cache缓存的文件描述符保留在缓存中，使用该指令配置最少使用文件描述符的次数</td>\n</tr>\n<tr>\n<td>open_file_cache_valid</td>\n<td>指定对open_file_cache缓存有效性检查的时间间隔</td>\n</tr>\n<tr>\n<td>postpone_output</td>\n<td>指定Nginx发送给客户端最小的数值，如果可能的话，没有数据会发送，直到达到此值</td>\n</tr>\n<tr>\n<td>read_ahead</td>\n<td>如果可能的话，内核将预读文件到设定的参数大小</td>\n</tr>\n<tr>\n<td>sendfile</td>\n<td>使用sendfile（2）直接复制数据从一个到另一个文件描述符</td>\n</tr>\n<tr>\n<td>sendfile_max_chunk</td>\n<td>设置在一个sendfile(2)拷贝中最大数据的大小，这是为了阻止worker”贪婪”</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"Hash指令\"><a href=\"#Hash指令\" class=\"headerlink\" title=\"Hash指令\"></a>Hash指令</h4><p>控制Nginx 分配给某些变量多大的静态文件</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>server_names_hash_bucket_size</td>\n<td>指定用于保存server_name哈希表大小的”桶”</td>\n</tr>\n<tr>\n<td>server_names_hash_max_size</td>\n<td>指定的server_name哈希表的最大值的大小</td>\n</tr>\n<tr>\n<td>types_hash_bucket_size</td>\n<td>指定用于存放哈希表的”桶”的大小</td>\n</tr>\n<tr>\n<td>types_hash_max_size</td>\n<td>指定哈希类型表的最大值的大小</td>\n</tr>\n<tr>\n<td>variables_hash_bucket_size</td>\n<td>指定用于存放保留变量”桶”的大小</td>\n</tr>\n<tr>\n<td>variables_hash_max_size</td>\n<td>指定存放保留变量最大哈希值的大小</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"Socket指令\"><a href=\"#Socket指令\" class=\"headerlink\" title=\"Socket指令\"></a>Socket指令</h4><p>描述Nginx如何设置创建TCP套接字的变量选项</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>lingering_close</td>\n<td>指定如何保持客户端的连接，以便用于更多数据的传输</td>\n</tr>\n<tr>\n<td>lingering_time</td>\n<td>在使用lingering_close指令的连接中，使用该指令指定客户端连接为了处理更多的数据需要保持打开连接的时间</td>\n</tr>\n<tr>\n<td>lingering_timeout</td>\n<td>结合lingering_close，该指令显示Nginx在关闭客户端连接之前，为获得更多数据会等待多久</td>\n</tr>\n<tr>\n<td>reset_timeout_connection</td>\n<td>使用这个指令之后，超时的连接会被立即关闭，释放相关的内存。默认的状态是处于FIN_WAIT1，这种状态将会一直保持连接</td>\n</tr>\n<tr>\n<td>send_lowat</td>\n<td>如果非零，Nginx将会在客户端套接字尝试减少发送操作</td>\n</tr>\n<tr>\n<td>send_timeout</td>\n<td>在两次成功的客户端接收响应的写操作之间设置一个超时时间</td>\n</tr>\n<tr>\n<td>tcp_nodelay</td>\n<td>启用或禁用TCP_NODELAY选项，用于keep-alive连接</td>\n</tr>\n<tr>\n<td>tcp_nopush</td>\n<td>仅依赖于sendfile的使用。它能够使Nginx在一个数据包中尝试发送响应头，以及在数据包中发送一个完整的文件</td>\n</tr>\n</tbody>\n</table>\n<h4 id=\"虚拟server部分\"><a href=\"#虚拟server部分\" class=\"headerlink\" title=\"虚拟server部分\"></a>虚拟server部分</h4><p>这部分称为“虚拟服务器”，描述的是一组根据<code>server_name</code>指令逻辑分割的资源。</p>\n<p>一个虚拟服务器由<code>listen</code>和<code>server_name</code>组合定义：</p>\n<pre><code class=\"Nginx\">server {\n    listen 80;\n    server_name _;\n}\n</code></pre>\n<p><strong><code>listen</code></strong></p>\n<ul>\n<li>说明: 绑定IP地址和端口, 用于socket连接</li>\n<li>范围: server</li>\n<li>格式: listen [address][:port] [additional options]; additional option包括:<ul>\n<li>default_server: 配置时,则当使用IP和Port请求,指到此虚拟主机</li>\n<li>ssl: 通道走ssl连接</li>\n<li>spdy: 当nginx spdy模块存在,则激活spdy协议</li>\n<li>proxy_protocol: 对所有连接激活PROXY协议</li>\n</ul>\n</li>\n<li>示例<pre><code class=\"Nginx\">listen 192.168.1.1:80;\nlisten 127.0.0.1;\nlisten 80 default;\nlisten [:::a8c9:1234]:80; # IPv6 addresses must be put between square brackets\nlisten 443 ssl;\n</code></pre>\n</li>\n</ul>\n<p><strong><code>server_name</code></strong></p>\n<ul>\n<li>说明: 配置虚拟主机名称，支持正则表达式配置，默认值为“”。如果没有一个server_name和请求域名匹配. 则根据listen指令的配置找到第一个匹配项，比如如下的配置项:<pre><code class=\"Nginx\">server{\n  listen 80;\n  server_name www.aaa.com;\n}\nserver{\n  listen 80;\n  server_name www.bbb.com;\n}\n</code></pre>\n  请求为 <a href=\"http://www.ccc.com:80/index.html\" target=\"_blank\" rel=\"noopener\">http://www.ccc.com:80/index.html</a>, 按照上面说明, 匹配第一个虚拟主机</li>\n<li>范围: server</li>\n<li>格式: server_name hostname1 [hostname2…];</li>\n<li>示例：<pre><code class=\"Nginx\">server_name www.website.com;\nserver_name www.website.com website.com;\nserver_name *.website.com;\nserver_name .website.com; # combines both *.website.com and website.com\nserver_name *.website.*;\nserver_name ~^(www)\\.example\\.com$; # $1 = www\n</code></pre>\n</li>\n</ul>\n<p>对于一个特定的请求，确定哪些虚拟服务器提供该请求的服务时，应该遵循下面的逻辑：</p>\n<ol>\n<li>匹配IP地址和<code>listen</code>指令指定的端口；</li>\n<li>将Host头字段作为一个字符串匹配<code>server_name</code>指令；</li>\n<li>将Host头字段与<code>server_name</code>指令字符串的开始部分做匹配。</li>\n<li>将Host头字段与<code>server_name</code>指令字符串的尾部分做匹配。</li>\n<li>将Host头字段与<code>server_name</code>指令进行正则表达式匹配。</li>\n<li>如果所有Host头字段匹配失败，那么将转向<code>listen</code>指令标记的<code>default_server</code>。</li>\n<li>若果所有将Host头字段匹配失败，且没有<code>defaul_server</code>，那么将转向第一个server的<code>listen</code>指令，以满足第一步。</li>\n</ol>\n<h4 id=\"location部分\"><a href=\"#location部分\" class=\"headerlink\" title=\"location部分\"></a>location部分</h4><p><code>location</code>指令可以用在虚拟服务器<code>server</code>部分，并意味着提供来自客户端的URL或者内部重定向。</p>\n<p>定义：</p>\n<pre><code class=\"Nginx\">location [modifier] uri {\n\n}\n</code></pre>\n<p>或者命名location，用于内部重定向：</p>\n<pre><code class=\"Nginx\">location @name {\n\n}\n</code></pre>\n<p>location修饰符：</p>\n<table>\n<thead>\n<tr>\n<th>修饰符</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>=</td>\n<td>使用精确匹配并且终止搜索</td>\n</tr>\n<tr>\n<td>~</td>\n<td>区分大小写的正则表达式匹配</td>\n</tr>\n<tr>\n<td>~*</td>\n<td>不去分大小写的正则表达式匹配</td>\n</tr>\n<tr>\n<td>\\^~</td>\n<td>如果该location是最佳的匹配，那么对于匹配这个location的字符串不在进行正则表达式检测。</td>\n</tr>\n</tbody>\n</table>\n<p>当一个请求进入时，URI将会检测匹配一个最佳的location(这里的匹配是指解码URI)：</p>\n<ul>\n<li>没有正则表达式的location被视作最佳匹配。</li>\n<li>在配置文件中按照查找顺序进行正则表达式匹配。</li>\n</ul>\n<p>仅用于location的指令：</p>\n<table>\n<thead>\n<tr>\n<th>指令</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>alias</td>\n<td>定义location的其他名字，在文件系统中能够找到。</td>\n</tr>\n<tr>\n<td>internal</td>\n<td>指定一个仅用于内部请求的location（其他指定定义的重定向，rewrite请求，error请求等）</td>\n</tr>\n<tr>\n<td>limit_except</td>\n<td>限定一个location可以执行的Http操作（如，GET或HEAD）</td>\n</tr>\n</tbody>\n</table>\n<p>location指令一般搭配try_files指令使用：</p>\n<pre><code class=\"Nginx\">location / {\n    try_files $uri $uri/ @mongrel;\n}\n\nlocation @mongrel {\n    proxy_pass http://appserver;\n}\n</code></pre>\n<p>这里有一个隐含的目录索引：<br>如果给定的URI作为一个文件没有找到，那么将会通过代理被传递到appserver。</p>\n<p>除以下前缀外，location可以被嵌套：</p>\n<ul>\n<li>具有 “=” 前缀。</li>\n<li>具名location。</li>\n</ul>\n<h4 id=\"内置全局变量\"><a href=\"#内置全局变量\" class=\"headerlink\" title=\"内置全局变量\"></a>内置全局变量</h4><ul>\n<li><code>$$args</code>：这个变量等于请求行中的参数，同\\$query_string</li>\n<li><code>$content_length</code>： 请求头中的Content-length字段。</li>\n<li><code>$content_type</code>： 请求头中的Content-Type字段。</li>\n<li><code>$document_root</code>： 当前请求在root指令中指定的值。</li>\n<li><code>$host</code>： 请求主机头字段，否则为服务器名称。</li>\n<li><code>$http_user_agent</code>： 客户端agent信息</li>\n<li><code>$http_cookie</code>： 客户端cookie信息</li>\n<li><code>$limit_rate</code>： 这个变量可以限制连接速率。</li>\n<li><code>$request_method</code>： 客户端请求的动作，通常为GET或POST。</li>\n<li><code>$remote_addr</code>： 客户端的IP地址。</li>\n<li><code>$remote_port</code>： 客户端的端口。</li>\n<li><code>$remote_user</code>： 已经经过Auth Basic Module验证的用户名。</li>\n<li><code>$request_filename</code>： 当前请求的文件路径，由root或alias指令与URI请求生成。</li>\n<li><code>$scheme</code>： HTTP方法（如http，https）。</li>\n<li><code>$server_protocol</code>： 请求使用的协议，通常是HTTP/1.0或HTTP/1.1。</li>\n<li><code>$server_addr</code>： 服务器地址，在完成一次系统调用后可以确定这个值。</li>\n<li><code>$server_name</code>： 服务器名称。</li>\n<li><code>$server_port</code>： 请求到达服务器的端口号。</li>\n<li><code>$request_uri</code>： 包含请求参数的原始URI，不包含主机名，如：”/foo/bar.php?arg=baz”。</li>\n<li><code>$uri</code>： 不带请求参数的当前URI，uri不包含主机名，如”/foo/bar.html”。</li>\n<li><code>$$document_uri</code>： 与\\$uri相同。</li>\n</ul>\n<h4 id=\"其他常用指令\"><a href=\"#其他常用指令\" class=\"headerlink\" title=\"其他常用指令\"></a>其他常用指令</h4><ul>\n<li><p><strong>set</strong></p>\n<p>  设置指定变量的值。变量的值可以包含文本，变量或者是它们的组合形式。</p>\n</li>\n<li><p><strong>if</strong></p>\n<p>  依据指定的条件决定是否执行 if 块语句中的内容。</p>\n<p>  范围：<code>server</code>，<code>location</code></p>\n<p>  if指令中的几种判断条件</p>\n<ul>\n<li>一个<code>变量</code>，如果变量 $variable 的值为空字符串或者字符串”0”，则为false</li>\n<li><code>变量</code>与一个字符串的比较 相等为(=) 不相等为(!=) 注意此处不要把相等当做赋值语句啊</li>\n<li><code>变量</code>与一个正则表达式的模式匹配 操作符可以是(~ 区分大小写的正则匹配， ~<em>不区分大小写的正则匹配， !~ !~</em>，前面两者的非)</li>\n<li>检测文件是否存在 使用 <code>-f</code>(存在) 和 <code>!-f</code>(不存在)</li>\n<li>检测路径是否存在 使用 <code>-d</code>(存在) 和 <code>!-d</code>(不存在) 后面判断可以是字符串也可是变量</li>\n<li>检测文件、路径、或者链接文件是否存在 使用 <code>-e</code>(存在) 和 <code>!-e</code>(不存在) 后面判断可以是字符串也可是变量</li>\n<li><p>检测文件是否为可执行文件 使用 <code>-x</code>(可执行) 和 <code>!-x</code>(不可执行) 后面判断可以是字符串也可是变量</p>\n<pre><code class=\"Nginx\">set $variable &quot;0&quot;; \nif ($variable) {\n  # 不会执行，因为 &quot;0&quot; 为 false\n  break;            \n}\n\n# 使用变量与正则表达式匹配 没有问题\nif ( $http_host ~ &quot;^star\\.igrow\\.cn$&quot; ) {\n  break;            \n}\n\n# 字符串与正则表达式匹配 报错\nif ( &quot;star&quot; ~ &quot;^star\\.igrow\\.cn$&quot; ) {\n  break;            \n}\n# 检查文件类的 字符串与变量均可\nif ( !-f &quot;/data.log&quot; ) {\n  break;            \n}\n\nif ( !-f $filename ) {\n  break;            \n}\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p><strong>return</strong></p>\n<p>  范围：server，location，if</p>\n<p>  停止处理并将指定的code码返回给客户端。 非标准code码 444 关闭连接而不发送响应报头。</p>\n<p>  从0.8.42版本开始， <code>return</code> 语句可以指定重定向 url (状态码可以为如下几种 301,302,303,307),<br>  也可以为其他状态码指定响应的文本内容，并且重定向的url和响应的文本可以包含变量。</p>\n<p>  有一种特殊情况，就是重定向的url可以指定为此服务器本地的url，这样的话，nginx会依据请求的协议<code>$scheme</code>， <code>server_name_in_redirect</code> 和 <code>port_in_redirect</code>自动生成完整的 url。</p>\n<pre><code class=\"Nginx\">  # return code [text]; 返回 ok 给客户端\n  location = /ok {\n      return 200 &quot;ok&quot;;\n  }\n\n  # return code URL; 临时重定向到 百度\n  location = /redirect {\n      return 302 http://www.baidu.com;\n  }\n\n  # return URL; 和上面一样 默认也是临时重定向\n  location = /redirect {\n      return http://www.baidu.com;\n  }\n</code></pre>\n</li>\n<li><p><strong>rewrite</strong></p>\n<p>  范围：server，location，if</p>\n<p>  格式：rewrite regex replacement [flag];</p>\n<p>  rewrite 指令是使用指定的正则表达式regex来匹配请求的urI，如果匹配成功，则使用replacement更改URI。rewrite指令按照它们在配置文件中出现的顺序执行。可以使用flag标志来终止指令的进一步处理。如果替换字符串replacement以http：//，https：//或$ scheme开头，则停止处理后续内容，并直接重定向返回给客户端。</p>\n<p>  rewrite 的四个 flag：</p>\n<ul>\n<li><code>last</code>：停止处理当前的ngx_http_rewrite_module的指令集，并开始搜索与更改后的URI相匹配的location;</li>\n<li><code>break</code>：停止处理当前的ngx_http_rewrite_module指令集，就像上面说的break指令一样;</li>\n<li><code>redirect</code>：返回302临时重定向。</li>\n<li><p><code>permanent</code>：返回301永久重定向。</p>\n<p><code>last</code>和<code>break</code>的区别：</p>\n<p><code>last</code> 和 <code>break</code>一样 它们都会终止此 <code>location</code> 中其他它<code>rewrite</code>模块指令的执行，<br>但是 <code>last</code> 立即发起新一轮的 <code>location</code> 匹配 而 <code>break</code> 则不会</p>\n<pre><code class=\"Nginx\">location / {\n  rewrite ^/test1 /test2;\n  rewrite ^/test2 /test3 last;  # 此处发起新一轮location匹配 uri为/test3\n  rewrite ^/test3 /test4;\n  proxy_pass http://www.baidu.com;\n}\n\nlocation = /test2 {\n  return 200 &quot;/test2&quot;;\n}  \n\nlocation = /test3 {\n  return 200 &quot;/test3&quot;;\n}\nlocation = /test4 {\n  return 200 &quot;/test4&quot;;\n}\n# 发送如下请求\n# curl 127.0.0.1:8080/test1\n# /test3 \n\n当如果将上面的 location / 改成如下代码\nlocation / {\n  rewrite ^/test1 /test2;\n  # 此处 不会 发起新一轮location匹配；当是会终止执行后续rewrite模块指令 重写后的uri为 /more/index.html\n  rewrite ^/test2 /more/index.html break;  \n  rewrite /more/index\\.html /test4; # 这条指令会被忽略\n\n  # 因为 proxy_pass 不是rewrite模块的指令 所以它不会被 break终止\n  proxy_pass https://www.baidu.com;\n}\n# 发送如下请求\n# 浏览器输入 127.0.0.1:8080/test1 \n# 代理到 百度产品大全页面 https://www.baidu.com/more/index.html;\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p><strong>rewrite_log</strong></p>\n<p>  开启或者关闭 <code>rewrite</code>模块指令执行的日志，如果开启，则重写将记录下<code>notice</code>等级的日志到nginx 的 <code>error_log</code>中，默认为关闭 <code>off</code></p>\n</li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://www.nginx.com/resources/wiki/start/\" target=\"_blank\" rel=\"noopener\">Nignx Configuration</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://openresty.org/download/agentzh-nginx-tutorials-zhcn.html#02-NginxDirectiveExecOrder01\" target=\"_blank\" rel=\"noopener\">agentzh 的Nignx教程</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://shouce.jb51.net/nginx/\" target=\"_blank\" rel=\"noopener\">Nginx中文参考手册</a></p>\n","categories":["Linux"],"tags":["Linux","Nignx"]},{"title":"Nignx工作原理","url":"http://shawnz.me/posts/d0c41e91/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"What-is-Nginx\"><a href=\"#What-is-Nginx\" class=\"headerlink\" title=\"What is Nginx?\"></a>What is Nginx?</h2><p><img src=\"/images/nignx.png\" alt=\"\"></p>\n<p>Nignx最初的设计是成为一个能够解决C10K问题的HTTP服务器，为了实现这个目标Nginx通过基于事件的处理机制并且操作系统也要使用相应的事件机制。Nignx同时也可以作为反向代理服务器，电子邮件（IMAP/POP3）代理服务器。</p>\n<p>到 2013 年，目前有很多国内网站采用 Nginx 作为 Web 服务器，如国内知名的新浪、163、腾讯、Discuz、豆瓣等。</p>\n<p>Nginx 因为它的稳定性、丰富的模块库、灵活的配置和低系统资源的消耗而闻名。</p>\n<p>Nginx 做为 HTTP 服务器，有以下几项基本特性：</p>\n<ul>\n<li>处理静态文件，索引文件以及自动索引；打开文件描述符缓冲。</li>\n<li>无缓存的反向代理加速，简单的负载均衡和容错。</li>\n<li>FastCGI，简单的负载均衡和容错。</li>\n<li>模块化的结构。包括 gzipping, byte ranges, chunked responses,以及 SSI-filter 等 filter。如果由 FastCGI 或其它代理服务器处理单页中存在的多个 SSI，则这项处理可以并行运行，而不需要相互等待。</li>\n<li>支持 SSL 和 TLSSNI。</li>\n</ul>\n<h2 id=\"Nignx-架构\"><a href=\"#Nignx-架构\" class=\"headerlink\" title=\"Nignx 架构\"></a>Nignx 架构</h2><p><img src=\"/images/nignx-struct.png\" alt=\"\"></p>\n<h3 id=\"Nignx-多进程模型\"><a href=\"#Nignx-多进程模型\" class=\"headerlink\" title=\"Nignx 多进程模型\"></a>Nignx 多进程模型</h3><p>Nginx 在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。我们也可以手动地关掉后台模式，让 Nginx 在前台运行，并且通过配置让 Nginx 取消 master 进程，从而可以使 Nginx 以单进程方式运行（一般用来调试）。当然 Nginx 也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是 Nginx 的默认方式。</p>\n<p>Nginx 在启动后，会有一个 master 进程和多个 worker 进程。</p>\n<p>master 进程主要用来管理 worker 进程，包含：</p>\n<ul>\n<li>接收来自外界的信号</li>\n<li>向各 worker 进程发送信号</li>\n<li>监控 worker 进程的运行状态，当 worker 进程退出后(异常情况下)，会自动重新启动新的 worker 进程。</li>\n</ul>\n<p>而基本的网络事件，则是放在 worker 进程中来处理了。</p>\n<ul>\n<li>多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。</li>\n<li>一个请求，只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。</li>\n<li>worker 进程的个数是可以设置的，一般我们会设置与机器 cpu 核数一致。</li>\n</ul>\n<h4 id=\"响应信号\"><a href=\"#响应信号\" class=\"headerlink\" title=\"响应信号\"></a>响应信号</h4><p>master 进程会接收来自外界发来的信号，再根据信号做不同的事情。</p>\n<p>要控制 Nginx，只需要通过 kill 向 master 进程发送信号就行了。比如<code>kill -HUP pid</code>，则是告诉 Nginx，从容地重启 Nginx，一般用这个信号来重启 Nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。</p>\n<p>Nginx 在 0.8 版本之后，引入了一系列命令行参数，来方便我们管理。比如，<code>./nginx -s reload</code>，就是来重启 Nginx(不会中断服务)，<code>./nginx -s stop</code>，就是来停止 Nginx 的运行。</p>\n<h3 id=\"Nignx事件模型\"><a href=\"#Nignx事件模型\" class=\"headerlink\" title=\"Nignx事件模型\"></a>Nignx事件模型</h3><p>传统的Web服务器下，一个请求由一个进程消费，请求在建立连接后将始终占用着系统资源，直到连接关闭才会释放资源。</p>\n<p>在Nginx中，接收到一个请求时，不会产生一个单独的进程来处理该请求，而是由事件收集、分发器（进程）调用某个模块，由模块处理请求，处理完后再返回到事件收集、分发器。</p>\n<p>在Nginx 的工作进程中主要关注的事件是 IO 网络事件和定时器事件：</p>\n<ul>\n<li>对于 IO 处理，Nignx默认采用 epoll 模型。将需要监听的socket加入到epoll中后，通过<code>epoll_wait</code>获取已发生的事件，避免对众多的socket进行轮寻。<a href=\"/posts/22c73ece/\" title=\"点击阅读《网络I/O模型》\">点击阅读《网络I/O模型》</a></li>\n<li>定时器采用红黑数实现，每个定时器事件以超时时间为key插入到红黑树中，每次取红黑树中key最小的结点与当前的系统时间比较即可知道是否超时。</li>\n</ul>\n<h4 id=\"处理请求\"><a href=\"#处理请求\" class=\"headerlink\" title=\"处理请求\"></a>处理请求</h4><p>前面有提到，worker 进程之间是平等的，每个进程，处理请求的机会也是一样的。当我们提供 80 端口的 http 服务时，当内核accept一个连接时，会唤醒所有在等待中的进程，但实际只有一个进程能获取连接，其他进程都被无效唤醒（“惊群效应”）。Nignx是怎么处理的呢？</p>\n<p>首先，每个 worker 进程都是从 master 进程 fork 过来，在 master 进程里面，先建立好需要 listen 的 socket（listenfd）之后，然后再 fork 出多个 worker 进程。</p>\n<p>所有 worker 进程的 listenfd 会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢 accept_mutex（全局锁），抢到互斥锁的那个进程注册 listenfd 读事件，在读事件里调用 accept 接受该连接。</p>\n<p>当一个 worker 进程在 accept 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。</p>\n<h4 id=\"定时器\"><a href=\"#定时器\" class=\"headerlink\" title=\"定时器\"></a>定时器</h4><p>在Nginx事件循环中除了要处理所有的从epoll中获取的事件之外，还要处理一些timer事件。</p>\n<p>Nignx通过红黑树来维护所有的timer节点，在worker进程的每一次循环中都会调用<code>ngx_process_events_and_timers</code>函数，在该函数中就会调用处理定时器的函数<code>ngx_event_expire_timers</code>，每次该函数都不断的从红黑树中取出时间值最小的，获取超时时间。如果超时则执行他们的函数，若没有超时则对epoll_wait加上超时时间，防止阻塞过长时间，妨碍定时器执行。直到取出的节点的时间没有超时为止。</p>\n<p>Nignx在处理事件循环的时候，总是先判断是否超时，然后在处理网络请求。可以用一段伪代码描述Nignx事件处理模型：</p>\n<pre><code class=\"code\">while (true) {\n    for t in run_tasks:\n        t.handler();\n    update_time(&amp;now);\n    timeout = ETERNITY;\n    for t in wait_tasks: /* sorted already */\n        if (t.time &lt;= now) {\n            t.timeout_handler();\n        } else {\n            timeout = t.time - now;\n            break;\n        }\n    nevents = poll_function(events, timeout);\n    for i in nevents:\n        task t;\n        if (events[i].type == READ) {\n            t.handler = read_handler;\n        } else { /* events[i].type == WRITE */\n            t.handler = write_handler;\n        }\n        run_tasks_add(t);\n}\n</code></pre>\n<h3 id=\"Nignx-模块化体系\"><a href=\"#Nignx-模块化体系\" class=\"headerlink\" title=\"Nignx 模块化体系\"></a>Nignx 模块化体系</h3><p>Nginx的内部结构是由核心部分和一系列功能模块组成的，这样可以使得每个模块的功能相对简单，便于对系统进行功能扩展，各模块之间的关系如下图：</p>\n<p><img src=\"/images/nignx-modules.png\" alt=\"\"></p>\n<p>Nginx 将各功能模块组织成一条链，当有请求到达的时候，请求依次经过这条链上的部分或者全部模块，进行处理。</p>\n<p>有两个模块比较特殊，他们居于 Nginx core 和各功能模块的中间。这两个模块就是 http 模块和 mail 模块。这 2 个模块在 Nginx core 之上实现了另外一层抽象，处理与 HTTP 协议和 Email 相关协议（SMTP/POP3/IMAP）有关的事件，并且确保这些事件能被以正确的顺序调用其他的一些功能模块。</p>\n<h4 id=\"模块分类\"><a href=\"#模块分类\" class=\"headerlink\" title=\"模块分类\"></a>模块分类</h4><p>Nginx 的模块根据其功能基本上可以分为以下几种类型：</p>\n<ul>\n<li><code>event module</code>: 搭建了独立于操作系统的事件处理机制的框架，及提供了各具体事件的处理。包括 ngx_events_module， ngx_event_core_module和ngx_epoll_module 等。Nginx 具体使用何种事件处理模块，这依赖于具体的操作系统和编译选项。</li>\n<li><code>phase handler</code>: 此类型的模块也被直接称为 handler 模块。主要负责处理客户端请求并产生待响应内容，比如 ngx_http_static_module 模块，负责客户端的静态页面请求处理并将对应的磁盘文件准备为响应内容输出。通常 phase handler 是与定义在配置文件中的某个 location 相关联的。</li>\n<li><code>output filter</code>: 也称为 filter 模块，主要是负责对输出的内容进行处理，可以对输出进行修改。例如，可以实现对输出的所有 html 页面增加预定义的 footbar 一类的工作，或者对输出的图片的 URL 进行替换之类的工作。</li>\n<li><code>upstream</code>: upstream 模块实现反向代理的功能，将真正的请求转发到后端服务器上，并从后端服务器上读取响应，发回客户端。upstream 模块是一种特殊的 handler，只不过响应内容不是真正由自己产生的，而是从后端服务器上读取的。</li>\n<li><code>load-balancer</code>: 负载均衡模块，实现特定的算法，在众多的后端服务器中，选择一个服务器出来作为某个请求的转发服务器。</li>\n<li><code>extend module</code>：根据特定业务需要编写的第三方模块。</li>\n</ul>\n<h4 id=\"HTTP-Request处理过程\"><a href=\"#HTTP-Request处理过程\" class=\"headerlink\" title=\"HTTP Request处理过程\"></a>HTTP Request处理过程</h4><p>Nginx将一个HTTP请求分成多个阶段，以模块为单位进行处理。</p>\n<p>从 Nginx 的内部来看，一个HTTPRequest的处理过程涉及到以下几个阶段。</p>\n<ul>\n<li>初始化HTTPRequest（读取来自客户端的数据，生成HTTPRequest对象，该对象含有该请求所有的信息）。</li>\n<li>处理请求头。</li>\n<li>处理请求体。</li>\n<li>如果有的话，调用与此请求（URL或者Location）关联的handler。</li>\n<li>依次调用各phasehandler进行处理。</li>\n</ul>\n<p><img src=\"/images/nginx-request-process-model.png\" alt=\"\"></p>\n<p>当Nginx读取到一个HTTPRequest的header的时候，Nginx首先查找与这个请求关联的虚拟主机的配置。如果找到了这个虚拟主机的配置，那么通常情况下，这个HTTPRequest将会经过以下几个阶段的处理（phasehandlers）：</p>\n<ul>\n<li><strong>NGX_HTTP_POST_READ_PHASE</strong>：读取请求内容阶段</li>\n<li><strong>NGX_HTTP_SERVER_REWRITE_PHASE</strong>：Server请求地址重写阶段</li>\n<li><strong>NGX_HTTP_FIND_CONFIG_PHASE</strong>：配置查找阶段：</li>\n<li><strong>NGX_HTTP_REWRITE_PHASE</strong>：Location请求地址重写阶段</li>\n<li><strong>NGX_HTTP_POST_REWRITE_PHASE</strong>：请求地址重写提交阶段</li>\n<li><strong>NGX_HTTP_PREACCESS_PHASE</strong>：访问权限检查准备阶段</li>\n<li><strong>NGX_HTTP_ACCESS_PHASE</strong>：访问权限检查阶段</li>\n<li><strong>NGX_HTTP_POST_ACCESS_PHASE</strong>：访问权限检查提交阶段</li>\n<li><strong>NGX_HTTP_TRY_FILES_PHASE</strong>：配置项try_files处理阶段</li>\n<li><strong>NGX_HTTP_CONTENT_PHASE</strong>：内容产生阶段</li>\n<li><strong>NGX_HTTP_LOG_PHASE</strong>：日志模块处理阶段</li>\n</ul>\n<p>在内容产生阶段，为了给一个request产生正确的响应，Nginx必须把这个request交给一个合适的contenthandler去处理。如果这个request对应的location在配置文件中被明确指定了一个contenthandler，那么Nginx就可以通过对location的匹配，直接找到这个对应的handler，并把这个request交给这个contenthandler去处理。这样的配置指令包括像，perl，flv，proxy_pass，mp4等。</p>\n<p>如果一个request对应的location并没有直接有配置的contenthandler，那么Nginx依次尝试:</p>\n<ul>\n<li>如果一个location里面有配置random_indexon，那么随机选择一个文件，发送给客户端。</li>\n<li>location里面有配置index指令，那么发送index指令指明的文件，给客户端。</li>\n<li>如果一个location里面有配置autoindexon，那么就发送请求地址对应的服务端路径下的文件列表给客户端。</li>\n<li>如果这个request对应的location上有设置gzip_staticon，那么就查找是否有对应的.gz文件存在，有的话，就发送这个给客户端（客户端支持gzip的情况下）。</li>\n<li>请求的URI如果对应一个静态文件，staticmodule就发送静态文件的内容到客户端。</li>\n</ul>\n<p>内容产生阶段完成以后，生成的输出会被传递到filter模块去进行处理。filter模块也是与location相关的。所有的fiter模块都被组织成一条链。输出会依次穿越所有的filter，直到有一个filter模块的返回值表明已经处理完成。</p>\n<p>这里列举几个常见的filter模块，例如：</p>\n<ul>\n<li>server-sideincludes。</li>\n<li>XSLTfiltering。</li>\n<li>图像缩放之类的。</li>\n<li>gzip压缩。</li>\n</ul>\n<p>在所有的filter中，有几个filter模块需要关注一下。按照调用的顺序依次说明如下：</p>\n<ul>\n<li>write:写输出到客户端，实际上是写到连接对应的socket上。</li>\n<li>postpone:这个filter是负责subrequest的，也就是子请求的。</li>\n<li>copy:将一些需要复制的buf(文件或者内存)重新复制一份然后交给剩余的bodyfilter 处理。</li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"http://wiki.jikexueyuan.com/project/nginx/\" target=\"_blank\" rel=\"noopener\">Nignx入门指南</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://www.kancloud.cn/digest/understandingnginx/202601\" target=\"_blank\" rel=\"noopener\">理解Nignx源码</a></p>\n","categories":["Linux"],"tags":["Linux","Nignx"]},{"title":"负载均衡(LB)","url":"http://shawnz.me/posts/4b8595ae/","content":"<h2 id=\"负载均衡的作用（解决的问题）：\"><a href=\"#负载均衡的作用（解决的问题）：\" class=\"headerlink\" title=\"负载均衡的作用（解决的问题）：\"></a>负载均衡的作用（解决的问题）：</h2><ul>\n<li>解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；</li>\n<li>提供故障转移，实现高可用；</li>\n<li>通过添加或减少服务器数量，提供网站伸缩性（扩展性）；</li>\n<li>安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）<a id=\"more\"></a>\n</li>\n</ul>\n<h2 id=\"负载均衡分类\"><a href=\"#负载均衡分类\" class=\"headerlink\" title=\"负载均衡分类\"></a>负载均衡分类</h2><ul>\n<li><p><strong>DNS负载均衡</strong><br>  DNS是最简单的、也是最常见的负载均衡方式，一般用来实现地理级别的均衡。</p>\n<p>  对于外网DNS一般使用GSLB（全局负载均衡）进行流量调度，可以使用DNS查询看到IP解析。<br>  对于内网DNS，可以实现简单的轮询负载均衡。</p>\n<p>  特点：解析和缓存时间长并且没有失败重试机制。</p>\n</li>\n<li><p><strong>硬件负载均衡</strong></p>\n<p>  采用硬件的方式实现负载均衡，一般是单独的负载均衡服务器，价格昂贵，目前业界领先的两款：F5和A10。<br>  当前大部分应用采用了软件负载均衡，也就核心应用采用硬件负载均衡，或者可以使用几台F5做全局负载均衡，内部使用Nginx等软件负载均衡。</p>\n</li>\n<li><p><strong>软件负载均衡</strong></p>\n<p>  DNS用于实现地理级别的负载均衡，而Nginx/LVS/HA就是用于同一地点内机器级别的负载均衡。其中Nginx是软件的7层负载均衡，LVS是内核的4层负载均衡。</p>\n<p>  澄清几个概念：</p>\n<ul>\n<li><code>二层负载均衡</code>：通过改写报文的目标MAC地址为上游服务器MAC地址，源IP地址和目标IP地址没有改变。负载均衡服务器和上游服务器共享同一个VIP，如LVS/DR模式。</li>\n<li><code>四层负载均衡</code>：根据端口将报文转发到上游服务器（不同的IP地址+端口），如LVS/NAT和HaProxy。</li>\n<li><code>七层负载均衡</code>：根据端口号和应用层协议，如HTTP协议的主机名、URL转发到上游服务器（不同的IP地址+端口），如HaProxy和Nignx。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"负载均衡算法\"><a href=\"#负载均衡算法\" class=\"headerlink\" title=\"负载均衡算法\"></a>负载均衡算法</h2><ul>\n<li><code>轮询调度(Round Robin)</code>：调度器通过“轮询”调度算法将外部请求按顺序轮流分配到集群中的真实服务器上。</li>\n<li><code>加权轮询调度(Round Robin)</code>：通过添加权重(weight)配置实现基于权重的轮询，可以保证处理能力强的服务器获得更多的访问量。</li>\n<li><code>最少链接(Least Connections)</code>：调度器通过“最少连接”调度算法动态地将网络请求调度到已建立的链接数最少的服务器上。如果集群中的真实服务器数量较少，性能相差不多，可以使用此策略。</li>\n<li><code>加权最少链接(Weighted Least Connections)</code>：基于权重的最少连接策略。</li>\n<li><code>源地址哈希法(ip hash)</code>：对请求IP地址采用哈希算法进行负载均衡。</li>\n<li><code>Generic Hash</code>：以用户自定义资源（如URL）的方式计算哈希值完成分配请求。采用hash算法面临的问题是：在添加/删除一台服务器时，将导致很多key被重新负载均衡到不同的服务器。这个时候就需要用到<a href=\"/posts/51aeee82/\" title=\"一致性hash算法\">一致性hash算法</a>。</li>\n</ul>\n<h2 id=\"LVS\"><a href=\"#LVS\" class=\"headerlink\" title=\"LVS\"></a>LVS</h2><h3 id=\"LVS基本介绍\"><a href=\"#LVS基本介绍\" class=\"headerlink\" title=\"LVS基本介绍\"></a>LVS基本介绍</h3><p>LVS是 Linux Virtual Server 的简称，也就是Linux虚拟服务器。这是一个由章文嵩博士发起的一个开源项目，它的现在 LVS 已经是 Linux 内核标准的一部分。使用 LVS 可以达到的技术目标是：通过 LVS 达到的负载均衡技术和 Linux 操作系统实现一个高性能高可用的 Linux 服务器集群，它具有良好的可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的性能。</p>\n<h3 id=\"LVS工作原理\"><a href=\"#LVS工作原理\" class=\"headerlink\" title=\"LVS工作原理\"></a>LVS工作原理</h3><ol>\n<li>当用户向负载均衡调度器（Director Server）发起请求，调度器将请求发往至内核空间</li>\n<li>PREROUTING链首先会接收到用户请求，判断目标IP确定是本机IP，将数据包发往INPUT链</li>\n<li>IPVS是工作在INPUT链上的，当用户请求到达INPUT时，IPVS会将用户请求和自己已定义好的集群服务进行比对，如果用户请求的就是定义的集群服务，那么此时IPVS会强行修改数据包里的目标IP地址及端口，并将新的数据包发往POSTROUTING链</li>\n<li>POSTROUTING链接收数据包后发现目标IP地址刚好是自己的后端服务器，那么此时通过选路，将数据包最终发送给后端的服务器</li>\n</ol>\n<h3 id=\"LVS相关术语\"><a href=\"#LVS相关术语\" class=\"headerlink\" title=\"LVS相关术语\"></a>LVS相关术语</h3><ul>\n<li>DS：Director Server。指的是前端负载均衡器节点。</li>\n<li>RS：Real Server。后端真实的工作服务器。</li>\n<li>VIP：向外部直接面向用户请求，作为用户请求的目标的IP地址。</li>\n<li>DIP：Director Server IP，主要用于和内部主机通讯的IP地址。</li>\n<li>RIP：Real Server IP，后端服务器的IP地址。</li>\n<li>6 CIP：Client IP，访问客户端的IP地址。</li>\n</ul>\n<h3 id=\"LVS-NAT原理和特点\"><a href=\"#LVS-NAT原理和特点\" class=\"headerlink\" title=\"LVS/NAT原理和特点\"></a>LVS/NAT原理和特点</h3><p><img src=\"/images/lvs-nat.png\" alt=\"\"></p>\n<p>LVS/NAT实现原理和数据包改变：</p>\n<ul>\n<li>当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP</li>\n<li>PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链</li>\n<li>IPVS比对数据包请求的服务是否为集群服务，若是，修改数据包的目标IP地址为后端服务器IP，然后将数据包发至POSTROUTING链。 此时报文的源IP为CIP，目标IP为RIP</li>\n<li>POSTROUTING链通过选路，将数据包发送给Real Server</li>\n<li>Real Server比对发现目标为自己的IP，开始构建响应报文发回给Director Server。 此时报文的源IP为RIP，目标IP为CIP</li>\n<li>Director Server在响应客户端前，此时会将源IP地址修改为自己的VIP地址，然后响应给客户端。 此时报文的源IP为VIP，目标IP为CIP</li>\n</ul>\n<p>LVS/NAT特点：</p>\n<ul>\n<li>RS应该使用私有地址，RS的网关必须指向DIP</li>\n<li>DIP和RIP必须在同一个网段内</li>\n<li>请求和响应报文都需要经过Director Server，高负载场景中，Director Server易成为性能瓶颈</li>\n</ul>\n<h3 id=\"LVS-DR原理和特点\"><a href=\"#LVS-DR原理和特点\" class=\"headerlink\" title=\"LVS/DR原理和特点\"></a>LVS/DR原理和特点</h3><p><img src=\"/images/lvs-dr.png\" alt=\"\"></p>\n<p>LVS/DR实现原理和数据包改变：</p>\n<ul>\n<li>当用户请求到达Director Server，此时请求的数据报文会先到内核空间的PREROUTING链。 此时报文的源IP为CIP，目标IP为VIP</li>\n<li>PREROUTING检查发现数据包的目标IP是本机，将数据包送至INPUT链</li>\n<li>IPVS比对数据包请求的服务是否为集群服务，若是，将请求报文中的源MAC地址修改为DIP的MAC地址，将目标MAC地址修改RIP的MAC地址，然后将数据包发至POSTROUTING链。 此时的源IP和目的IP均未修改，仅修改了源MAC地址为DIP的MAC地址，目标MAC地址为RIP的MAC地址</li>\n<li>由于DS和RS在同一个网络中，所以是通过二层来传输。POSTROUTING链检查目标MAC地址为RIP的MAC地址，那么此时数据包将会发至Real Server。</li>\n<li>RS发现请求报文的MAC地址是自己的MAC地址，就接收此报文。处理完成之后，将响应报文通过lo接口传送给eth0网卡然后向外发出。 此时的源IP地址为VIP，目标IP为CIP</li>\n<li>响应报文最终送达至客户端</li>\n</ul>\n<p>LVS/NAT特点：</p>\n<ul>\n<li>保证前端路由将目标地址为VIP报文统统发给Director Server，而不是RS(在前端路由器做静态地址路由绑定，将对于VIP的地址仅路由到Director Server)</li>\n<li>RS可以使用私有地址；也可以是公网地址，如果使用公网地址，此时可以通过互联网对RIP进行直接访问</li>\n<li>RS跟Director Server必须在同一个物理网络中</li>\n<li>所有的请求报文经由Director Server，但响应报文必须不能进过Director Server</li>\n<li>RS的网关绝不允许指向DIP(因为我们不允许他经过director)</li>\n</ul>\n<h3 id=\"LVS特点：\"><a href=\"#LVS特点：\" class=\"headerlink\" title=\"LVS特点：\"></a>LVS特点：</h3><ul>\n<li>负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生；</li>\n<li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；</li>\n<li>工作稳定，自身有完整的双机热备方案；</li>\n<li>无流量，保证了均衡器IO的性能不会收到大流量的影响；</li>\n<li>应用范围比较广，可以对所有应用做负载均衡；</li>\n<li>LVS需要向IDC多申请一个IP来做Visual IP，因此需要一定的网络知识，所以对操作人的要求比较高。</li>\n</ul>\n<h2 id=\"Nignx\"><a href=\"#Nignx\" class=\"headerlink\" title=\"Nignx\"></a>Nignx</h2><p>Nignx目前提供HTTP(ngx_http_upstream_module)七层负载均衡。<br>在1.9.0版本也开始支持TCP(ngx_stream_upstream_module)四层负载均衡。<br><a href=\"/posts/51aeee82/\" title=\"Nignx学习\">Nignx学习</a></p>\n<p>Nignx特点：</p>\n<ul>\n<li>工作在七层之上，可以针对http应用做分流策略，它的正则规则比HaProxy更为强大和灵活。</li>\n<li>Nginx对网络稳定性的依赖非常小，基本上能ping通也可以做负载均衡。</li>\n<li>Nginx安装和配置比较简单，测试起来比较方便；</li>\n<li>Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；</li>\n<li>功能多，除了负载均衡，还能作Web服务器。</li>\n<li>不支持Session的保持、对Big request header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。</li>\n</ul>\n<h2 id=\"HaProxy\"><a href=\"#HaProxy\" class=\"headerlink\" title=\"HaProxy\"></a>HaProxy</h2><p>HaProxy特点：</p>\n<ul>\n<li>HAProxy是工作在网络7层之上。</li>\n<li>能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作</li>\n<li>支持url检测后端的服务器出问题的检测会有很好的帮助。</li>\n<li>更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现</li>\n<li>单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。</li>\n<li>HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。</li>\n</ul>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://segmentfault.com/a/1190000010742014\" target=\"_blank\" rel=\"noopener\">LVS负载均衡</a></p>\n","categories":["架构"],"tags":["Nginx"]},{"title":"RESTful","url":"http://shawnz.me/posts/17798683/","content":"<h2 id=\"什么是REST\"><a href=\"#什么是REST\" class=\"headerlink\" title=\"什么是REST?\"></a>什么是REST?</h2><p>REST——Representational State Transfer（表述性状态转移）这个概念于 2000 年由 Roy Fielding ( HTTP 规范的主要编写者之一) 在他的博士论文 “Architectural Styles and the Design of Network-based Software Architectures (架构风格与基于网络的软件架构设计) “ 中首次提出。论文中对使用 Web 服务作为分布式计算平台的一系列软件体系结构原则进行了分析。<br><a id=\"more\"></a><br>REST并不是一种规范，而是一种架构风格，是对分布式超媒体系统中的架构元素的一种抽象。REST风格作用于WEB架构之上，通过附加一系列的约束，更好的反应现代WEB架构所期待的元素，正确的使用WEB标准。</p>\n<h2 id=\"REST风格约束-原则\"><a href=\"#REST风格约束-原则\" class=\"headerlink\" title=\"REST风格约束(原则)\"></a>REST风格约束(原则)</h2><p>在Roy Fielding的论文中<code>Deriving REST</code>一节中，明确提出一系列的架构级的约束：</p>\n<ul>\n<li><p><strong><code>客户-服务器：</code></strong>客户-服务器约束背后的原则是分离关注点。通过分离用户接口和数据存储这两个关注点,我们改善了用户接口跨多个平台的可移植性;同时通过简化服务器组件,改善了系统的可伸缩性。然而,对于 Web 来说,最重要的是这种关注点的分离允许组件独立地进化,从而支持多个组织领域的 Internet 规模的需求。</p>\n</li>\n<li><p><strong><code>无状态:</code></strong>通信必须在本质上是无状态的,因此从客户到服务器的每个请求都必须包含理解该请求所必需的所有信息,不能利用任何存储在服务器上的上下文,会话状态因此要全部保存在客户端。</p>\n<p>  无状态带来的是可见性、可靠性和伸缩性三个架构属性。改善了可见性是因为监视系统不必为了确定一个请求的全部性质而去查看该请求之外的多个请求。改善了可靠性是因为它减轻了从局部故障中恢复的任务量。改善了可伸缩性是因为不必在多个请求之间保存状态,从而允许服务器组件迅速释放资源,并进一步简化其实现,因为服务器不必跨多个请求管理资源的使用。</p>\n<p>  这一约束和大多数的架构抉择一样，反映出设计的平衡。缺点是：由于不能在服务器保存上下文信息，因此在一系列请求中重复发送的数据，降低了网络性能。此外，将应用状态保存在客户端，也降低了服务器对于一致的应用行为的控制。</p>\n</li>\n<li><p><strong><code>缓存:</code></strong>缓存约束要求一个请求的响应中的数据被隐式地或显式地标记为可缓存的或不可缓存的。如果响应是可缓存的,那么客户端缓存就可以为以后的相同请求重用这个响应的数据。</p>\n<p>  缓存约束的好处是，能够部分或者全部的消除交互，来提升效率、可伸缩性和用户可觉察性能。而代价是过期数据会导致可靠性降低。</p>\n</li>\n<li><p><strong><code>统一接口:</code></strong>REST架构区别于其他架构的核心特征是：它强调组件之间要有一个统一的接口。在组件上应用通用性的软件工程原则，带来的好处显而易见：架构得到了简化，交互可见性得到改善，实现与他们所提供的服务是解耦的，促进了独立的可进化性。付出的代价是，统一接口降低了效率，因为不能满足特定于应用的形式。</p>\n<p>  为了获得统一的接口，REST提供了四个接口约束来指导组件的行为：</p>\n<ul>\n<li>资源的识别(identification of resources)</li>\n<li>通过表述对资源执行的操作</li>\n<li>自描述的消息(self-descriptive message）</li>\n<li>作为应用状态引擎的超媒体</li>\n</ul>\n</li>\n<li><p><strong><code>分层系统:</code></strong>为了改善与Internet规模需求相关的行为，REST添加了分层的系统约束，限制组件的行为(即每个组件只能”看到“与其交互的相邻组件)。带来的好处是为整个系统设置的复杂边界，简化了组件的实现。中间组件还能够通过支持跨多个网络和处理器的负载均衡,来改善系统的可伸缩性。</p>\n<p>  分层系统的缺点是：增加了数据处理的开销和延迟，降低了用户可觉察的性能。但同时中间组件可以通过共享缓存获得显著的性能提升，中间层还允许对跨组件的数据执行安全策略。</p>\n</li>\n<li><p><strong><code>按需代码:</code></strong>这一约束是可选的，通过下载并执行applet形式或脚本形式的代码，REST允许对客户端进行扩展。</p>\n</li>\n</ul>\n<h2 id=\"深入理解RESTful\"><a href=\"#深入理解RESTful\" class=\"headerlink\" title=\"深入理解RESTful\"></a>深入理解RESTful</h2><p>要深入理解RESTful，首先需要理解REST的五个关键词：</p>\n<ol>\n<li><p><strong><code>资源(Resource)</code></strong>REST对信息的核心抽象是资源。一个资源是到一组实体的概念上的映射,而不是在任何特定时刻与该映射相关联的实体本身。对于一个资源来说，其实体对应的值可能随时间在变化，而唯一必须静态的是映射上的语义，因为语义才是区别资源的关键。</p>\n</li>\n<li><p><strong><code>资源的表述(Representation)</code></strong>REST通过以下方式在一个资源上执行操作：使用一个表述来捕获资源的当前或者预期的状态、在组件之间传递该表述。一个表述是一个字节序列，以及描述这些字节的表述元数据。表述是REST的表现层。资源的表述可以有多种格式，例如HTML/XML/JSON/纯文本/图片/视频/音频等等。</p>\n</li>\n<li><p><strong><code>状态转移(State Transfer)</code></strong>首先明确一点REST是无状态的，实际上这里指的状态是客户端维护的应用状态，REST中服务器端不能保留状态信息，只有在收到请求的时候，才关注应用状态。</p>\n<p> 应用状态的转移就可以理解为客户端的应用状态在得到服务端的超媒体的指引下发生变迁(transfer)。</p>\n<p> 还是指资源状态的表述在客户端和服务端之间的转移(transfer)</p>\n</li>\n<li><p><strong><code>统一接口</code></strong>REST要求必须通过统一的接口来操作资源的转移，HTTP/1.1协议定义了一套操作资源的统一接口：</p>\n<ul>\n<li>7个HTTP方法：GET/POST/PUT/DELETE/PATCH/HEAD/OPTIONS</li>\n<li>HTTP头信息（可自定义）</li>\n<li>HTTP响应状态代码（可自定义）</li>\n<li>一套标准的内容协商机制</li>\n<li>一套标准的缓存机制</li>\n<li>一套标准的客户端身份认证机制</li>\n</ul>\n</li>\n<li><p><strong><code>超媒体驱动</code></strong>又名”将超媒体作为应用状态的引擎”（Hypermedia As The Engine Of Application State）。将WEB应用看作一个虚拟的状态机，资源之间通过超链接关联，超链接即代表资源的关系，也表明可执行的状态转移。用户通过选择链接（状态转移）在应用中前进，导致下个页面（应用的下个状态）被转移给用户。</p>\n<p> 通过超媒体暴露服务器提供的资源，服务器提供的资源是在运行时解析超媒体发现的，而不是事先定义好的。从面向服务的角度看，超媒体定义了服务器所提供服务的协议。客户端应该依赖的是超媒体的状态迁移语义，而不应该对于是否存在某个URI或URI的某种特殊构造方式作出假设。一切都有可能变化，只有超媒体的状态迁移语义能够长期保持稳定。</p>\n</li>\n</ol>\n<h2 id=\"RESTful-API设计规范\"><a href=\"#RESTful-API设计规范\" class=\"headerlink\" title=\"RESTful API设计规范\"></a>RESTful API设计规范</h2><p>收集了一些先关的资料，其中有关于如何设计优秀的RESTful API的经验和建议，也有优秀的RESTful API设计案例。</p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://www.ics.uci.edu/~fielding/pubs/dissertation/top.htm\" target=\"_blank\" rel=\"noopener\">Roy Fielding博士论文英文版</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://yuedu.baidu.com/ebook/780324fbf121dd36a32d8269\" target=\"_blank\" rel=\"noopener\">Roy Fielding博士论文中文版</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://www.cnblogs.com/loveis715/p/4669091.html\" target=\"_blank\" rel=\"noopener\">REST简介</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://www.infoq.com/cn/articles/how-to-design-a-good-restful-api\" target=\"_blank\" rel=\"noopener\">虚拟研讨会：如何设计好的RESTful API？</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://codeplanet.io/principles-good-restful-api-design/\" target=\"_blank\" rel=\"noopener\">Principles of good RESTful API Design</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://github.com/bolasblack/http-api-guide\" target=\"_blank\" rel=\"noopener\">HTTP 接口设计指北</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://geemus.gitbooks.io/http-api-design/content/en/index.html\" target=\"_blank\" rel=\"noopener\">HTTP API Design Guide</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://novoland.github.io/%E8%AE%BE%E8%AE%A1/2015/08/17/Restful%20API%20%E7%9A%84%E8%AE%BE%E8%AE%A1%E8%A7%84%E8%8C%83.html\" target=\"_blank\" rel=\"noopener\">Restful API 的设计规范</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://github.com/Microsoft/api-guidelines/blob/vNext/Guidelines.md\" target=\"_blank\" rel=\"noopener\">Microsoft REST API Guidelines</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://developer.github.com/v3/\" target=\"_blank\" rel=\"noopener\">Github API v3</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://developers.coinbase.com/api/v2\" target=\"_blank\" rel=\"noopener\">Coinbase API</a></p>\n","categories":["架构"],"tags":["HTTP"]},{"title":"TCP协议","url":"http://shawnz.me/posts/51aeee82/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"面向连接的\"><a href=\"#面向连接的\" class=\"headerlink\" title=\"面向连接的\"></a>面向连接的</h2><p>TCP协议头部：</p>\n<pre><code>0                   1                   2                   3\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|          Source Port          |       Destination Port        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                        Sequence Number                        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                    Acknowledgment Number                      |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|  Data |           |U|A|P|R|S|F|                               |\n| Offset| Reserved  |R|C|S|S|Y|I|            Window             |\n|       |           |G|K|H|T|N|N|                               |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|           Checksum            |         Urgent Pointer        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                    Options                    |    Padding    |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|   .... data ....                                              |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n</code></pre><ul>\n<li><code>SYN</code>:表示同步序号，用来建立连接。SYN和ACK标志位搭配使用，当请求连接的时候，SYN=1,ACK=0;当响应连接的时候，SYN=1,ACK=1;</li>\n<li><code>ACK</code>:表示应答域有效，有两个取值：0和１，为1的时候表示应答域有效，反之为0;</li>\n<li><code>FIN</code>:表示发送端已经到达数据末尾，发送FIN标志位的数据包后，连接将被断开;</li>\n<li><code>Sequence number</code>:序列号</li>\n<li><code>Ackonwleage number</code>:确认号</li>\n</ul>\n<p>如下图所示，TCP建立连接和断开连接会经历三次握手和四次挥手的过程:</p>\n<p><img src=\"http://oufa7cuo5.bkt.clouddn.com/17-8-9/22804988.jpg\" alt=\"TCP三次握手四次挥手\"></p>\n<h3 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h3><ol>\n<li>第一次握手：建立连接。客户端发送连接请求报文段，将SYN置为1，Sequence number为x；然后客户端进入SYN_SEND状态，等待服务器的确认；</li>\n<li>第二次握手：服务器端收到SYN报文段。对报文段进行确认，设置Ackonwleage number为x + 1(Sequence number + 1);同时服务器将的SYN位置为１，Sequence number为y，发送给客户端，此时服务器进入SYN_RECV状态；</li>\n<li>第三次握手：客户端收到服务器的SYN + ACK报文段，将Ackonwleage number设置为y + 1,向服务器发送ACK报文段,发送完毕后，客户端和服务端都进入ESTABLISHED状态，完成TCP三次握手。</li>\n</ol>\n<h3 id=\"四次挥手\"><a href=\"#四次挥手\" class=\"headerlink\" title=\"四次挥手\"></a>四次挥手</h3><ol>\n<li>第一次挥手：主机１，设置Sequence number和Ackonwleage number，向主机２发送一个FIN报文段，此时主机１，进入FIN_WAIT_1状态：表示主机１没有数据发送给主机2了;</li>\n<li>第二次挥手：主机2收到主机1发送的FIN报文段，向主机1回送一个ACK报文段，置Ackonwleage number为Sequence number + 1;主机1进入FIN_WAIT_2状态；主机2告诉主机1：我同意了你的关闭请求，主机2进入CLOSE_WAIT状态；</li>\n<li>第三次挥手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；</li>\n<li>第四次挥手：主机1接收到主机2的FIN报文段，向主机2发送ACK报文段，主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接，此时主机1等待２MSL依然没有收到回复，则证明Server端正常关闭了，主机1也可以关闭连接了。</li>\n</ol>\n<h3 id=\"为什么需要三次握手？\"><a href=\"#为什么需要三次握手？\" class=\"headerlink\" title=\"为什么需要三次握手？\"></a>为什么需要三次握手？</h3><p>现在三次握手的过程已经十分清晰明了：A(建立连接发起方)向B(连接建立接受方)发送一个Sync，B向A回送Ack+Sync，A再向B发送Ack这样的一个过程。</p>\n<p>然而TCP建立连接为什么使用的是三次握手协议，而不是两次或者四次呢？</p>\n<blockquote>\n<p>为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p>\n<p align=\"right\">—— 谢希仁的《计算机网络》的关于第三次握手的必要性</p>\n</blockquote>\n<blockquote>\n<p>为了“解决网络中存在延迟的重复分组”问题</p>\n<p align=\"right\">—— 在Andrew S.Tanenbaum的《计算机网络》中的讲三次握手的目的</p>\n</blockquote>\n<p>从以上两种不同的描述，我们可以知道第三次握手主要解决的是这样一种情况：</p>\n<p>假设Client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。<br>本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是Client再次发出的一个新的连接请求。于是就向Client发出确认报文段，同意建立连接。<br>如果没有“第三次握手”，那么只要Server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬Server的确认，也不会向Server发送数据。但Server却以为新的运输连接已经建立，并一直等待Client发来数据。这样，Server的很多资源就白白浪费掉了。</p>\n<p>在仔细研究三次握手的过程，可以发现其实客户端和服务器各自发起了一次请求和一次确认，所以一共是“四次”，不过在第二次握手时，服务器将确认和请求合并成一次。</p>\n<blockquote>\n<p>“这个问题的本质是, 信道不可靠, 但是通信双发需要就某个问题达成一致. 而要解决这个问题,  无论你在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足”在不可靠信道上可靠地传输信息”这一需求所导致的. 请注意这里的本质需求,信道不可靠, 数据传输要可靠. 三次达到了, 那后面你想接着握手也好, 发数据也好, 跟进行可靠信息传输的需求就没关系了. 因此,如果信道是可靠的, 即无论什么时候发出消息, 对方一定能收到, 或者你不关心是否要保证对方收到你的消息, 那就能像UDP那样直接发送消息就可以了.”</p>\n</blockquote>\n<p align=\"right\">—— Google网上论坛这样的<a href=\"https://groups.google.com/forum/#!msg/pongba/kF6O7-MFxM0/5S7zIJ4yqKUJ\" target=\"_blank\" rel=\"noopener\">一条回复</a></p>\n\n<h3 id=\"为什么要四次分手\"><a href=\"#为什么要四次分手\" class=\"headerlink\" title=\"为什么要四次分手\"></a>为什么要四次分手</h3><p>TCP是全双工模式，关键在于理解四次挥手过程的状态转化。</p>\n<p><code>FIN_WAIT_1：</code>FIN_WAIT_1和FIN_WAIT_2状态的都是表示等待对方的FIN报文。<br>而这两种状态的区别是：FIN_WAIT_1状态实际上是当SOCKET在ESTABLISHED状态时，它想主动关闭连接，向对方发送了FIN报文，此时该SOCKET即进入到FIN_WAIT_1状态。而当对方回应ACK报文后，则进入到FIN_WAIT_2状态，当然在实际的正常情况下，无论对方何种情况下，都应该马上回应ACK报文，所以FIN_WAIT_1状态一般是比较难见到的，而FIN_WAIT_2状态还有时常常可以用netstat看到。</p>\n<p><code>FIN_WAIT_2：</code>实际上FIN_WAIT_2状态下的SOCKET，表示半连接。</p>\n<p><code>CLOSE_WAIT：</code>是表示在等待关闭。当主动关闭方发送FIN报文给对方时，接收方无疑会回传一个ACK报文，此时接收方进入CLOSE_WAIT状态，而接收方需要考虑的事情是查看是否还有数据需要发送给对方，如果没有那么，被动关闭方也可以发送FIN报文关闭连接。</p>\n<p><code>LAST_ACK：</code>这是被动关闭方发送FIN报文，最后等待对方ACK报文。当收到ACK报文后，也即可以进入到CLOSED状态了。（被动方）</p>\n<p><code>TIME_WAIT：</code> 表示收到了对方的FIN报文，并发送出了ACK报文，就等2MSL后即可回到CLOSED可用状态了。如果FINWAIT1状态下，收到了对方同时带FIN标志和ACK标志的报文时，可以直接进入到TIME_WAIT状态，而无须经过FIN_WAIT_2状态。（主动方）</p>\n<p><code>CLOSED：</code>表示连接关闭。</p>\n<h3 id=\"2MSL-TIME-WAIT\"><a href=\"#2MSL-TIME-WAIT\" class=\"headerlink\" title=\"2MSL TIME_WAIT\"></a>2MSL TIME_WAIT</h3><ul>\n<li><p><strong>什么是2MSL?</strong><br>  MSL是Maximum Segment Lifetime,译为“报文最大生存时间”。<br>2MSL即两倍的MSL，TCP的TIME_WAIT状态也称为2MSL等待状态。主动关闭方在收到对方的FIN报文，第四次挥手发送ACK报文后，必须等待2MSL时间。</p>\n</li>\n<li><p><strong>为什么必须等待2MSL?</strong><br>  主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。<br>  另一个原因是如果TIME_WAIT状态保持不够长，那么当第二个相同的五元组连接出现，而第一个连接的迟到报文出现，将会干扰第二个连接。这是因为IP头部有个TTL，限制了一个包在网络中的最大跳数，当TTL变为0，报文将在网络中消失，要么或者在TTL在变为0之前凭借剩余的TTL跳数终于到达目的地。而等待2MSL可以保证较早的连接的迟到报文不会解析成替身连接上的一部分报文(MSL要大于等于TTL)。</p>\n</li>\n<li><p><strong>正确的对待2MSL TIME_WAIT：</strong></p>\n<p>  RFC要求socket pair在处于TIME_WAIT时，不能再起一个incarnation connection。但绝大部分TCP实现，强加了更为严格的限制。在2MSL等待期间，socket中使用的本地端口在默认情况下不能再被使用。</p>\n<p>  这一实现的限制，对客户端来说无所谓，但是对于server来说，情况就不同了，因为服务器使用熟知的端口。这在许多TCP具体实现中可以通过设置SO_REUSEADDR选项达到不必等待2MSL时间结束再使用此端口。然而RFC的那个socket pair限制依然存在，不允许一个新的连接建立在相同的socket pair上。</p>\n</li>\n</ul>\n<h3 id=\"backlog\"><a href=\"#backlog\" class=\"headerlink\" title=\"backlog\"></a>backlog</h3><p><code>socket.listen(backlog)</code>中的backlog参数称为积压值，用来描述固定长度的连接队列。<br>在TCP三次握手阶段，监听的服务器发送SYN+ACK后，会进入SYN RECEIVED状态，此时处于半连接，只有在收到客户端的ACK后才完成连接，进入ESTABLISHED状态。</p>\n<p>关于backlog有两种实现：</p>\n<ul>\n<li>使用单一队列，队列大小有backlog参数决定，同事维护SYN RECEIVED和ESTABLISHED状态的连接。只有后一种状态才会从accept中返回。</li>\n<li>使用两个队列，一个SYN队列（即半连接队列）和一个全连接队列（ACCEPT队列）。backlog参数决定全连接队列的大小。accept从全连接队列获取连接。</li>\n</ul>\n<h3 id=\"RST\"><a href=\"#RST\" class=\"headerlink\" title=\"RST\"></a>RST</h3><p>RST在TCP协议中RST表示复位，用来异常的关闭连接。</p>\n<p>发送RST包关闭连接时，不必等缓冲区的包都发出去，直接就丢弃缓存区的包发送RST包。而接收端收到RST包后，也不必发送ACK包来确认。用RST而不是FIN关闭连接，称为<code>abortive release</code>（相对<code>orderly release</code>），api会通知应用层连接是异常关闭的。</p>\n<p>常见的RST关闭时机：</p>\n<ul>\n<li>连接到或者发送数据到没有打开的端口，收到RST；</li>\n<li>SYN请求超时，会发送RST拒绝进一步发送数据；</li>\n<li>提前关闭连接，在关闭连接时接收缓冲区还有数据没有被消费，将发送RST；</li>\n<li>向一个已经close()的socket发送数据，会受到RST。（close和shutdown虽然都会发送FIN关闭连接，但是前者的语义是关闭读写，后者是关闭写，依然可读）</li>\n</ul>\n<h3 id=\"SYN-Flood\"><a href=\"#SYN-Flood\" class=\"headerlink\" title=\"SYN Flood\"></a>SYN Flood</h3><ul>\n<li><p><strong>什么是SYN攻击？</strong></p>\n<p>  在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 SYN_RCVD 状态。当收到 ACK 后，服务器才能转入 ESTABLISHED 状态.</p>\n<p>  SYN 攻击指的是，攻击客户端在短时间内伪造大量不存在的IP地址，向服务器不断地发送SYN包，服务器回复确认包，并等待客户的确认。由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的SYN包将长时间占用未连接队列，正常的SYN请求被丢弃，导致目标系统运行缓慢，严重者会引起网络堵塞甚至系统瘫痪。</p>\n<p>  SYN 攻击是一种典型的 DoS/DDoS 攻击。</p>\n</li>\n<li><p><strong>SYN攻击检测和预防</strong></p>\n<p>  当通过netstat查看到大量的半连接状态时，并且源地址是随机的，那么可以断定这是一次SYN攻击。</p>\n<p>  SYN攻击不能完全阻止，除非重新设计TCP协议。常见的几种防御措施：</p>\n<ul>\n<li>缩短超时（SYN Timeout）时间</li>\n<li>增加最大半连接数</li>\n<li>过滤网关防护</li>\n<li>SYN cookies技术</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"面向字节流的\"><a href=\"#面向字节流的\" class=\"headerlink\" title=\"面向字节流的\"></a>面向字节流的</h2><h3 id=\"消息确认-ACK-机制\"><a href=\"#消息确认-ACK-机制\" class=\"headerlink\" title=\"消息确认(ACK)机制\"></a>消息确认(ACK)机制</h3><p>TCP是一种流协议(stream protocol)，对于一条TCP连接，尽管数据是以IP分组的形式传输的，但是对于<strong>分组中的数据量和send调用传送给TCP多少数据并没有直接关系</strong>，没有固有的“报文”或边界等概念（<a href=\"\">粘包现象</a>）。TCP的ACK机制能保证数据的完整和有序。</p>\n<p>ACK机制没有采用Message ID字段，而是使用的片段内最后一个字节的Sequence Number。在TCP三次握手阶段，通信双方确认各自的初始序列号x和y，在之后的每次传送报文段中Sequence Number为该报文第一个字节的序号。</p>\n<p>ACK通常被理解为接收方对收到的最高序列号的一个确认，TCP的确认机制可以不对每个TCP数据包发送单独的确认包，而是在传送的时候，顺便把确认信息传出（Delayed ACK机制）。ACK通常包含两个信息：</p>\n<ul>\n<li>期望收到的下一字节序号n，例如接收方收到1-1024字节，它会发送确认号为1025的ACK。</li>\n<li>当前窗口大小m。<br>这样接收方收到这两个数据，就可以确定下一次发送多少数据给对方，假设当前发送方已发送到x字节，那么可以发送的字节数：y=m-(x-n)，这是滑动窗口的原理。</li>\n</ul>\n<p>另外， 关于TCP的延迟确认机制和默认启用的Nagle算法， 会在<code>Write-Write-Read</code>操作模式， 可能产生40ms的延时。可以使用<code>TCP_NODELAY</code>为<code>true</code>， 关闭延迟ACK机制。</p>\n<h3 id=\"滑动窗口协议\"><a href=\"#滑动窗口协议\" class=\"headerlink\" title=\"滑动窗口协议\"></a>滑动窗口协议</h3><h4 id=\"滑动窗口概念\"><a href=\"#滑动窗口概念\" class=\"headerlink\" title=\"滑动窗口概念\"></a>滑动窗口概念</h4><p>TCP头部有个window字段，只有16位来表示，最大值为2^16-1=65536（对于特殊需要可以扩展到32位的滑动窗口）。主要用作接收方通过通告发送方自己的窗口大小，这个字段在通信双方建立连接时协商确定，并且在通信过程中不断更新，故取名为滑动窗口。滑动窗口协议主要有两个作用：一提供TCP可靠性，二提供TCP流控特性。</p>\n<p>对于TCP发送方，任何时刻TCP缓冲区的数据分为以下四类：</p>\n<ul>\n<li>已经发送并得到对端ACK确认的，如图已有31个字节已经发送并确认，类别一；</li>\n<li>已经发送但没有收到对端ACK确认的(SND.UNA)，在发送确认之前，不认为这些数据已经被处理，如图14个字节标识为类别二；</li>\n<li>未发送但对端允许发送的(SND.NEXT)，将被发送到接收方的数据的下一个字节的序列号，如图类别三有6个字节；</li>\n<li>未发送并且对端不允许发送的，这部分数据不允许发送出去。</li>\n</ul>\n<p>接收方采用类似的机制，在某一时刻缓冲区中存在三种数据：</p>\n<ul>\n<li>已接收</li>\n<li>未接收且准备接收</li>\n<li>未接收且未准备接收<br>由于ACK直接由TCP协议栈回复，默认无应用延迟，不存在“已接收为回复ACK”。</li>\n</ul>\n<p>TCP是全双工协议，在会话的双方都可以接收和发送数据，在连接建立阶段会交换各自窗口大小。</p>\n<ul>\n<li>对于接收方来讲，“未接收准备接收”称为接收窗口，有时称为窗口；</li>\n<li>对于发送方，”已发送未确认“和”未发送但对端允许发送“称为发送窗口(其实就是把发送方的接收作为发送方的发送窗口)。</li>\n<li>可用窗口(useable window)：对于正在传输的数据，发送仍被允许发送的数据量。</li>\n</ul>\n<p><img src=\"/images/tcpslidingwindow.png\" alt=\"TCP sliding window\"></p>\n<h4 id=\"窗口移动规则\"><a href=\"#窗口移动规则\" class=\"headerlink\" title=\"窗口移动规则\"></a>窗口移动规则</h4><ul>\n<li><p><strong>窗口合拢：</strong>在收到对端数据后，自己确认过了数据的正确性，这些数据会被存储到缓冲区等待应用程序来取。这个时候因为确认了数据的正确性，需要回复ACK，但是数据还没有被消费，这个时候需要进行窗口合拢，缓冲区的窗口左边缘向右滑动，窗口减小。</p>\n</li>\n<li><p><strong>窗口张开：</strong>窗口收缩后，应用程序一旦从缓冲区取得数据，TCP滑动窗口需要扩张，这时窗口右边缘向右扩张，实际上窗口是一个环形缓冲区，右边缘的扩展会使用之前应用程序取走的缓冲区。在窗口扩张后，需要进行ACK通知发送方，这时ACK序号还是上次确认的字节序号。窗口张开可能会多次响应相同的ACK。</p>\n</li>\n<li><p><strong>窗口收缩：</strong>窗口右边缘向左滑动，Host Requirement RFC强烈建议不要这样做，但TCP必须能够在某一端产生这种情况时进行处理。</p>\n</li>\n</ul>\n<h4 id=\"面向流的可靠性\"><a href=\"#面向流的可靠性\" class=\"headerlink\" title=\"面向流的可靠性\"></a>面向流的可靠性</h4><ul>\n<li>最基本的传输可靠性源于”确认重传“机制；</li>\n<li>发送窗口只有在收到对端对于本端发送窗口内字节的ACK确认，才会移动发送窗口左边缘；</li>\n<li>接收窗口只有在前面的所有端都确认的情况下，才会移动左边界。当前面的字节还没有收到确认，收到后面字节的ACK确认的情况下，边界并不会移动，不对后续字节确认，保证对端会对这些数据重发。</li>\n</ul>\n<h4 id=\"流控特性\"><a href=\"#流控特性\" class=\"headerlink\" title=\"流控特性\"></a>流控特性</h4><p>应用程序可以根据自身的处理能力，对本端的TCP接收窗口控制来对对端的发送窗口流量控制。<br>应用程序在需要（如内存不足）时，通过API通知TCP协议栈缩小TCP的接收窗口。然后TCP协议栈在下个段发送时包含新的窗口大小通知给对端，对端按通知的窗口来改变发送窗口，以此达到减缓发送速率的目的。</p>\n<h2 id=\"确认重传机制\"><a href=\"#确认重传机制\" class=\"headerlink\" title=\"确认重传机制\"></a>确认重传机制</h2><p><strong>检测丢失片段以及重传</strong></p>\n<ul>\n<li>放置于重传队列中，计时器开始。每次发送一个片段，就会把片段放入重传队列，并启动重传计时器。</li>\n<li>确认处理。如果在计时器超时前收到确认，会从重传队列删除该片段。</li>\n<li>重传超时。如果计时器超时前没有收到确认，片段会自动重传。这一过程如果一直失败会重复进行，达到一定次数会判断连接故障终止连接。</li>\n</ul>\n<p>TCP接收端采用字节序号累积确认机制，缺点就是在前面的字节没有到达的情况下，无法确认后面的字节。针对重传超时片段TCP不同的实现有不同的方案。</p>\n<h2 id=\"拥塞控制\"><a href=\"#拥塞控制\" class=\"headerlink\" title=\"拥塞控制\"></a>拥塞控制</h2><p><code>拥塞</code>：即对资源的需求超过了可用的资源。若网络中许多资源同时供应不足，网络的性能就要明显变坏，整个网络的吞吐量随之负荷的增大而下降。<br><code>拥塞控制</code>：防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。拥塞控制是一个全局过程。<br><code>流量控制</code>：指点对点通信量的控制，是端到端正的问题。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。</p>\n<p>TCP还会在发送端维护一个拥塞窗口，<code>真实发送窗口= min(接收窗口，拥塞窗口)</code>。<br>拥塞控制主要依赖于<code>拥塞窗口</code>(congestion window, cwnd) 和<code>慢启动阈值</code>(slow start threshold, ssthresh)。<code>cwnd</code>是发送端根据网络的拥塞程度所预设的一个窗口大小，而<code>ssthresh</code>则是慢启动窗口的阈值，cwnd超过此阈值则转变控制策略。</p>\n<p>拥塞控制的主要算法有：<code>慢启动</code>(Slow Start)、<code>拥塞避免</code>(Congestion Avoidance)、<code>快速重传</code>(Fast Retransmit)、<code>快速恢复</code>(Fast Recovery)等</p>\n<h3 id=\"慢启动\"><a href=\"#慢启动\" class=\"headerlink\" title=\"慢启动\"></a>慢启动</h3><p>系统从slow start阶段开始。在这一阶段cwnd被置为1，发送端按照cwnd大小发送数据，每当数据被确认时，cwnd就以2为倍数进行指数级增长，即$cwnd_{n}=2*cwnd_{n-1}$</p>\n<p>当cwnd值超过慢启动阈值(ssthresh)时，慢启动过程结束，进入拥塞避免阶段。</p>\n<h3 id=\"拥塞避免\"><a href=\"#拥塞避免\" class=\"headerlink\" title=\"拥塞避免\"></a>拥塞避免</h3><p>在拥塞避免阶段，cwnd将不再呈指数增长，而是呈线性增长。一般来说：</p>\n<ul>\n<li>收到一个ACK时，$cwnd = cwnd + 1/cwnd$</li>\n<li>当每过一个RTT时，$cwnd = cwnd + 1$</li>\n</ul>\n<p>这样放缓了拥塞窗口的增长速率，避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值</p>\n<h3 id=\"拥塞状态\"><a href=\"#拥塞状态\" class=\"headerlink\" title=\"拥塞状态\"></a>拥塞状态</h3><p>在慢启动阶段与拥塞避免阶段，只要判断发送方出现丢包，就会进行相应的控制。有两种情况：</p>\n<p>1) 等待RTO超时，重传数据包，此时TCP反应强烈：<br>    将ssthresh降低为此时cwnd的一半<br>    将cwnd重新设为初始值(IW)<br>    重新进入慢启动阶段<br>    原则：加法增大、乘法减小。</p>\n<p>2) 连续收到3个duplicate ACK时，重传数据包，无须等待RTO。此情况即为下面的快速重传。</p>\n<h3 id=\"快速重传\"><a href=\"#快速重传\" class=\"headerlink\" title=\"快速重传\"></a>快速重传</h3><p>TCP在收到一个乱序的报文段时，会立即发送一个重复的ACK，并且此ACK不可被延迟。<br>例如：发送端发送了４/5/6/7/8，接收端按顺序收到了4/6/7/8，５丢失了，当接收端收到6/7/8的时候都会发送ACK=5，那么发送端就会收到三个相同的ACK,并认为５丢失了，立即重传５片段。</p>\n<p>如果连续收到3个或3个以上重复的ACK，TCP会判定此报文段丢失，需要重新传递，而无需等待RTO(超时重传计时)。这就叫做快速重传。</p>\n<p>注：快速重传始于BSD 4.3 Tahoe，但Tahoe的TCP实现没有包含快速恢复阶段，快速重传后会退回至慢启动阶段。</p>\n<h3 id=\"快速恢复\"><a href=\"#快速恢复\" class=\"headerlink\" title=\"快速恢复\"></a>快速恢复</h3><p>快速恢复是指快速重传后直接进入拥塞避免阶段而非慢启动阶段。总结一下快速恢复的步骤（以SMSS为单位）：</p>\n<p>​当收到3个重复的ACK时，将ssthresh设置为cwnd的一半(ssthresh = cwnd/2)，然后将cwnd的值设为ssthresh加3(cwnd = ssthresh + 3)，然后快速重传丢失的报文段<br>每次收到重复的ACK时，cwnd增加1(cwnd += 1)，并发送1个packet(如果允许的话)<br>当收到新的ACK时，将cwnd设置为第一步中ssthresh的值(cwnd = ssthresh)，代表恢复过程结束<br>快速恢复后将进入拥塞避免阶段。</p>\n<p>注：快速恢复始于BSD 4.3 Reno。</p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://scotdoyle.com/python-epoll-howto.html\" target=\"_blank\" rel=\"noopener\"></a></p>\n","categories":["网络"],"tags":["网络","TCP"]},{"title":"动态规划(Dynamic Programming)","url":"http://shawnz.me/posts/a80d0031/","content":"<h2 id=\"动态规划\"><a href=\"#动态规划\" class=\"headerlink\" title=\"动态规划\"></a>动态规划</h2><p>动态规划（英语：Dynamic programming，简称DP）通常用来求解最优化问题（optimization problem）。适用于具有重复子问题（overlapping subproblems）和最优子结构（optimal substructure）特点的问题，所耗时间往往远少于朴素解法。<br><a id=\"more\"></a></p>\n<p><code>最优子结构性质：</code>在自顶向下的递归求解中，往往会反复求解相同的子问题。动态规划可以仔细的安排求解顺序，对每个子问题只计算一次，并将结果保存下来。</p>\n<p><code>最优子结构：</code>一个问题的最优解包含其子问题的最优解。使用动态规划时，我们用子问题的最优解来构造原问题的最优解。</p>\n<p><code>无后效性：</code>将各阶段按照一定的次序排列好之后，对于某个给定的阶段状态，它以前各阶段的状态无法直接影响它未来的决策，而只能通过当前的这个状态。换句话说，每个状态都是过去历史的一个完整总结。这就是无后向性，又称为无后效性。</p>\n<h2 id=\"拆分问题\"><a href=\"#拆分问题\" class=\"headerlink\" title=\"拆分问题\"></a>拆分问题</h2><p>如何拆分问题，才是动态规划的核心。而拆分问题，靠的就是状态的定义和状态转移方程的定义。</p>\n<p><code>问题状态：</code>问题在某一时刻的情况的抽象。</p>\n<p><code>状态转移方程：</code>问题从当前状态到下一状态（通常更接近我们要求解的状态，即目标状态）所经历步骤的抽象。</p>\n<p>动态规划的核心就是拆分问题，依靠状态的定义和状态转移方程，使得问题能够以递推的方式得以解决。</p>\n<p>通常按如下４个步骤来设计动态规划算法：</p>\n<ol>\n<li>刻画最优解的结构特征（寻找最优子结构）</li>\n<li>递归地定义最优解的值（确定状态转移方程）</li>\n<li>计算最优解的值（带备忘的自顶向下实现和自底向上的实现）</li>\n<li>利用计算出来的信息构造一个最优解</li>\n</ol>\n<h2 id=\"问题实例\"><a href=\"#问题实例\" class=\"headerlink\" title=\"问题实例\"></a>问题实例</h2><h3 id=\"数塔问题\"><a href=\"#数塔问题\" class=\"headerlink\" title=\"数塔问题\"></a>数塔问题</h3><p><strong>问题描述</strong><br>给定一个三角形，从上到下找到最小路径和。每一步你都可以移动到下一行的相邻数字。</p>\n<blockquote>\n<p>[<br><br>     [2],<br><br>    [3,4],<br><br>   [6,5,7],<br><br>  [4,1,8,3]<br><br>]</p>\n</blockquote>\n<p>从顶到底部的最小路径和为 <code>11</code> (i.e., 2 + 3 + 5 + 1 = 11)</p>\n<p><strong>状态转移方程</strong></p>\n<p>用子问题定义状态：$F_{k,i}$为：数塔中第k行第i项的最小路径和</p>\n<p>那么，状态转移方程(其中 $A_{k,i}$ 为第k行第i项的值)：</p>\n<blockquote>\n<p>$F_{k,i} = max(F_{k+1, i}, F_{k+1, i+1}) + A_{k,i}$</p>\n</blockquote>\n<p><strong>实现</strong></p>\n<pre><code class=\"python\">def minimumTotal(self, triangle):\n    &quot;&quot;&quot;\n    :type triangle: List[List[int]]\n    :rtype: int\n    &quot;&quot;&quot;\n    if not triangle:\n        return\n    res = triangle[-1]  # 优化空间\n    for k in range(len(triangle)-2, -1, -1):\n\n        for i in range(0, len(triangle[k]), 1):\n            res[i] = min(res[i], res[i+1]) + triangle[k][i]\n    return res[0]\n</code></pre>\n<h3 id=\"背包问题\"><a href=\"#背包问题\" class=\"headerlink\" title=\"背包问题\"></a>背包问题</h3><p><strong>问题描述</strong></p>\n<p>给出n个物品的重量W[i]和其价值V[i]，背包的容量为w磅，问最多能装入的总价值有多大？</p>\n<p><strong>状态转移</strong></p>\n<p>用子问题定义状态：F[i][w]表示前i件物品恰放入一个容量为w的背包可以获得最大价值。</p>\n<p>那么状态转移方程：</p>\n<blockquote>\n<p>$$F[i][w] = \\begin{cases}<br>0, &amp;if\\ i=0\\ or\\ w=0\\<br>F[i-1][w], &amp;if\\ W[i] &gt; w\\<br>max(F[i-1][w-W[i]]+V[i], F[i-1][w]), &amp;if\\ W[i] &lt;= w\\<br>\\end{cases}$$</p>\n</blockquote>\n<p><strong>实现</strong></p>\n<pre><code class=\"python\">def backPackII(self, w, W, V):\n    &quot;&quot;&quot;\n    :type w: An integer m denotes the size of a backpack\n    :type W: Given n items with size W[i]\n    :type V: Given n items with value V[i]\n    :rtype: int\n    &quot;&quot;&quot;\n    res = [0] * (w+1)  # 空间优化\n\n    for i in range(1, len(W)+1):\n\n        for j in reversed(range(W[i-1], w+1)):\n            res[j] = max(res[j], res[j-A[i-1]]+V[i-1])\n    return res[w]\n</code></pre>\n<h3 id=\"最长公共子序列问题\"><a href=\"#最长公共子序列问题\" class=\"headerlink\" title=\"最长公共子序列问题\"></a>最长公共子序列问题</h3><p><strong>问题描述</strong></p>\n<p>给定两个序列$X=[x_1, x_2, …, x_m]$和$Y=[y_1, y_2, …, y_n]$，求X和Y的最长公共子序列。</p>\n<blockquote>\n<p>X=[A, B, C, B, D, A, B], Y=[B, D, C, A, B, A]</p>\n</blockquote>\n<p>那么<code>[B, C, B, A]</code>和<code>[B, D, A, B]</code>都是X和Y的最长公共子序列，长度为<code>4</code>。</p>\n<p><strong>状态描述</strong></p>\n<blockquote>\n<p>$$<br>C[i, j]= \\begin{cases}<br>0, &amp;\\text {if i = 0 or j = 0}\\<br>C[i-1, j-1] + 1, &amp;\\text {if i,j &gt; 0 and $x_i=y_j$} \\<br>max(C[i-1, j], C[i, j-1]), &amp; \\text {if i,j &gt; 0 and $x_i \\neq y_j$}<br>\\end{cases} $$</p>\n</blockquote>\n<p><strong>实现</strong></p>\n<pre><code class=\"python\">def longestCommonSubsequence(A, B):\n    &quot;&quot;&quot;\n    @param: A: A string\n    @param: B: A string\n    @return: The length of longest common subsequence of A and B\n    &quot;&quot;&quot;\n    m = len(A)\n    n = len(B)\n    c = [[0] * (n+1) for i in range(m+1)]\n\n    for i in range(1, m+1):\n        for j in range(1, n+1):\n            if A[i-1] == B[j-1]:\n                c[i][j] = c[i-1][j-1] + 1\n            else:\n                c[i][j] = max(c[i-1][j], c[i][j-1])\n    return c[m][n]\n</code></pre>\n<h3 id=\"最长公共子串问题\"><a href=\"#最长公共子串问题\" class=\"headerlink\" title=\"最长公共子串问题\"></a>最长公共子串问题</h3><p><strong>问题描述</strong></p>\n<p>最大公共字串要求的字串是连续的。</p>\n<blockquote>\n<p>A=”ABCD”，B=”CBCE”</p>\n</blockquote>\n<p>那么最长公共子串为<code>BC</code>，长度为<code>2</code></p>\n<p><strong>状态转移</strong></p>\n<p>和最长公共子序列类似的，只是在$A[i] \\neq B[j]$时，长度为0，而不是求$max(C[i-1][j], C[i][j-1])$<br>状态转移方程为：</p>\n<blockquote>\n<p>$$<br>C[i, j]= \\begin{cases}<br>0, &amp;\\text {if i = 0 or j = 0}\\<br>C[i-1, j-1] + 1, &amp;\\text {if i,j &gt; 0 and $x_i=y_j$} \\<br>C[i-1, j-1], &amp; \\text {if i,j &gt; 0 and $x_i \\neq y_j$}<br>\\end{cases}<br>$$</p>\n</blockquote>\n<p><strong>实现</strong></p>\n<pre><code class=\"python\">def longestCommonSubstring(self, A, B):\n    &quot;&quot;&quot;\n    @param: A: A string\n    @param: B: A string\n    @return: the length of the longest common substring.\n    &quot;&quot;&quot;\n    m = len(A)\n    n = len(B)\n    c = [[0] * (n+1) for i in range(2)]\n    ans = 0\n\n    for i in range(1, m+1):\n        for j in range(1, n+1):\n            if A[i-1] == B[j-1]:\n                c[1][j] = c[0][j-1] + 1\n                ans = max(ans, c[1][j])\n\n            else:\n                c[1][j] =0\n        c[0], c[1] = c[1], c[0]\n    return ans\n</code></pre>\n<h3 id=\"最长递增序列问题\"><a href=\"#最长递增序列问题\" class=\"headerlink\" title=\"最长递增序列问题\"></a>最长递增序列问题</h3><p><strong>问题描述</strong></p>\n<p>最长递增子序列（Longest Increasing Subsequence）是指找到一个给定序列的最长子序列的长度，使得子序列中的所有元素单调递增。</p>\n<blockquote>\n<p>[10, 9, 2, 5, 3, 7, 101, 18]</p>\n</blockquote>\n<p>其最长递增子序列为：<code>[2, 3, 7, 101]]</code>，长度为<code>4</code>。注意可能不只一个最长子序列。</p>\n<p><strong>解法一</strong></p>\n<p>其实可以把 求最长递增子序列问题 转化为 求最长公共子序列的问题：</p>\n<ul>\n<li>设原数组[10, 9, 2, 5, 3, 7, 101, 18]为A</li>\n<li>对数组排序过后，得到B=[2, 3, 5, 7, 9, 10, 18, 101]</li>\n<li>求数组A和B的最长公共子序列</li>\n</ul>\n<p><strong>解法二</strong></p>\n<p>设F[i]表示以i结尾的子序列中LIS的长度。用$F<a href=\"0&lt;=j&lt;i\">j</a>$来表示在i之前的LIS的长度。</p>\n<p>所以状态转移方程为：</p>\n<blockquote>\n<p>$F[i]=\\mathop{max}\\limits_{0 \\le j\\lt i}(F[j])+(a[i]&gt;a[j])?1:0$</p>\n</blockquote>\n<p>代码：</p>\n<pre><code class=\"python\">def lengthOfLIS(self, nums):\n    &quot;&quot;&quot;\n    :type nums: List[int]\n    :rtype: int\n    :O(n) = n^2\n    &quot;&quot;&quot;        \n    if not nums:\n        return 0\n    n = len(nums)\n    c = [1] * n\n\n    for i in range(1, n):\n        for j in range(0, i):\n            if nums[i] &gt; nums[j] and c[i] &lt; c[j] + 1:\n                c[i] = c[j] + 1\n    return max(c)\n</code></pre>\n<p><strong>解法三</strong></p>\n<pre><code class=\"python\">def lengthOfLIS(self, nums):\n    tails = [0] * len(nums)\n    size = 0\n    for x in nums:\n        i, j = 0, size\n        while i != j:\n            m = (i + j) // 2\n            if tails[m] &lt; x:\n                i = m + 1\n            else:\n                j = m\n        tails[i] = x\n        size = max(i + 1, size)\n    return size\n</code></pre>\n","categories":["算法"],"tags":["算法","动态规划"]},{"title":"排序算法","url":"http://shawnz.me/posts/735e5788/","content":"<!--  -->\n<a id=\"more\"></a>\n<h2 id=\"选择排序\"><a href=\"#选择排序\" class=\"headerlink\" title=\"选择排序\"></a>选择排序</h2><p><strong>基本思想：</strong></p>\n<p>首先，找到数组中最小的那个元素，其次，将他和数组中的第一个元素交换位置（如果第一个元素就是最小那个元素那么它就和自己交换）。再次，在剩余的元素中找到最小的元素，将它与第二个元素交换位置。如此往复，直到整个数组有序。</p>\n<p><strong>时间复杂度：</strong>$O(n^2)$</p>\n<p><strong>算法分析:</strong></p>\n<pre><code class=\"python\">def selection_sort(collection):\n    &#39;&#39;&#39;\n    &gt;&gt;&gt; selection_sort([4, -2, 10, 7]) \n    [-2, 4, 7, 10]\n    &#39;&#39;&#39;\n\n    for i in range(len(collection)):\n        least = i\n        for j in range(i+1, len(collection)):\n            if collection[j] &lt; collection[least]:\n                least = j\n\n        collection[i], collection[least] = collection[least], collection[i]\n    return collection\n</code></pre>\n<p><strong>特点：</strong></p>\n<ul>\n<li>运行时间与输入无关。为了找出最小元素而扫描一遍数组并不能为下一次找到最小值提供有用信息，会发现一个有序数组或者元素全部相等的数组和一个随机数组的排序时间是一样的。而其他的算法能更好的利用输入的初始状态。</li>\n<li>数据移动最少。选择排序的用了N次交换，而其他任何排序算法都具备这个特征。</li>\n</ul>\n<h2 id=\"插入排序\"><a href=\"#插入排序\" class=\"headerlink\" title=\"插入排序\"></a>插入排序</h2><p><strong>基本思想：</strong></p>\n<p>插入排序通过把元素插入到一个已经有序数组中的合适位置来达到排序目的.从第二个元素开始,假设左边的元素都是有序的,通过比较找到合适的位置,插入该元素.重复这个步骤,知道索引达到数组最右边,这是整个数组已经排序完成.</p>\n<p><strong>时间复杂度:</strong>$O(n^2)$</p>\n<p><strong>代码实现:</strong></p>\n<pre><code class=\"python\">def insertration_sort(collection):\n    &#39;&#39;&#39;\n    &gt;&gt;&gt; insertration_sort([-4, 45, 5, -10])\n    [-10, -4, 5, 45]\n    &#39;&#39;&#39;\n    if len(collection) &lt; 2:\n        return collection\n\n    for i in range(1, len(collection)):\n        while i &gt;    0 and (collection[i] &lt; collection[i-1]):\n            collection[i], collection[i-1] = collection[i-1], collection[i]\n            i -= 1\n\n    return collection\n</code></pre>\n<p><strong>特点:</strong><br>插入排序对于基本有序数组十分高效,也适用于小规模数组.经常出现其他高级排序算法的中间过程.</p>\n<h2 id=\"希尔排序\"><a href=\"#希尔排序\" class=\"headerlink\" title=\"希尔排序\"></a>希尔排序</h2><p><strong>基本思想:</strong></p>\n<p>希尔排序是对插入排序的一种高效率实现,因为插入排序只能把小元素一个一个的从一端移到另一端.</p>\n<p>希尔排序的思想是:数组中任意间隔为h的元素都是有序数组(一个h有序数组就是h个相互独立的有序数组编织在一起组成的一个数组).如果h很大,那么元素就可以移动到很远的距离,为实现更小的h有序数组提供方便.</p>\n<p>希尔排序的一种方法是:先将整个待排记录序列分割成为h个子序列,用插入排序将h个子数组独立地排序,待整个序列中的记录基本有序时再对全体记录进行一次直接插入排序。</p>\n<p><strong>时间复杂度:</strong> 希尔排序的分析是复杂的，时间复杂度是所取增量的函数，这涉及一些数学上的难题。但是在大量实验的基础上推出当n在某个范围内时，时间复杂度可以达到$O(n^{1.3})$</p>\n<p><strong>代码实现:</strong></p>\n<pre><code class=\"python\">\ndef shell_sort(collections):\n    &#39;&#39;&#39;\n    &gt;&gt;&gt; shell_sort([0, 5, 3, 2, 2])\n    [0, 2, 2, 3, 5]\n\n    &gt;&gt;&gt; shell_sort([])\n    []\n\n    &gt;&gt;&gt; shell_sort([-2, -5, -45])\n    [-45, -5, -2]\n    &#39;&#39;&#39;\n\n    def shell_insert_sort(arr, d):\n\n        for i in range(d, len(arr)):\n            while i &gt; 0 and arr[i] &lt; arr[i-d]:\n                arr[i], arr[i-d] = arr[i-d], arr[i]\n                i -= d\n\n    n = len(collections)\n    d = n // 2\n\n    while d &gt;= 1:\n        shell_insert_sort(collections, d)\n        d = d // 2\n\n    print(collections)\n</code></pre>\n<p><strong>特点:</strong></p>\n<p>对于中等大小的数组,希尔排序的运行时间是可以接受的,代码量小,而且不需要额外的内存空间.</p>\n<h2 id=\"归并排序\"><a href=\"#归并排序\" class=\"headerlink\" title=\"归并排序\"></a>归并排序</h2><p><strong>基本思想：</strong></p>\n<p>递归实现的归并排序是<code>分治法</code>（Divide and Conquer）的一个非常典型的应用．该算法基于归并这个操作．</p>\n<p>要将一个数组排序，可以（递归地）先将它分为两半分别排序，然后将结果归并起来．</p>\n<p><strong>时间复杂度：</strong>　归并排序是一种渐近最优的基于比较排序的算法, 意即: 其在最坏情况下的比较次数和任意基于比较的排序算法所需的最少比较次数都是~NlgN。其主要的优点是可以保证将任意长度为 N 的数组排序的时间复杂度为 O(NlgN); 其主要缺点是空间复杂度为 O(N)</p>\n<p><strong>代码实现:</strong></p>\n<pre><code class=\"python\">def merge_sort(collections):\n    &#39;&#39;&#39;\n    Examples:\n    &gt;&gt;&gt; merge_sort([0, 5, 3, 2, 2])\n    [0, 2, 2, 3, 5]\n\n    &gt;&gt;&gt; merge_sort([])\n    []\n\n    &gt;&gt;&gt; merge_sort([-2, -5, -45])\n    [-45, -5, -2]\n    &#39;&#39;&#39;\n    n = len(collections)\n    if n &gt; 1:\n        mid = n // 2\n        left_half = merge_sort(collections[:mid])\n        right_half = merge_sort(collections[mid:])\n\n        i = 0\n        j = 0\n        for k in range(n):\n\n            if i &gt;= mid:\n                collections[k] = right_half[j]\n                j += 1\n            elif j &gt;= n-mid:\n                collections[k] = left_half[i]\n                i += 1\n            elif left_half[i] &lt; right_half[j]:\n                collections[k] = left_half[i]\n                i += 1\n            else:\n                collections[k] = right_half[j]\n                j += 1\n\n    return collections\n</code></pre>\n<p><strong>算法分析：</strong></p>\n<ul>\n<li><p>优化一: 对小规模子数组使用插入排序</p>\n<p>  递归会使小规模问题中方法的调度过于频繁, 而插入或者选择在小数组上比归并要快, 所以改进对小规模子数组的处理方法可以改进整个算法。根据经验, 使用插入处理小规模子数组(&lt;15)可将归并的运行时间缩短10%~15%。</p>\n</li>\n<li><p>优化二: 测试子数组是否有序</p>\n<p>  添加一个判断条件: if (a[mid] &gt; a[mid+1]) 再进行 Merge() 操作, 否则数组已经是有序的。进行此优化可以令任意有序的子数组算法时间复杂度变为线性。</p>\n</li>\n<li><p>优化三: 不将元素复制到辅助数组</p>\n<p>  在递归调用的每个层次交换输入数组和辅助数组的角色, 可节省将数组元素复制到用于归并的辅助数组的时间(无法节省空间)。</p>\n</li>\n</ul>\n<h2 id=\"快速排序\"><a href=\"#快速排序\" class=\"headerlink\" title=\"快速排序\"></a>快速排序</h2><p><strong>基本思想：</strong></p>\n<p>快速排序是一种分治的排序算法．它将整个数组分为两个数组，两个数组独立排序．</p>\n<p>快速排序和归并排序是互补：</p>\n<ul>\n<li>归并排序是将数组分为两个子数组分别排序，然后再将有序子数组归并，以使整个数组有序．<br>  快速排序则是当两个子数组都有序时整个数组也就有序了．</li>\n<li>归并排序递归调用在处理整个数组之前．快速排序递归调用发生在处理整个数组之后．</li>\n<li>归并排序数组被等分为两个部分．快速排序切分（partition）的位置取决于数组的内容</li>\n</ul>\n<p>快速排序的关键在于<code>切分</code>,找到基准元素<code>pivot</code>的位置将数组切分为:<br>    <code>a[low..pivot-1] ≤ a[pivot] ≤ a[pivot+1..high]</code></p>\n<p>切分方法有两种思路:</p>\n<ul>\n<li>A</li>\n<li>B</li>\n</ul>\n<p><strong>时间复杂度：</strong>快速排序是不稳定的,平均时间复杂度为$O(NlgN)$ 最坏情况是$O(n^2)$</p>\n<p><strong>代码实现:</strong></p>\n<pre><code class=\"python\">def sort(a, lo, hi):\n    if hi &lt;= lo:\n        return\n    p = partition(a, lo, hi)\n    sort(a, lo, p-1)  # 将左半部分[lo, p-1]排序\n    sort(a, p+1, hi)  # 将右半部分[p+1, hi]排序\n\n\ndef partition(a, lo, hi):\n    &#39;&#39;&#39; 将数组a切分为a[lo..i-1] a[i] a[i+1..hi] &#39;&#39;&#39;\n    pivot = a[lo]\n    i = lo + 1\n    j = hi\n    while True:\n        while a[i] &lt; pivot:\n            i += 1\n            if i == hi:\n                break\n        while a[j] &gt; pivot:\n            j -= 1\n            if j == lo:\n                break\n        if (i &gt;= j):\n            break\n        a[i], a[j] = a[j], a[i]\n    a[lo], a[j] = a[j], a[lo]\n    return j\n\n\ndef quick_sort(collections):\n    &#39;&#39;&#39;\n    Examples:\n    &gt;&gt;&gt; quick_sort([0, 5, 3, 2, 2])\n    [0, 2, 2, 3, 5]\n\n    &gt;&gt;&gt; quick_sort([])\n    []\n\n    &gt;&gt;&gt; quick_sort([-2, -5, -45])\n    [-45, -5, -2]\n    &#39;&#39;&#39;\n    sort(collections, 0, len(collections)-1)\n    return collections\n\n</code></pre>\n<p><strong>算法分析：</strong></p>\n<p>在大多数情况下,快速排序都是高效的.有几个改进快速排序性能的方法:</p>\n<ul>\n<li>对小数组切换到插入排序.<br>  将 <code>if hi &lt;= lo return</code> 改为 <code>if hi &lt; lo + M: insertion_sort(a, lo, hi) return</code><br>  经验表明,在大多数情况下<code>M</code>取值5-15能够取得较好的性能.</li>\n<li>三样取切分.<br>  取子数组的小部分中位数能更好地切分数组,代价是计算中位数.一种常用的方法是取数组最左边值和最右边值以及数组中间位置值这三个数据项中的中间值作为切分值.</li>\n<li>熵最优的排序<br>  对于元素全部是重复元素的子数组,就不需要在进行排序,但是快速排序依旧会将他切分成更小的数组.<br>  一种方法是<code>三向切分法</code>,将数组分为小于,等于以及大于切分元素的三部分数组.这也是<code>Dijkstra</code>解法.</li>\n</ul>\n<h2 id=\"堆排序\"><a href=\"#堆排序\" class=\"headerlink\" title=\"堆排序\"></a>堆排序</h2><p><strong>基本思想:</strong><br>堆排序使用堆的数据结构来构造了优先队列.</p>\n<p><code>堆有序</code>当一颗二叉树的每个结点都大于等于它的两个子结点时,它被称为堆有序.</p>\n<p><code>二叉堆</code>是一组能够用堆有序的完全二叉树排序的元素,并在数组中按照层级存储.</p>\n<pre><code>- `不使用数组的第一个位置`那么位置k的结点的父结点的位置为[k/2],而它的两个子结点的位置分别为2k和2k+1.\n- `在第一个元素的索引为 0 时`：位置为k的父结点索引是 floor((k-1)/2), 而它的左右子结点分别为2*k+1和2*k+2.\n</code></pre><p><code>堆的有序化</code>(HEAPIFY):</p>\n<ul>\n<li><p>由下至上的堆有序化<br>  如果堆的有序化状态因为某个结点的值变得比它的父结点大而被打破时,需要交换它和它的父结点来修复堆.<br>  由下至上的堆有序化当一个结点太大时,需要上浮(swim)到堆的更高层.</p>\n<pre><code class=\"python\">  def swim(A, k):\n      while k &gt; 1 and A[k//2] &lt; A[k]:\n          A[k//2], A[k] = A[k], A[k//2]  \n          k = k // 2\n</code></pre>\n</li>\n<li><p>由上至下的堆有序化<br>  如果堆的有序状态由于某个结点变得比它的两个子结点或者其中之一小而打破,那么可以将它和两个子结点中较大的值交换来修复堆.<br>  由上至下的堆有序化当一个结点太小时,需要下沉(sink)到堆的更底层.</p>\n<pre><code class=\"python\">  def sink(A, i):\n      while (2 * k &lt; N):\n          j = 2 * k\n          if (j &lt; N and A[j] &lt; A[j+1]):\n              j = j + 1\n          if A[k] &gt;= A[j]:\n              break\n          A[k], A[j] = A[j], A[k]\n          k = j\n</code></pre>\n</li>\n</ul>\n<p><code>堆排序</code> 堆排序可以分为两个阶段:</p>\n<ul>\n<li><p>堆的构造:构造堆的方法又有两种:</p>\n<ul>\n<li>从左到右扫描数组,使用<code>swim</code>保证指针左侧的所有元素已经是一颗堆有序完全树.</li>\n<li>另一种更好的做法是从右到左扫描数组,使用<code>sink</code>函数构造子堆.数组的每一个位置都已经是一个子堆的根结点,那么sink函数堆对这些子堆也适用.如果一个结点的两个子结点都已经是堆,那么使用<code>sink</code>函数可以构成一个新的堆.<br>开始时,可以跳过大小为1的子堆,从数组的一半开始扫描,直到在位置为1的地方使用<code>sink</code>结束扫描.</li>\n</ul>\n</li>\n<li><p>堆排序:选择堆中最大的元素删除,放到堆缩小空出的位置.堆的排序过程和选择排序相似(按照降序而不是升序选取元素).</p>\n</li>\n</ul>\n<p><strong>时间复杂度:</strong></p>\n<p><strong>代码实现:</strong></p>\n<pre><code class=\"python\">def sink(A, k, n):\n    &#39;&#39;&#39;\n    :params :A 待排序数组\n    :params :k 被调节元素的位置\n    :params :n 堆的大小\n    &#39;&#39;&#39;\n    while (2 * k + 1 &lt; n):\n        j = 2 * k + 1\n        if j &lt; n - 1 and A[j] &lt; A[j + 1]:\n            j = j + 1\n        if A[k] &gt;= A[j]:\n            break\n        A[j], A[k] = A[k], A[j]\n        k = j\n\n\ndef heap_sort(collections):\n    &#39;&#39;&#39;\n    Examples:\n    &gt;&gt;&gt; heap_sort([0, 5, 3, 2, 2])\n    [0, 2, 2, 3, 5]\n\n    &gt;&gt;&gt; heap_sort([])\n    []\n\n    &gt;&gt;&gt; heap_sort([-2, -5, -45])\n    [-45, -5, -2]\n    &#39;&#39;&#39;\n    n = len(collections)\n\n    if n &lt; 1:\n        return collections\n\n    for i in range(n-1, -1, -1):\n        sink(collections, i, n)\n    while (n &gt; 0):\n        collections[0], collections[n-1] = collections[n-1], collections[0]\n        n = n - 1\n        sink(collections, 0, n)\n    return collections\n</code></pre>\n<p><strong>算法分析:</strong></p>\n<h2 id=\"计数排序\"><a href=\"#计数排序\" class=\"headerlink\" title=\"计数排序\"></a>计数排序</h2><p><strong>基本思想：</strong></p>\n<p>虽然基于比较的排序算法，其下限是$O(nlgn)$.但确实有许多线性时间复杂度排序，不过待排序的元素需要满足一定条件．</p>\n<p>计数排序的前提条件是：待排序的元素必须是一定范围内的整数，而且需要比较多的辅助空间．</p>\n<p>其思想是：对于每个输入的元素ｘ，确定小于ｘ的元素个数．利用这一点可以直接把ｘ放到数组正确的位置上，不过对于有相同元素时，这一方案需要略做修改．</p>\n<p><strong>时间复杂度：</strong>$O(n)$</p>\n<p><strong>代码实现：</strong></p>\n<pre><code class=\"python\">def counting_sort(collection):\n    &#39;&#39;&#39;\n    Examples:\n    &gt;&gt;&gt; counting_sort([0, 5, 3, 2, 2])\n    [0, 2, 2, 3, 5]\n    &gt;&gt;&gt; counting_sort([])\n    []\n    &gt;&gt;&gt; counting_sort([-2, -5, -45])\n    [-45, -5, -2]\n    &#39;&#39;&#39;\n    if not collection:\n        return collection\n\n    collection_max = max(collection)\n    collection_min = min(collection)\n    collection_len = len(collection)\n    counting_arr_len = collection_max - collection_min + 1\n\n    counting_arr = [0] * counting_arr_len\n    for i in collection:\n        counting_arr[i-collection_min] += 1\n\n    for i in range(1, counting_arr_len):\n        counting_arr[i] = counting_arr[i] + counting_arr[i-1]\n\n    ordered = [0] * collection_len\n\n    for i in range(collection_len - 1, -1, -1):\n        ordered[counting_arr[collection[i]-collection_min]-1] = collection[i]\n        counting_arr[collection[i]-collection_min] -= 1\n\n    return ordered\n</code></pre>\n<p><strong>算法分析：</strong></p>\n<p>计数排序的一个重要性质就是它是<strong>稳定的</strong>：具有相同值的元素在输出数组中的相对次序和在输入数组中的相对次序相同．这一性质也是计数排序经常用于基数排序的一个子过程的原因．</p>\n<h2 id=\"基数排序\"><a href=\"#基数排序\" class=\"headerlink\" title=\"基数排序\"></a>基数排序</h2><h2 id=\"桶排序\"><a href=\"#桶排序\" class=\"headerlink\" title=\"桶排序\"></a>桶排序</h2><p><strong>基本思想：</strong></p>\n<p>桶排序假设输入数据服从均匀分布．</p>\n<p>对于一组长度为N的待排关键字序列Ａ[1….n]。首先将这个序列划分成M个的子区间(桶) 。然后基于某种映射函数 ，将待排序列的关键字Ａ映射到第i个桶中(即桶数组B的下标 i) ，那么该关键字A就作为B[i]中的元素(每个桶B[i]都是一组大小为N/M的序列)。接着对每个桶B[i]中的所有元素进行比较排序(可以使用插入排序)。然后依次枚举输出B[0]….B[M]中的全部内容即是一个有序序列。</p>\n<p><strong>代码实现：</strong></p>\n<pre><code class=\"python\">\n</code></pre>\n<p><strong>算法分析：</strong></p>\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n    tex2jax: {\n        inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"]  ],\n        processEscapes: true,\n        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']\n    }\n});\nconsole.log(\"======================\")\nMathJax.Hub.Queue(function() {\n    var all = MathJax.Hub.getAllJax(), i;\n    for(i=0; i < all.length; i += 1) {\n        all[i].SourceElement().parentNode.className += ' has-jax';                 \n    }       \n});\n</script>\n\n<p><link href=\"https://cdn.bootcss.com/KaTeX/0.7.1/katex.min.css\" rel=\"stylesheet\"></p>\n<script src=\"//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>","categories":["算法"],"tags":["算法","排序"]},{"title":"项目：命令行聊天室","url":"http://shawnz.me/posts/a319874a/","content":"<p>在学习Python socket时候，通过动手实现一个命令行在线聊天室项目，加深对socket编程和网络编程的理解。主要使用到了<code>socket</code>和<code>select</code>模块来监听多客户端接入。<br><a id=\"more\"></a></p>\n<blockquote>\n<p>项目代码仓库：<a href=\"https://github.com/zhongshangwu/E-Chat\" target=\"_blank\" rel=\"noopener\">E-Chat</a></p>\n</blockquote>\n<h2 id=\"C-S-架构\"><a href=\"#C-S-架构\" class=\"headerlink\" title=\"C/S 架构\"></a>C/S 架构</h2><p><img src=\"/images/聊天室架构.png\" alt=\"聊天室架构\"></p>\n<p>主要实现两个部分：</p>\n<ul>\n<li>Client：聊天客户端，将用户输入转换成命令发送给服务器。</li>\n<li>Server：聊天服务器，负责与用户建立连接，处理客户端命令，并加入数据库模块，具备信息存储功能。</li>\n</ul>\n<p>服务器设计思路:</p>\n<ol>\n<li>服务器监听连接队列：<br> <code>select.select(list(map(lambda x: x.socket, secure_channels))+ self.inputs, [], [])</code></li>\n<li>当服务器<code>soctet</code>有数据可读时：表示有的新的客户端接入。把客户端<code>socket</code>添加到监听队列。</li>\n<li>当客户端<code>socket</code>有数据可读时：表示客户端发送了命令。</li>\n<li>从字节序列的<code>socket stream</code>解析出<code>命令</code>和<code>参数</code>。</li>\n<li>设计一套WEB框架类似的<code>路由机制</code>,根据<code>命令</code>找到对应的处理函数。</li>\n<li>在服务器端，把<code>socket</code>连接和用户信息放到内存中，使用数据库存储用户，聊天室，好友和聊天记录等数据。</li>\n</ol>\n<p>客户端设计思路：</p>\n<ol>\n<li>客户端连接到服务器，并监听终端输入和服务器连接。</li>\n<li>客户端会处于不同的模式模式，在不同的模式下，对于终端输入和服务端消息做不同的处理。</li>\n<li>客户端把好友，聊天室以及聊天记录存放到内存中，可以查看。</li>\n</ol>\n<h2 id=\"聊天协议\"><a href=\"#聊天协议\" class=\"headerlink\" title=\"聊天协议\"></a>聊天协议</h2><p>在Socket API上包装了一套简单的应用层协议：采用分层设计，先发送长度后发送内容以及AES数据加密的原则。</p>\n<p>数据包格式：</p>\n<pre><code>+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n| Length of Message Body(4Bytes)| AES padding_n(1Bytes)| AES IV(16Bytes)|\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|                        Command(4Bytes)                                |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|     Type of Parameter(1Bytes)     |     Length of Body(4Bytes)        |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|         int/str/bool/loat类型的字节序列    list和dict特殊处理             |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n</code></pre><ul>\n<li>对于list类型的参数：每个item都相当于处理第三层的数据包。</li>\n<li>对于dict类型的参数：<ul>\n<li>key格式为：<code>|--Length of Key(1Byte)--|--Key--|</code>；</li>\n<li>value值相当于第三层的数据包。</li>\n</ul>\n</li>\n</ul>\n<p>源代码：<a href=\"https://github.com/zhongshangwu/E-Chat/blob/master/messages.py\" target=\"_blank\" rel=\"noopener\">messages.py</a></p>\n<h3 id=\"AES加密以及DH密钥交换\"><a href=\"#AES加密以及DH密钥交换\" class=\"headerlink\" title=\"AES加密以及DH密钥交换\"></a>AES加密以及DH密钥交换</h3><p>使用AES加密算法对传输的数据进行加密。在加密之前通过Diffie Hellman密钥交换算法，计算客户端和服务器的共享密钥。</p>\n<p>源代码：<a href=\"https://github.com/zhongshangwu/E-Chat/blob/master/secure_channel.py\" target=\"_blank\" rel=\"noopener\">secure_channel.py</a></p>\n<h2 id=\"Command-路由\"><a href=\"#Command-路由\" class=\"headerlink\" title=\"Command 路由\"></a>Command 路由</h2><p>在服务器端，模仿WEB框架的URL路由机制，实现一套Command路由机制。主要使用到Python中的装饰器模式。<br>(可以尝试的做法：传输的参数和HTTP协议的请求参数一样，统一按照键值对处理。那么根据函数内省机制，请求参数可以自动填充到函数调用中。)</p>\n<p>源代码：<a href=\"https://github.com/zhongshangwu/E-Chat/blob/master/server/routes.py\" target=\"_blank\" rel=\"noopener\">routes.py</a></p>\n","categories":["Python"],"tags":["Python","实战"]},{"title":"AES加密","url":"http://shawnz.me/posts/2e799336/","content":"<h2 id=\"AES\"><a href=\"#AES\" class=\"headerlink\" title=\"AES.\"></a>AES.</h2><p>AES（Advanced Encryption Standard），在密码学中又称Rijndael加密法，是美国联邦政府采用的一种区块加密标准。这个标准用来替代原先的DES。其密钥长度则可以是128，192或256比特。</p>\n<a id=\"more\"></a>\n<h2 id=\"工作模式\"><a href=\"#工作模式\" class=\"headerlink\" title=\"工作模式\"></a>工作模式</h2><p>AES是分组加密，AES标准支持的分组大小固定为128位（16字节），对于怎样按分组大小切分以及数据不对齐怎么处理，AES提供了几种工作模式：</p>\n<ul>\n<li><code>电子密码本</code>：Electronic Code Book Mode (ECB)：密文被分割成分组长度相等的块（不足补齐），然后单独一个个加密，一个个输出组成密文。模式的问题是无法隐藏原明文数据的模式，因为同样的明文分组加密得到的密文也是一样的。</li>\n<li><code>密码分组链接</code>：Cipher Block Chaining Mode (CBC)：引入了IV（初始化向量：Initialization Vector）的概念，IV是长度为分组大小的一组随机。CBC要求第一个分组的明文在加密运算前先与IV进行异或；从第二组开始，所有的明文先与前一分组加密后的密文进行异或。CBC模式相比ECB实现了更好的模式隐藏，但由于将密文引入运算，加解密操作无法并行操作。同时引入的IV向量，还需要加、解密双方共同知晓方可。</li>\n<li><code>密文反馈</code>：Cipher Feedback Mode (CFB)：CFB模式先生成密码流字典，然后用密码字典与明文进行异或操作并最终生成密文。后一分组的密码字典的生成需要前一分组的密文参与运算。</li>\n<li><code>输出反馈</code>：Output Feedback Mode (OFB)：与CFB模式不同的地方是生成字典的时候会采用明文参与运算，CFB采用的是密文。<br>(ps: 后面两种反馈模式不太明白。。)</li>\n</ul>\n<h2 id=\"AES-In-Python\"><a href=\"#AES-In-Python\" class=\"headerlink\" title=\"AES In Python\"></a>AES In Python</h2><p>PyCrypto加密算法库提供了AES的加解密算法：</p>\n<pre><code class=\"python\">from Crypto.Cipher import AES\nclipher = AES.new(key, mode, IV)\n</code></pre>\n<p>该方法返回一个<code>AESCipher</code>对像，函数的几个参数：</p>\n<ul>\n<li><code>key</code>：字节或者字符串，必须为16 (<em>AES-128</em>), 24 (<em>AES-192</em>), 或者2 (<em>AES-256</em>)字节，用来对称加密。</li>\n<li><code>mode</code>： 工作模式常量，默认为<code>MODE_ECB</code>。</li>\n<li><code>IV</code>： 可选，初始化向量，必须和分组大小相同16个字节，缺省的时候为全0字节。</li>\n</ul>\n<pre><code class=\"python\">import os\nimport hashlib\nfrom Crypto.Cipher import AES\n\n\nclass AESCryptor():\n    &#39;&#39;&#39; AES加密器 &#39;&#39;&#39;\n\n    def __init__(self):\n        # key 长度必须为16、24、或32Bytes 长度\n        # AES-256\n        self.key = hashlib.sha256(&#39;zhongshangwu&#39;.encode(&#39;utf-8&#39;)).digest()\n        self.mode = AES.MODE_CBC\n        self.iv = bytes(os.urandom(16))\n        self.block_size = 16  # 分组大小\n\n    def encrypt(self, plain):\n        &#39;&#39;&#39; 加密 &#39;&#39;&#39;        \n        # 转成字节序列\n        if isinstance(plain, str):\n            plain = plain.encode(&#39;utf-8&#39;)\n        assert isinstance(plain, bytes)\n\n        length_of_plain = len(plain)\n\n        # 补齐\n        padding_count = self.block_size - (length_of_plain % self.block_size)\n        plain += b&#39;\\0&#39; * padding_count\n\n        cryptor = AES.new(self.key, self.mode, self.iv)\n        cipher = cryptor.encrypt(plain)\n        # 统一把加密后的字符串转化为16进制字符串\n        cipher = (padding_count).to_bytes(4, byteorder=&#39;big&#39;) + cipher\n        return cipher\n\n    def decrypt(self, cipher):\n        &#39;&#39;&#39; 解密 &#39;&#39;&#39;\n        assert isinstance(cipher, bytes)\n        assert cipher and len(cipher) &gt; 4\n\n        padding_count_bytes = cipher[:4]\n        padding_count = int.from_bytes(padding_count_bytes, byteorder=&#39;big&#39;)\n        encrypted_cipher = cipher[4:]\n\n        cryptor = AES.new(self.key, self.mode, self.iv)\n        plain = cryptor.decrypt(encrypted_cipher)\n        plain = plain[:-padding_count]\n        return plain.decode(&#39;utf-8&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    cryptor = AESCryptor()\n    e = cryptor.encrypt(&#39;zhongshangwu&#39;)\n    d = cryptor.decrypt(e)\n    print(d)\n</code></pre>\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://github.com/matt-wu/AES\" target=\"_blank\" rel=\"noopener\">AES简介</a></li>\n</ul>\n","categories":["算法"],"tags":["Python","算法"]},{"title":"迪菲-赫尔曼密钥交换","url":"http://shawnz.me/posts/de8de911/","content":"<p><strong>迪菲-赫尔曼密钥交换</strong>（英语：Diffie–Hellman key exchange，缩写为D-H） 是一种安全协议(ps：不是加密算法)。它可以让双方在完全没有对方任何预先信息的条件下通过不安全信道创建起一个密钥。这个密钥可以在后续的通讯中作为对称密钥来加密通讯内容。<br><a id=\"more\"></a></p>\n<p><img src=\"DH.png\" alt=\"\"></p>\n<p>最简单，最早提出的这个协议使用一个质数p的整数模n乘法群以及其原根g。</p>\n<p>算法如下，绿色表示非秘密信息, 红色粗体表示秘密信息：</p>\n<ol>\n<li>爱丽丝与鲍伯协定使用 p=23以及base g=5.</li>\n<li>爱丽丝选择一个秘密整数a=6, 计算A = ga mod p并发送给鲍伯。<br> $$A = 56 mod 23 = 8$$</li>\n<li>鲍伯选择一个秘密整数b=15, 计算B = gb mod p并发送给爱丽丝。<br> $$B = 515 mod 23 = 19$$</li>\n<li>爱丽丝计算s = B a mod p<br> $$196 mod 23 = 2$$</li>\n<li>鲍伯计算s = A b mod p<br> $$815 mod 23 = 2$$</li>\n</ol>\n<p>爱丽丝和鲍伯最终都得到了同样的值，因为在模p下 $g^{ab}$$g^{ab}$和 $g^{ba}$ $g^{ba}$ 相等。 注意a, b 和 gab = gba mod p 是秘密的。 其他所有的值p, g, $ga modp$, 以及 gb mod p都可以在公共信道上传递。</p>\n<p>一旦爱丽丝和鲍伯得出了公共秘密，他们就可以把它用作对称密钥，以进行双方的加密通讯，因为这个密钥只有他们才能得到。</p>\n<p>当然，为了使这个例子变得安全，必须使用非常大的a, b 以及 p， 否则可以实验所有$g^{ab} mod 23 $的可能取值(总共有最多22个这样的值, 就算a和b很大也无济于事)。 如果 p 是一个至少 300 位的质数，并且a和b至少有100位长， 那么即使使用全人类所有的计算资源和当今最好的算法也不可能从g, p和$ga \\bmod p$ 中计算出 a。这个问题就是著名的离散对数问题。注意g则不需要很大, 并且在一般的实践中通常是2或者5</p>\n<p>以下是一个更为一般的描述:</p>\n<ol>\n<li>爱丽丝和鲍伯写上一个有限循环群 G 和它的一个生成元 g。 （这通常在协议开始很久以前就已经规定好； g是公开的，并可以被所有的攻击者看到。）</li>\n<li>爱丽丝选择一个随机自然数 a 并且将 $g^{a} mod p$发送给鲍伯。</li>\n<li>鲍伯选择一个随机自然数 b 并且将$g^{b} mod p$发送给爱丽丝。</li>\n<li>爱丽丝 计算 $(g^{b})^{a} mod p$。</li>\n<li>鲍伯 计算 $(g^{a})^{b} mod p$。</li>\n</ol>\n<p>爱丽丝和鲍伯就同时协商出群元素$g^{ab}$，它可以被用作共享秘密。$(g^{b})^{a}$和 $(g^{a})^{b}$因为群是乘法交换的。</p>\n","categories":["算法"],"tags":["Python","算法"]},{"title":"网络I/O模型","url":"http://shawnz.me/posts/22c73ece/","content":"<!-- ... -->\n<a id=\"more\"></a>\n<h2 id=\"异步和同步-阻塞和非阻塞\"><a href=\"#异步和同步-阻塞和非阻塞\" class=\"headerlink\" title=\"异步和同步/阻塞和非阻塞\"></a>异步和同步/阻塞和非阻塞</h2><ul>\n<li>同步和异步：关注的是<code>消息通知机制</code>。<ul>\n<li>同步：发出一个功能调用时，在没有得到结果之前，该调用就不返回。</li>\n<li>异步：当一个调用发出返回后，调用者不能立刻得到结果。</li>\n</ul>\n</li>\n<li>阻塞和非阻塞：关注的是<code>等待消息通知期间的状态</code>。<ul>\n<li>阻塞：调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。</li>\n<li>非阻塞:在不能立刻得到结果之前，该调用不会阻塞当前线程。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"文件描述符\"><a href=\"#文件描述符\" class=\"headerlink\" title=\"文件描述符\"></a>文件描述符</h2><p>文件描述符（file descriptor，简称 fd）在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的该进程打开文件的记录表。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。</p>\n<p>在 Linux 中，内核将所有的外部设备都当做一个文件来进行操作，而对一个文件的读写操作会调用内核提供的系统命令，返回一个 fd，对一个 socket 的读写也会有相应的描述符，称为 socketfd（socket 描述符），实际上描述符就是一个数字，它指向内核中的一个结构体（文件路径、数据区等一些属性）。</p>\n<h2 id=\"用户空间和内核空间，用户态和内核态\"><a href=\"#用户空间和内核空间，用户态和内核态\" class=\"headerlink\" title=\"用户空间和内核空间，用户态和内核态\"></a>用户空间和内核空间，用户态和内核态</h2><p>现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。<br>操心系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。<br>为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分：</p>\n<ul>\n<li>内核空间</li>\n<li>用户空间</li>\n</ul>\n<p>针对 linux 操作系统而言（以32位操作系统为例）：</p>\n<ul>\n<li>将最高的 1G 字节（从虚拟地址 0xC0000000 到 0xFFFFFFFF），供内核使用，称为内核空间；</li>\n<li>将较低的 3G 字节（从虚拟地址 0x00000000 到 0xBFFFFFFF），供各个进程使用，称为用户空间。</li>\n</ul>\n<p>每个进程可以通过系统调用进入内核，因此，Linux 内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有 4G 字节的虚拟空间。</p>\n<p>当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈；</p>\n<p>当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。</p>\n<h2 id=\"I-O模型\"><a href=\"#I-O模型\" class=\"headerlink\" title=\"I/O模型\"></a>I/O模型</h2><p>Linux I/O模型有以下五种：</p>\n<ul>\n<li>阻塞IO(blocking IO)</li>\n<li>非阻塞(non-blocking IO)</li>\n<li>IO多路复用(IO multiplexing)</li>\n<li>信号驱动IO(signal driven IO)</li>\n<li>异步IO(asynchronous IO)</li>\n</ul>\n<p>这几种模式的区别主要体现在对socket对象的read或write操作所经过的两个阶段各有所不同：</p>\n<ul>\n<li>等待操作系统内核数据准备好</li>\n<li>从内核拷贝数据到应用进程</li>\n</ul>\n<h3 id=\"1-阻塞IO：Blocking-I-O\"><a href=\"#1-阻塞IO：Blocking-I-O\" class=\"headerlink\" title=\"1. 阻塞IO：Blocking I/O\"></a>1. 阻塞IO：Blocking I/O</h3><p>大多数操作系统下的socket默认都是阻塞的， 除非单独设置为非阻塞。<br><img src=\"/images/blocking-io.png\" alt=\"\"></p>\n<p>默认情况下，socket所有accept()、read()、write()等操作均阻塞当前线程。</p>\n<h3 id=\"2-非阻塞IO-non-blocking-IO\"><a href=\"#2-非阻塞IO-non-blocking-IO\" class=\"headerlink\" title=\"2. 非阻塞IO: non-blocking IO\"></a>2. 非阻塞IO: non-blocking IO</h3><p>非阻塞IO需要对socket单独设置non-blocking属性</p>\n<p><img src=\"/images/non-blocking-io.png\" alt=\"\"></p>\n<h3 id=\"3-IO多路复用：IO-multiplexing\"><a href=\"#3-IO多路复用：IO-multiplexing\" class=\"headerlink\" title=\"3. IO多路复用：IO multiplexing\"></a>3. IO多路复用：IO multiplexing</h3><p>IO多路复用：通过一种机制，一个进程可以监视多个描述符，一旦某个描述符就绪（一般是读就绪或者写就绪），能够通知程序进行相应的读写操作。</p>\n<p>目前操作系统实现IO多路复主要有select、poll、epoll等几种方式。</p>\n<p>这些模块都能够同时监听一组socket，内核负责不断轮询或检测所负责的所有socket，当其中某一个socket满足可读或者可写了就唤醒用户进程进行处理。</p>\n<p>但select，pselect，poll，epoll本质上都是同步I/O，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。<br><img src=\"/images/io-multiplexing.png\" alt=\"\"></p>\n<p><strong>select</strong></p>\n<p>select 函数监视的文件描述符分3类，分别是writefds、readfds、和exceptfds。调用后select函数会阻塞，直到有描述符就绪（有数据 可读、可写、或者有except），或者超时（timeout指定等待时间，如果立即返回设为null即可），函数返回。当select函数返回后，可以通过遍历fdset，来找到就绪的描述符。</p>\n<p>select的调用过程：</p>\n<p><img src=\"/images/select.png\" alt=\"\"></p>\n<p>select本质是通过设置或者检查存放fd标志位的数据结构来进行下一步处理，这样存在几大缺点：</p>\n<ul>\n<li>每次调用<code>select</code>，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大；</li>\n<li>同时每次调用<code>select</code>都需要在内核遍历(线性扫描，即轮询)传递进来的所有fd，这个开销在fd很多时也很大；<br>(ps：如果能给套接字注册某个回调函数，当他们活跃时，自动完成相关操作，那就避免了轮询，这正是epoll与kqueue做的)</li>\n<li><code>select</code>支持的文件描述符数量太小了，默认是<code>1024</code>。</li>\n</ul>\n<p><strong>poll</strong></p>\n<p>poll本质上和select没有区别，只是描述fd集合的方式不同，poll使用pollfd结构（基于链表），而不是select的fd_set结构，它没有描述符限制。</p>\n<p><strong>epoll</strong></p>\n<p>epoll使用一个文件描述符管理多个描述符，将用户关系的文件描述符的事件存放到内核的一个事件表中，这样在用户空间和内核空间的copy只需一次。epoll提供了三个函数：</p>\n<ul>\n<li><code>epoll_create</code>，创建一个epoll句柄；</li>\n<li><code>epoll_ctl</code>，注册要监听的事件类型；</li>\n<li><code>epoll_wait</code>，等待事件的产生。</li>\n</ul>\n<p><code>epoll</code>的特点：</p>\n<ul>\n<li><code>epoll_ctl</code>函数。每次注册新的事件到epoll句柄中时（在 epoll_ctl 中指定 EPOLL_CTL_ADD ），会把所有的 fd 拷贝进内核，而不是在 epoll_wait 的时候重复拷贝。epoll 保证了每个 fd 在整个过程中只会拷贝一次。</li>\n<li><code>epoll</code>不像<code>select</code>或<code>poll</code>一样每次都把 current 轮流加入 fd 对应的设备等待队列中，而只在<code>epoll_ctl</code>时把 current 挂一遍（这一遍必不可少）并为每个 fd 指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。<code>epoll_wait</code>的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用<code>schedule_timeout()</code>实现睡一会，判断一会的效果，和<code>select</code>实现中的是类似的）</li>\n<li>和<code>poll</code>一样，epoll没有 fd 数量限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看, 一般来说这个数目和系统内存关系很大。</li>\n<li>使用<code>mmap</code>加速内核与用户空间的消息传递, 减少复制开销.</li>\n<li>在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。</li>\n</ul>\n<p><code>epoll</code>同时支持水平触发(Level Trigger, LT)和边缘触发(Edge Trigger, ET):</p>\n<ul>\n<li>LT: 当<code>epoll</code>检测到描述符准备就绪事件时通知应用程序, 应用程序可以不立即处理, <code>epoll</code>会在下一次调用<code>epoll_wait</code>时, 再次通知应用程序;</li>\n<li>ET: 当<code>epoll</code>检测到描述符准备就绪事件时通知应用程序, 应用程序必须立即处理. 如果不处理, 下次调用<code>epoll_wait</code>, 不会再响应应用程序并通知此事件. 边缘触发只支持非阻塞I/O, 以避免处理多个描述符的应用程序阻塞读写, 造成其他描述符饿死.</li>\n</ul>\n<p>显然, <code>ET</code>模式比<code>LT</code>模式更加高效, 因为它减少了重复<code>epoll</code>事件触发次数.</p>\n<p><strong>三种模型的比较</strong></p>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>select</th>\n<th>poll</th>\n<th>epoll</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>支持的最大连接数</td>\n<td>由 FD_SETSIZE 限制</td>\n<td>基于链表存储，没有限制</td>\n<td>受系统最大句柄数限制</td>\n<td></td>\n</tr>\n<tr>\n<td>fd 剧增的影响</td>\n<td>线性扫描 fd 导致性能很低</td>\n<td>同 select</td>\n<td>基于 fd 上的 callback 实现，没有性能下降的问题</td>\n<td></td>\n</tr>\n<tr>\n<td>消息传递机制</td>\n<td>内核需要将消息传递到用户空间，需要内核拷贝</td>\n<td>同 select</td>\n<td>epoll 通过 mmap 内核与用户空间共享内存来实现</td>\n<td></td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"4-信号驱动I-O：signal-driven-IO\"><a href=\"#4-信号驱动I-O：signal-driven-IO\" class=\"headerlink\" title=\"4. 信号驱动I/O：signal driven IO\"></a>4. 信号驱动I/O：signal driven IO</h3><p>需要先开启 socket 信号驱动 IO 功能，并通过系统调用<code>sigaction</code>执行一个信号处理函数（非阻塞，立即返回）。当数据就绪时，会为该进程生成一个 <code>SIGIO</code> 信号，通过信号回调通知应用程序调用 <code>recvfrom</code> 来读取数据，并通知主循环处理数据，流程如下图所示</p>\n<p><img src=\"/images/signal-io.jpg\" alt=\"\"></p>\n<h3 id=\"5-异步I-O：asynchronous-IO\"><a href=\"#5-异步I-O：asynchronous-IO\" class=\"headerlink\" title=\"5. 异步I/O：asynchronous IO\"></a>5. 异步I/O：asynchronous IO</h3><p>用户进程进行aio_read系统调用之后，无论内核数据是否准备好，都会直接返回给用户进程，然后用户态进程可以去做别的事情。等到socket数据准备好了，内核直接复制数据给进程，然后从内核向进程发送通知。IO两个阶段，进程都是非阻塞的。</p>\n<p><img src=\"/images/asynchronous-io.png\" alt=\"\"></p>\n<p>与信号驱动模式的主要区别是：</p>\n<ul>\n<li>信号驱动IO由内核通知我们何时可以开始一个IO操作；</li>\n<li>异步IO操作由内核通知我们IO何时完成</li>\n</ul>\n<h3 id=\"五种IO模型比较\"><a href=\"#五种IO模型比较\" class=\"headerlink\" title=\"五种IO模型比较\"></a>五种IO模型比较</h3><p><img src=\"/images/io模型比较.png\" alt=\"\"></p>\n<ol>\n<li><p>blocking IO和non-blocking IO：<br> 调用blocking IO会一直block住对应的进程直到操作完成，而non-blocking IO会立刻返回。</p>\n</li>\n<li><p>synchronous IO和asynchronous IO：<br> 在说明synchronous IO和asynchronous IO的区别之前，需要先给出两者的定义。Stevens给出的定义（其实是POSIX的定义）是这样子的：</p>\n<ul>\n<li>A synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes;</li>\n<li><p>An asynchronous I/O operation does not cause the requesting process to be blocked;</p>\n<p>两者的区别就在于synchronous IO做“IO operation”的时候会将process阻塞。按照这个定义，之前所述的blocking IO，non-blocking IO，IO multiplexing都属于synchronous IO。有人可能会说，non-blocking IO并没有被block啊。这里有个非常“狡猾”的地方，定义中所指的“IO operation”是指真实的IO操作，就是例子中的recvfrom这个系统调用。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h2><h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"http://blog.csdn.net/tennysonsky/article/details/45745887\" target=\"_blank\" rel=\"noopener\">Linux系统编程——I/O多路复用select、poll、epoll的区别使用</a></li>\n<li><a href=\"http://billowkiller.com/blog/2014/07/15/linux-epoll-module/\" target=\"_blank\" rel=\"noopener\">Linux Epoll Module</a></li>\n<li><a href=\"http://www.cnblogs.com/maociping/p/5121788.html\" target=\"_blank\" rel=\"noopener\">python网络编程——网络IO模型</a></li>\n<li><a href=\"http://www.jianshu.com/p/486b0965c296\" target=\"_blank\" rel=\"noopener\">聊聊Linux 五种IO模型</a></li>\n</ul>\n","categories":["网络"],"tags":["网络","并发"]},{"title":"Python网络编程","url":"http://shawnz.me/posts/d317e8c4/","content":"<blockquote>\n<p>Socket(套接字)通常指”通信端点“，用于进程间通信。<br><a id=\"more\"></a></p>\n</blockquote>\n<h2 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h2><p>Socket API 是由操作系统提供的一个编程接口，让应用程序可以控制使用 socket 技术。</p>\n<p>在TCP/IP五层架构中，Socket API 不属于TCP/IP协议簇，只是操作系统提供的一个用于网络编程的接口，工作在应用层与传输层之间：</p>\n<pre><code class=\"code\">     +----------------+\n     |  Application   | &lt;+\n     +----------------+  |\n     +----------------+  |\n  +&gt; |   Socket API   | &lt;+\n  |  +----------------+  |\n  |  +----------------+  |\n  |  |   Transport    | &lt;+\n  |  +----------------+\n  |  +----------------+\n  +&gt; |    Internet    |\n     +----------------+\n     +----------------+\n     | Network Access |\n     +----------------+\n</code></pre>\n<p>一个socket包含两个必要组成部分：</p>\n<ul>\n<li>地址，由ip和端口组成，例如192.168.1.10：80。</li>\n<li>协议，socket用的传输控制层协议，目前有三种：<code>TCP</code>，<code>UDP</code>和<code>rawIP</code>。</li>\n</ul>\n<p>地址与协议可以确定一个socket；一台机器上，只允许存在一个同样的socket。TCP 端口 53 的 socket 与 UDP 端口 53 的 socket 是两个不同的 socket。</p>\n<p>根据 socket 传输数据方式的不同（使用协议不同），可以分为以下三种：</p>\n<ol>\n<li><code>Stream sockets</code>，也称为“面向连接”的 socket，使用 TCP 协议。提供序列化的，可靠地和不重复的数据交付，而没有记录边界，这意味着上层协议需要自己去界定数据分隔符，其优势是数据是可靠的。创建流套接字，必须使用<code>SOCK_STREAM</code>作为套接字类型。</li>\n<li><code>Datagram sockets</code>，也称为“无连接”的 socket，使用 UDP 协议。实际通信前不需要连接，在传输过程中，无法确保它的顺序性，可靠性或重复性，然而数据确实保存了边界记录，这意味着消息是以整体发送的。创建数据包套接字，必须使用<code>SOCK_DAGRAM</code>作为套接字类型。<br>3.<code>Raw sockets</code>, 原始套接字（raw socket）是一种网络套接字，允许直接发送/接收IP协议数据包而不需要任何传输层协议格式。用原始套接字发送数据，是否自动增加传输层协议包头是可选的。<code>SOCK_RAW</code>作为套接字类型。</li>\n</ol>\n<p>根据使用的地址家族不同，可以分为两种：</p>\n<ol>\n<li>UNIX套接字：基于文件，创建时使用<code>AF_UNIX</code>，或<code>AF_LOCAL</code>作为地址家族。</li>\n<li>INET套接字：面向网络，创建时使用<code>AF_INET</code>,或<code>AF_INET6</code>作为地址家族。</li>\n</ol>\n<h2 id=\"Python中的Socket编程\"><a href=\"#Python中的Socket编程\" class=\"headerlink\" title=\"Python中的Socket编程\"></a>Python中的Socket编程</h2><p>在Python中提供了socket和SocketServer模块可以面向套接字编程。</p>\n<h3 id=\"TCP-Socket通信\"><a href=\"#TCP-Socket通信\" class=\"headerlink\" title=\"TCP Socket通信\"></a>TCP Socket通信</h3><p><a href=\"\">tcp_echo_server.py</a></p>\n<pre><code class=\"python\">import socket\nfrom time import ctime\n\ntcp_server_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ntcp_server_sock.bind((&#39;&#39;, 1024))\ntcp_server_sock.listen(5)\n\n\ndef handle_message(client_sock, addr):\n    while True:\n        data = client_sock.recv(1024)\n        if not data:\n            break\n        print(&#39;[from %s:%s] %s&#39; % (addr + (data.decode(&#39;utf-8&#39;),)))\n        client_sock.\\\n            send(bytes(&quot;[%s] %s&quot; % (ctime(), data.decode(&#39;utf-8&#39;)), &#39;utf-8&#39;))\n    client_sock.close()\n    print(&#39;client[%s:%s] socket closed&#39; % addr)\n\n\ndef loop_forever():\n    try:\n        while True:\n            print(&quot;waiting for connection...&quot;)\n            tcp_client_sock, addr = tcp_server_sock.accept()\n            print(&quot;connected from:%s:%s&quot;, addr)\n            handle_message(tcp_client_sock, addr)\n    finally:\n        tcp_server_sock.close()\n        print(&#39;server socket closed...&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    loop_forever()\n</code></pre>\n<p><a href=\"\">tcp_echo_client.py</a></p>\n<pre><code class=\"python\">import socket\n\ntcp_client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\ntcp_client_sock.connect((&#39;&#39;, 1024))\n\n\ndef loop_forver():\n    try:\n        while True:\n            data = input(&#39;&gt; &#39;)\n            if not data:\n                break\n            tcp_client_sock.send(bytes(data, &#39;utf-8&#39;))\n            data = tcp_client_sock.recv(1024)\n            if not data:\n                break\n            print(data.decode(&#39;utf-8&#39;))\n    finally:\n        tcp_client_sock.close()\n        print(&#39;client socket closed...&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    loop_forver()\n</code></pre>\n<h3 id=\"UDP-Socke通信\"><a href=\"#UDP-Socke通信\" class=\"headerlink\" title=\"UDP Socke通信\"></a>UDP Socke通信</h3><p><a href=\"\">udp_server.py</a></p>\n<pre><code class=\"python\">import socket\nfrom time import ctime\n\nudp_server_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nudp_server_sock.bind((&#39;&#39;, 1024))\n\n\ndef loop_forever():\n    try:\n        while True:\n            print(&quot;waiting for message...&quot;)\n            data, addr = udp_server_sock.recvfrom(1024)\n            if not data:\n                break\n            print(&#39;[from %s:%s] %s&#39; % (addr + (data.decode(&#39;utf-8&#39;),)))\n            udp_server_sock.\\\n                sendto(bytes(&quot;[%s] %s&quot; % (ctime(),\n                             data.decode(&#39;utf-8&#39;)), &#39;utf-8&#39;), addr)\n            print(&#39;...received from and returned to:%s:%s&#39; % addr)\n    finally:\n        udp_server_sock.close()\n        print(&#39;server socket closed...&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    loop_forever()\n\n</code></pre>\n<p><a href=\"\">udp_client.py</a></p>\n<pre><code class=\"python\">import socket\n\nudp_client_sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n\n\ndef loop_forver():\n    try:\n        while True:\n            data = input(&#39;&gt; &#39;)\n            if not data:\n                break\n            udp_client_sock.sendto(bytes(data, &#39;utf-8&#39;), (&#39;&#39;, 1024))\n            data, addr = udp_client_sock.recvfrom(1024)\n            if not data:\n                break\n            print(data.decode(&#39;utf-8&#39;))\n    finally:\n        udp_client_sock.close()\n        print(&#39;client socket closed...&#39;)\n\n\nif __name__ == &#39;__main__&#39;:\n    loop_forver()\n\n</code></pre>\n<p>###</p>\n<blockquote>\n<font face=\"Sans Serif\"><em><strong>最简单的socket通信</strong></em></font>\n</blockquote>\n<font face=\"Sans Serif\"><em><strong>SocketServer</strong></em></font><br><font face=\"Sans Serif\"><em><strong>select</strong></em></font>\n\n<h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><ul>\n<li><a href=\"https://docs.python.org/3/library/socket.html\" target=\"_blank\" rel=\"noopener\">socket文档</a></li>\n</ul>\n","categories":["Python"],"tags":["Python","Socket"]},{"title":"Python并发编程","url":"http://shawnz.me/posts/6cd209b1/","content":"<h2 id=\"Python中的并发\"><a href=\"#Python中的并发\" class=\"headerlink\" title=\"Python中的并发\"></a>Python中的并发</h2><p>本文主要介绍Python中的并发库：</p>\n<ul>\n<li>thread</li>\n<li>threading</li>\n<li>queue</li>\n<li>multiprocessing</li>\n<li>concurrent.futures</li>\n<li>yield协程</li>\n<li>asyncio<a id=\"more\"></a>\n</li>\n</ul>\n<h2 id=\"多线程\"><a href=\"#多线程\" class=\"headerlink\" title=\"多线程\"></a>多线程</h2><p>Python提供了多个模块来支持多线程编程，包括thread、threading和queue。thread提供了基本的线程和锁定的支持，而threading模块提供了更高级别的，功能更全面的线程管理。使用queue.Queue创建队列，用于线程之间共享。</p>\n<h3 id=\"thread\"><a href=\"#thread\" class=\"headerlink\" title=\"thread\"></a><strong>thread</strong></h3><center>表-1 thread模块和锁对象</center>\n\n<table>\n<thead>\n<tr>\n<th>函数/方法</th>\n<th>描          述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>thread.start_new_thread(func, args, kwargs=None)</td>\n<td>派生一个新的线程，使用给定的args和可选的kwargs来执行func</td>\n</tr>\n<tr>\n<td>thread.allocate_lock()</td>\n<td>分配LockType所对象</td>\n</tr>\n<tr>\n<td>thread.exit()</td>\n<td>给线程退出指令</td>\n</tr>\n<tr>\n<td>LockType.accquire(wait=None)</td>\n<td>尝试获取所对象</td>\n</tr>\n<tr>\n<td>LockType.locked()</td>\n<td>如果获取了锁对象，则返回True，否则返回False</td>\n</tr>\n<tr>\n<td>LockType.release()</td>\n<td>释放锁</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"threading\"><a href=\"#threading\" class=\"headerlink\" title=\"threading\"></a><strong>threading</strong></h3><center>表-2 threading模块的对象</center>\n\n<table>\n<thead>\n<tr>\n<th>对象</th>\n<th>描          述</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Thread</td>\n<td>表示一个执行线程的对象</td>\n</tr>\n<tr>\n<td>Lock</td>\n<td>锁原语对象</td>\n</tr>\n<tr>\n<td>RLock</td>\n<td>可重入所对象，使用单一线程可以再次获得已持有的锁</td>\n</tr>\n<tr>\n<td>Coordition</td>\n<td>条件变量对象，使得一个线程等待另一个线程满足特定的条件，比如改变状态或者某个数值</td>\n</tr>\n<tr>\n<td>Event</td>\n<td>条件变量的通用版本，任意数量线程等待某个事件发生，在该事件发生后所有线程被激活</td>\n</tr>\n<tr>\n<td>Semaphore</td>\n<td>为线程之间共享的资源提供一个“计数器”，如果没有可用资源则阻塞</td>\n</tr>\n<tr>\n<td>BoundedSemaphore</td>\n<td>与Semaphore相似，不过允许超过初始值</td>\n</tr>\n<tr>\n<td>Timer</td>\n<td>与Thread相似，不过它在运行前等待一定时间</td>\n</tr>\n<tr>\n<td>Barrier</td>\n<td>创建一个“障碍”，必须达到制定数量的线程才能继续</td>\n</tr>\n</tbody>\n</table>\n<p>避免使用thread模块，推荐使用更高级别的threading模块的原因：</p>\n<ul>\n<li>threading模块更加先进，有更好的线程支持，并且thread中的某些属性和threading的一些属性存在冲突</li>\n<li>低级别的thread模块拥有同步原语很少，而threding有很多</li>\n<li>thread模块对于进程何时退出没有做控制。当主进程结束时，其他线程也就结束了，没有清理和警告。</li>\n</ul>\n<p><code>示例</code></p>\n<pre><code class=\"python\">import threading\nfrom time import ctime, sleep\n\nloops = [4, 2]\n\ndef loop(nloop, nsec):\n    print(&quot;start loop&quot;, nloop, &quot;at:&quot;, ctime())\n    sleep(nsec)\n    print(&quot;loop&quot;, nloop, &quot;done at:&quot;, ctime())\n\ndef main():\n    print(&quot;starting at:&quot;, ctime())\n    threads = []\n    for i in loops:\n        thread = treading.Thread(target=loop, args=(i, loops[i]))\n        threads.append(thread)\n\n    for thread in threads:\n        thread.start()\n\n    for thread in threads:\n        thread.join()\n\n    print(&quot;all done at:&quot;, ctime())\n\nif __name__ == &#39;__main__&#39;:\n    main()\n</code></pre>\n<p>可以得到如下输出</p>\n<pre><code class=\"log\">starting at: Sat Nov 25 01:34:01 2017\nstart loop 0 at: Sat Nov 25 01:34:01 2017\nstart loop 1 at: Sat Nov 25 01:34:01 2017\nloop 1 done at: Sat Nov 25 01:34:03 2017\nloop 0 done at: Sat Nov 25 01:34:05 2017\nall done at: Sat Nov 25 01:34:05 2017\n</code></pre>\n<p>在threading模块中，实例化<code>Thread</code>和调用<code>thread.starat_new_thread</code>的最大的区别就是新的线程不会立即执行，在线程分配完成过后，可以通过<code>start</code>方法启动线程。<code>join</code>方法将等待线程结束，或者达到超时时间后结束线程。</p>\n<ul>\n<li><p><strong>Thread的创建和启动：</strong></p>\n<ul>\n<li>创建Thread实例，并传递一个函数</li>\n<li>创建Thread实例，并传递一个可调用对象</li>\n<li>派生Thread的子类，并创建子类的实例</li>\n</ul>\n</li>\n<li><p><strong>Lock和RLock</strong></p>\n<p>  RLock是可重入锁，除了Lock使用的锁定和解锁之外，还“拥有线程”和“递归级别”的概念。一旦线程获得了可重入锁，同一线程可以再次获取它而不阻塞；线程必须每获取一次必须有对应的释放一次，才能彻底释放锁。</p>\n</li>\n<li><p><strong>Condition</strong></p>\n<p>  Condition提供了比Lock, RLock更高级的功能，允许我们能够控制复杂的线程同步问题。Condition内部维护一把锁，默认是RLock，也可以通过构造方法传递，accquire和release操作关联的锁。在获取到锁之后，才可以调用相应的其他方法。</p>\n<p>  wait方法释放锁，然后阻塞，直到另一个线程通过调用 notify 或 notify_all唤醒它。一旦被唤醒，wait 重新获取锁并返回。也可以指定超时。</p>\n<p>  notify 和 notify_all 方法不释放锁；这意味着被唤醒的线程或线程不会立即从它们的 wait 调用返回，而是只有当调用 notify 或 notify_all 的线程最终放弃锁的所有权时</p>\n<p>  可以看个生产者-消费者模式</p>\n<pre><code class=\"python\">  # Consume one item\n  with cv:\n      while not an_item_is_available():\n          cv.wait()\n      get_an_available_item()\n\n  # Produce one item\n  with cv:\n      make_an_item_available()\n      cv.notify()\n</code></pre>\n<p>  while 循环检查应用程序的条件是必要的，因为 wait() 可以在任意长时间后返回，并且 notify() 调用的条件可能不再成立。这是多线程编程固有的。 wait_for() 方法可以用于自动化条件检查，并且减少超时的计算:</p>\n<pre><code class=\"python\">  # Consume an item\n  with cv:\n      cv.wait_for(an_item_is_available)\n      get_an_available_item()\n</code></pre>\n</li>\n<li><p><strong>Semphore和BoundSemphore</strong></p>\n<p>  对于拥有有限资源的应用来说，使用信号量是个不错的选择。BoundedSemphore实现有界信号对象，能保证信号量的释放次数不会大于信号量初始的值。</p>\n</li>\n<li><p><strong>Event</strong></p>\n<p>  事件对象是线程之间通信的最简单机制之一：一个线程表示事件，而其他线程等待它。事件对象管理内部标志，set方法设置为True，clear设置为False，另外wait将阻塞直到另外一个线程调用set将标志设置为True，或者等待可选的超时发生。</p>\n</li>\n<li><p><strong>Barrier</strong></p>\n<p>  这个类提供了一个简单的同步原语，供需要彼此等待的固定数量的线程使用。每个线程尝试通过调用 wait 方法通过屏障，并将阻塞，直到所有线程都已调用。在这一点上，线程被同时释放。</p>\n</li>\n<li><p><strong>在with语句中使用lock，condition和semphore：</strong></p>\n<p>  threading模块提供的所有实现了accquire和release方法的对象，都实现了上下文管理器，在进入时accquire，退出时release。</p>\n</li>\n</ul>\n<h3 id=\"Queue\"><a href=\"#Queue\" class=\"headerlink\" title=\"Queue\"></a><strong>Queue</strong></h3><p>在生产者消费者场景下，可以通过queue/Queue模块提供的队列数据结构，进行安全的交换数据。</p>\n<p>可以实现一个简单的实例：</p>\n<pre><code class=\"python\">from threading import Thread\nfrom queue import Queue\nfrom time import sleep\nfrom random import randint\n\n\nqueue = Queue(32)\n\n\ndef consumer():\n    &#39;&#39;&#39; 消费者 &#39;&#39;&#39;\n    while True:\n        queue.get(&#39;xxx&#39;)\n        # do something\n        print(&quot;consuming from queue...size now:&quot;, queue.qsize())\n        sleep(randint(2, 5))\n\n\ndef producer():\n    &#39;&#39;&#39; 生产者 &#39;&#39;&#39;\n    while True:\n        queue.put(&#39;xxx&#39;, block=True)\n        print(&quot;producing to queue...size now:&quot;, queue.qsize())\n        sleep(randint(1, 3))\n\n\nif __name__ == &#39;__main__&#39;:\n    consumers = []\n    producers = []\n\n    for i in range(2):\n        thread = Thread(target=consumer)\n        consumers.append(thread)\n        thread = Thread(target=producer)\n        producers.append(thread)\n\n    for c, p in zip(consumers, producers):\n        c.start()\n        p.start()\n\n    for c, p in zip(consumers, producers):\n        c.join()\n        p.join()\n</code></pre>\n<pre><code class=\"code\">producing to queue...size now: 1\nconsuming from queue...size now: 0\nproducing to queue...size now: 1\nconsuming from queue...size now: 0\nproducing to queue...size now: 1\nproducing to queue...size now: 2\nproducing to queue...size now: 3\nconsuming from queue...size now: 2\nconsuming from queue...size now: 1\nproducing to queue...size now: 2\nproducing to queue...size now: 3\nproducing to queue...size now: 4\n</code></pre>\n<h3 id=\"怎么结束线程\"><a href=\"#怎么结束线程\" class=\"headerlink\" title=\"怎么结束线程\"></a>怎么结束线程</h3><h3 id=\"join方法\"><a href=\"#join方法\" class=\"headerlink\" title=\"join方法\"></a>join方法</h3><h2 id=\"多进程\"><a href=\"#多进程\" class=\"headerlink\" title=\"多进程\"></a>多进程</h2><p>多进程模块<code>mutilprocessing</code>有着类似<code>threading</code>相似的接口API。</p>\n<h3 id=\"GIL是什么？\"><a href=\"#GIL是什么？\" class=\"headerlink\" title=\"GIL是什么？\"></a>GIL是什么？</h3><!-- more -->\n<p>GIL的全称是Global Interpreter Lock(全局解释器锁)，在Python语言的实现CPython中，一个防止多线程并发执行机器码的一个Mutex，并不是 Python 的一个特性。</p>\n<p>在解释器解释执行任何 Python 代码时，都需要先获得这把锁才行当一个线程开始sleep或者进行I/O操作时，另一个线程就有机会拿到GIL锁，开始执行它的代码。这就是cooperative multitasking(协作式多任务处理)。</p>\n<p>同时CPython也有preemptive multitasking(抢占式多任务处理)的机制：在Python2采用ticks计步，当一个线程无中断地运行了100个字节码(可以通过sys.getcheckinterval()查看)，或者在Python3中，新的GIL实现中用一个固定的超时时间来指示当前的线程放弃全局锁。在当前线程保持这个锁，且其他线程请求这个锁时，当前线程就会在5毫秒后被强制释放该锁。</p>\n<h3 id=\"一个例子\"><a href=\"#一个例子\" class=\"headerlink\" title=\"一个例子\"></a>一个例子</h3><pre><code class=\"python\">import time\nfrom threading import Thread\n\ndef countdown(n):\n    while n &gt; 0:\n        n -= 1\n\nif __name__ == &#39;__main__&#39;:\n    s = time.time()\n    for i in range(2):\n        countdown(100000000)\n    print(&quot;use time:&quot;, time.time() - s)\n</code></pre>\n<p>单线程下执行耗时:<code>use time: 11.602031946182251</code></p>\n<pre><code class=\"python\">import time\nfrom threading import Thread\n\ndef countdown(n):\n    while n &gt; 0:\n        n -= 1\n\n\nif __name__ == &#39;__main__&#39;:\n    s = time.time()\n    threads = []\n    for i in range(2):\n        thread = Thread(target=countdown, args=(100000000, ))\n        thread.start()\n        threads.append(thread)\n    for thread in threads:\n        thread.join()\n    print(&quot;use time:&quot;, time.time() - s)\n</code></pre>\n<p>两个并发线程下执行耗时：<code>use time: 11.905225038528442</code>，可以看到Python多线程并不能能提高效率，线程进行锁竞争、切换线程，一定程度上还会消耗资源。</p>\n<p>解决GIL问题的方法：</p>\n<ul>\n<li>使用多线程在解决IO密集型任务，能有效规避GIL</li>\n<li>使用C扩展，在C扩展里面能够创建原生线程。</li>\n<li>使用mutilprocessing模块，使用多进程替换多线程。</li>\n</ul>\n<pre><code class=\"python\">from multiprocessing import Process\nimport time\n\ndef countdown(n):\n    while n &gt; 0:\n        n -= 1\n\nif __name__ == &#39;__main__&#39;:\n    s = time.time()\n    processes = []\n    for i in range(2):\n        process = Process(target=countdown, args=(100000000, ))\n        processes.append(process)\n        process.start()\n    for process in processes:\n        process.join()\n    print(&quot;use time:&quot;, time.time() - s)\n</code></pre>\n<p>在多进程下，执行时间为：<code>use time: 5.931055545806885</code>，可以发现执行时间大幅度减少了。</p>\n<ul>\n<li><p><strong>Process</strong></p>\n<p>  Process有着类似Thread的API，只是从线程换成了进程。</p>\n</li>\n<li><p><strong>进程间交换对象</strong><br>  支持进程之间的两种类型的通信信道</p>\n<ul>\n<li>队列。</li>\n<li>管道。</li>\n</ul>\n</li>\n<li><p><strong>进程同步</strong>  </p>\n<p>  multiprocessing 包含来自 threading 的所有同步原语的等同物。</p>\n</li>\n<li><p><strong>共享状态</strong>  </p>\n<p>  当进行并发编程时，通常最好避免使用尽可能共享的状态。在使用多个进程时尤其如此。<br>  然而，如果你真的需要使用一些共享数据，那么 multiprocessing 提供了这样做的几种方法</p>\n<ul>\n<li>共享内存。提供Array和Value类，另外 multiprocessing.sharedctypes 模块支持创建从共享内存分配的任意ctpyes对象。</li>\n<li>服务器进程。Manager()返回的管理器对象控制一个服务器进程， 返回的管理器将支持类型 list，dict，Namespace，Lock，RLock，Semaphore，BoundedSemaphore，Condition，Event，Barrier，Queue，Value 和 Array。此外，单个管理器可以由网络上不同计算机上的进程共享。但是，它们比使用共享内存慢。</li>\n</ul>\n</li>\n<li><p><strong>进程池</strong>   </p>\n<p>  Pool 类控制可以提交作业的工作进程池。它支持具有超时和回调的异步结果，并具有并行映射实现。</p>\n</li>\n</ul>\n<h2 id=\"concurrent-futures\"><a href=\"#concurrent-futures\" class=\"headerlink\" title=\"concurrent.futures\"></a>concurrent.futures</h2><p>concurrent.futures是Python3增加的一个异步并发库，提供了ThreadPoolExecutor和ProcessPoolExecutor两个池的类，实现了对threading和multiprocessing的进一步封装，对于用户来讲，可以不用直接动手处理线程、进程和队列等底层基础设施。<br><!-- more --><br>concurrent.futures的源码只有三个文件：<code>base.py</code>，<code>thread.py</code>和<code>process.py</code>，通过Executor和Future对外暴露API。</p>\n<h3 id=\"Executor类\"><a href=\"#Executor类\" class=\"headerlink\" title=\"Executor类\"></a>Executor类</h3><p>Executor有两个实现：ThreadPoolExecutor和ProcessPoolExecutor，两个类的逻辑代码大致相同，只是分别对线程池(threading)和进程池(multiprocessing)进行实现，同事内部维护一个工作队列(queue.Queue)。</p>\n<ul>\n<li><p><strong>实现上下文管理协议</strong></p>\n<p>  Executor实现了<code>__enter__</code>和<code>__exit__</code>两个方法，可以使用如下用法：</p>\n<pre><code class=\"python\">  with concurrent.futures.ThreadPoolExecutor(max_workers) as executor:\n      pass\n</code></pre>\n</li>\n<li><p><strong>Executor.submit()</strong></p>\n<pre><code class=\"python\">  def submit(self, fn, *args, **kwargs):\n      with self._shutdown_lock:\n          if self._shutdown:\n              raise RuntimeError(&#39;cannot schedule new futures after shutdown&#39;)\n\n          f = _base.Future()\n          w = _WorkItem(f, fn, args, kwargs)\n\n          self._work_queue.put(w)\n          self._adjust_thread_count()\n          return f\n</code></pre>\n<p>  使用submit方法往池中添加一个任务<code>fn</code>，submit方法返回一个Future对象。</p>\n</li>\n<li><p><strong>Executor.map()</strong></p>\n<pre><code class=\"python\">  def map(self, fn, *iterables, timeout=None, chunksize=1):\n      if timeout is not None:\n          end_time = timeout + time.time()\n\n      fs = [self.submit(fn, *args) for args in zip(*iterables)]\n\n      def result_iterator():\n          try:\n              for future in fs:\n                  if timeout is None:\n                      yield future.result()\n                  else:\n                      yield future.result(end_time - time.time())\n          finally:\n              for future in fs:\n                  future.cancel()\n      return result_iterator()\n</code></pre>\n<p>  使用<code>map</code>方法返回一个<code>Future生成器</code>，对该生成器迭代将调用<code>result</code>获取结果。</p>\n</li>\n</ul>\n<h3 id=\"Future类\"><a href=\"#Future类\" class=\"headerlink\" title=\"Future类\"></a>Future类</h3><blockquote>\n<p>期物<br>在《流畅的Python》中，译者将<code>future</code>翻译成期物，用来表示可能已经发生或者尚未完成的延迟计算。<br>由于期物表示终将发成的事情，而确定某件事情会发生的唯一方式就是执行时间已经排定，所以应该把排定某件事情交个框架来做，并实例化<code>Future</code>，而不是自己来创建期物。<br>有几个概念具有相似的作用和语义：concurrent.futures.Future类、asyncio.Future类、Twisted中的Deffered类、Tornado中的Future类以及JavaScript中的Promise对象。</p>\n</blockquote>\n<ul>\n<li><p><strong>状态</strong><br>  并发框架在期物表示的延迟计算结束后会改变期物的状态，客户端不应该主动做修改，可以通过几个方法来获取状态：</p>\n<ul>\n<li><code>running()</code></li>\n<li><code>canceled</code></li>\n<li><p><code>done</code></p>\n<p>这个几个方法不会阻塞，返回布尔值，表明期物所处于的状态。对于客户端来说，一般不会主动来查询这个状态，而是通过<code>add_done_callback</code>来添加回调方法(参数为期物本身)，等待通知。</p>\n<pre><code class=\"python\">def add_done_callback(self, fn):\n  with self._condition:  # 使用threading模块的Condition条件对象。\n      if self._state not in [CANCELLED, CANCELLED_AND_NOTIFIED, FINISHED]:\n          self._done_callbacks.append(fn)\n          return\n  fn(self)\n</code></pre>\n</li>\n</ul>\n</li>\n<li><p><strong>Future.result()</strong></p>\n<p>  在期物代表的延迟计算运行结束后，<code>result()</code>方法将返回可调用对象的结果。如果期物没有运行完成，那么这个方法将会阻塞调用该方法的线程，可以接收可选的<code>timeout</code>参数。</p>\n<pre><code class=\"python\">  def result(self, timeout=None):\n      with self._condition:\n          if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n              raise CancelledError()\n          elif self._state == FINISHED:\n              return self.__get_result()\n\n          self._condition.wait(timeout)\n\n          if self._state in [CANCELLED, CANCELLED_AND_NOTIFIED]:\n              raise CancelledError()\n          elif self._state == FINISHED:\n              return self.__get_result()\n          else:\n              raise TimeoutError()\n</code></pre>\n</li>\n</ul>\n<h3 id=\"其他辅助函数\"><a href=\"#其他辅助函数\" class=\"headerlink\" title=\"其他辅助函数\"></a>其他辅助函数</h3><ul>\n<li><p><strong>as_completed()</strong></p>\n</li>\n<li><p><strong>wait()</strong></p>\n</li>\n</ul>\n<!-- 1). waiter 类。\n\nclass _Waiter(object):\nclass _AsCompletedWaiter(_Waiter):\nclass _FirstCompletedWaiter(_Waiter):\nclass _AllCompletedWaiter(_Waiter):\n\n_Waiter 类用来等待 Future 执行完，_Waiter 里定义了 threading.Event()，_AsCompletedWaiter 每个 Future 完成都会触发 event.set()，_FirstCompletedWaiter 每个 Future 完成也会触发，_AllCompletedWaiter 会等所有 Future 完成才触发 event.set()。\n\n另外，_AsCompletedWaiter 和 _AllCompletedWaiter 还有把锁 threading.Lock()。\n\n2). 辅助函数。\n\ndef _create_and_install_waiters(fs, return_when):\ndef as_completed(fs, timeout=None):\ndef wait(fs, timeout=None, return_when=ALL_COMPLETED):\n\n_create_and_install_waiters 是对 Future 列表 fs 创建和安装 waiter，创建好响应的 waiter 之后，会对 fs 中的每一个 Future 增加此 waiter (Future 有个列表变量 _waiters，加入即可)，并且返回此 waiter；\n\nas_completed 是一个生成器，配合 for 使用可以循环得到已经完成的 Future，as_completed 使用了 _create_and_install_waiters；\n\nwait 用于等待 Future 列表依次完成。 -->\n<h2 id=\"协程\"><a href=\"#协程\" class=\"headerlink\" title=\"协程\"></a>协程</h2><p>在以往的Python并发编程中，大多使用多进程/多线程模型，<br>Python的多线程由于GIL的限制，无法发挥多核CPU的能力，并且python的线程是内核级线程，抢占锁和线程上下文切换存在大量的开销。对于IO密集性任务来说，还有一个更好的选择那就是协程。</p>\n<h3 id=\"协程-Coroutine-简介\"><a href=\"#协程-Coroutine-简介\" class=\"headerlink\" title=\"协程(Coroutine)简介\"></a>协程(Coroutine)简介</h3><blockquote>\n<p>Coroutines are computer program components that generalize subroutines for non-preemptive multitasking, by allowing multiple entry points for suspending and resuming execution at certain locations.</p>\n</blockquote>\n<p>从维基百科上的定义上看，协程可以理解为流程控制，能够在特定位置暂停和恢复执行协作式多任务编程。协程运行在单线程中，避免了线程上下文切换的开销，属于用户态线程。</p>\n<p>对于python生成器中的<code>yield</code>来说，具有<code>产出和让步</code>的语意：yield item产出一个值，提供next()的调用方，并且作出让步。</p>\n<p>协程的底层框架在“PEP 342”中定义，在生成器API中增加了<code>send()</code>方法，生成器的调用方可以使用<code>send(...)</code>发送数据，发送的数据将成为生成器函数yeild表达式的值，因此，生成器可以作为协程来使用。除此之外，还添加了<code>throw()</code>和<code>close()</code>方法，前者的作用是让调用方抛出异常，在生成器中处理，后者的作用是终止生成器。在“PEP 380”中对生成器函数做了两处改动以更好的支持协程：</p>\n<ul>\n<li>生成器函数可以返回一个值。以前在生成器函数中给return语句提供值，会抛出<code>SyntaxError</code>异常。</li>\n<li>引入<code>yeild from</code>语法，可以把复杂生成器重构为小型的生成器。</li>\n</ul>\n<h3 id=\"一个基本的协程演示\"><a href=\"#一个基本的协程演示\" class=\"headerlink\" title=\"一个基本的协程演示\"></a>一个基本的协程演示</h3><pre><code class=\"python\">&gt;&gt;&gt; def simple_coroutine():\n...     print(&quot;coroutine started...&quot;)\n...     x = yield\n...     print(&#39;coroutine received:&#39;, x)\n... \n&gt;&gt;&gt; my_coro = simple_coroutine()\n&gt;&gt;&gt; next(my_coro)\ncoroutine started...\n&gt;&gt;&gt; my_coro.send(42)\ncoroutine received: 42\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nStopIteration\n</code></pre>\n<p>可以使用<code>inspect.getgenratorstate()</code>，查看当前处于的状态：</p>\n<ul>\n<li><code>GEN_CREATED</code>等待开始执行</li>\n<li><code>GEN_RUNNING</code>解释器正在执行</li>\n<li><code>GEN_SUSPENDED</code>在yield表达式处暂停</li>\n<li><code>GEN_CLOSED</code>执行结束</li>\n</ul>\n<p>调用方可以使用<code>send()</code>方法发送数据给生成器，参数将成为暂停yield表达式的值。只有暂停状态下的生成器才可以发送数据。<br>最先使用<code>next(my_coro)</code>”预激“协程，使生成器运行到yield处，作为活跃的协程使用。</p>\n<h3 id=\"抛出异常和停止\"><a href=\"#抛出异常和停止\" class=\"headerlink\" title=\"抛出异常和停止\"></a>抛出异常和停止</h3><ul>\n<li>如果协程中抛出的异常，没有在协程内部处理掉，那么异常将会向上冒泡给<code>next()</code>或<code>send()</code>调用方。</li>\n<li><code>throw</code>方法。致使生成器在<code>暂停yield表达式处</code>抛出指定异常。如果生成器处理了异常，代码将继续执行到下一个yield表达式处，并且产生的值作为<code>throw()</code>的返回值；若没有处理异常，那么异常将向上冒泡到调用处。</li>\n<li><code>close</code>方法。致使生成器在<code>暂停的yield表达式</code>处抛出<code>Generator</code>异常。如果生成器没有处理这个异常，或者抛出了<code>StopInteration</code>异常，那么调用方不会报错；如果生成器处理了这个异常，那么一定不能返回值，不然会抛出<code>RuntimeError</code>；生成器产生的其他异常将会向上冒泡传给调用方。</li>\n</ul>\n<h3 id=\"协程返回值\"><a href=\"#协程返回值\" class=\"headerlink\" title=\"协程返回值\"></a>协程返回值</h3><pre><code class=\"python\">&gt;&gt;&gt; from collections import namedtuple\n&gt;&gt;&gt; Result = namedtuple(&#39;Result&#39;, &#39;count average&#39;)\n&gt;&gt;&gt; def averager():\n...     total = 0\n...     count = 0\n...     while True:\n...         item = yield\n...         if item == None:\n...             break\n...         total = item + total\n...         count += 1\n...     average = total / count\n...     return Result(count=count, average=average)\n... \n&gt;&gt;&gt; avg_coro = averager()\n&gt;&gt;&gt; next(avg_coro)\n&gt;&gt;&gt; avg_coro.send(10)\n&gt;&gt;&gt; avg_coro.send(20)\n&gt;&gt;&gt; avg_coro.send(45)\n&gt;&gt;&gt; avg_coro.send(None)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nStopIteration: Result(count=3, average=25.0)\n</code></pre>\n<p>Python3.3实现的”PEP 380“改动中，生成器可以使用<code>return</code>返回值。从上面可以看到，<code>yield</code>所处的循环中，<code>yield</code>产生None值(所以交互式解释器没有打印)，接受一个<code>None</code>标志位结束循环，结束协程执行。一如既往，生成器结束将抛出<code>StopInteration</code>异常，并将生成器返回值作为异常的<code>value</code>属性。</p>\n<p>此外，添加的<code>yield from</code>结构能够内部处理<code>StopInteration</code>异常(这种处理方式和<code>for</code>循环处理<code>StopInteration</code>异常一样：循环机制使用用户易于理解的方式处理异常)，并将<code>value</code>属性的值作为<code>yield from</code>表达式的值。</p>\n<h3 id=\"yield-from\"><a href=\"#yield-from\" class=\"headerlink\" title=\"yield from\"></a>yield from</h3><p>一个简单了案例，接受数据生成男生和女生的身高和体重报告：</p>\n<pre><code class=\"python\">from collections import namedtuple\n\nResult = namedtuple(&#39;Result&#39;, &#39;count average&#39;)\n\n# 子生成器\ndef averager():\n    total = 0\n    count = 0\n    while True:\n        item = yield &#39;tmp&#39;\n        if item is None:\n            break\n        total = total + item\n        count += 1\n    average = total / count\n    return Result(count=count, average=average)\n\n# 委派生成器\ndef grouper(results, key):\n    while True:\n        results[key] = yield from averager()\n\n# 数据报表\ndef report(results):\n    for key, result in sorted(results.items()):\n        group, unit = key.split(&#39;;&#39;)\n        print(&#39;{:2} {:5} averaging {:.2f}{}&#39;.format(result.count, group, result.average, unit))\n\ndef main(data):\n    results = {}\n    for key, values in data.items():\n        group = grouper(results, key)\n        next(group)\n        for value in values:\n            tmp = group.send(value)\n#             print(tmp)\n        group.send(None)\n        print(results)\n    report(results)\n\ndata = {\n    &#39;girls;kg&#39;: [40.9, 38.5, 44.3, 43.2, 45.2, 41.7, 44.5, 38.0, 40.6, 44.5],\n    &#39;gils;m&#39;: [1.6, 1.51, 1.4, 1.3, 1.41, 1.39, 1.33, 1.46, 1.45, 1.43],\n    &#39;boys;kg&#39;: [39.0, 40.8, 43.2, 40.8, 43.1, 38.6, 41.4, 40.6, 36.3],\n    &#39;boys;m&#39;: [1.38, 1.5, 1.32, 1.25, 1.37, 1.48, 1.25, 1.49, 1.46]\n}\n\nif __name__ == &#39;__main__&#39;:\n    main(data)\n</code></pre>\n<p>运行结果：</p>\n<pre><code class=\"code\">{&#39;girls;kg&#39;: Result(count=10, average=42.14)}\n{&#39;girls;kg&#39;: Result(count=10, average=42.14), &#39;gils;m&#39;: Result(count=10, average=1.4279999999999997)}\n{&#39;girls;kg&#39;: Result(count=10, average=42.14), &#39;gils;m&#39;: Result(count=10, average=1.4279999999999997), &#39;boys;kg&#39;: Result(count=9, average=40.422222222222224)}\n{&#39;girls;kg&#39;: Result(count=10, average=42.14), &#39;gils;m&#39;: Result(count=10, average=1.4279999999999997), &#39;boys;kg&#39;: Result(count=9, average=40.422222222222224), &#39;boys;m&#39;: Result(count=9, average=1.3888888888888888)}\n 9 boys  averaging 40.42kg\n 9 boys  averaging 1.39m\n10 gils  averaging 1.43m\n10 girls averaging 42.14kg\n</code></pre>\n<p>在这里使用了一个新的语言结构<code>yield from</code>，在说明之前，先了解”PEP 380“引进的几个新的术语：</p>\n<ul>\n<li>委派生成器：包含<code>yield from &lt;iterable&gt;</code>表达式的生成器，上面的<code>grouper()</code>函数。</li>\n<li>子生成器：从<code>yield from &lt;iterable&gt;</code>表达式中的<code>iterable</code>获取的生成器。</li>\n<li>调用方：客户端调用委派生成器的代码。</li>\n</ul>\n<p><img src=\"/images/coroutine.png\" alt=\"yield from结构用法\"></p>\n<p>使用<code>yield from</code>结构可以打开管道，把调用方和子生成器连接起来。</p>\n<ol>\n<li>调用方可以发送数据到委派生成器，值通过管道传递到子生成器的<code>yield</code>位置。</li>\n<li>此时，委派生成器会在<code>yield from</code>处暂停，子生成器等待接受客户端发来的值，并通过<code>yield</code>产生值，使用管道直接传给调用方。</li>\n<li>当子生成器执行完毕，返回的值将作为<code>yield from</code>表达式的值，绑定到<code>results[key]</code>上，委派生成器再次激活执行。</li>\n</ol>\n<p>在上面的例子中，已经见识到了<code>yield from</code>能够在自动内部处理子生成器返回值和抛出的<code>StopIteration</code>异常。除此之外，<code>yield from</code>还需要处理，<code>throw()</code>和<code>close()</code>以及子生成器只是一个普通的迭代器的情况。</p>\n<p><code>RESULT = yield from EXPR</code>语句的具体理解可以参考”PEP 380“伪代码的实现：</p>\n<pre><code class=\"python\">The statement\n\nRESULT = yield from EXPR\nis semantically equivalent to\n\n_i = iter(EXPR)\ntry:\n    _y = next(_i)\nexcept StopIteration as _e:\n    _r = _e.value\nelse:\n    while 1:\n        try:\n            _s = yield _y\n        except GeneratorExit as _e:\n            try:\n                _m = _i.close\n            except AttributeError:\n                pass\n            else:\n                _m()\n            raise _e\n        except BaseException as _e:\n            _x = sys.exc_info()\n            try:\n                _m = _i.throw\n            except AttributeError:\n                raise _e\n            else:\n                try:\n                    _y = _m(*_x)\n                except StopIteration as _e:\n                    _r = _e.value\n                    break\n        else:\n            try:\n                if _s is None:\n                    _y = next(_i)\n                else:\n                    _y = _i.send(_s)\n            except StopIteration as _e:\n                _r = _e.value\n                break\nRESULT = _r\n</code></pre>\n<h2 id=\"asyncio\"><a href=\"#asyncio\" class=\"headerlink\" title=\"asyncio\"></a>asyncio</h2><h2 id=\"gevent\"><a href=\"#gevent\" class=\"headerlink\" title=\"gevent\"></a>gevent</h2><h2 id=\"参考链接\"><a href=\"#参考链接\" class=\"headerlink\" title=\"参考链接\"></a>参考链接</h2><p><code>&gt;&gt;&gt;</code> <a href=\"https://www.rddoc.com/doc/Python/3.6.0/zh/library/threading/\" target=\"_blank\" rel=\"noopener\">threading RD文档</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://yangwenbo.com/articles/python-thread-cancel.html\" target=\"_blank\" rel=\"noopener\">Python不支持杀死子线程</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://zhuoqiang.me/python-thread-gil-and-ctypes.html\" target=\"_blank\" rel=\"noopener\">python 线程，GIL 和 ctypes</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"http://cenalulu.github.io/python/gil-in-python/\" target=\"_blank\" rel=\"noopener\">Python的GIL是什么鬼，多线程性能究竟如何</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://www.rddoc.com/doc/Python/3.6.0/zh/library/multiprocessing/\" target=\"_blank\" rel=\"noopener\">multiprocessing RD文档</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://www.python.org/dev/peps/pep-0380/\" target=\"_blank\" rel=\"noopener\">PEP 380</a></p>\n<p><code>&gt;&gt;&gt;</code> <a href=\"https://lightless.me/archives/python-coroutine-from-start-to-boom.html\" target=\"_blank\" rel=\"noopener\">Python协程从零开始到放弃</a></p>\n","categories":["Python"],"tags":["Python","并发"]},{"title":"并发编程简介","url":"http://shawnz.me/posts/7a7167a/","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>并发是计算机编程的一个重要概念，指多个子任务同时运行，从而提高整个任务的性能。<br>在继续学习Python并发编程之前，先介绍并发编程的概念。<br><a id=\"more\"></a></p>\n<h2 id=\"并发编程解决的问题\"><a href=\"#并发编程解决的问题\" class=\"headerlink\" title=\"并发编程解决的问题\"></a>并发编程解决的问题</h2><h2 id=\"进程和线程\"><a href=\"#进程和线程\" class=\"headerlink\" title=\"进程和线程\"></a>进程和线程</h2><p><code>进程</code>(也叫重量级进程)，指一个执行中程序。每个进程都有自己的地址空间，内存，数据栈以及其它记录其运行轨迹的辅助数据。进程也可以通过 <code>fork</code> 和 <code>spawn</code> 操作 来完成其它的任务。不过各个进程有自己的内存空间，数据栈等，所以只能使用进程间通讯(IPC)， 而不能直接共享信息。</p>\n<p><code>线程</code>(也称为轻量级进程)，跟进程类似，不过它们运行在同一个进程中，共享相同的上下文。它们可以想像成是在主进程或“主线程”中并行运行的“迷你进程”。</p>\n<p>线程有开始，顺序执行和结束三部分。它有一个自己的指令指针，记录当前的运行上下文。 线程的运行可能被抢占(中断)，或暂时的被挂起(也叫睡眠)—这种做法称为让步(yielding)。 </p>\n<p>一个进程中的各个线程之间共享同一片数据空间，所以线程之间可以比进程之间更方便地共享数据以及相互通讯。但是这种分享也会带来一个新的问题：竞态条件。</p>\n<blockquote>\n<p>我们知道，线程，在计算机里面通常的分类是内核级线程和用户级线程。内核级线程的调度是由系统完成的，而用户级线程的调度是由用户来控制的。那么Python标准库提供的线程是那一类呢？如果我们了解或者使用过gevent和eventlet，进行下对比，我们就很容易回答出来了。Python提供的线程是内核级的，而gevent和eventlet提供的则是用户级的线程。这类用户级的线程，我们叫它协程，也可以叫green thread。本文中的线程，主要针对Python标准库提供的线程。下文提到的线程一词，也都是指Python标准库提供的线程。</p>\n</blockquote>\n<h2 id=\"什么是线程安全\"><a href=\"#什么是线程安全\" class=\"headerlink\" title=\"什么是线程安全\"></a>什么是线程安全</h2><p>当多个线程同时运行时，保证运行结果符合预期，就是线程安全的。</p>\n<h3 id=\"线程切换上下文\"><a href=\"#线程切换上下文\" class=\"headerlink\" title=\"线程切换上下文\"></a>线程切换上下文</h3><p>在单核处理中，CPU通过给每个线程分配时间片来支持多线程执行代码。在切换前会保存上一个任务的状态，以便下一次换回这个任务的时候，可以再加载这个任务的状态。所以从保存到再加载状态的过程称为上下文切换。</p>\n<h3 id=\"竞态条件和临界区\"><a href=\"#竞态条件和临界区\" class=\"headerlink\" title=\"竞态条件和临界区\"></a>竞态条件和临界区</h3><p>当某个计算的正确性取决于多个线程的交替执行时序时，那么就会产生<code>竞态条件</code>，导致竞态条件发生的代码区称作<code>临界区</code>。</p>\n<p>最为常见的竞态条件就是“先检查后执行”。例如，延迟初始化：</p>\n<pre><code class=\"python\">class Singleton:\n    _instance = None\n\n    def __new__(cls, *args, **kwargs):\n        if not cls._instance:\n            cls._instance = super(Singleton, cls).__new__(cls, *args, **kwargs)\n        return cls._instance\n\n\nclass Simple(Singleton):\n    pass\n</code></pre>\n<p>假设两个线程同时实例化Simple类，A发现<code>cls._instance</code>为<code>None</code>，因而创建的Simple对象；B同样需要判断<code>cls._instance</code>是否为空，此时的<code>cls._instance</code>是否为空，取决于不可预测的时序，包括线程调度方式，以及A创建对象需要对象到设置<code>_instance</code>需要花费多久时间。如果B也检查为空，那么就会有两个不同的simple实例。</p>\n<p>还有另外一种竞态条件类型：“读取－修改－写入”。例如，计数器(无法保证没其他线程更新使用count值)：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; dis.dis(&#39;count += 1&#39;)\n              0 LOAD_NAME                0 (count)  # 加载count变量的值\n              3 LOAD_CONST               0 (1)\n              6 INPLACE_ADD                         # 加1\n              7 STORE_NAME               0 (count)  # 让count变量指向新的值\n             10 LOAD_CONST               1 (None)\n             13 RETURN_VALUE\n</code></pre>\n<h2 id=\"如何解决线程安全问题\"><a href=\"#如何解决线程安全问题\" class=\"headerlink\" title=\"如何解决线程安全问题\"></a>如何解决线程安全问题</h2><ol>\n<li><p><strong>无状态(Stateless)</strong><br> 由于线程访问无状态对象(没有域，也没有任何对其他类中域的引用)的行为不会影响到其他线程中操作的正确性，因此，无状态对象是线程安全的。</p>\n<p> 例如，在Java中的Servlet设计成无状态的，这样在大量并发请求中，能够线程安全地处理请求。</p>\n</li>\n<li><p><strong>不可变性(Immuable)</strong><br> 涉及同步需求的另一个方法就是使用不可变对象，许多的线程安全问题都是由于不正当的多个线程同时访问同个对象的一个可变状态而引起的。如果对象的状态不可改变，那么问题与复杂性就随之消失了。</p>\n<p> 例如，在Java里可以通过关键字<code>final</code>声明不可变变量，在Python里可以通过只读<code>特性</code>来达到相同的目的。不过两者需要确保在对象属性构造过程的</p>\n</li>\n<li><p><strong>原子性操作(CAS)</strong><br> 线程执行的过程中，有时需要保证一系列操作以原子的方式执行。</p>\n<p> 例如，在Python中，由于GIL的存在以及最小执行单元是字节码，许多built-in的类型的读写操作本身都是原子操作的。但是有时候，Python中的一行代码是被解释成了多条字节码，也就是非原子操作的。这是需要通过同步机制来实现原子性。</p>\n</li>\n<li><p><strong>锁机制(Lock)</strong></p>\n<ul>\n<li><p><code>互斥锁(mutex)</code>是一种用于多线程编程中，防止两条线程同时对同一公共资源（比如全局变量）进行读写的机制。在多进程编程中，只防止多个进程同时对同一共享内存进行读写的机制。用来保护临界区的。</p>\n</li>\n<li><p><code>自旋锁(spinlock)</code>自旋锁与互斥锁有点类似，是互斥锁的一种实现。自旋锁不会引起调用者睡眠，如果自旋锁已经被别的执行单元保持，调用者就一直循环在那里看是 否该自旋锁的保持者已经释放了锁，”自旋”一词就是因此而得名。因为自旋锁不会引起调用者睡眠，所以自旋锁的效率远高于互斥锁,适合于适合于保持时间较短的情况，这种锁可能存在两个问题：死锁和过多占用cpu资源(<code>忙等待</code>)。</p>\n<blockquote>\n<p><strong>自旋锁导致死锁</strong><br>  想象你的内核代码请求到一个自旋锁并且在它的临界区里做它的事情。在中间某处，你的代码失去了处理器：它调用了一个函数（copy_from_user，假设）使进程进入睡眠；或者内核抢占发威，一个更高优先级的进程将你的代码推到了一边(注意,这都是假设,自旋锁其实不允许这些操作)。此时，正好某个别的进程或线程想获取同一个锁，如果这个线程运行在和你的内核代码不同的处理器上（幸运的情况），那么它可能要自旋等待一段时间（可能很长），当你的代码从休眠中唤醒或者重新得到处理器并释放锁，它就能得到锁。而最坏的情况是，那个想获取锁得线程刚好和你的代码运行在同一个处理器上，这时它将一直持有CPU进行自旋操作，导致你的代码永远不可能有任何机会来获得CPU释放这个锁了，这就是悲催的死锁。 </p>\n</blockquote>\n<p>  自旋锁旋锁有个特性：<code>被自旋锁保护的临界区代码执行时，它不能因为任何原因放弃处理器</code>。</p>\n<pre><code>  1. 被自旋锁保护的临界区代码执行时不能进入休眠；\n  2. 被自旋锁保护的临界区代码执行时是不能被被其他中断中断；\n  3. 被自旋锁保护的临界区代码执行时，内核不能被抢占。\n</code></pre></li>\n<li><p><code>可重入锁</code>指线程可以重复获得它已经持有的锁。例如threading模块的RLock。</p>\n</li>\n<li><p><code>公平锁</code>指每个线程抢占锁的顺序为先后调用lock方法的顺序依次获取锁，类似于排队吃饭。而非公平锁指线程抢占锁的顺序随机的。</p>\n</li>\n<li><p><code>乐观锁</code>一种并发控制的思想，相对于悲观锁需要获取锁，才能访问资源，乐观锁假设并发事务不会彼此相互影响，在数据提交的时候会检查，如果发生冲突，会返回错误信息，并由用户决定如何处理。可以通过版本号或者时间戳来实现。</p>\n</li>\n<li><p><code>信号量(semaphore)</code>是一种更高级的同步机制，本质上是一个计数器，它用来记录对某个资源（如共享内存）的存取状况。当线程完成一次对该semaphore对象的等待（wait）时，该计数值减1；当线程完成一次对semaphore对象的释放（release）时，计数值加1。当计数值为0，则线程等待，该semaphore对象不再能成功直至该semaphore对象变成signaled状态。semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态。适用于控制一个仅支持有限个用户的共享资源，互斥锁可以看做二值信号量。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>线程封闭(ThreadLocal)</strong><br> 当访问共享数据的时候，通常需要同步。而避免使用同步的一种方式就是不共享数据，如果仅在单线程中访问数据，就不需要同步。<br> 而<code>栈封闭</code>是一种更强的线程封闭技术，只能通过局部变量访问对象，数据保存在执行线程的栈中。<br> 更加规范的方法是使用<code>ThreadLocal</code>对象，例如threading.local，Flask中的LocalStack以及Werkebug实现的LocalStack和LocalProxy。</p>\n</li>\n</ol>\n","categories":["Python"],"tags":["Python","并发"]},{"title":"文本和字节序列","url":"http://shawnz.me/posts/a5c816d6/","content":"<blockquote>\n<p>人类使用文本，计算机使用字节序列</p>\n<p style=\"text-align:right\">—Esther Nam 和 Travis Fischer</p><br><p style=\"text-align:right\">“Character Encoding and Unicode in Python”</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"字符和字节\"><a href=\"#字符和字节\" class=\"headerlink\" title=\"字符和字节\"></a>字符和字节</h2><p>计算机以字节的形式存储数据，一个字节8个比特位。<br>而字符只是一个符号，用于显示，方便阅读。<br>一个”字符串“就是一个字符序列，关键在于”字符“是怎么的定义。<br>在Python3中，str对象获取的是unicode字符，相当于Python2中unicode对象获取的元素。<br>在Python2中，str对象获取的是原始的字节序列。</p>\n<p>Unicode标准把字符的标识和具体的码位进行了明确的区分：</p>\n<ul>\n<li>字符的标识，即码位，是十进制0~1114111数字，以4~6个十六进制表示。例如，字母A码位’U+0041’。</li>\n<li>字节的具体表述取决于编码。</li>\n</ul>\n<h2 id=\"编码和解码\"><a href=\"#编码和解码\" class=\"headerlink\" title=\"编码和解码\"></a>编码和解码</h2><p>把码位转换成字节序列的过程是<code>编码</code>；<br>把字节序列转换成码位的过程是<code>解码</code>。</p>\n<p>由于Python2中的str和unicode对象存在隐式转换，所以会发现既可以对str进行<code>encode</code>，也可以对unicode进行<code>decode</code>，但是这种用法是不对的。<br>这种行为在Python3中得到了矫正，str对象只具备<code>encode</code>方法。</p>\n<pre><code class=\"python\">&gt;&gt;&gt; a = &#39;zhong&#39;\n&gt;&gt;&gt; a.encode(&#39;utf8&#39;)\nb&#39;zhong&#39;\n</code></pre>\n<p>那么既然<code>encode</code>得到的是bytes对象，那么<code>b&#39;zhong&#39;</code>和<code>&#39;zhong&#39;</code>看起来一样呢？<br>这是因为bytes的字面量表示法中有ASCII文本，因此会以下面三种方式显示：</p>\n<ul>\n<li>可打印的ASCII范围内的字节，使用ASCII字符本身；</li>\n<li>制表符、换行符、回车符和\\对应的字节，使用转移序列\\t、\\n、\\r和\\\\；</li>\n<li>其他字节的值，使用十六进制转移序列</li>\n</ul>\n<p>Python内置了100多种编解码器，用于文本和字节序列的转换，例如’utf_8’(别名’utf8’、’U8’)。<br>在编码和解码过程中，可能会遇到一下问题：</p>\n<ul>\n<li><code>UnicodeEncodeError</code>，字符串转化成字节序列出错；</li>\n<li><code>UnicodeDecodeError</code>，字节序列转换成字符串出错；</li>\n<li><code>SystaxError</code>，编码与预期的的不符。</li>\n</ul>\n<h2 id=\"Python编码问题\"><a href=\"#Python编码问题\" class=\"headerlink\" title=\"Python编码问题\"></a>Python编码问题</h2><h3 id=\"Python2中的str和unicode\"><a href=\"#Python2中的str和unicode\" class=\"headerlink\" title=\"Python2中的str和unicode\"></a>Python2中的str和unicode</h3><p>在Python2中str中存储的原始的字节序列，所以str更为合适的一种叫法”字节串“(Python2中的bytes相当于str的别名)，而真正意义上的字符串应该是unicode对象。</p>\n<pre><code class=\"python\">&gt;&gt;&gt; str1 = &#39;这是一个str&#39;\n&gt;&gt;&gt; [c for c in str1]\n[&#39;\\xe8&#39;, &#39;\\xbf&#39;, &#39;\\x99&#39;, &#39;\\xe6&#39;, &#39;\\x98&#39;, &#39;\\xaf&#39;, &#39;\\xe4&#39;, &#39;\\xb8&#39;, &#39;\\x80&#39;, &#39;\\xe4&#39;, &#39;\\xb8&#39;, &#39;\\xaa&#39;, &#39;s&#39;, &#39;t&#39;, &#39;r&#39;]\n&gt;&gt;&gt; str1[0]\n&#39;\\xe8&#39;\n</code></pre>\n<p>终端采用utf8编码，所以输入‘这是一个str’字面值，python解释器接收到<br>‘\\xe8\\xbf\\x99\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe4\\xb8\\xaastr’，并存储到str1变量中；<br>输出也是相同的道理，str1中的字节会被终端使用utf8解码。</p>\n<p>可以对str对象进行迭代或者索引，发现str中存储的元素是字节。而unicode对象却不然：</p>\n<pre><code class=\"python\">&gt;&gt;&gt; str2 = u&#39;这是一个str&#39;\n&gt;&gt;&gt; [c for c in str2]\n[u&#39;\\u8fd9&#39;, u&#39;\\u662f&#39;, u&#39;\\u4e00&#39;, u&#39;\\u4e2a&#39;, u&#39;s&#39;, u&#39;t&#39;, u&#39;r&#39;]\n&gt;&gt;&gt; str2[0]\nu&#39;\\u8fd9&#39;\n</code></pre>\n<p>在str和unicode之间的转换为:<br><img src=\"/images/str和unicode.png\" alt=\"str和unicode转换\"></p>\n<p>Python2采用的默认编码是<code>ascii</code>，所以在转换时如果不指定编码集，那么python默认使用<code>ascii</code>编解码。</p>\n<pre><code class=\"python\">&gt;&gt;&gt; unicode(&#39;中&#39;)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nUnicodeDecodeError: &#39;ascii&#39; codec cant decode byte 0xe4 in position 0: ordinal not in range(128)\n&gt;&gt;&gt; &#39;中&#39;.encode(&#39;utf8&#39;)\nTraceback (most recent call last):\n  File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;\nUnicodeDecodeError: &#39;ascii&#39; codec cant decode byte 0xe4 in position 0: ordinal not in range(128)\n</code></pre>\n<p>在python源代码文件中，如果出现ASCII字符集之外的字符，在编译时解释器也会报错，一般有两种解决方案：</p>\n<ul>\n<li>Bad Way：修改内部默认编码方式 <code>import sys;reload(sys);sys.setdefaultencoding(&#39;utf-8&#39;)</code></li>\n<li>Good Way：在源文件头部加上一句 <code># coding: utf-8</code></li>\n</ul>\n<h3 id=\"Python3中的str和bytes\"><a href=\"#Python3中的str和bytes\" class=\"headerlink\" title=\"Python3中的str和bytes\"></a>Python3中的str和bytes</h3><p>Python3的一个重要改进就是解决了Python2中字符和编码的问题:</p>\n<ol>\n<li>python3的默认编码从<code>ascii</code>改为了<code>utf-8</code>。</li>\n<li>另外对于文本和字节序列以更加清晰的方式划分开来：<ul>\n<li><code>str</code>标识unicode字符串</li>\n<li><code>bytes</code>表示二进制字节数组</li>\n</ul>\n</li>\n<li>python2中str和Unicode都是basestring的子类，可以拼接；在Python3中str和bytes被设计成两个独立的类</li>\n</ol>\n<p>在str和bytes之间的转换为:<br><img src=\"/images/str和bytes.png\" alt=\"str和bytes转换\"></p>\n<h3 id=\"Python3中的字节序列\"><a href=\"#Python3中的字节序列\" class=\"headerlink\" title=\"Python3中的字节序列\"></a>Python3中的字节序列</h3><ul>\n<li>python3中的bytes和bytearray区别：<ul>\n<li>bytes是不可变序列 ，bytearray是可变的。</li>\n</ul>\n</li>\n<li>python3中的bytes和python2的str/bytes在许多方面表现不一样：<ul>\n<li>python3中bytes中的元素是0~255之间的整数，而python2中是单个的字节；</li>\n<li>然而python3中二进制序列的切片始终是同一类型的二进制序列</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h2><blockquote>\n<p><a href=\"http://pycoders-weekly-chinese.readthedocs.io/en/latest/issue5/unipain.html\" target=\"_blank\" rel=\"noopener\">Unicode之痛</a><br><a href=\"https://www.zhihu.com/question/31833164\" target=\"_blank\" rel=\"noopener\">Python编码为什么那么蛋疼？</a></p>\n</blockquote>\n","categories":["Python"],"tags":["Python"]},{"title":"元组(tuple)","url":"http://shawnz.me/posts/4fc2401b/","content":"<h2 id=\"元组和列表的区别是什么？\"><a href=\"#元组和列表的区别是什么？\" class=\"headerlink\" title=\"元组和列表的区别是什么？\"></a>元组和列表的区别是什么？</h2><blockquote>\n<p><code>元组和列表都属于序列，而元组是不可变的。</code></p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"元组的用法\"><a href=\"#元组的用法\" class=\"headerlink\" title=\"元组的用法\"></a>元组的用法</h2><ol>\n<li><p>作为字典的键<br> 由于元组的不可变性质，可以使用元组作为字典的键(要求元组里面的元素都是可散列的数据类型)。</p>\n</li>\n<li><p>当做记录使用<br> 元组其实是对数据的记录：元组除了数据本身还记录的里面元素的个数和位置信息。<br> 例如一条位置记录：</p>\n<pre><code class=\"python\"> city, latitude, longitude = (&#39;Beijing&#39;, 116.46, 39.92)\n</code></pre>\n<p> 具名元组<br> <code>collections.namedtuple</code>是一个工厂函数，返回一个类，可以用来创建带有字段名的元组。</p>\n<pre><code class=\"python\"> from collection import namedtuple\n City = namedtuple(&#39;City&#39;, &#39;name latitude longitude&#39;)\n beijing = City(name=&#39;Beijing&#39;, latitude=116.46, longitude=39.92)\n assert beijing.name == &#39;Beijing&#39;\n</code></pre>\n<p> 创建具名元组需要两个参数，第一个类名，第二个是类中各字段名称(可以是字符串组成的可迭代对象，也可以是空格分隔的字段名组成的字符串)</p>\n</li>\n<li><p>函数返回值和元组拆包(可迭代元素拆包)</p>\n<pre><code class=\"python\"> def func(a, b, c):\n     return a, b, c\n\n a, b, c = func(1, 2, 3)\n a, _, c = func(1, 2, 3)\n a, * = func(1, 2, 3)\n</code></pre>\n<p> 在上面的用法中：</p>\n<ul>\n<li>可以使用<code>_</code>占位符来处理不感兴趣的数据</li>\n<li><p>可以使用<code>*</code>收集不确定数量的元素</p>\n<p>另外：</p>\n</li>\n<li>交叉赋值：<code>a, b = b, a</code></li>\n<li>嵌套拆包：<code>city, (latitude, longitude) = (&#39;Beijing&#39;, (116.46, 39.92))</code></li>\n</ul>\n</li>\n<li><p>增量运算</p>\n<pre><code class=\"python\"> b = (1, 2)\n b += b\n\n a = (1, [2, 3])\n a[1] += [4]\n</code></pre>\n<ul>\n<li><p>对元组进行增量赋值运算，相当于<code>b = b + b</code>，会产生一个新的对象，和变量<code>b</code>绑定。<br>(一个类如果没有实现<code>__iadd__</code>，python会调用<code>__add__</code>)</p>\n</li>\n<li><p>对于<code>a[1] += 4</code>，a会变成<code>(1, [2, 3, 4])</code>，同时也会抛出异常<code>TypeError</code><br>(可以通过dis.dis(‘s[a] += b’)查看字节码，增量赋值不是一个原子操作，先增然后赋值)</p>\n</li>\n</ul>\n</li>\n</ol>\n","categories":["Python"],"tags":["Python"]},{"title":"新浪登录流程","url":"http://shawnz.me/posts/b9e0b33e/","content":"<h1 id=\"登录流程\"><a href=\"#登录流程\" class=\"headerlink\" title=\"登录流程\"></a>登录流程</h1><h2 id=\"Step1-客户端预登录\"><a href=\"#Step1-客户端预登录\" class=\"headerlink\" title=\"Step1:客户端预登录\"></a>Step1:客户端预登录</h2><p><strong>响应参数：</strong></p>\n<ul>\n<li>servertime</li>\n<li>nonce</li>\n<li>rsakey<a id=\"more\"></a>\n<strong>加密用户名和密码：</strong></li>\n</ul>\n<pre><code class=\"javascript\">var makeRequest = function(username, password, savestate) {\n    var request = {\n      entry: me.getEntry(),\n      gateway: 1,\n      from: me.from,\n      savestate: savestate,\n      useticket: me.useTicket ? 1 : 0\n    };\n    if (me.failRedirect) {\n      me.loginExtraQuery.frd = 1\n    }\n    request = objMerge(request, {\n      pagerefer: document.referrer || &quot;&quot;\n    });\n    request = objMerge(request, me.loginExtraFlag);\n    request = objMerge(request, me.loginExtraQuery);\n    // 用户名加密，可以base64解码\n    request.su = sinaSSOEncoder.base64.encode(urlencode(username));\n    if (me.service) {\n      request.service = me.service\n    }\n    if ((me.loginType &amp; rsa) &amp;&amp; me.servertime &amp;&amp; sinaSSOEncoder &amp;&amp; sinaSSOEncoder.RSAKey) {\n      request.servertime = me.servertime;\n      request.nonce = me.nonce;\n      request.pwencode = &quot;rsa2&quot;;\n      request.rsakv = me.rsakv;\n      var RSAKey = new sinaSSOEncoder.RSAKey();\n      RSAKey.setPublic(me.rsaPubkey, &quot;10001&quot;);\n      //公钥加密，服务器端私钥解密 可以得到原始密码\n      password = RSAKey.encrypt([me.servertime, me.nonce].join(&quot;\\t&quot;) + &quot;\\n&quot; + password)\n    } else {\n      if ((me.loginType &amp; wsse) &amp;&amp; me.servertime &amp;&amp; sinaSSOEncoder &amp;&amp; sinaSSOEncoder.hex_sha1) {\n        request.servertime = me.servertime;\n        request.nonce = me.nonce;\n        request.pwencode = &quot;wsse&quot;;\n        password = sinaSSOEncoder.hex_sha1(&quot;&quot; + sinaSSOEncoder.hex_sha1(sinaSSOEncoder.hex_sha1(password)) + me.servertime + me.nonce)\n      }\n    }\n    request.sp = password;\n    try {\n      request.sr = window.screen.width + &quot;*&quot; + window.screen.height\n    } catch (e) {}\n    return request\n  };\n</code></pre>\n<h2 id=\"Step2-客户端登录\"><a href=\"#Step2-客户端登录\" class=\"headerlink\" title=\"Step2:客户端登录\"></a>Step2:客户端登录</h2><p><strong>请求参数：</strong></p>\n<ul>\n<li>cdult: 3</li>\n<li>domain: sina.com.cn</li>\n<li>encoding: UTF-8</li>\n<li>entry: account</li>\n<li>from:</li>\n<li>gateway: 1</li>\n<li><code>nonce</code>: AFE3O9 //随机值</li>\n<li>pagerefer: <a href=\"http://login.sina.com.cn/sso/logout.php\" target=\"_blank\" rel=\"noopener\">http://login.sina.com.cn/sso/logout.php</a></li>\n<li>prelt: 41</li>\n<li><code>pwencode</code>: rsa2  //加密算法</li>\n<li>returntype: TEXT</li>\n<li><code>rsakv</code>: 1330428213  //密钥</li>\n<li>savestate: 30</li>\n<li><code>servertime</code>: 1478568922 //服务器时间</li>\n<li>service: sso</li>\n<li><code>sp</code>: password //密码</li>\n<li>sr: 1366*768</li>\n<li><code>su</code>: username  //用户名</li>\n<li>useticket: 0</li>\n<li>vsnf: 1</li>\n</ul>\n<h2 id=\"Step3-服务端登录校验过程\"><a href=\"#Step3-服务端登录校验过程\" class=\"headerlink\" title=\"Step3:服务端登录校验过程\"></a>Step3:服务端登录校验过程</h2><ol>\n<li>服务端使用RSA私钥对客户端传递的sp进行解密，得到原始密码。</li>\n<li>然后通过MD5生成摘要和数据库保存的密码进行对比</li>\n<li>缓存Token-Username，返回Token/Cookie</li>\n</ol>\n<h2 id=\"Note-安全问题及解决方案\"><a href=\"#Note-安全问题及解决方案\" class=\"headerlink\" title=\"Note:安全问题及解决方案\"></a>Note:安全问题及解决方案</h2><ol>\n<li><p>加密算法泄漏</p>\n<blockquote>\n<p>客户端加密算法打包/混淆</p>\n</blockquote>\n</li>\n<li><p>用户名、密码泄漏</p>\n<blockquote>\n<p>检测异地登录/登录异常，提示修改密码</p>\n</blockquote>\n</li>\n<li><p>登录报文(用户名/密码)截获</p>\n<blockquote>\n<p>包含servertime,nonce无法在下一次登录使用</p>\n</blockquote>\n</li>\n<li><p>响应报文(Cookie/Token)截获</p>\n<blockquote>\n<p>设置过期时间，每次或者短时间内过期</p>\n</blockquote>\n</li>\n<li><p>帐号异常锁定</p>\n<blockquote>\n<p>登录检查帐号异常</p>\n</blockquote>\n</li>\n<li><p>密码、用户名等信息的修改/Token过期，需要重新登录</p>\n<blockquote>\n<p>移除/过期服务端的Token-Username缓存</p>\n</blockquote>\n</li>\n<li><p>登录过程中间人攻击</p>\n<blockquote>\n<p>攻击者伪造成服务器，返回客户端错误的密钥等参数，客户端在登录时将参数发送给攻击者，攻击者破译用户名和密码</p>\n</blockquote>\n</li>\n<li><p>服务端需要保存状态</p>\n<blockquote>\n<p>在登录过程中产生的中间参数，诸如验证码/nonce需要服务器保存，在下一步登录中进行校验</p>\n</blockquote>\n</li>\n</ol>\n","categories":[],"tags":[]},{"title":"封闭开发的两个月","url":"http://shawnz.me/posts/653170c4/","content":"<a id=\"more\"></a>","categories":[],"tags":["生活"]},{"title":"哈希表","url":"http://shawnz.me/posts/850f2080/","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>数组和链表的比较:</p>\n<ol>\n<li>数组内的元素在内存中是连续存放的；链表的元素不是连续的，而是通过指针联系在一起．</li>\n<li>数组的长度必须固定；链表可以动态分配存储空间</li>\n<li>数组从栈中分配；链表从堆分配空间</li>\n</ol>\n<a id=\"more\"></a>\n<p>在查询和插入删除上的区别：</p>\n<ol>\n<li>查询．数组可以通过索引找到元素，而链表需要从头遍历．所以数组查询效率高于链表<br><code>note</code>从头遍历时间复杂度为O(n),采用二叉排序树存储，时间复杂度O(logn)</li>\n<li>插入或删除．数组插入和删除需要移动大量的元素，而链表只需要改变指针指向．所以插入删除链表效率高于数组</li>\n</ol>\n<p>而哈希表介于两者之间:既具备数组的高效查询，又能融合链表增加和删除元素的优势</p>\n<h2 id=\"实现\"><a href=\"#实现\" class=\"headerlink\" title=\"实现\"></a>实现</h2><p>哈希表就是根据Key直接访问访问对应的值的存储结构．对于不同长度的输入产生一个固定长度输出，散列结果应具有同一性(输出应尽量分布均匀)和雪崩效应(微笑的输入变化导致输出发生巨大的变化)</p>\n<p>实现思路：｀<br>将key通过散列函数转换成数组的索引．如果没有内存限制，那么可以将健作为索引，需要定义m&gt;n,即数组的长度大于元素的数量，时间复杂度为O(1)．由于将近乎无限的关键字集合压缩映射到有限的哈希表中的地址值中，那么必然存在产生＂冲突＂的现象，需要处理哈希碰撞冲突．<br>关于哈希表实现的两个关键在于哈希函数的构造和冲突的解决方法．</p>\n<h2 id=\"常见的散列函数构造方法\"><a href=\"#常见的散列函数构造方法\" class=\"headerlink\" title=\"常见的散列函数构造方法\"></a>常见的散列函数构造方法</h2><ol>\n<li><strong>直接寻址法</strong><br>取某个关键字的线性函数值为散列地址，比例在0~100的年龄统计表里，可以直接将年龄作为地址,即<br> $$f(key) = a * key + b$$</li>\n<li><strong>平方取中法</strong><br>假设关键字是123,那么平方是1522756，取中间3位就是227，作为散列地址．<code>适用于关键字位数少</code></li>\n<li><strong>折叠法</strong><br>将关键字从左到右分割成位数相等的几部分，然后将这几部分叠加求和，并按散列表表长，取后几位作为散列地址。叠加方法又分为移位叠加和边界叠加．<code>适用于关键字位数较多</code></li>\n<li><strong>减去法</strong><br>减去一个特定数值求得存储地址．</li>\n<li><strong>基数转化法</strong><br>将十进制X看作其他进制，例如十三进制，再转换成十进制取其中几位作为存储地址．</li>\n<li><strong>取模余数法</strong><br>对于散列表长度为m的散列公式函数为:$f(key) = key mod p(p&lt;=m)$<br>这种方法的关键在于p的选取，根据经验:模p取不大于表长且最接近表长m素数时效果最好，且p最好取1.1n～1.7n之间的一个素数（n为存在的数据元素个数）</li>\n<li><strong>随机数法</strong><br>取关键字的随机函数值作为散列地址，即$f(key) = random(key)$.<code>适用于长度不确定</code></li>\n</ol>\n<p>实际应用中需要根据关键字位数，分布情况，散列表长度等因素选择合适的策略，可以采用多种方式协作处理．</p>\n<h2 id=\"处理冲突\"><a href=\"#处理冲突\" class=\"headerlink\" title=\"处理冲突\"></a>处理冲突</h2><ol>\n<li><strong>链地址法</strong><br>解决冲突的一种常用方法，将所有散列到同一个地址元素保存在一个同义词链表里，散列数组中只保存链表的头指针。<br><code>实例</code><br>假设有哈希表长度m = 5, f(key) = key mod 5, 关键词序列为3, 12, 7, 19, 24, 32, 26，那么采用外链地址法会建立如下哈希表：</li>\n</ol>\n<p>链地址法处理简单，没有堆积现象，因此平均查找长度较小。另外结点空间是动态申请的，适合于表长未知的情况</p>\n<ol>\n<li><strong>开放定址法</strong><br>开放定址，即在散列产生冲突的时候，寻找下一个散列地址，只要表的空间足够大，那么总能找到位置插入元素。分为一下几种方法：</li>\n</ol>\n<ul>\n<li><p>线性探测法<br>线性探测的函数为 $f(k, i) = (h(k) + 1) mod m, i = 0, 1, 2,.., m - 1$<br>步骤：<br>首先探查 h(k) mod m的位置，当被占用时，继续探查(h(k) + 1) mod m的位置，如果依然被占用，那么继续探查，直到找到合适的位置，或者达到表的末尾，则停止。</p>\n</li>\n<li><p>二次探测法<br>二次探测在一次探测的基础上增加了一个二项式， $f(k, i) = (h(k) + c_1i + c_2i^2) mod m$,相对线性探测，二次探测群聚现象没那么重，但依然存在二次群聚。</p>\n</li>\n<li><p>双散列函数探测法</p>\n</li>\n</ul>\n<ol>\n<li><strong>建立公共溢出区</strong><br>单独设立一个溢出表，只要散列值发生冲突，就存入改表中。</li>\n</ol>\n","categories":["数据结构"],"tags":["Hash","数据结构"]},{"title":"布隆算法","url":"http://shawnz.me/posts/86a93a60/","content":"","categories":["算法"],"tags":["算法"]},{"title":"装饰器","url":"http://shawnz.me/posts/da520e93/","content":"","categories":["Python"],"tags":["Python"]},{"title":"PEP8代码规范","url":"http://shawnz.me/posts/169f56b2/","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><blockquote>\n<p><strong>愚蠢的一致性就像没有脑子的妖怪</strong></p>\n<p><strong>「别人在阅读代码过程中飙脏话的频率是衡量你代码质量的唯一标准」。</strong></p>\n<p>Guido 的一个核心观点认为，相比于被编写，代码更多的是被阅读。这篇指南意在提高代码的可读性并使之在广袤的 Python 编码中保持风格一致。<br><a id=\"more\"></a></p>\n</blockquote>\n<h2 id=\"相关连接\"><a href=\"#相关连接\" class=\"headerlink\" title=\"相关连接\"></a>相关连接</h2><blockquote>\n<p><a href=\"http://www.cnblogs.com/ajianbeyourself/p/4377933.html#_label0\" target=\"_blank\" rel=\"noopener\">PEP8–Style Guide for Python Code</a></p>\n<p><a href=\"\">重构:改善既有代码的设计</a></p>\n<p><a href=\"http://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/contents/\" target=\"_blank\" rel=\"noopener\">Google 开源项目风格指南</a></p>\n</blockquote>\n<h1 id=\"怎样提高代码的可读性\"><a href=\"#怎样提高代码的可读性\" class=\"headerlink\" title=\"怎样提高代码的可读性\"></a>怎样提高代码的可读性</h1><blockquote>\n<ul>\n<li>代码规范</li>\n<li>组织结构v</li>\n<li>逻辑抽象、简化</li>\n</ul>\n</blockquote>\n<h2 id=\"代码缩进\"><a href=\"#代码缩进\" class=\"headerlink\" title=\"代码缩进\"></a>代码缩进</h2><ol>\n<li>缩进。4个空格的缩进，不使用Tab，更不能混合使用Tab和空格。</li>\n<li>每行最大长度79，换行可以使用反斜杠。换行点要在操作符的后边敲回车。</li>\n<li>类和top-level函数定义之间空两行；类中的方法定义之间空一行；函数内逻辑无关段落之间空一行；其他地方尽量不要再空行。</li>\n</ol>\n<h2 id=\"文档编排\"><a href=\"#文档编排\" class=\"headerlink\" title=\"文档编排\"></a>文档编排</h2><ol>\n<li>模块内容的顺序：模块说明和docstring—import—globals&amp;constants—其他定义。其中import部分，又按标准、三方和自己编写顺序依次排放，之间空一行。</li>\n<li>不要在一句import中多个库，比如<code>import os, sys</code>不推荐</li>\n<li>如果采用<code>from XX import XX</code>引用库，可以省略<code>module</code>，都是可能出现命名冲突，这时就要采用<code>import XX</code></li>\n</ol>\n<h2 id=\"空格\"><a href=\"#空格\" class=\"headerlink\" title=\"空格\"></a>空格</h2><ol>\n<li>括号</li>\n<li>参数</li>\n<li>赋值语句</li>\n<li>逗号、冒号、分号前后区别</li>\n</ol>\n<h2 id=\"注释\"><a href=\"#注释\" class=\"headerlink\" title=\"注释\"></a>注释</h2><ol>\n<li>谨慎地使用内嵌注释</li>\n<li>内嵌注释是一种和语句在同一行的注释。内嵌注释至少和语句间隔2个空格。他们开始于一个 # 和一个空格。</li>\n</ol>\n<pre><code class=\"java\">                   ::\n                  :;J7, :,                        ::;7:\n                  ,ivYi, ,                       ;LLLFS:\n                  :iv7Yi                       :7ri;j5PL\n                 ,:ivYLvr                    ,ivrrirrY2X,\n                 :;r@Wwz.7r:                :ivu@kexianli.\n                :iL7::,:::iiirii:ii;::::,,irvF7rvvLujL7ur\n               ri::,:,::i:iiiiiii:i:irrv177JX7rYXqZEkvv17\n            ;i:, , ::::iirrririi:i:::iiir2XXvii;L8OGJr71i\n          :,, ,,:   ,::ir@mingyi.irii:i:::j1jri7ZBOS7ivv,\n             ,::,    ::rv77iiiriii:iii:i::,rvLq@huhao.Li\n         ,,      ,, ,:ir7ir::,:::i;ir:::i:i::rSGGYri712:\n       :::  ,v7r:: ::rrv77:, ,, ,:i7rrii:::::, ir7ri7Lri\n      ,     2OBBOi,iiir;r::        ,irriiii::,, ,iv7Luur:\n    ,,     i78MBBi,:,:::,:,  :7FSL: ,iriii:::i::,,:rLqXv::\n    :      iuMMP: :,:::,:ii;2GY7OBB0viiii:i:iii:i:::iJqL;::\n   ,     ::::i   ,,,,, ::LuBBu BBBBBErii:i:i:i:i:i:i:r77ii\n  ,       :       , ,,:::rruBZ1MBBqi, :,,,:::,::::::iiriri:\n ,               ,,,,::::i:  @arqiao.       ,:,, ,:::ii;i7:\n:,       rjujLYLi   ,,:::::,:::::::::,,   ,:i,:,,,,,::i:iii\n::      BBBBBBBBB0,    ,,::: , ,:::::: ,      ,,,, ,,:::::::\ni,  ,  ,8BMMBBBBBBi     ,,:,,     ,,, , ,   , , , :,::ii::i::\n:      iZMOMOMBBM2::::::::::,,,,     ,,,,,,:,,,::::i:irr:i:::,\ni   ,,:;u0MBMOG1L:::i::::::  ,,,::,   ,,, ::::::i:i:iirii:i:i:\n:    ,iuUuuXUkFu7i:iii:i:::, :,:,: ::::::::i:i:::::iirr7iiri::\n:     :rk@Yizero.i:::::, ,:ii:::::::i:::::i::,::::iirrriiiri::,\n :      5BMBBBBBBSr:,::rv2kuii:::iii::,:i:,, , ,,:,:i@petermu.,\n      , :r50EZ8MBBBBGOBBBZP7::::i::,:::::,: :,:,::i;rrririiii::\n          :jujYY7LS0ujJL7r::,::i::,::::::::::::::iirirrrrrrr:ii:\n       ,:  :@kevensun.:,:,,,::::i:i:::::,,::::::iir;ii;7v77;ii;i,\n       ,,,     ,,:,::::::i:iiiii:i::::,, ::::iiiir@xingjief.r;7:i,\n    , , ,,,:,,::::::::iiiiiiiiii:,:,:::::::::iiir;ri7vL77rrirri::\n     :,, , ::::::::i:::i:::i:i::,,,,,:,::i:i:::iir;@Secbone.ii:::\n</code></pre>\n<pre><code class=\"python\">\n# 写这段代码的时候，只有上帝和我知道它是干嘛的\n# 现在只有上帝知道\n\n# 实在干不下去了\n\n# 已经找好下家明天就辞职\n\n# 如果你也不想干了\n\n# 找我给你内推\n</code></pre>\n<h2 id=\"命名规范\"><a href=\"#命名规范\" class=\"headerlink\" title=\"命名规范\"></a>命名规范</h2><p><strong>应该避免的名称</strong></p>\n<ol>\n<li>单字符名称, 除了计数器和迭代器. <code>x</code>,<code>y</code>变量</li>\n<li>包/模块名中的连字符(-)</li>\n<li>双下划线开头并结尾的名称(Python保留, 例如<strong>init</strong>)</li>\n</ol>\n<p><strong>命名约定</strong></p>\n<ol>\n<li>用单下划线(_)开头表示模块变量或函数是protected的(使用import * from时不会包含).</li>\n<li>用双下划线(__)开头的实例变量或方法表示类内私有.</li>\n<li>将相关的类和顶级函数放在同一个模块里. 不像Java, 没必要限制一个类一个模块.</li>\n<li>对类名使用大写字母开头的单词(如CapWords, 即Pascal风格), 但是模块名应该用小写加下划线的方式(如lower_with_under.py). 尽管已经有很多现存的模块使用类似于CapWords.py这样的命名, 但现在已经不鼓励这样做, 因为如果模块名碰巧和类名一致, 这会让人困扰.</li>\n</ol>\n<pre><code class=\"python\"># 作者：xlzd\n# 链接：https://www.zhihu.com/question/21395276/answer/33747423\n# 来源：知乎\n# 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n(lambda _________, _, __, ___, ____, _____, ______, _______, ________: \\\ngetattr(getattr( \\\n__import__(None.__class__.__name__.__class__.__name__[_____-_____] \\\n+ False.__class__.__class__.__name__[_ &lt;&lt; (_____-_____)] \\\n+ [].__class__.__name__[_ &lt;&lt; _]),\\\n[].__class__.__name__[________ &gt;&gt; __:] + {}.__class__.__name__[______-______] + _________(__&lt;&lt;_______, \\\n(_______ &lt;&lt; (_____ &lt;&lt; __)) + (____ &lt;&lt; (____ &lt;&lt; __)) + (__ ** (_______ &lt;&lt; _)) \\\n+ __ ** (_____ + ________) + (_ &lt;&lt; (____ * ___)) + __ ** (________ + __) \\\n+ (_ &lt;&lt; ________) + __**_______ - _ - (__ &lt;&lt; ___))), \\\n_________(__**________, (_ &lt;&lt; (_____ * ________ - __)) + (_ &lt;&lt; (_____ * ________ - ___)) + \\\n(__ ** ((_ &lt;&lt; _____) + __)) + (__ ** (_ &lt;&lt; _____)) + (__ ** ((_ &lt;&lt; _____) - __)) + \\\n(__ ** ((_ &lt;&lt; _____) - ___)) + (__ ** ((_ &lt;&lt; _____) - ____)) + (_ &lt;&lt; (_____ ** __ + _)) + \\\n(__ ** (____ * _____ + __)) + (_ &lt;&lt; (__ ** ____ + _____)) + (__ ** (_____ * ____ - _)) + \\\n(__ ** (_ &lt;&lt; ____)) + ( 1 &lt;&lt; (__ ** ____ - __)) + (_ &lt;&lt; (______ * __ + _)) + \\\n(_ &lt;&lt; (______ * __)) + (__ ** (___ ** __)) + __ ** ______ + __ ** _____ + __ ** ____ + ____ + __ + _)\\\n)(_________(____ &lt;&lt; ______, (((_____ &lt;&lt; ____) + _) &lt;&lt; ((___ &lt;&lt; _____) - ___)) + \\\n(((((___ &lt;&lt; __) - _) &lt;&lt; ___) + _) &lt;&lt; ((_____ &lt;&lt; ____) + (_ &lt;&lt; _))) + \\\n(((_______ &lt;&lt; __) - _) &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; ___) + (_ &lt;&lt; _))) + \\\n(((_______ &lt;&lt; ___) + _) &lt;&lt; ((_ &lt;&lt; ______) + _)) + (((_______ &lt;&lt; ____) - _) &lt;&lt; ((_______ &lt;&lt; ___))) + \\\n(((_ &lt;&lt; ____) - _) &lt;&lt; ((((___ &lt;&lt; __) + _) &lt;&lt; __) - _)) - \\\n(((((___ &lt;&lt; __) + _) &lt;&lt; __) + _) &lt;&lt; ((_____ &lt;&lt; ___) + (_ &lt;&lt; _))) + \\\n(_______ &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; __))) - \\\n((((((_ &lt;&lt; ___) + _)) &lt;&lt; __) + _) &lt;&lt; ((((___ &lt;&lt; __) + _) &lt;&lt; _))) + \\\n(((_______ &lt;&lt; __) - _) &lt;&lt; (((((_ &lt;&lt; ___) + _)) &lt;&lt; _))) + (((___ &lt;&lt; ___) + _) &lt;&lt; ((_____ &lt;&lt; _))) \\\n+ ((((___ &lt;&lt; __) - _)) &lt;&lt; _____) + (_ &lt;&lt; ___))))\\\n(lambda _______, ___ : (lambda _, __ : _(_, __))(lambda _, __ : chr(__ % _______) + \\\n_(_, __ // _______) if __ else (lambda: _).func_code.co_lnotab, ___),\\\n*(lambda _, __, ___: _(_, __, ___))(\n(lambda _, __, ___:\n[__(___[(lambda: _).func_code.co_nlocals])] +\n_(_, __, ___[(lambda _: _).func_code.co_nlocals:]) if ___ else []\n),\nlambda _: _.func_code.co_argcount,\n(\nlambda _: _,\nlambda _, __: _,\nlambda _, __, ___: _,\nlambda _, __, ___, ____: _,\nlambda _, __, ___, ____, _____: _,\nlambda _, __, ___, ____, _____, ______: _,\nlambda _, __, ___, ____, _____, ______, _______: _,\nlambda _, __, ___, ____, _____, ______, _______, ________: _\n)\n))\n\n</code></pre>\n<h2 id=\"编码建议\"><a href=\"#编码建议\" class=\"headerlink\" title=\"编码建议\"></a>编码建议</h2><ol>\n<li><p>尽可能使用<code>is</code> <code>is not</code>取代<code>==</code>，比如<code>if x is not None</code>要优于<code>if x</code>。</p>\n</li>\n<li><p>异常中不要使用裸露的except，except后跟具体的exceptions。</p>\n</li>\n<li><p>异常中try的代码尽可能少。<br><code>`</code>python</p>\n</li>\n</ol>\n<h1 id=\"YES\"><a href=\"#YES\" class=\"headerlink\" title=\"YES\"></a>YES</h1><p>try:<br>    value = collection[key]<br>except KeyError:<br>    return key_not_found(key)<br>else:<br>    return handle_value(value)</p>\n<h1 id=\"NO：\"><a href=\"#NO：\" class=\"headerlink\" title=\"NO：\"></a>NO：</h1><p>try:</p>\n<pre><code># 很多代码\nreturn handle_value(collection[key])\n</code></pre><p>except KeyError:</p>\n<pre><code># 捕获由handle_value()抛出的KeyError\nreturn key_not_found(key)\n</code></pre><pre><code>\n4. 每次循环 判断条件不如 失败 `try except`。\n\n5. 列表推导式，字典推导式，lambda函数\n```python\nsorted_warehouse = sorted(warehouses,\n                              key=lambda x:\n                              min(x.expresses,\n                                  key=lambda y: y.first_weight_price).\n                                  first_weight_price)\n\ndef split_order(order):\n    # 检查库存\n    ret_1 = {}\n    ret_2 = {}\n    ret_3 = {}\n    for item in order[&quot;order_details&quot;]:\n        stock = order_api.get_stock(order[&quot;user_id&quot;], item[&quot;item_id&quot;])\n        sku_id = stock[&#39;sku_id&#39;]\n        ret_3[sku_id] = item[&#39;quantity&#39;]\n        ret_1[sku_id] = {warehouse[&#39;id&#39;] for warehouse in stock[&#39;warehouse&#39;] if\n                         warehouse[&#39;available_count&#39;] &gt;= item[&#39;quantity&#39;]}\n        for warehouse in stock[&#39;warehouse&#39;]:\n            ret_2.setdefault(warehouse[&#39;id&#39;], [])\n            ret_2[warehouse[&#39;id&#39;]].append(\n                (sku_id, warehouse[&#39;available_count&#39;]))\n    tmp = next(iter(ret_1.values()))\n    for r in ret_1.values():\n        tmp = r &amp; tmp\n    if tmp:\n        tmp = list(tmp)\n        ret = []\n        for warehouse_id in tmp:\n            dict_data = {}\n            for item in order[&quot;order_details&quot;]:\n                dict_data[item[&quot;sku_id&quot;]] = item[&quot;quantity&quot;]\n            ret.append({warehouse_id: dict_data})\n        return ret\n    else:\n        success_item = []\n        success_item_1 = []\n        # print(&quot;没有仓可以全部发货，需要拆单&quot;)\n        for item in combinations(ret_2.keys(), 2):\n            tag = True\n            tmp = {}\n            tmp[item[0]] = {}\n            tmp[item[1]] = {}\n            for sku_id in ret_3.keys():\n                a = [value[1] for value in ret_2[item[0]] if value[0] == sku_id][0] if [\n                    value[1] for value in ret_2[item[0]] if value[0] == sku_id] else 0\n                b = [value[1] for value in ret_2[item[1]] if value[0] == sku_id][0] if [\n                    value[1] for value in ret_2[item[1]] if value[0] == sku_id] else 0\n                if ret_3[sku_id] &lt;= a + b:\n                    if a &gt; ret_3[sku_id]:\n                        tmp[item[0]][sku_id] = ret_3[sku_id]\n                    elif b &gt; ret_3[sku_id]:\n                        tmp[item[1]][sku_id] = ret_3[sku_id]\n                    else:\n                        tmp[item[0]][sku_id] = max(a, b)\n                        tmp[item[1]][sku_id] = ret_3[sku_id] - max(a, b)\n                else:\n                    tag = False\n            if tag:\n                success_item.append(item)\n                success_item_1.append(tmp)\n        return success_item_1\n\n</code></pre><ol>\n<li><p>判断序列为空 <code>if sequence</code> 优于 <code>if len(sequence) &gt; 0</code>,利用空序列是<code>False</code>的事实。。</p>\n</li>\n<li><p>返回语句保持一致。函数中的所有返回语句都有返回值，或都没有返回值。<br><code>`</code>python</p>\n</li>\n</ol>\n<h1 id=\"YES-1\"><a href=\"#YES-1\" class=\"headerlink\" title=\"YES\"></a>YES</h1><p>def foo(x):<br>    if x &gt;= 0:<br>        return math.sqrt(x)<br>    else:<br>        return None</p>\n<p>def bar(x):<br>    if x &lt; 0:<br>        return None<br>    return math.sqrt(x)</p>\n<h1 id=\"NO\"><a href=\"#NO\" class=\"headerlink\" title=\"NO\"></a>NO</h1><p>def foo(x):<br>    if x &gt;= 0:<br>        return math.sqrt(x)</p>\n<p>def bar(x):<br>    if x &lt; 0:<br>        return<br>    return math.sqrt(x)</p>\n<pre><code>8. 对象类型的比较使用`isinstance()`代替`type`直接比较类型。\n```python\n# 风格良好\nif isinstance(obj, int):\n# 风格不良\nif type(obj) is type(1):\n</code></pre><h1 id=\"RESTful-API\"><a href=\"#RESTful-API\" class=\"headerlink\" title=\"RESTful API\"></a>RESTful API</h1><h2 id=\"简介\"><a href=\"#简介\" class=\"headerlink\" title=\"简介\"></a>简介</h2><blockquote>\n<p>REST是<code>REpresentational State Transfer</code>的缩写，可以翻译成<code>表现状态转换</code></p>\n</blockquote>\n<ul>\n<li><strong>客户-服务器（Client-Server）</strong>，提供服务的服务器和使用服务的客户需要被隔离对待。</li>\n<li><strong>无状态（Stateless）</strong>，来自客户的每一个请求必须包含服务器处理该请求所需的所有信息。换句话说，服务器端不能存储来自某个客户的某个请求中的信息，并在该客户的其他请求中使用。</li>\n<li><strong>可缓存（Cachable）</strong>，服务器必须让客户知道请求是否可以被缓存。（Ross：更详细解释请参考 理解本真的REST架构风格 以及 StackOverflow 的这个问题 中对缓存的解释。）</li>\n<li><strong>分层系统（Layered System）</strong>，服务器和客户之间的通信必须被这样标准化：允许服务器和客户之间的中间层（Ross：代理，网关等）可以代替服务器对客户的请求进行回应，而且这些对客户来说不需要特别支持。</li>\n<li><strong>统一接口（Uniform Interface）</strong>，客户和服务器之间通信的方法必须是统一化的。（Ross：GET,POST,PUT.DELETE, etc）* <strong>支持按需代码（Code-On-Demand，可选）</strong>，服务器可以提供一些代码或者脚本（Ross：Javascrpt，flash，etc）并在客户的运行环境中执行。这条准则是这些准则中唯一不必必须满足的一条。（Ross：比如客户可以在客户端下载脚本生成密码访问服务器。）</li>\n</ul>\n<p>blah, blah, blah…</p>\n<h4 id=\"URL-知道要什么\"><a href=\"#URL-知道要什么\" class=\"headerlink\" title=\"URL 知道要什么\"></a>URL 知道要什么</h4><h4 id=\"HTTP-method-知道干什么\"><a href=\"#HTTP-method-知道干什么\" class=\"headerlink\" title=\"HTTP method 知道干什么\"></a>HTTP method 知道干什么</h4><h4 id=\"HTTP-status-code-知道结果如何\"><a href=\"#HTTP-status-code-知道结果如何\" class=\"headerlink\" title=\"HTTP status code 知道结果如何\"></a>HTTP status code 知道结果如何</h4><h4 id=\"“HTTP协议是这样设计的，别用错了”-——RESTfull\"><a href=\"#“HTTP协议是这样设计的，别用错了”-——RESTfull\" class=\"headerlink\" title=\"“HTTP协议是这样设计的，别用错了” ——RESTfull**\"></a>“HTTP协议是这样设计的，别用错了” ——RESTfull**</h4><p>示例A：</p>\n<ul>\n<li>/createProduct </li>\n<li>/getProduct?prductID=</li>\n<li>/listOrders</li>\n<li>/getStoreByUserID?userID=1</li>\n</ul>\n<p>示例B:</p>\n<ul>\n<li><code>GET</code> /products/ : 返回所有店铺列表</li>\n<li><code>POST</code> /products/ : 创建一个店铺</li>\n<li><code>GET</code> /products/4/ : 获取id=4的店铺信息</li>\n<li><code>DELETE</code> /products/4/ 删除id=4的店铺</li>\n<li><code>PUT</code> /products/4/ 更新id=4的店铺</li>\n</ul>\n","categories":["Python"],"tags":["Python"]},{"title":"Passing Arguments by Reference or Value","url":"http://shawnz.me/posts/e40cacb6/","content":"<p>在区分这两种方式之前，先要理解所有的对象或者说是基本数据类型，都有两样东西：</p>\n<ul>\n<li>值</li>\n<li>指向内存地址的引用<br>假设有<code>foo = &quot;hello world!&quot;</code><blockquote>\n<p><strong>Passing by Value</strong>指将值的副本传递给被调用的函数，意味着有了两个<strong>独立</strong>的变量，互不干扰。传递的就是<code>hello world</code></p>\n<p><strong>Passing by Reference</strong>指将变量或者说是引用传递给函数，对<strong>引用的实体</strong>的修改将改变原有的变量。传递的可能是<code>0x7fd5d258dd00</code>这种形式的内存地址，任何指向这个地址变量的值都是<code>hello world</code></p>\n</blockquote>\n</li>\n</ul>\n<a id=\"more\"></a>\n<p>在这里介绍了一下Java和Python关于参数传递的过程和机制：</p>\n<h2 id=\"Java\"><a href=\"#Java\" class=\"headerlink\" title=\"Java\"></a>Java</h2><p>在大多java的书籍中都强调：<strong>只有值传递</strong>。v<br>像这样：</p>\n<pre><code class=\"java\">Dog myDog = new Dog(&quot;Bailey&quot;)  // 内存地址&amp;42\n\npublic void foo(Dog someDog){\n    someDog.setName(&quot;Max&quot;);  // Line A\n    someDog = new Dog(&quot;Buddy&quot;);  // Line B\n    someDog.setName(&quot;Rocky&quot;);  // Line C\n}\n\nfoo(myDog)\n</code></pre>\n<p>看看都发生些什么：</p>\n<ul>\n<li><code>foo</code>方法中的参数<code>someDog</code>，接收到<code>Dog Bailey</code>的引用的值的副本<code>&amp;42</code></li>\n<li>Line A<ul>\n<li><code>someDog</code>现在的内存地址<code>&amp;42</code></li>\n<li>然后将<code>Dog Bailey</code>更名为<code>Max</code></li>\n</ul>\n</li>\n<li>Line B<ul>\n<li>新创建了一只<code>Dog Buddy</code>，它在内存中的地址是<code>&amp;63</code></li>\n<li>将变量<code>someDog</code>的引用指向到<code>&amp;63</code></li>\n</ul>\n</li>\n<li>Line C<ul>\n<li><code>someDog</code>现在的内存地址<code>&amp;63</code></li>\n<li>将<code>Dog Buddy</code> 更名为<code>Rocky</code></li>\n</ul>\n</li>\n</ul>\n<p>最后myDog的名称应该是<code>Max</code>，指向地址<code>&amp;42</code></p>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><h2 id=\"Difference\"><a href=\"#Difference\" class=\"headerlink\" title=\"Difference\"></a>Difference</h2>","categories":["Python"],"tags":["Python"]},{"title":"uWsgi部署导致Apscheduler任务不运行","url":"http://shawnz.me/posts/431b23f2/","content":"<p><strong>前言</strong></p>\n<blockquote>\n<p><a href=\"http://uwsgi-docs-zh.readthedocs.io/zh_CN/latest/index.html\" target=\"_blank\" rel=\"noopener\">uWSGI官方文档</a></p>\n</blockquote>\n<p>在一个Flask项目里，采用Apscheduler做定时任务处理（订单的过期和活动的开始）。<br>但是在正式生产环境下，使用Nginx+Supervisor+uWSGI的方式部署FLask项目，发现定时任务成功存储到了Store job里，然而不会触发，只有在项目重启的时候，才会执行那些没有执行的任务。<br>采用的uwsgi 配置<br><a id=\"more\"></a></p>\n<pre><code>[uwsgi]\nmaster = true\nwsgi-file = application.py\ncallable = app\nhttp = :5000\nprocesses = 2\nthreads = 4\n</code></pre><p>在网上查过相关资料，发现两种解决方案：</p>\n<p><strong>方案一：</strong><br>uwsgi 默认采用one thread one processor,在没有请求的时候，会导致部分线程会被挂起，<br>在uwsgi配置文件中加上</p>\n<pre><code>enable-thread = true \n</code></pre><p>上面这个解决方案，存在两个问题：</p>\n<blockquote>\n<p>在上面的配置文件里，我有启用两个进程和四个线程，那么为什么还会导致线程被挂起呢?<br>另外，在采用这种解决方案后，还是没有触发那些动态添加的定时任务<br>关于这部分还需要深入研究uwsgi和apscheduler的运行机制，另外有了解的可以在下面的评论区回复<img class=\"github-emoji\" title=\"blush\" alt=\"blush\" src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png?v8\" height=\"20\" width=\"20\"><img class=\"github-emoji\" title=\"blush\" alt=\"blush\" src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png?v8\" height=\"20\" width=\"20\"><img class=\"github-emoji\" title=\"blush\" alt=\"blush\" src=\"https://assets-cdn.github.com/images/icons/emoji/unicode/1f60a.png?v8\" height=\"20\" width=\"20\"></p>\n</blockquote>\n<p><strong>方案二：</strong><br>尽管uWSGI的最常见的应用场景是作为web服务器使用，但是uWSGI还有许多强大和复杂的功能等待我们发现。<br>其中一个重要的机制就是uWSGI信号框架(负责进程通信和事件管理)<br>通过master进程注册信号或者是定时任务，那么worker可以在信号触发的时候运行对应的处理程序</p>\n<pre><code class=\"python\">import uwsgi\n\ndef hello_timer(num):\n        print &quot;2 seconds elapsed, signal %d raised&quot; % num\n\ndef oneshot_timer(num):\n        print &quot;40 seconds elapsed, signal %d raised. You will never see me again.&quot; % num\n\nuwsgi.register_signal(26, &quot;worker&quot;, hello_timer)\nuwsgi.register_signal(30, &quot;&quot;, oneshot_timer)\n\nuwsgi.add_timer(26, 2) # never-ending timer every 2 seconds\nuwsgi.add_rb_timer(30, 40, 1) # one shot rb timer after 40 seconds\n</code></pre>\n<p>上面是一个简单的官方demo。<br>首先注册了信号26，发送给第一个可用的worker，执行回调函数hello_timer;<br>注册信号30,空字符串代表默认选项（发送给第一个可用worker），执行回调函数oneshot_timer<br>每2秒钟就会引发一次信号26，并且由第一个可用worker处理。40秒过后会引发一次信号30，然后只执行一次。<br>采用这种方式可以完美的解决上面遇到的问题，但是需要大量的改动原有的代码，无奈只能放弃。</p>\n<p><strong>方案三：</strong><br>简单粗暴且高效，直接更换部署方式：采用Nginx+supervisor+gunicorn来部署Flask项目。<br>    gunicorn -w 4 -b 127.0.0.1:5000 application:app</p>\n<p><strong>总结：</strong><br>到这,只有第一种方案是在解决uWSGI和apscheduler的冲突问题，至于后面两种方案只是去避开这个问题。另外关于uWSGI和gunicorn的区别与比较，在后面会进行分析了解。</p>\n","categories":["Linux"],"tags":["Linux","Python"]},{"title":"Python升级路线和技能点","url":"http://shawnz.me/posts/d356139b/","content":"<p>从毕业到现在工作将近2个月，经历一个项目的洗礼后，接触到了不少新的技术,，从Flask到Django再到Tornado,从关系数据库Mysql、Postgres到非关系数据库Redis、MongoDB，从Memcached缓存到消息队列RabbitMQ。<br>然而对许多技术的认知阶段，大多停留在怎么使用这一层面，对于底层的实现机制或者是一些高级用法是没有深入研究和学习的。<br>现在回过头来，整理了一下Python开发的技能体系，在之后一段时间里慢慢get这些技能点。</p>\n<blockquote>\n<p>分享两个相关链接</p>\n<ul>\n<li><a href=\"https://github.com/taizilongxu/interview_python\" target=\"_blank\" rel=\"noopener\">关于Python面试题</a></li>\n<li><a href=\"https://segmentfault.com/a/1190000008758381\" target=\"_blank\" rel=\"noopener\">2017后端面试经历分享</a></li>\n</ul>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"第一部分：Python\"><a href=\"#第一部分：Python\" class=\"headerlink\" title=\"第一部分：Python\"></a>第一部分：Python</h2><blockquote>\n<ul>\n<li>基础语法与标准库</li>\n<li>网络编程、并发编程、IO、函数式编程</li>\n<li>装饰器、推导式、lambda、位置参数与关键词参数、鸭子类型、魔法方法等语言特性</li>\n<li>性能优化、垃圾回收、解释器</li>\n<li>Web开发:<ul>\n<li>socket网络编程(select/poll/epoll)以及Twisted、 gevent库</li>\n<li>Flask、Django、Tornado三个主流Web开发框架</li>\n<li>SQLAlchemy、Django ORM</li>\n<li>路由、表单、模板</li>\n</ul>\n</li>\n<li>调度机制和定时任务<ul>\n<li>Celery</li>\n<li>Apscheduler</li>\n</ul>\n</li>\n<li>爬虫框架<ul>\n<li>requests、urllib</li>\n<li>Scrapy</li>\n<li>beautifulsoup、xpath</li>\n</ul>\n</li>\n<li>科学计算库<ul>\n<li>Numpy</li>\n<li>Pandas</li>\n<li>Matplotlib</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<h2 id=\"第二部分：项目部署\"><a href=\"#第二部分：项目部署\" class=\"headerlink\" title=\"第二部分：项目部署\"></a>第二部分：项目部署</h2><blockquote>\n<ul>\n<li>Linux操作命令、Shell</li>\n<li>Git</li>\n<li>虚拟环境：pyenv、virtualenv</li>\n<li>WSGI服务器：gunicorn、uwsgi</li>\n<li>HTTP服务器：Nginx、Apach</li>\n<li>自动化部署：Fabric、Ansible</li>\n</ul>\n</blockquote>\n<h2 id=\"第三部分：数据库\"><a href=\"#第三部分：数据库\" class=\"headerlink\" title=\"第三部分：数据库\"></a>第三部分：数据库</h2><blockquote>\n<ul>\n<li>SQL语句</li>\n<li>关系数据库的设计和调优</li>\n<li>非关系数据库Redis/MongoDB应用</li>\n</ul>\n</blockquote>\n<h2 id=\"第四部分：其他\"><a href=\"#第四部分：其他\" class=\"headerlink\" title=\"第四部分：其他\"></a>第四部分：其他</h2><blockquote>\n<ul>\n<li>Redis</li>\n<li>Memcached</li>\n<li>消息队列RabbitMQ</li>\n<li>高可用、大并发、大数据</li>\n</ul>\n</blockquote>\n","categories":["Python"],"tags":["Python","总结"]},{"title":"进程管理工具Supervisor","url":"http://shawnz.me/posts/779b7ee0/","content":"<h1 id=\"Supervisor简介\"><a href=\"#Supervisor简介\" class=\"headerlink\" title=\"Supervisor简介\"></a>Supervisor简介</h1><blockquote>\n<p>  <a href=\"&#39;http://supervisord.org/installing.html#installing-a-distribution-package&#39;\">官方文档</a></p>\n</blockquote>\n<p>Supervisor是一个用 Python 写的进程管理工具，可以很方便的用来启动、重启、关闭进程。能够将命令行进程变为后台守护进程，并监控进程状态，在意外崩溃时重启进程。Supervisor采用 C/S 架构，有几个部分组成:</p>\n<ul>\n<li>supervisord: 服务守护进程</li>\n<li>supervisorctl: 命令行客户端</li>\n<li>Web Server: 提供相当于supervisorctl功能的WEB操作界面</li>\n<li>XML-RPC Interface: XML-RPC接口</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><p>Debian/Ubuntu 通过apt安装:</p>\n<pre><code># apt-get install supervisor\n</code></pre><p>Pyhon 2　通过pip 安装</p>\n<pre><code># pip install supervisor\n</code></pre><h1 id=\"配置\"><a href=\"#配置\" class=\"headerlink\" title=\"配置\"></a>配置</h1><p>Supervisor配置分为两个部分:supervisord(服务端，对应客户端supervisorctl)和应用程序配置。<br>安装完supervisor后，运行echo_supervisord_conf命令生成默认的配置文件，也可以重定向到一个指定文件:</p>\n<pre><code>echo_supervisord_conf &gt; /etc/supervisord.conf\n</code></pre><h2 id=\"supervisord配置\"><a href=\"#supervisord配置\" class=\"headerlink\" title=\"supervisord配置:\"></a>supervisord配置:</h2><pre><code class=\"ini\">[unix_http_server]\nfile=/tmp/supervisor.sock   ; UNIX socket 文件，supervisorctl 会使用\n;chmod=0700                 ; socket 文件的 mode，默认是 0700\n;chown=nobody:nogroup       ; socket 文件的 owner，格式： uid:gid\n\n;[inet_http_server]         ; HTTP 服务器，提供 web 管理界面\n;port=127.0.0.1:9001        ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性\n;username=user              ; 登录管理后台的用户名\n;password=123               ; 登录管理后台的密码\n\n[supervisord]\nlogfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.log\nlogfile_maxbytes=50MB        ; 日志文件大小，超出会 rotate，默认 50MB\nlogfile_backups=10           ; 日志文件保留备份数量默认 10\nloglevel=info                ; 日志级别，默认 info，其它: debug,warn,trace\npidfile=/tmp/supervisord.pid ; pid 文件\nnodaemon=false               ; 是否在前台启动，默认是 false，即以 daemon 的方式启动\nminfds=1024                  ; 可以打开的文件描述符的最小值，默认 1024\nminprocs=200                 ; 可以打开的进程数的最小值，默认 200\n\n; the below section must remain in the config file for RPC\n; (supervisorctl/web interface) to work, additional interfaces may be\n; added by defining them in separate rpcinterface: sections\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致\n;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord\n\n; 包含其他的配置文件\n[include]\nfiles = relative/directory/*.ini    ; 可以是 *.conf 或 *.ini\n</code></pre>\n<h2 id=\"program配置\"><a href=\"#program配置\" class=\"headerlink\" title=\"program配置\"></a>program配置</h2><p>这部分是supervisord要管理的进程的配置文件。这里有两种方式:</p>\n<ol>\n<li>把所有配置文件都放在supervisord.conf配置文件里面</li>\n<li>通过include的方式把不同程序写到不同的配置文件里</li>\n</ol>\n<p><strong>示例</strong>:<br>新建目录/etc/supervisor/存放不同程序的配置文件，修改/etc/supervisord.conf:</p>\n<pre><code>[include]\nfiles = /etc/supervisor/*.conf\n</code></pre><p>以uwsgi的方式部署FLASK应用:</p>\n<pre><code>[program:your appname]\ncommand=/path/to/virtual/env/bin/uwsgi -s /tmp/uwsgi.sock -w flask_file_name:app -H /path/to/virtual/env --chmod-socket 666\ndirectory=/path/to/app\nautostart=true\nautorestart=true\nstdout_logfile=/path/to/app/logs/uwsgi.log\nredirect_stderr=true\nstopsignal=QUIT\n</code></pre><p>一份supervisord配置文件至少需要一个[program:x]部分的部署，x表示program name，会在supervisorctl或Web管理界面显示，在supervisorctl中通过这个值对程序进行start、stop、restart等操作</p>\n<h1 id=\"启动\"><a href=\"#启动\" class=\"headerlink\" title=\"启动\"></a>启动</h1><p>supervisord启动配置文件的默认查找顺序为:$CWD/supervisord.conf, $CWD/etc/supervisord.conf, /etc/supervisord.conf。也可以通过 -c 选项指定配置文件路径:<br>    supervisord -c /etc/supervisord.conf</p>\n<h1 id=\"使用supervisorctl\"><a href=\"#使用supervisorctl\" class=\"headerlink\" title=\"使用supervisorctl\"></a>使用supervisorctl</h1><p>supervisorctl是supervisord的一个命令行管理客户端工具、启动是需要和supervisord一样指定配置文件、否则按照与supervisord一样的顺序查找配置文件。<br>    supervisorctl -c /etc/supervisord.conf<br>supervisorctl命令会启动Shell界面，然后可以执行各种命令:<br>    &gt; status    # 查看程序状态<br>    &gt; stop usercenter   # 关闭 usercenter 程序<br>    &gt; start usercenter  # 启动 usercenter 程序<br>    &gt; restart usercenter    # 重启 usercenter 程序<br>    &gt; reread    ＃ 读取有更新（增加）的配置文件，不会启动新添加的程序<br>    &gt; update    ＃ 重启配置文件修改过的程序<br>除了进入Shell界面，也可以直接在Bash终端运行:<br>    $ supervisorctl status<br>    $ supervisorctl stop usercenter<br>    $ supervisorctl start usercenter<br>    $ supervisorctl restart usercenter<br>    $ supervisorctl reread<br>    $ supervisorctl update<br>另外也可以登入WEB管理界面进行操作，除了单进程管理，supervisor还具备配置group，进行分组管理等功能</p>\n","categories":["Linux"],"tags":["Linux"]},{"title":"Redis学习笔记","url":"http://shawnz.me/posts/8eda3648/","content":"<h1 id=\"Redis简介\"><a href=\"#Redis简介\" class=\"headerlink\" title=\"Redis简介\"></a>Redis简介</h1><blockquote>\n<p>  <a href=\"&#39;http://www.redis.io/&#39;\">官方网站</a><br>  <a href=\"&#39;&#39;\">操作命令</a></p>\n</blockquote>\n<p>Redis 是一个开源，高级的键值存储和一个适用的解决方案，用于构建高性能，可扩展的Web应用程序。</p>\n<h2 id=\"非关系数据库相比关系数据库的优势：\"><a href=\"#非关系数据库相比关系数据库的优势：\" class=\"headerlink\" title=\"非关系数据库相比关系数据库的优势：\"></a>非关系数据库相比关系数据库的优势：</h2><ol>\n<li>费用：相对传统的关系数据库昂贵的费用，非关系数据库大多是免费的；</li>\n<li>功能：NoSQL数据库阉割到了许多关系数据库所具备的功能，更简洁，不具备事务支持；</li>\n<li>性能：由于NoSQL基于键值对的，不需要经过SQL层解析,另外由于牺牲掉了一些特性，速度更快</li>\n</ol>\n<blockquote>\n<p>在不同的应用场景，为达到不同的使用效果，需要根据实际需求采取不同的策略。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"Redis优势\"><a href=\"#Redis优势\" class=\"headerlink\" title=\"Redis优势:\"></a>Redis优势:</h2><ul>\n<li>速度快：基于内存、舍去ACID等特性。每秒可执行大约110000次的设置<strong>(SET)</strong>操作，每秒大约可执行81000次的读取/获取<strong>(GET)</strong>操作。</li>\n<li>丰富的数据类型：支持大多常用数据类型，例如列表、集合、排列集和散列等。</li>\n<li>原子性操作：更好的应对并发场景</li>\n<li>实用价值高：可用于多种不同的场景，例如：缓存、消息队列(Redis本地支持发布/订阅模式)</li>\n</ul>\n<h1 id=\"Redis数据类型\"><a href=\"#Redis数据类型\" class=\"headerlink\" title=\"Redis数据类型\"></a>Redis数据类型</h1><p>Redis一共支持五种数据类型。</p>\n<h2 id=\"字符串\"><a href=\"#字符串\" class=\"headerlink\" title=\"字符串\"></a>字符串</h2><p>Redis中存储的字符串是一个字节序列。Redis中的字符串是二进制安全的。一个字符串可以存储512兆字节的内容。</p>\n<p><strong> 示例 </strong></p>\n<blockquote>\n<p>redis 127.0.0.1:6379&gt; set name ‘value’<br>OK<br>redis 127.0.0.1:6379&gt; get name<br>‘value’</p>\n</blockquote>\n<h2 id=\"散列-哈希\"><a href=\"#散列-哈希\" class=\"headerlink\" title=\"散列/哈希\"></a>散列/哈希</h2><p>Redis散列/哈希是字符串字段和字符串值之间的映射。因此，它们用于表示对象。</p>\n<p><strong> 示例 </strong></p>\n<blockquote>\n<p>redis 127.0.0.1:6379&gt; HMSET ukey username “yiibai” password “passswd123” points 200</p>\n</blockquote>\n<h2 id=\"列表\"><a href=\"#列表\" class=\"headerlink\" title=\"列表\"></a>列表</h2><p>Redis列表只是字符串列表，按插入顺序排序。您可以向Redis列表的头部或尾部添加元素。</p>\n<p><strong> 示例 </strong></p>\n<blockquote>\n<p>redis 127.0.0.1:6379&gt; lpush alist redis<br>(integer) 1<br>redis 127.0.0.1:6379&gt; lpush alist mongodb<br>(integer) 2<br>redis 127.0.0.1:6379&gt; lpush alist sqlite<br>(integer) 3<br>redis 127.0.0.1:6379&gt; lrange alist 0 10  </p>\n</blockquote>\n<blockquote>\n<p>1) “sqlite”<br>2) “mongodb”<br>3) “redis”</p>\n</blockquote>\n<h2 id=\"集合\"><a href=\"#集合\" class=\"headerlink\" title=\"集合\"></a>集合</h2><p>Redis集合是字符串的无序集合。在Redis中，您可以添加，删除和测试成员存在的时间O(1)复杂性</p>\n<p><strong> 示例 </strong></p>\n<blockquote>\n<p>redis 127.0.0.1:6379&gt; sadd yiibailist redis<br>(integer) 1<br>redis 127.0.0.1:6379&gt; sadd yiibailist mongodb<br>(integer) 1<br>redis 127.0.0.1:6379&gt; sadd yiibailist sqlite<br>(integer) 1<br>redis 127.0.0.1:6379&gt; sadd yiibailist sqlite<br>(integer) 0<br>redis 127.0.0.1:6379&gt; smembers yiibailist  </p>\n</blockquote>\n<blockquote>\n<p>1) “sqlite”<br>2) “mongodb”<br>3) “redis”</p>\n</blockquote>\n<h2 id=\"可排序集合\"><a href=\"#可排序集合\" class=\"headerlink\" title=\"可排序集合\"></a>可排序集合</h2><p>Redis可排序集合类似于Redis集合，是不重复的字符集合。 不同之处在于，排序集合的每个成员都与分数相关联，这个分数用于按最小分数到最大分数来排序的排序集合。虽然成员是唯一的，但分数值可以重复。</p>\n<p><strong> 示例 </strong><br>    &gt; redis 127.0.0.1:6379&gt; zadd yiibaiset 0 redis<br>    &gt; (integer) 1<br>    &gt; redis 127.0.0.1:6379&gt; zadd yiibaiset 0 mongodb<br>    &gt; (integer) 1<br>    &gt; redis 127.0.0.1:6379&gt; zadd yiibaiset 1 sqlite<br>    &gt; (integer) 1<br>    &gt; redis 127.0.0.1:6379&gt; zadd yiibaiset 1 sqlite<br>    &gt; (integer) 0<br>    &gt; redis 127.0.0.1:6379&gt; ZRANGEBYSCORE yiibaiset 0 1000  </p>\n<pre><code>&gt; 1) &quot;mongodb&quot;\n&gt; 2) &quot;redis&quot;\n&gt; 3) &quot;sqlite&quot;\n</code></pre>","categories":["数据库"],"tags":["数据库","Redis"]},{"title":"数据库事务与隔离级别","url":"http://shawnz.me/posts/1acbf803/","content":"<h1 id=\"什么是事务？\"><a href=\"#什么是事务？\" class=\"headerlink\" title=\"什么是事务？\"></a>什么是事务？</h1><blockquote>\n<p>  访问并可能更新数据库中各种数据项的一个程序执行单元(unit)。</p>\n</blockquote>\n<h1 id=\"使用事务的目的\"><a href=\"#使用事务的目的\" class=\"headerlink\" title=\"使用事务的目的\"></a>使用事务的目的</h1><p>一个数据库事务通常包含对数据库进行读或者写的一个操作序列。通过事务我们可以达到两个目的：</p>\n<blockquote>\n<ul>\n<li>在失败的时候提供一个回到正常状态的方法，是数据库在异常状态保持一致性</li>\n<li>在并发访问的时候，为应用程序提供一个隔离方法，控制相互之间的干扰程度</li>\n</ul>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"事务特性\"><a href=\"#事务特性\" class=\"headerlink\" title=\"事务特性\"></a>事务特性</h1><p>事务应该具有4个属性：原子性、一致性、隔离性和一致性，又称ACID特性。</p>\n<blockquote>\n<p>  <strong> 原子性(Atomicity) </strong>:在事务内的所有操作要么完全执行要么一起撤销，在任何操作出现错误的情况下，该事务应该回滚到正常状态。<br>  <strong> 一致性(Consistency) </strong>:事务应该保护定义在数据上的所有完整性约束，将系统从一个一致状态转化成另一个一致状态。<br>  <strong> 隔离性(Isolation) </strong>:<br>  <strong> 持久性(Durability) </strong>:</p>\n</blockquote>\n","categories":["数据库"],"tags":["数据库"]},{"title":"HTTP那些事儿","url":"http://shawnz.me/posts/b10175ff/","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><blockquote>\n<p>  主题：《HTTP的那些事儿》</p>\n</blockquote>\n<blockquote>\n<p>  分享的过程，也是自己的一个学习过程。<br>  推荐两个学习资源：</p>\n<ul>\n<li>《HTTP权威指南》</li>\n<li><a href=\"&#39;https://developer.mozilla.org/zh-CN/docs/Web/HTTP&#39;\">Mozilla 开发者网络 (MDN)-HHTP 文档</a></li>\n</ul>\n</blockquote>\n<a id=\"more\"></a>\n<h1 id=\"概述\"><a href=\"#概述\" class=\"headerlink\" title=\"概述\"></a>概述</h1><p>超文本传输​​协议（HTTP，HyperText Transfer Protocol）是用于传输诸如HTML的超媒体文档的应用层协议。<br>HHTP协议的主要特点可以概括为以下几点:</p>\n<ol>\n<li>支持客户端/服务器模式</li>\n<li>简单、快速</li>\n<li>无状态，有会话</li>\n<li>灵活、可扩展</li>\n</ol>\n<h1 id=\"HTTP工作流程\"><a href=\"#HTTP工作流程\" class=\"headerlink\" title=\"HTTP工作流程\"></a>HTTP工作流程</h1><p>在了解HTTP之前，我们先梳理一下，浏览器与服务器的通信过程:<br>从我们在浏览器地址栏输入要访问的网站URL(代表资源的位置)，例如<code>http://www.baidu.com</code>，首先需要通过DNS域名解析服务，将域名映射到对应的服务器IP上，例如ip:<code>202.108.22.220</code>。这样就可以建立TCP连接，接下来根据客户端请求生成HTTP请求报文，依靠TCP的传输方式，将报文可靠的传输到服务器端，到达服务器后，经过一定的处理，生成HTTP响应，传送给客户端，最后断开TCP连接。<br><img src=\"http://oufa7cuo5.bkt.clouddn.com/17-8-9/62131177.jpg\" alt=\"一次简单的请求响应过程\"></p>\n<h1 id=\"TCP连接\"><a href=\"#TCP连接\" class=\"headerlink\" title=\"TCP连接\"></a>TCP连接</h1><p>TCP是一种面向连接的、可靠的、基于字节流的传输层通信协议。而HTTP是应用层协议，所有的传输工作都是通过TCP/IP进行的。HTTP的三次握手，也就是三次TCP握手确认建立一个HTTP连接。如下图所示，TCP建立连接和断开连接会经历三次握手和四次分手的过程。其中:</p>\n<ul>\n<li><code>SYN</code>:表示同步序号，用来建立连接。SYN和ACK标志位搭配使用，当请求连接的时候，SYN=1,ACK=0;当响应连接的时候，SYN=1,ACK=1;</li>\n<li><code>ACK</code>:表示应答域有效，有两个取值：0和１，为1的时候表示应答域有效，反之为0;</li>\n<li><code>FIN</code>:表示发送端已经到达数据末尾，发送FIN标志位的数据包后，连接将被断开;</li>\n<li><code>Sequence number</code>:序列号</li>\n<li><code>Ackonwleage number</code>:确认号</li>\n</ul>\n<p><img src=\"http://oufa7cuo5.bkt.clouddn.com/17-8-9/22804988.jpg\" alt=\"TCP三次握手四次分手\"></p>\n<h3 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h3><ol>\n<li>第一次握手：建立连接。客户端发送连接请求报文段，将SYN置为1,Sequence number为x;然后客户端进入SYN_SEND状态，等待服务器的确认；</li>\n<li>第二次握手：服务器端收到SYN报文段。对报文段进行确认，设置Ackonwleage number为x + 1(Sequence number + 1);同时服务器将的SYN位置为１，Sequence number为y，发送给客户端，此时服务器进入SYN_RECV状态；</li>\n<li>第三次握手：客户端收到服务器的SYN + ACK报文段，将Ackonwleage number设置为y + 1,向服务器发送ACK报文段,发送完毕后，客户端和服务端都进入ESTABLISHED状态，完成TCP三次握手。</li>\n</ol>\n<h3 id=\"四次挥手\"><a href=\"#四次挥手\" class=\"headerlink\" title=\"四次挥手\"></a>四次挥手</h3><ol>\n<li>第一次分手：主机１，设置Sequence number和Ackonwleage number，向主机２发送一个FIN报文段，此时主机１，进入FIN_WAIT_1状态：表示主机１没有数据发送给主机2了;</li>\n<li>第二次分手：主机2收到主机1发送的FIN报文段，向主机1回送一个ACK报文段，置Ackonwleage number为Sequence number + 1;主机1进入FIN_WAIT_2状态：主机2告诉主机1：我同意了你的关闭请求；</li>\n<li>第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态；</li>\n<li>第四次分手：主机1接收到主机2的FIN报文段，向主机2发送ACK报文段，主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接，此时主机1等待２MSL依然没有收到回复，则证明Server端正常关闭了，主机1也可以关闭连接了。</li>\n</ol>\n<h3 id=\"为什么需要三次握手？\"><a href=\"#为什么需要三次握手？\" class=\"headerlink\" title=\"为什么需要三次握手？\"></a>为什么需要三次握手？</h3><p>现在三次握手的过程已经十分清晰明了：A(建立连接发起方)向B(连接建立接受方)发送一个Sync，B向A回送Ack+Sync，A再向B发送Ack这样的一个过程。然而TCP建立连接为什么使用的是三次握手协议，而不是两次或者四次呢？这是通信当中的一个基本问题，可以参考著名的“Two Generals’ Problem”，这个问题的本质是<strong>信道传输是不可靠的，但是通讯双方需要就某个问题达成一致。在这里“一致”暗含着TCP的全双工通信可靠性的需求。</strong>而要解决这个问题，三次通信是理论上的最小值。<br>关于第三次握手的必要性，在谢希仁的《计算机网络》中是这样描述的：</p>\n<blockquote>\n<p>  为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。</p>\n</blockquote>\n<p>在Andrew S.Tanenbaum的《计算机网络》中的讲三次握手的目的是：</p>\n<blockquote>\n<p>  为了“解决网络中存在延迟的重复分组”问题</p>\n</blockquote>\n<p>从以上两种不同的描述，我们可以知道第三次握手主要解决的是这样一种情况：</p>\n<blockquote>\n<p>  假设Client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是Client再次发出的一个新的连接请求。于是就向Client发出确认报文段，同意建立连接。如果没有“第三次握手”，那么只要Server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬Server的确认，也不会向Server发送数据。但Server却以为新的运输连接已经建立，并一直等待Client发来数据。这样，Server的很多资源就白白浪费掉了。</p>\n</blockquote>\n<p>在仔细研究三次握手的过程，可以发现其实客户端和服务器各自发起了一次请求和一次确认，所以一共是“四次”，不过在第二次握手时，服务器将确认和请求合并成一次。也就可以理解Google网上论坛这样得<a href=\"https://groups.google.com/forum/#!msg/pongba/kF6O7-MFxM0/5S7zIJ4yqKUJ\" target=\"_blank\" rel=\"noopener\">一条回复</a>“这个问题的本质是, 信道不可靠, 但是通信双发需要就某个问题达成一致. 而要解决这个问题,  无论你在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足”在不可靠信道上可靠地传输信息”这一需求所导致的. 请注意这里的本质需求,信道不可靠, 数据传输要可靠. 三次达到了, 那后面你想接着握手也好, 发数据也好, 跟进行可靠信息传输的需求就没关系了. 因此,如果信道是可靠的, 即无论什么时候发出消息, 对方一定能收到, 或者你不关心是否要保证对方收到你的消息, 那就能像UDP那样直接发送消息就可以了.”</p>\n<h1 id=\"HTTP连接\"><a href=\"#HTTP连接\" class=\"headerlink\" title=\"HTTP连接\"></a>HTTP连接</h1><p>了解了TCP连接，也就对应该如何管理HTTP连接有了初步的认识。下面列出了部分会对HTTP性能产生影响的、常见的TCP相关时延，其中有：</p>\n<ul>\n<li>TCP连接建立的握手协议</li>\n<li>TCP慢启动拥塞控制</li>\n<li>数据聚焦的Nagle算法</li>\n<li>用于携带确认的TCP延迟确认算法</li>\n<li>TIME_WAIT时延和端口耗尽</li>\n</ul>\n<h3 id=\"TCP连接的握手时延\"><a href=\"#TCP连接的握手时延\" class=\"headerlink\" title=\"TCP连接的握手时延\"></a>TCP连接的握手时延</h3><p>在建立一条新的TCP连接，甚至在发送任意数据前，TCP协议要求交换一系列的IP分组（“三次握手”），在现代的TCP栈都允许客户端在第二个确认中发送数据</p>\n<h3 id=\"延迟确认\"><a href=\"#延迟确认\" class=\"headerlink\" title=\"延迟确认\"></a>延迟确认</h3><p>由于因特网无法确保可靠的分组传输，TCP实现了自己的确认机制来保证数据传输的可靠。<br>每个TCP段都有一个序列号和数据完整性校验和。当接收方收到完好的段时，会向发送方回送一个小的确认分组。如果发送方在指定时间内没有收到确认信息，那么发送端就认为分组已经被破坏，并重发数据。<br>由于确认报文很小，所以TCP允许在发往相同方向的输出数据分组中对其进行“捎带”，将确认信息和输出数据结合在一起，更有效的利用网络。为了增加确认报文找到相同方向的输出数据分组的可能性，TCP栈有一种“延迟确认”算法：在一个特定的窗口时间内将确认存放在缓冲区，以寻找能够捎带他的输出数据，若在指定时间内没有输出，就单独发送确认信息。<br>然而，TCP具有双峰特征的请求-应答行为降低了捎带信息的可能。通常，延迟确认会引入相当大的时延，根据操作系统，可以调整或禁止延迟去确认算法。</p>\n<h3 id=\"TCP慢启动和拥塞控制\"><a href=\"#TCP慢启动和拥塞控制\" class=\"headerlink\" title=\"TCP慢启动和拥塞控制\"></a>TCP慢启动和拥塞控制</h3><p>TCP连接会随着时间进行“自我协调”，起初限制连接的最大速度，如果数据传输成功，会随着时间推移，提高传输速度</p>\n<h1 id=\"RESTful\"><a href=\"#RESTful\" class=\"headerlink\" title=\"RESTful\"></a>RESTful</h1><h1 id=\"HTTP认证\"><a href=\"#HTTP认证\" class=\"headerlink\" title=\"HTTP认证\"></a>HTTP认证</h1><h1 id=\"HTTP代理\"><a href=\"#HTTP代理\" class=\"headerlink\" title=\"HTTP代理\"></a>HTTP代理</h1><h1 id=\"HTTP缓存\"><a href=\"#HTTP缓存\" class=\"headerlink\" title=\"HTTP缓存\"></a>HTTP缓存</h1><h1 id=\"HTTP安全\"><a href=\"#HTTP安全\" class=\"headerlink\" title=\"HTTP安全\"></a>HTTP安全</h1>","categories":["网络"],"tags":["HTTP","网络"]},{"title":"","url":"http://shawnz.me/baidu_verify_bEj466Tiad.html","content":"bEj466Tiad","categories":[],"tags":[]},{"title":"about","url":"http://shawnz.me/about/index.html","content":"","categories":[],"tags":[]},{"title":"category","url":"http://shawnz.me/category/index.html","content":"","categories":[],"tags":[]},{"title":"","url":"http://shawnz.me/css/custom.css","content":"/*@font-face {*/\n  /*font-family: \"Chancery\";*/\n  /*src: url(\"/fonts/Chancery.TTF\");*/\n  /* IE9 */\n  /*src: url(\"/fonts/Chancery.TTF?#iefix\") format(\"embedded-opentype\"), /* IE6-IE8 */*/\n   /*url(\"/fonts/Meiryo.woff\") format(\"woff\"), /* chrome, firefox */\n  /* url(\"/fonts/Meiryo.ttf\") format(\"truetype\"), /* chrome, firefox, opera, Safari, Android, iOS 4.2+ */\n  /*url(\"/fonts/Meiryo.svg#Meiryo\") format(\"svg\");*/\n  /* iOS 4.1- */\n  /*font-style: normal;\n  font-weight: normal;\n}*/\nhtml.page-home {\n  position: absolute;\n  top: 0;\n  left: 0;\n  right: 0;\n  bottom: 0;\n  /*background-image: url('/images/home-background.jpg');*/\n  background-color: transparent;\n  background-size: cover;\n  background-position: center center;\n  background-repeat: no-repeat;\n\n  /*background: linear-gradient( #1abc9c, transparent), linear-gradient( 90deg, skyblue, transparent), linear-gradient( -90deg, coral, transparent);*/\n  /*background-blend-mode: screen;*/\n\n  /*background: linear-gradient(to left, #5f2c82, #49a09d);*/\n}\n\n/*.toc-article/* {*/\n  /*position: fixed;*/\n  /*top: 20px;*/\n/*}*/","categories":[],"tags":[]},{"title":"link","url":"http://shawnz.me/link/index.html","content":"","categories":[],"tags":[]},{"title":"search","url":"http://shawnz.me/search/index.html","content":"","categories":[],"tags":[]},{"title":"tag","url":"http://shawnz.me/tag/index.html","content":"","categories":[],"tags":[]},{"title":"学习计划","url":"http://shawnz.me/study/index.html","content":"<h2 id=\"MOTIVATION\"><a href=\"#MOTIVATION\" class=\"headerlink\" title=\"MOTIVATION\"></a>MOTIVATION</h2><iframe width=\"760\" height=\"428\" src=\"https://www.youtube.com/embed/g-jwWYX7Jlo\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n\n\n<h2 id=\"时间安排模板\"><a href=\"#时间安排模板\" class=\"headerlink\" title=\"时间安排模板\"></a>时间安排模板</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">第N周</th>\n<th style=\"text-align:center\">周一</th>\n<th style=\"text-align:center\">周二</th>\n<th style=\"text-align:center\">周三</th>\n<th style=\"text-align:center\">周四</th>\n<th style=\"text-align:center\">周五</th>\n<th style=\"text-align:center\">周六</th>\n<th style=\"text-align:center\">周日</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">06:30~07:00</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n<td style=\"text-align:center\">洗漱</td>\n</tr>\n<tr>\n<td style=\"text-align:center\">07:00~09:00</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">10:00~12:00</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">13:30~19:30</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\">工作</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">21:00~:24:00</td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n<td style=\"text-align:center\"><code>学习</code></td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><p><strong>2018-03-10总结与反思: </strong></p>\n<ul>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 已完成的任务</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 还没有完成的任务</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"任务概览\"><a href=\"#任务概览\" class=\"headerlink\" title=\"任务概览\"></a>任务概览</h2><ol>\n<li>英语</li>\n<li>Python开发</li>\n<li>程序员基本修养: 网络/数据库/算法/操作系统…</li>\n<li>系统设计/软件工程</li>\n<li>其他语言: Java/前端/Go</li>\n<li>机器学习/大数据处理</li>\n<li>开源项目</li>\n<li>业余爱好: 看书/健身</li>\n</ol>\n<h2 id=\"第二周\"><a href=\"#第二周\" class=\"headerlink\" title=\"第二周\"></a>第二周</h2><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">第2周</th>\n<th>周一</th>\n<th>周二</th>\n<th>周三</th>\n<th>周四</th>\n<th>周五</th>\n<th>周六</th>\n<th>周日</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\">06:30~07:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">07:00~09:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">10:00~12:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">13:30~19:30</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td style=\"text-align:center\">21:00~:24:00</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n","categories":[],"tags":[]}]